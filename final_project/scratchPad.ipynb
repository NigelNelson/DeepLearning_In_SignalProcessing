{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4d733d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 17:22:36.483301: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "#@title Imports \n",
    "import os\n",
    "import mne \n",
    "import pickle\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Inner_Speech_Dataset.Python_Processing.Data_extractions import  Extract_data_from_subject, Extract_subject_from_BDF, load_events\n",
    "from Inner_Speech_Dataset.Python_Processing.Data_processing import  Select_time_window, Transform_for_classificator, Split_trial_in_time,  Filter_by_condition\n",
    "\n",
    "\n",
    "mne.set_log_level(verbose='warning') #to avoid info at terminal\n",
    "warnings.filterwarnings(action = \"ignore\", category = DeprecationWarning ) \n",
    "warnings.filterwarnings(action = \"ignore\", category = FutureWarning )\n",
    "\n",
    "from EEGNet import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import utils as np_utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import KFold\n",
    "from pyriemann.utils.viz import plot_confusion_matrix\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96055289",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyperparameters\n",
    "\n",
    "# The root dir have to point to the folder that cointains the database\n",
    "root_dir = \"/data/datasets/inner_speech/ds003626/\"\n",
    "\n",
    "# Data Type\n",
    "datatype = \"EEG\"\n",
    "\n",
    "# Sampling rate\n",
    "fs = 256\n",
    "\n",
    "# Select the useful par of each trial. Time in seconds\n",
    "t_start = 1.5\n",
    "t_end = 3.5\n",
    "\n",
    "# Subject number\n",
    "N_S = 1   #[1 to 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e468df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Data extraction and processing\n",
    "\n",
    "# Load all trials for a sigle subject\n",
    "X, Y = Extract_data_from_subject(root_dir, N_S, datatype)\n",
    "X1, Y1 = Extract_subject_from_BDF(root_dir, N_S, 1)\n",
    "\n",
    "#events = load_events(root_dir, N_S, 1)\n",
    "\n",
    "# Cut usefull time. i.e action interval\n",
    "X = Select_time_window(X = X, t_start = t_start, t_end = t_end, fs = fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fa66f3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "As = [0, 1, 3, 4, 7, 8, 9, 14, 18, 19, 21, 22, 23]\n",
    "Cs = [18, 20, 27, 31, 32]\n",
    "Ds = [5, 6, 10, 15, 19, 21, 26, 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3bd9a8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 14,\n",
       " 18,\n",
       " 19,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 81,\n",
       " 83,\n",
       " 90,\n",
       " 94,\n",
       " 95,\n",
       " 100,\n",
       " 101,\n",
       " 105,\n",
       " 110,\n",
       " 114,\n",
       " 116,\n",
       " 121,\n",
       " 125]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs = list(map(lambda x: x+63, Cs))\n",
    "ds = list(map(lambda x: x+95, Ds))\n",
    "As + cs + ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "087d3f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X1.to_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c04d256f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time\n",
      "A1\n",
      "A2\n",
      "A3\n",
      "A4\n",
      "A5\n",
      "A6\n",
      "A7\n",
      "A8\n",
      "A9\n",
      "A10\n",
      "A11\n",
      "A12\n",
      "A13\n",
      "A14\n",
      "A15\n",
      "A16\n",
      "A17\n",
      "A18\n",
      "A19\n",
      "A20\n",
      "A21\n",
      "A22\n",
      "A23\n",
      "A24\n",
      "A25\n",
      "A26\n",
      "A27\n",
      "A28\n",
      "A29\n",
      "A30\n",
      "A31\n",
      "A32\n",
      "B1\n",
      "B2\n",
      "B3\n",
      "B4\n",
      "B5\n",
      "B6\n",
      "B7\n",
      "B8\n",
      "B9\n",
      "B10\n",
      "B11\n",
      "B12\n",
      "B13\n",
      "B14\n",
      "B15\n",
      "B16\n",
      "B17\n",
      "B18\n",
      "B19\n",
      "B20\n",
      "B21\n",
      "B22\n",
      "B23\n",
      "B24\n",
      "B25\n",
      "B26\n",
      "B27\n",
      "B28\n",
      "B29\n",
      "B30\n",
      "B31\n",
      "B32\n",
      "C1\n",
      "C2\n",
      "C3\n",
      "C4\n",
      "C5\n",
      "C6\n",
      "C7\n",
      "C8\n",
      "C9\n",
      "C10\n",
      "C11\n",
      "C12\n",
      "C13\n",
      "C14\n",
      "C15\n",
      "C16\n",
      "C17\n",
      "C18\n",
      "C19\n",
      "C20\n",
      "C21\n",
      "C22\n",
      "C23\n",
      "C24\n",
      "C25\n",
      "C26\n",
      "C27\n",
      "C28\n",
      "C29\n",
      "C30\n",
      "C31\n",
      "C32\n",
      "D1\n",
      "D2\n",
      "D3\n",
      "D4\n",
      "D5\n",
      "D6\n",
      "D7\n",
      "D8\n",
      "D9\n",
      "D10\n",
      "D11\n",
      "D12\n",
      "D13\n",
      "D14\n",
      "D15\n",
      "D16\n",
      "D17\n",
      "D18\n",
      "D19\n",
      "D20\n",
      "D21\n",
      "D22\n",
      "D23\n",
      "D24\n",
      "D25\n",
      "D26\n",
      "D27\n",
      "D28\n",
      "D29\n",
      "D30\n",
      "D31\n",
      "D32\n",
      "EXG1\n",
      "EXG2\n",
      "EXG3\n",
      "EXG4\n",
      "EXG5\n",
      "EXG6\n",
      "EXG7\n",
      "EXG8\n",
      "Status\n"
     ]
    }
   ],
   "source": [
    "for c in x.columns:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eea73d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "30832779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 3, 512)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,[1,2,3],:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "694f17fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min = X.min(axis=(2), keepdims=True)\n",
    "x_max = X.max(axis=(2), keepdims=True)\n",
    "\n",
    "x_min.shape\n",
    "\n",
    "x = (X - x_min)/(x_max-x_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29d6ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = Filter_by_condition(X, Y, \"INNER\")\n",
    "y_labels = Y[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56d464e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: [trials x channels x samples]\n",
      "(200, 128, 512)\n",
      "Labels shape\n",
      "(200, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data shape: [trials x channels x samples]\")\n",
    "print(X.shape) # Trials, channels, samples\n",
    "\n",
    "print(\"Labels shape\")\n",
    "print(Y.shape) # Time stamp, class , condition, session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fdf34bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y_labels, test_size=0.2, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cacdc1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels, chans, samples = 1, X.shape[1], X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f6f3ec49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert labels to one-hot encodings.\n",
    "Y_train      = np_utils.to_categorical(Y_train)\n",
    "Y_test       = np_utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2cc5d11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train      = X_train.reshape(X_train.shape[0], chans, samples, kernels)\n",
    "X_test       = X_test.reshape(X_test.shape[0], chans, samples, kernels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "98fc2205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure the EEGNet-8,2,16 model with kernel length of 32 samples (other \n",
    "# model configurations may do better, but this is a good starting point)\n",
    "model = EEGNet(nb_classes = 4, Chans = chans, Samples = samples) \n",
    "               #dropoutRate = 0.5, kernLength = 106, F1 = 40, D = 10, F2 = 128, \n",
    "               #dropoutType = 'Dropout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3b6ee66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "        tf.keras.optimizers.Adam(\n",
    "            # Specifies the range of values for the tuner to try\n",
    "            learning_rate=0.00011714,\n",
    "            name=\"Adam\"),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6bd35d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of parameters in the model\n",
    "numParams    = model.count_params()    \n",
    "\n",
    "# set a valid path for your system to record model checkpoints\n",
    "checkpointer = ModelCheckpoint(filepath='checkpoint.h5', verbose=1, monitor='val_accuracy',\n",
    "                               save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7b0549eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.4, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dd6fda9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.25000, saving model to checkpoint.h5\n",
      "3/3 - 1s - loss: 1.3893 - accuracy: 0.2604 - val_loss: 1.3863 - val_accuracy: 0.2500 - 705ms/epoch - 235ms/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3860 - accuracy: 0.2917 - val_loss: 1.3863 - val_accuracy: 0.2500 - 125ms/epoch - 42ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3862 - accuracy: 0.2188 - val_loss: 1.3864 - val_accuracy: 0.2500 - 111ms/epoch - 37ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3865 - accuracy: 0.1979 - val_loss: 1.3864 - val_accuracy: 0.2500 - 96ms/epoch - 32ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3856 - accuracy: 0.2917 - val_loss: 1.3864 - val_accuracy: 0.2500 - 89ms/epoch - 30ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3855 - accuracy: 0.2812 - val_loss: 1.3864 - val_accuracy: 0.2500 - 80ms/epoch - 27ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3864 - accuracy: 0.2604 - val_loss: 1.3864 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3848 - accuracy: 0.3333 - val_loss: 1.3864 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3847 - accuracy: 0.3125 - val_loss: 1.3865 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3853 - accuracy: 0.2604 - val_loss: 1.3865 - val_accuracy: 0.2500 - 80ms/epoch - 27ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3847 - accuracy: 0.3542 - val_loss: 1.3865 - val_accuracy: 0.2500 - 81ms/epoch - 27ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3848 - accuracy: 0.3021 - val_loss: 1.3865 - val_accuracy: 0.2500 - 81ms/epoch - 27ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3840 - accuracy: 0.3438 - val_loss: 1.3865 - val_accuracy: 0.2500 - 80ms/epoch - 27ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3856 - accuracy: 0.2812 - val_loss: 1.3865 - val_accuracy: 0.2500 - 78ms/epoch - 26ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3830 - accuracy: 0.3958 - val_loss: 1.3866 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3844 - accuracy: 0.3333 - val_loss: 1.3866 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3833 - accuracy: 0.3229 - val_loss: 1.3866 - val_accuracy: 0.2500 - 83ms/epoch - 28ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3836 - accuracy: 0.3542 - val_loss: 1.3866 - val_accuracy: 0.2500 - 83ms/epoch - 28ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3829 - accuracy: 0.3750 - val_loss: 1.3866 - val_accuracy: 0.2500 - 81ms/epoch - 27ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3836 - accuracy: 0.3229 - val_loss: 1.3866 - val_accuracy: 0.2500 - 77ms/epoch - 26ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3817 - accuracy: 0.3854 - val_loss: 1.3867 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3815 - accuracy: 0.4167 - val_loss: 1.3867 - val_accuracy: 0.2500 - 80ms/epoch - 27ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3817 - accuracy: 0.4062 - val_loss: 1.3867 - val_accuracy: 0.2500 - 82ms/epoch - 27ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3811 - accuracy: 0.3229 - val_loss: 1.3867 - val_accuracy: 0.2500 - 78ms/epoch - 26ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3829 - accuracy: 0.3854 - val_loss: 1.3867 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3819 - accuracy: 0.3958 - val_loss: 1.3868 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3818 - accuracy: 0.3438 - val_loss: 1.3868 - val_accuracy: 0.2500 - 78ms/epoch - 26ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3825 - accuracy: 0.3958 - val_loss: 1.3868 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3799 - accuracy: 0.3438 - val_loss: 1.3868 - val_accuracy: 0.2500 - 80ms/epoch - 27ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3796 - accuracy: 0.4271 - val_loss: 1.3868 - val_accuracy: 0.2500 - 80ms/epoch - 27ms/step\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3805 - accuracy: 0.3542 - val_loss: 1.3868 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3804 - accuracy: 0.4375 - val_loss: 1.3869 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3780 - accuracy: 0.3646 - val_loss: 1.3869 - val_accuracy: 0.2500 - 81ms/epoch - 27ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3804 - accuracy: 0.3646 - val_loss: 1.3869 - val_accuracy: 0.2500 - 78ms/epoch - 26ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3779 - accuracy: 0.3854 - val_loss: 1.3869 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3778 - accuracy: 0.3854 - val_loss: 1.3869 - val_accuracy: 0.2500 - 80ms/epoch - 27ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3757 - accuracy: 0.4062 - val_loss: 1.3870 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3765 - accuracy: 0.4375 - val_loss: 1.3870 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3742 - accuracy: 0.4062 - val_loss: 1.3870 - val_accuracy: 0.2500 - 78ms/epoch - 26ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3761 - accuracy: 0.3750 - val_loss: 1.3870 - val_accuracy: 0.2500 - 80ms/epoch - 27ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3739 - accuracy: 0.4375 - val_loss: 1.3870 - val_accuracy: 0.2500 - 80ms/epoch - 27ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3722 - accuracy: 0.4896 - val_loss: 1.3871 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3724 - accuracy: 0.4062 - val_loss: 1.3871 - val_accuracy: 0.2500 - 80ms/epoch - 27ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3715 - accuracy: 0.4375 - val_loss: 1.3871 - val_accuracy: 0.2500 - 80ms/epoch - 27ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3688 - accuracy: 0.4271 - val_loss: 1.3871 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3671 - accuracy: 0.4062 - val_loss: 1.3871 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3671 - accuracy: 0.4479 - val_loss: 1.3872 - val_accuracy: 0.2500 - 80ms/epoch - 27ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3686 - accuracy: 0.4167 - val_loss: 1.3872 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3647 - accuracy: 0.4479 - val_loss: 1.3872 - val_accuracy: 0.2500 - 81ms/epoch - 27ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3665 - accuracy: 0.4375 - val_loss: 1.3872 - val_accuracy: 0.2500 - 80ms/epoch - 27ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3607 - accuracy: 0.4062 - val_loss: 1.3872 - val_accuracy: 0.2500 - 76ms/epoch - 25ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3613 - accuracy: 0.4271 - val_loss: 1.3872 - val_accuracy: 0.2500 - 80ms/epoch - 27ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3626 - accuracy: 0.4167 - val_loss: 1.3873 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3565 - accuracy: 0.4479 - val_loss: 1.3873 - val_accuracy: 0.2500 - 82ms/epoch - 27ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3564 - accuracy: 0.4583 - val_loss: 1.3873 - val_accuracy: 0.2500 - 83ms/epoch - 28ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3540 - accuracy: 0.4792 - val_loss: 1.3873 - val_accuracy: 0.2500 - 81ms/epoch - 27ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3494 - accuracy: 0.4583 - val_loss: 1.3873 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3534 - accuracy: 0.4479 - val_loss: 1.3873 - val_accuracy: 0.2500 - 80ms/epoch - 27ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3482 - accuracy: 0.4167 - val_loss: 1.3873 - val_accuracy: 0.2500 - 80ms/epoch - 27ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3421 - accuracy: 0.4792 - val_loss: 1.3874 - val_accuracy: 0.2500 - 78ms/epoch - 26ms/step\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3426 - accuracy: 0.4688 - val_loss: 1.3874 - val_accuracy: 0.2500 - 80ms/epoch - 27ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3456 - accuracy: 0.4167 - val_loss: 1.3874 - val_accuracy: 0.2500 - 84ms/epoch - 28ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3348 - accuracy: 0.4688 - val_loss: 1.3874 - val_accuracy: 0.2500 - 81ms/epoch - 27ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3346 - accuracy: 0.4271 - val_loss: 1.3874 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3319 - accuracy: 0.4792 - val_loss: 1.3874 - val_accuracy: 0.2500 - 86ms/epoch - 29ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3316 - accuracy: 0.4167 - val_loss: 1.3874 - val_accuracy: 0.2500 - 81ms/epoch - 27ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3243 - accuracy: 0.4688 - val_loss: 1.3873 - val_accuracy: 0.2500 - 78ms/epoch - 26ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3212 - accuracy: 0.4167 - val_loss: 1.3873 - val_accuracy: 0.2500 - 77ms/epoch - 26ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3234 - accuracy: 0.4896 - val_loss: 1.3873 - val_accuracy: 0.2500 - 80ms/epoch - 27ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3157 - accuracy: 0.4271 - val_loss: 1.3873 - val_accuracy: 0.2500 - 77ms/epoch - 26ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3168 - accuracy: 0.4062 - val_loss: 1.3873 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3168 - accuracy: 0.4375 - val_loss: 1.3874 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3002 - accuracy: 0.4688 - val_loss: 1.3873 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.3015 - accuracy: 0.4479 - val_loss: 1.3873 - val_accuracy: 0.2500 - 81ms/epoch - 27ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.2993 - accuracy: 0.4375 - val_loss: 1.3873 - val_accuracy: 0.2500 - 77ms/epoch - 26ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.2884 - accuracy: 0.4896 - val_loss: 1.3872 - val_accuracy: 0.2500 - 81ms/epoch - 27ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.2917 - accuracy: 0.4375 - val_loss: 1.3872 - val_accuracy: 0.2500 - 81ms/epoch - 27ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.2877 - accuracy: 0.4479 - val_loss: 1.3872 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.2911 - accuracy: 0.4375 - val_loss: 1.3871 - val_accuracy: 0.2500 - 77ms/epoch - 26ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.2729 - accuracy: 0.5000 - val_loss: 1.3871 - val_accuracy: 0.2500 - 81ms/epoch - 27ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.2821 - accuracy: 0.4583 - val_loss: 1.3871 - val_accuracy: 0.2500 - 78ms/epoch - 26ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.2704 - accuracy: 0.4583 - val_loss: 1.3870 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.2816 - accuracy: 0.4375 - val_loss: 1.3869 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.2895 - accuracy: 0.4062 - val_loss: 1.3868 - val_accuracy: 0.2500 - 81ms/epoch - 27ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.2615 - accuracy: 0.4792 - val_loss: 1.3867 - val_accuracy: 0.2500 - 78ms/epoch - 26ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.2416 - accuracy: 0.4896 - val_loss: 1.3865 - val_accuracy: 0.2500 - 80ms/epoch - 27ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.2536 - accuracy: 0.4688 - val_loss: 1.3864 - val_accuracy: 0.2500 - 81ms/epoch - 27ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.2553 - accuracy: 0.4896 - val_loss: 1.3863 - val_accuracy: 0.2500 - 80ms/epoch - 27ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.2468 - accuracy: 0.4583 - val_loss: 1.3863 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.2640 - accuracy: 0.5000 - val_loss: 1.3863 - val_accuracy: 0.2500 - 77ms/epoch - 26ms/step\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.2422 - accuracy: 0.5521 - val_loss: 1.3863 - val_accuracy: 0.2500 - 80ms/epoch - 27ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.2462 - accuracy: 0.4792 - val_loss: 1.3864 - val_accuracy: 0.2500 - 77ms/epoch - 26ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.2305 - accuracy: 0.5208 - val_loss: 1.3864 - val_accuracy: 0.2500 - 81ms/epoch - 27ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.2407 - accuracy: 0.5104 - val_loss: 1.3865 - val_accuracy: 0.2500 - 80ms/epoch - 27ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.2214 - accuracy: 0.5417 - val_loss: 1.3865 - val_accuracy: 0.2500 - 80ms/epoch - 27ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.2189 - accuracy: 0.5312 - val_loss: 1.3866 - val_accuracy: 0.2500 - 81ms/epoch - 27ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.2155 - accuracy: 0.5521 - val_loss: 1.3866 - val_accuracy: 0.2500 - 78ms/epoch - 26ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.2240 - accuracy: 0.4792 - val_loss: 1.3866 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.2187 - accuracy: 0.5104 - val_loss: 1.3865 - val_accuracy: 0.2500 - 78ms/epoch - 26ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.2103 - accuracy: 0.5417 - val_loss: 1.3865 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.1983 - accuracy: 0.5000 - val_loss: 1.3864 - val_accuracy: 0.2500 - 78ms/epoch - 26ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.2072 - accuracy: 0.5104 - val_loss: 1.3864 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.1955 - accuracy: 0.5417 - val_loss: 1.3863 - val_accuracy: 0.2500 - 77ms/epoch - 26ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.1866 - accuracy: 0.5000 - val_loss: 1.3862 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.1889 - accuracy: 0.5417 - val_loss: 1.3861 - val_accuracy: 0.2500 - 80ms/epoch - 27ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.1950 - accuracy: 0.5000 - val_loss: 1.3861 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.1820 - accuracy: 0.4792 - val_loss: 1.3861 - val_accuracy: 0.2500 - 81ms/epoch - 27ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.1814 - accuracy: 0.5729 - val_loss: 1.3861 - val_accuracy: 0.2500 - 78ms/epoch - 26ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.1687 - accuracy: 0.5417 - val_loss: 1.3862 - val_accuracy: 0.2500 - 78ms/epoch - 26ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.1810 - accuracy: 0.5000 - val_loss: 1.3863 - val_accuracy: 0.2500 - 80ms/epoch - 27ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.1593 - accuracy: 0.5625 - val_loss: 1.3864 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.1677 - accuracy: 0.5833 - val_loss: 1.3865 - val_accuracy: 0.2500 - 80ms/epoch - 27ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.1538 - accuracy: 0.5729 - val_loss: 1.3864 - val_accuracy: 0.2500 - 77ms/epoch - 26ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.1446 - accuracy: 0.6354 - val_loss: 1.3865 - val_accuracy: 0.2500 - 81ms/epoch - 27ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.1423 - accuracy: 0.5521 - val_loss: 1.3866 - val_accuracy: 0.2500 - 78ms/epoch - 26ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.1503 - accuracy: 0.5833 - val_loss: 1.3866 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.1542 - accuracy: 0.5312 - val_loss: 1.3866 - val_accuracy: 0.2500 - 78ms/epoch - 26ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.1498 - accuracy: 0.5729 - val_loss: 1.3866 - val_accuracy: 0.2500 - 82ms/epoch - 27ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.1505 - accuracy: 0.5417 - val_loss: 1.3865 - val_accuracy: 0.2500 - 77ms/epoch - 26ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.1410 - accuracy: 0.5833 - val_loss: 1.3864 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.1425 - accuracy: 0.5521 - val_loss: 1.3863 - val_accuracy: 0.2500 - 83ms/epoch - 28ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.1233 - accuracy: 0.6042 - val_loss: 1.3862 - val_accuracy: 0.2500 - 80ms/epoch - 27ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.1120 - accuracy: 0.5729 - val_loss: 1.3863 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.1245 - accuracy: 0.5833 - val_loss: 1.3863 - val_accuracy: 0.2500 - 80ms/epoch - 27ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.1186 - accuracy: 0.5938 - val_loss: 1.3864 - val_accuracy: 0.2188 - 78ms/epoch - 26ms/step\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.1265 - accuracy: 0.5625 - val_loss: 1.3864 - val_accuracy: 0.2188 - 83ms/epoch - 28ms/step\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.1359 - accuracy: 0.4896 - val_loss: 1.3867 - val_accuracy: 0.2344 - 81ms/epoch - 27ms/step\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.1127 - accuracy: 0.5625 - val_loss: 1.3869 - val_accuracy: 0.2344 - 80ms/epoch - 27ms/step\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0954 - accuracy: 0.5833 - val_loss: 1.3871 - val_accuracy: 0.2344 - 80ms/epoch - 27ms/step\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.1206 - accuracy: 0.6042 - val_loss: 1.3871 - val_accuracy: 0.2344 - 79ms/epoch - 26ms/step\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0849 - accuracy: 0.6250 - val_loss: 1.3871 - val_accuracy: 0.2344 - 79ms/epoch - 26ms/step\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0974 - accuracy: 0.6250 - val_loss: 1.3872 - val_accuracy: 0.2344 - 77ms/epoch - 26ms/step\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.1135 - accuracy: 0.5938 - val_loss: 1.3874 - val_accuracy: 0.2344 - 79ms/epoch - 26ms/step\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0738 - accuracy: 0.6250 - val_loss: 1.3877 - val_accuracy: 0.2344 - 77ms/epoch - 26ms/step\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 135: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.1078 - accuracy: 0.5833 - val_loss: 1.3879 - val_accuracy: 0.2344 - 78ms/epoch - 26ms/step\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 136: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0988 - accuracy: 0.6250 - val_loss: 1.3881 - val_accuracy: 0.2344 - 77ms/epoch - 26ms/step\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 137: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0858 - accuracy: 0.6146 - val_loss: 1.3884 - val_accuracy: 0.2344 - 78ms/epoch - 26ms/step\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 138: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0902 - accuracy: 0.6250 - val_loss: 1.3887 - val_accuracy: 0.2344 - 79ms/epoch - 26ms/step\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 139: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0940 - accuracy: 0.5521 - val_loss: 1.3888 - val_accuracy: 0.2344 - 79ms/epoch - 26ms/step\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 140: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0907 - accuracy: 0.5625 - val_loss: 1.3889 - val_accuracy: 0.2344 - 80ms/epoch - 27ms/step\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 141: val_accuracy did not improve from 0.25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 1.0743 - accuracy: 0.6146 - val_loss: 1.3890 - val_accuracy: 0.2344 - 80ms/epoch - 27ms/step\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 142: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.1006 - accuracy: 0.5521 - val_loss: 1.3891 - val_accuracy: 0.2344 - 80ms/epoch - 27ms/step\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 143: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0827 - accuracy: 0.6042 - val_loss: 1.3893 - val_accuracy: 0.2344 - 77ms/epoch - 26ms/step\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 144: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0591 - accuracy: 0.6458 - val_loss: 1.3894 - val_accuracy: 0.2344 - 78ms/epoch - 26ms/step\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 145: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0674 - accuracy: 0.6250 - val_loss: 1.3897 - val_accuracy: 0.2344 - 83ms/epoch - 28ms/step\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 146: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0739 - accuracy: 0.5938 - val_loss: 1.3900 - val_accuracy: 0.2344 - 78ms/epoch - 26ms/step\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 147: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0531 - accuracy: 0.6146 - val_loss: 1.3901 - val_accuracy: 0.2344 - 81ms/epoch - 27ms/step\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 148: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0503 - accuracy: 0.6042 - val_loss: 1.3901 - val_accuracy: 0.2344 - 81ms/epoch - 27ms/step\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 149: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0584 - accuracy: 0.6146 - val_loss: 1.3902 - val_accuracy: 0.2344 - 79ms/epoch - 26ms/step\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 150: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0675 - accuracy: 0.6146 - val_loss: 1.3903 - val_accuracy: 0.2344 - 80ms/epoch - 27ms/step\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 151: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0533 - accuracy: 0.6458 - val_loss: 1.3907 - val_accuracy: 0.2344 - 82ms/epoch - 27ms/step\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 152: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0562 - accuracy: 0.5938 - val_loss: 1.3911 - val_accuracy: 0.2344 - 79ms/epoch - 26ms/step\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 153: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0439 - accuracy: 0.6354 - val_loss: 1.3913 - val_accuracy: 0.2344 - 84ms/epoch - 28ms/step\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 154: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0430 - accuracy: 0.6354 - val_loss: 1.3915 - val_accuracy: 0.2344 - 78ms/epoch - 26ms/step\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 155: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0056 - accuracy: 0.6875 - val_loss: 1.3916 - val_accuracy: 0.2344 - 78ms/epoch - 26ms/step\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 156: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0525 - accuracy: 0.6354 - val_loss: 1.3917 - val_accuracy: 0.2188 - 82ms/epoch - 27ms/step\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 157: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0248 - accuracy: 0.6562 - val_loss: 1.3920 - val_accuracy: 0.2188 - 80ms/epoch - 27ms/step\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 158: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0417 - accuracy: 0.6146 - val_loss: 1.3924 - val_accuracy: 0.2188 - 79ms/epoch - 26ms/step\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 159: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0236 - accuracy: 0.6562 - val_loss: 1.3931 - val_accuracy: 0.2188 - 79ms/epoch - 26ms/step\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 160: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0386 - accuracy: 0.6354 - val_loss: 1.3941 - val_accuracy: 0.2188 - 81ms/epoch - 27ms/step\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 161: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0079 - accuracy: 0.6250 - val_loss: 1.3951 - val_accuracy: 0.2188 - 80ms/epoch - 27ms/step\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 162: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0462 - accuracy: 0.5729 - val_loss: 1.3961 - val_accuracy: 0.2188 - 79ms/epoch - 26ms/step\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 163: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9968 - accuracy: 0.7396 - val_loss: 1.3975 - val_accuracy: 0.2188 - 79ms/epoch - 26ms/step\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 164: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0002 - accuracy: 0.6875 - val_loss: 1.3987 - val_accuracy: 0.2188 - 79ms/epoch - 26ms/step\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 165: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0009 - accuracy: 0.7083 - val_loss: 1.3996 - val_accuracy: 0.2188 - 81ms/epoch - 27ms/step\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 166: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0090 - accuracy: 0.6042 - val_loss: 1.3995 - val_accuracy: 0.2188 - 78ms/epoch - 26ms/step\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 167: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0118 - accuracy: 0.6458 - val_loss: 1.4002 - val_accuracy: 0.1875 - 83ms/epoch - 28ms/step\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 168: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0227 - accuracy: 0.6354 - val_loss: 1.4008 - val_accuracy: 0.1719 - 78ms/epoch - 26ms/step\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 169: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0051 - accuracy: 0.6562 - val_loss: 1.4016 - val_accuracy: 0.2031 - 79ms/epoch - 26ms/step\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 170: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0144 - accuracy: 0.6146 - val_loss: 1.4029 - val_accuracy: 0.1719 - 81ms/epoch - 27ms/step\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 171: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0267 - accuracy: 0.5833 - val_loss: 1.4043 - val_accuracy: 0.1719 - 78ms/epoch - 26ms/step\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 172: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0052 - accuracy: 0.6354 - val_loss: 1.4064 - val_accuracy: 0.1719 - 81ms/epoch - 27ms/step\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 173: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9939 - accuracy: 0.6458 - val_loss: 1.4085 - val_accuracy: 0.1719 - 77ms/epoch - 26ms/step\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 174: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0035 - accuracy: 0.6354 - val_loss: 1.4116 - val_accuracy: 0.2031 - 77ms/epoch - 26ms/step\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 175: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9915 - accuracy: 0.6771 - val_loss: 1.4140 - val_accuracy: 0.2188 - 78ms/epoch - 26ms/step\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 176: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9967 - accuracy: 0.6875 - val_loss: 1.4164 - val_accuracy: 0.2031 - 80ms/epoch - 27ms/step\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 177: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 1.0002 - accuracy: 0.6771 - val_loss: 1.4188 - val_accuracy: 0.2031 - 79ms/epoch - 26ms/step\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 178: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9882 - accuracy: 0.6458 - val_loss: 1.4208 - val_accuracy: 0.2031 - 79ms/epoch - 26ms/step\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 179: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9830 - accuracy: 0.6771 - val_loss: 1.4238 - val_accuracy: 0.2031 - 81ms/epoch - 27ms/step\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 180: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9864 - accuracy: 0.6562 - val_loss: 1.4258 - val_accuracy: 0.2031 - 79ms/epoch - 26ms/step\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 181: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9917 - accuracy: 0.6458 - val_loss: 1.4288 - val_accuracy: 0.2031 - 79ms/epoch - 26ms/step\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 182: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9729 - accuracy: 0.6875 - val_loss: 1.4297 - val_accuracy: 0.2031 - 79ms/epoch - 26ms/step\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 183: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9545 - accuracy: 0.6667 - val_loss: 1.4305 - val_accuracy: 0.2031 - 78ms/epoch - 26ms/step\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 184: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9516 - accuracy: 0.6562 - val_loss: 1.4320 - val_accuracy: 0.2031 - 81ms/epoch - 27ms/step\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 185: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9848 - accuracy: 0.6875 - val_loss: 1.4337 - val_accuracy: 0.2031 - 77ms/epoch - 26ms/step\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 186: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9658 - accuracy: 0.6771 - val_loss: 1.4360 - val_accuracy: 0.2031 - 78ms/epoch - 26ms/step\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 187: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9596 - accuracy: 0.7188 - val_loss: 1.4392 - val_accuracy: 0.2031 - 79ms/epoch - 26ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188/300\n",
      "\n",
      "Epoch 188: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9581 - accuracy: 0.6979 - val_loss: 1.4443 - val_accuracy: 0.1875 - 79ms/epoch - 26ms/step\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 189: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9849 - accuracy: 0.6146 - val_loss: 1.4476 - val_accuracy: 0.2031 - 81ms/epoch - 27ms/step\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 190: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9475 - accuracy: 0.6875 - val_loss: 1.4498 - val_accuracy: 0.2031 - 82ms/epoch - 27ms/step\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 191: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9532 - accuracy: 0.6979 - val_loss: 1.4550 - val_accuracy: 0.1875 - 79ms/epoch - 26ms/step\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 192: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9657 - accuracy: 0.6875 - val_loss: 1.4585 - val_accuracy: 0.2031 - 79ms/epoch - 26ms/step\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 193: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9335 - accuracy: 0.7396 - val_loss: 1.4632 - val_accuracy: 0.2188 - 81ms/epoch - 27ms/step\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 194: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9645 - accuracy: 0.6667 - val_loss: 1.4647 - val_accuracy: 0.2188 - 82ms/epoch - 27ms/step\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 195: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9539 - accuracy: 0.7083 - val_loss: 1.4666 - val_accuracy: 0.2188 - 76ms/epoch - 25ms/step\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 196: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9651 - accuracy: 0.6667 - val_loss: 1.4663 - val_accuracy: 0.2188 - 83ms/epoch - 28ms/step\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 197: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9510 - accuracy: 0.6667 - val_loss: 1.4649 - val_accuracy: 0.2188 - 79ms/epoch - 26ms/step\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 198: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9906 - accuracy: 0.6667 - val_loss: 1.4662 - val_accuracy: 0.2188 - 79ms/epoch - 26ms/step\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 199: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9396 - accuracy: 0.7188 - val_loss: 1.4663 - val_accuracy: 0.2188 - 83ms/epoch - 28ms/step\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 200: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9300 - accuracy: 0.6979 - val_loss: 1.4705 - val_accuracy: 0.2188 - 78ms/epoch - 26ms/step\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 201: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9629 - accuracy: 0.6667 - val_loss: 1.4766 - val_accuracy: 0.2188 - 80ms/epoch - 27ms/step\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 202: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9493 - accuracy: 0.7188 - val_loss: 1.4774 - val_accuracy: 0.2188 - 79ms/epoch - 26ms/step\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 203: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9718 - accuracy: 0.6667 - val_loss: 1.4779 - val_accuracy: 0.2188 - 79ms/epoch - 26ms/step\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 204: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9439 - accuracy: 0.6771 - val_loss: 1.4789 - val_accuracy: 0.2188 - 77ms/epoch - 26ms/step\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 205: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9360 - accuracy: 0.7188 - val_loss: 1.4772 - val_accuracy: 0.2031 - 77ms/epoch - 26ms/step\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 206: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9341 - accuracy: 0.7292 - val_loss: 1.4776 - val_accuracy: 0.2031 - 81ms/epoch - 27ms/step\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 207: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9325 - accuracy: 0.7292 - val_loss: 1.4801 - val_accuracy: 0.1875 - 78ms/epoch - 26ms/step\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 208: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9084 - accuracy: 0.7708 - val_loss: 1.4834 - val_accuracy: 0.2188 - 78ms/epoch - 26ms/step\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 209: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8924 - accuracy: 0.7604 - val_loss: 1.4834 - val_accuracy: 0.2188 - 80ms/epoch - 27ms/step\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 210: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9052 - accuracy: 0.7708 - val_loss: 1.4864 - val_accuracy: 0.2188 - 79ms/epoch - 26ms/step\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 211: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9375 - accuracy: 0.6771 - val_loss: 1.4893 - val_accuracy: 0.2188 - 80ms/epoch - 27ms/step\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 212: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9136 - accuracy: 0.7292 - val_loss: 1.4921 - val_accuracy: 0.2188 - 80ms/epoch - 27ms/step\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 213: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9144 - accuracy: 0.7083 - val_loss: 1.4906 - val_accuracy: 0.2188 - 79ms/epoch - 26ms/step\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 214: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8936 - accuracy: 0.7396 - val_loss: 1.4903 - val_accuracy: 0.2188 - 80ms/epoch - 27ms/step\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 215: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9011 - accuracy: 0.7083 - val_loss: 1.4907 - val_accuracy: 0.2188 - 81ms/epoch - 27ms/step\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 216: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8801 - accuracy: 0.7396 - val_loss: 1.4934 - val_accuracy: 0.2188 - 79ms/epoch - 26ms/step\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 217: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9080 - accuracy: 0.7292 - val_loss: 1.4986 - val_accuracy: 0.2500 - 80ms/epoch - 27ms/step\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 218: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.9228 - accuracy: 0.7292 - val_loss: 1.5007 - val_accuracy: 0.2344 - 79ms/epoch - 26ms/step\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 219: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8735 - accuracy: 0.7396 - val_loss: 1.5052 - val_accuracy: 0.2344 - 80ms/epoch - 27ms/step\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 220: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8891 - accuracy: 0.7604 - val_loss: 1.5125 - val_accuracy: 0.2344 - 79ms/epoch - 26ms/step\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 221: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8847 - accuracy: 0.7188 - val_loss: 1.5175 - val_accuracy: 0.2344 - 78ms/epoch - 26ms/step\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 222: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8775 - accuracy: 0.7292 - val_loss: 1.5180 - val_accuracy: 0.2344 - 79ms/epoch - 26ms/step\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 223: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8823 - accuracy: 0.7708 - val_loss: 1.5191 - val_accuracy: 0.2344 - 79ms/epoch - 26ms/step\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 224: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8729 - accuracy: 0.7604 - val_loss: 1.5203 - val_accuracy: 0.2500 - 83ms/epoch - 28ms/step\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 225: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8978 - accuracy: 0.7500 - val_loss: 1.5249 - val_accuracy: 0.2500 - 80ms/epoch - 27ms/step\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 226: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8920 - accuracy: 0.7708 - val_loss: 1.5254 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 227: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8809 - accuracy: 0.7396 - val_loss: 1.5301 - val_accuracy: 0.2344 - 78ms/epoch - 26ms/step\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 228: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8852 - accuracy: 0.7500 - val_loss: 1.5344 - val_accuracy: 0.2344 - 80ms/epoch - 27ms/step\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 229: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8943 - accuracy: 0.7604 - val_loss: 1.5449 - val_accuracy: 0.2188 - 78ms/epoch - 26ms/step\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 230: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8771 - accuracy: 0.7604 - val_loss: 1.5559 - val_accuracy: 0.2031 - 78ms/epoch - 26ms/step\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 231: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8698 - accuracy: 0.7708 - val_loss: 1.5608 - val_accuracy: 0.2031 - 78ms/epoch - 26ms/step\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 232: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8659 - accuracy: 0.7708 - val_loss: 1.5708 - val_accuracy: 0.2188 - 80ms/epoch - 27ms/step\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 233: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8591 - accuracy: 0.7500 - val_loss: 1.5818 - val_accuracy: 0.2031 - 79ms/epoch - 26ms/step\n",
      "Epoch 234/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 234: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8663 - accuracy: 0.7500 - val_loss: 1.5892 - val_accuracy: 0.2031 - 78ms/epoch - 26ms/step\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 235: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8771 - accuracy: 0.6979 - val_loss: 1.5888 - val_accuracy: 0.2188 - 79ms/epoch - 26ms/step\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 236: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8826 - accuracy: 0.7083 - val_loss: 1.5910 - val_accuracy: 0.2188 - 80ms/epoch - 27ms/step\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 237: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8700 - accuracy: 0.7188 - val_loss: 1.5902 - val_accuracy: 0.2344 - 81ms/epoch - 27ms/step\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 238: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8791 - accuracy: 0.7604 - val_loss: 1.5819 - val_accuracy: 0.2031 - 81ms/epoch - 27ms/step\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 239: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8550 - accuracy: 0.7708 - val_loss: 1.5740 - val_accuracy: 0.2031 - 78ms/epoch - 26ms/step\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 240: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8618 - accuracy: 0.7708 - val_loss: 1.5677 - val_accuracy: 0.2344 - 80ms/epoch - 27ms/step\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 241: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8534 - accuracy: 0.7917 - val_loss: 1.5684 - val_accuracy: 0.2188 - 80ms/epoch - 27ms/step\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 242: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8264 - accuracy: 0.7917 - val_loss: 1.5699 - val_accuracy: 0.2188 - 84ms/epoch - 28ms/step\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 243: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8547 - accuracy: 0.7917 - val_loss: 1.5740 - val_accuracy: 0.2344 - 79ms/epoch - 26ms/step\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 244: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8524 - accuracy: 0.7604 - val_loss: 1.5783 - val_accuracy: 0.2500 - 80ms/epoch - 27ms/step\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 245: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8576 - accuracy: 0.7188 - val_loss: 1.5812 - val_accuracy: 0.2500 - 80ms/epoch - 27ms/step\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 246: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8275 - accuracy: 0.7812 - val_loss: 1.5877 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 247: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8495 - accuracy: 0.7083 - val_loss: 1.5931 - val_accuracy: 0.2500 - 80ms/epoch - 27ms/step\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 248: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8309 - accuracy: 0.8021 - val_loss: 1.6027 - val_accuracy: 0.2344 - 81ms/epoch - 27ms/step\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 249: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8574 - accuracy: 0.7188 - val_loss: 1.6067 - val_accuracy: 0.2344 - 81ms/epoch - 27ms/step\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 250: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8285 - accuracy: 0.8125 - val_loss: 1.6069 - val_accuracy: 0.2500 - 78ms/epoch - 26ms/step\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 251: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8500 - accuracy: 0.7500 - val_loss: 1.6063 - val_accuracy: 0.2500 - 79ms/epoch - 26ms/step\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 252: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8435 - accuracy: 0.7708 - val_loss: 1.6113 - val_accuracy: 0.2500 - 83ms/epoch - 28ms/step\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 253: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8252 - accuracy: 0.8542 - val_loss: 1.6178 - val_accuracy: 0.2500 - 85ms/epoch - 28ms/step\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 254: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8220 - accuracy: 0.8333 - val_loss: 1.6174 - val_accuracy: 0.2500 - 81ms/epoch - 27ms/step\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 255: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8081 - accuracy: 0.7812 - val_loss: 1.6151 - val_accuracy: 0.2344 - 78ms/epoch - 26ms/step\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 256: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8083 - accuracy: 0.7708 - val_loss: 1.6180 - val_accuracy: 0.2188 - 81ms/epoch - 27ms/step\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 257: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8055 - accuracy: 0.7812 - val_loss: 1.6230 - val_accuracy: 0.2188 - 81ms/epoch - 27ms/step\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 258: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8239 - accuracy: 0.8021 - val_loss: 1.6247 - val_accuracy: 0.2344 - 79ms/epoch - 26ms/step\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 259: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.7946 - accuracy: 0.8021 - val_loss: 1.6272 - val_accuracy: 0.2031 - 82ms/epoch - 27ms/step\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 260: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8082 - accuracy: 0.7917 - val_loss: 1.6269 - val_accuracy: 0.1875 - 80ms/epoch - 27ms/step\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 261: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8120 - accuracy: 0.8333 - val_loss: 1.6325 - val_accuracy: 0.2031 - 81ms/epoch - 27ms/step\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 262: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.7939 - accuracy: 0.8125 - val_loss: 1.6342 - val_accuracy: 0.2031 - 78ms/epoch - 26ms/step\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 263: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.7960 - accuracy: 0.7917 - val_loss: 1.6377 - val_accuracy: 0.2031 - 80ms/epoch - 27ms/step\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 264: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8149 - accuracy: 0.8021 - val_loss: 1.6397 - val_accuracy: 0.1875 - 81ms/epoch - 27ms/step\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 265: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8233 - accuracy: 0.8333 - val_loss: 1.6424 - val_accuracy: 0.1406 - 78ms/epoch - 26ms/step\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 266: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8197 - accuracy: 0.7812 - val_loss: 1.6471 - val_accuracy: 0.1719 - 81ms/epoch - 27ms/step\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 267: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.7783 - accuracy: 0.8229 - val_loss: 1.6521 - val_accuracy: 0.2031 - 78ms/epoch - 26ms/step\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 268: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.7763 - accuracy: 0.8125 - val_loss: 1.6580 - val_accuracy: 0.2031 - 76ms/epoch - 25ms/step\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 269: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8136 - accuracy: 0.7396 - val_loss: 1.6684 - val_accuracy: 0.1719 - 79ms/epoch - 26ms/step\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 270: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.8030 - accuracy: 0.7708 - val_loss: 1.6759 - val_accuracy: 0.1719 - 82ms/epoch - 27ms/step\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 271: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.7906 - accuracy: 0.8125 - val_loss: 1.6839 - val_accuracy: 0.1719 - 78ms/epoch - 26ms/step\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 272: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.7902 - accuracy: 0.8542 - val_loss: 1.6941 - val_accuracy: 0.1719 - 78ms/epoch - 26ms/step\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 273: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.7863 - accuracy: 0.8229 - val_loss: 1.6949 - val_accuracy: 0.1562 - 78ms/epoch - 26ms/step\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 274: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.7705 - accuracy: 0.8542 - val_loss: 1.6937 - val_accuracy: 0.1719 - 79ms/epoch - 26ms/step\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 275: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.7856 - accuracy: 0.8229 - val_loss: 1.6971 - val_accuracy: 0.1875 - 80ms/epoch - 27ms/step\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 276: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.7826 - accuracy: 0.8333 - val_loss: 1.7057 - val_accuracy: 0.1875 - 81ms/epoch - 27ms/step\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 277: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.7852 - accuracy: 0.7917 - val_loss: 1.7110 - val_accuracy: 0.1875 - 80ms/epoch - 27ms/step\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 278: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.7834 - accuracy: 0.8542 - val_loss: 1.7129 - val_accuracy: 0.1719 - 79ms/epoch - 26ms/step\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 279: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.7888 - accuracy: 0.8125 - val_loss: 1.7171 - val_accuracy: 0.1875 - 81ms/epoch - 27ms/step\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 280: val_accuracy did not improve from 0.25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 0.7574 - accuracy: 0.8125 - val_loss: 1.7186 - val_accuracy: 0.1719 - 79ms/epoch - 26ms/step\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 281: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.7905 - accuracy: 0.7812 - val_loss: 1.7203 - val_accuracy: 0.1875 - 79ms/epoch - 26ms/step\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 282: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.7527 - accuracy: 0.8333 - val_loss: 1.7246 - val_accuracy: 0.1719 - 82ms/epoch - 27ms/step\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 283: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.7615 - accuracy: 0.8125 - val_loss: 1.7270 - val_accuracy: 0.1875 - 79ms/epoch - 26ms/step\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 284: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.7640 - accuracy: 0.8021 - val_loss: 1.7309 - val_accuracy: 0.1719 - 81ms/epoch - 27ms/step\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 285: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.7691 - accuracy: 0.7917 - val_loss: 1.7330 - val_accuracy: 0.1562 - 80ms/epoch - 27ms/step\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 286: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.7485 - accuracy: 0.8646 - val_loss: 1.7308 - val_accuracy: 0.1562 - 79ms/epoch - 26ms/step\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 287: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.7681 - accuracy: 0.8125 - val_loss: 1.7296 - val_accuracy: 0.1719 - 80ms/epoch - 27ms/step\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 288: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.7591 - accuracy: 0.8229 - val_loss: 1.7314 - val_accuracy: 0.1562 - 80ms/epoch - 27ms/step\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 289: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.7480 - accuracy: 0.8542 - val_loss: 1.7308 - val_accuracy: 0.1562 - 77ms/epoch - 26ms/step\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 290: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.7668 - accuracy: 0.8229 - val_loss: 1.7309 - val_accuracy: 0.1719 - 80ms/epoch - 27ms/step\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 291: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.7639 - accuracy: 0.8438 - val_loss: 1.7314 - val_accuracy: 0.1719 - 81ms/epoch - 27ms/step\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 292: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.7515 - accuracy: 0.8438 - val_loss: 1.7381 - val_accuracy: 0.1719 - 79ms/epoch - 26ms/step\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 293: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.7545 - accuracy: 0.8646 - val_loss: 1.7429 - val_accuracy: 0.1719 - 78ms/epoch - 26ms/step\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 294: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.7543 - accuracy: 0.8229 - val_loss: 1.7396 - val_accuracy: 0.1719 - 80ms/epoch - 27ms/step\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 295: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.7380 - accuracy: 0.8333 - val_loss: 1.7412 - val_accuracy: 0.1406 - 79ms/epoch - 26ms/step\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 296: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.7611 - accuracy: 0.8333 - val_loss: 1.7454 - val_accuracy: 0.1562 - 79ms/epoch - 26ms/step\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 297: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.7313 - accuracy: 0.8438 - val_loss: 1.7448 - val_accuracy: 0.1562 - 82ms/epoch - 27ms/step\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 298: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.7423 - accuracy: 0.8229 - val_loss: 1.7457 - val_accuracy: 0.1562 - 81ms/epoch - 27ms/step\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 299: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.7256 - accuracy: 0.8229 - val_loss: 1.7448 - val_accuracy: 0.1719 - 82ms/epoch - 27ms/step\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 300: val_accuracy did not improve from 0.25000\n",
      "3/3 - 0s - loss: 0.7465 - accuracy: 0.8542 - val_loss: 1.7458 - val_accuracy: 0.1562 - 79ms/epoch - 26ms/step\n"
     ]
    }
   ],
   "source": [
    "fittedModel = model.fit(X_train, Y_train, batch_size = 32, epochs = 300, \n",
    "                        verbose = 2,\n",
    "                        validation_data=(X_val, Y_val),\n",
    "                        callbacks=[checkpointer])\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a545b8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('checkpoint.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b962b705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step\n",
      "Classification accuracy: 0.150000 \n"
     ]
    }
   ],
   "source": [
    "probs       = model.predict(X_test)\n",
    "preds       = probs.argmax(axis = -1)  \n",
    "acc         = np.mean(preds == Y_test.argmax(axis=-1))\n",
    "print(\"Classification accuracy: %f \" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b4c053b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fittedModel.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7dd25252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = fittedModel\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a68ef2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6d346148",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Data extraction and processing\n",
    "N_S = 3\n",
    "# Load all trials for a sigle subject\n",
    "X, Y = Extract_data_from_subject(root_dir, N_S, datatype)\n",
    "\n",
    "# Cut usefull time. i.e action interval\n",
    "X = Select_time_window(X = X, t_start = t_start, t_end = t_end, fs = fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "58913497",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = Filter_by_condition(X, Y, \"INNER\")\n",
    "y_labels = Y[:,1]\n",
    "\n",
    "X = X[:,left_channels,:]\n",
    "\n",
    "x_min = X.min(axis=(2), keepdims=True)\n",
    "x_max = X.max(axis=(2), keepdims=True)\n",
    "\n",
    "x_min.shape\n",
    "\n",
    "X = (X - x_min)/(x_max-x_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50c23266",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_channel_mask = [False, False,  True,  True, False, True, False, False, False, False, False,  True,\n",
    "    False,  True, False, False, False, False, False, False, False, False,  True, False,\n",
    "    False, False, False, False, False, False, False,  True, False, False, False, False,\n",
    "    False,  True, False, False,  True, False,  True, False,  True,  True, False, False,\n",
    "    False, False, False, False, False, False, False,  True, False, False, False, False,\n",
    "    False,  True, False, False, False,  True, False, False, False, False,  True,  True,\n",
    "    False, False,  True, False, False, False, False, False, False, False,  True, False,\n",
    "    False,  True, False,  True, False, False,  True,  True, False, False, False, False,\n",
    "    True,  True, False, False, False,  True, False, False,  True, False, False, False,\n",
    "    False, False,  True, False, False, False,  True, False,  True, False, False, False,\n",
    "    False, False, False,  True, False,  True, False, False,]\n",
    "\n",
    "X = X[:,best_channel_mask,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9bae5645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Number of devices: 2\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=4, shuffle=True)\n",
    "kf.get_n_splits(X)\n",
    "accuracies = []\n",
    "\n",
    "kernLength = 128\n",
    "f1 = 8\n",
    "f2 = 16\n",
    "d = 2\n",
    "dr = 0.5\n",
    "\n",
    "kernels, chans, samples = 1, X.shape[1], X.shape[2]\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b2fca8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernLength = 20\n",
    "f1 = 28\n",
    "f2 = 10\n",
    "d = 128\n",
    "dr = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "921e578a",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_channels = np.array([0,\n",
    "                        1,\n",
    "                        3,\n",
    "                        4,\n",
    "                        7,\n",
    "                        8,\n",
    "                        9,\n",
    "                        14,\n",
    "                        18,\n",
    "                        19,\n",
    "                        21,\n",
    "                        22,\n",
    "                        23,\n",
    "                        81,\n",
    "                        83,\n",
    "                        90,\n",
    "                        94,\n",
    "                        95,\n",
    "                        100,\n",
    "                        101,\n",
    "                        105,\n",
    "                        110,\n",
    "                        114,\n",
    "                        116,\n",
    "                        121,\n",
    "                        125\n",
    "                        ])\n",
    "best_channel_mask = [False, False,  True,  True, False, True, False, False, False, False, False,  True,\n",
    "    False,  True, False, False, False, False, False, False, False, False,  True, False,\n",
    "    False, False, False, False, False, False, False,  True, False, False, False, False,\n",
    "    False,  True, False, False,  True, False,  True, False,  True,  True, False, False,\n",
    "    False, False, False, False, False, False, False,  True, False, False, False, False,\n",
    "    False,  True, False, False, False,  True, False, False, False, False,  True,  True,\n",
    "    False, False,  True, False, False, False, False, False, False, False,  True, False,\n",
    "    False,  True, False,  True, False, False,  True,  True, False, False, False, False,\n",
    "    True,  True, False, False, False,  True, False, False,  True, False, False, False,\n",
    "    False, False,  True, False, False, False,  True, False,  True, False, False, False,\n",
    "    False, False, False,  True, False,  True, False, False,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c193a83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "2/2 [==============================] - 0s 10ms/step\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = y_labels[train_index], y_labels[test_index]\n",
    "    # convert labels to one-hot encodings.\n",
    "    Y_train      = np_utils.to_categorical(Y_train)\n",
    "    Y_test       = np_utils.to_categorical(Y_test)\n",
    "    X_train      = X_train.reshape(X_train.shape[0], chans, samples, kernels)\n",
    "    X_test       = X_test.reshape(X_test.shape[0], chans, samples, kernels)\n",
    "    \n",
    "    #X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.25, random_state=24)\n",
    "    \n",
    "    checkpointer = ModelCheckpoint(filepath='checkpoint.h5', verbose=1, monitor='val_accuracy',\n",
    "                               save_best_only=True)\n",
    "    \n",
    "    #with strategy.scope():\n",
    "\n",
    "#         model = EEGNet(nb_classes = 4, Chans = chans, Samples = samples,\n",
    "#                    dropoutRate = dr, kernLength = kernLength, F1 = f1, D = d, F2 = f2, \n",
    "#                    dropoutType = 'Dropout')\n",
    "#         model.compile(\n",
    "#                 tf.keras.optimizers.Adam(\n",
    "#                     # Specifies the range of values for the tuner to try\n",
    "#                     name=\"Adam\"),\n",
    "#                 loss='categorical_crossentropy',\n",
    "#                 metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "#     fittedModel = model.fit(X_train, Y_train, batch_size = 32, epochs = 300, \n",
    "#                         verbose = 2,\n",
    "#                         validation_data=(X_val, Y_val),\n",
    "#                         callbacks=[checkpointer]\n",
    "#                            )\n",
    "    best_model = tf.keras.models.load_model('best_EEGNet_Left.h5')\n",
    "    #best_model = tf.keras.models.load_model('best_EEGNet_S1.h5')\n",
    "    probs       = best_model.predict(X_test)\n",
    "    preds       = probs.argmax(axis = -1)  \n",
    "    acc         = np.mean(preds == Y_test.argmax(axis=-1))\n",
    "    accuracies.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aed10dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.26666666666666666,\n",
       " 0.2222222222222222,\n",
       " 0.28888888888888886,\n",
       " 0.35555555555555557]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a2160cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2833333333333333"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(accuracies)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acd30a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 3, 3, 3, 0, 2, 3, 3, 1, 0, 1, 3, 3, 1, 2, 0, 2, 0, 3, 1, 0,\n",
       "       1, 1, 3, 2, 2, 0, 1, 2, 2, 0, 1, 2, 3, 0, 2, 0, 0, 2, 3, 0, 2, 0,\n",
       "       1, 1, 3, 0, 2, 3, 3, 0, 2, 1, 1, 1, 3, 1, 1, 2, 3, 1, 1, 0, 2, 3,\n",
       "       3, 0, 2, 0, 2, 2, 0, 0, 0, 1, 2, 3, 3, 2, 1, 1, 2, 2, 3, 0, 0, 2,\n",
       "       1, 1, 3, 1, 2, 0, 3, 0, 0, 0, 2, 1, 1, 1, 3, 2, 1, 2, 0, 1, 2, 3,\n",
       "       2, 3, 3, 0, 3, 3, 2, 3, 0, 0, 1, 1, 3, 1, 0, 3, 2, 2, 0, 0, 0, 0,\n",
       "       3, 0, 1, 2, 2, 2, 1, 2, 1, 2, 3, 3, 0, 3, 0, 0, 3, 1, 2, 1, 1, 0,\n",
       "       3, 2, 3, 3, 1, 2, 2, 2, 1, 2, 0, 0, 1, 1, 3, 2, 1, 2, 0, 1, 3, 3,\n",
       "       3, 3, 0, 0, 3, 0, 2, 1, 3, 3, 0, 1, 2, 2, 0, 0, 1, 3, 0, 3, 2, 1,\n",
       "       2, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9844ee4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "names = ['UP', 'DOWN', 'RIGHT', 'LEFT']\n",
    "confusion_matrix = metrics.confusion_matrix(Y_test.argmax(axis = -1), preds)\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels =names)\n",
    "cm_display.plot()\n",
    "plt.title('128-Channel Base EEGNet Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af853c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "kernLength = 72\n",
    "f1 = 24\n",
    "f2 = 8\n",
    "d = 116\n",
    "dr = 0.5\n",
    "av_accuracies = {1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0}\n",
    "av_precisions = {1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0}\n",
    "av_recalls = {1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0}\n",
    "av_F1s = {1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714ac7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Number of devices: 2\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 09:07:24.920123: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_8285312\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:544516\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
      "2022-11-11 09:07:29.057923: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_8288382\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:544558\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38633, saving model to checkpoint1.h5\n",
      "4/4 - 6s - loss: 1.5370 - accuracy: 0.2381 - val_loss: 1.3863 - val_accuracy: 0.1778 - 6s/epoch - 1s/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss did not improve from 1.38633\n",
      "4/4 - 0s - loss: 1.3401 - accuracy: 0.3714 - val_loss: 1.3867 - val_accuracy: 0.1778 - 305ms/epoch - 76ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss did not improve from 1.38633\n",
      "4/4 - 0s - loss: 1.2877 - accuracy: 0.4476 - val_loss: 1.3870 - val_accuracy: 0.1778 - 301ms/epoch - 75ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss did not improve from 1.38633\n",
      "4/4 - 0s - loss: 1.2414 - accuracy: 0.4952 - val_loss: 1.3873 - val_accuracy: 0.1778 - 294ms/epoch - 74ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss did not improve from 1.38633\n",
      "4/4 - 0s - loss: 1.2012 - accuracy: 0.5524 - val_loss: 1.3874 - val_accuracy: 0.2000 - 304ms/epoch - 76ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.38633\n",
      "4/4 - 0s - loss: 1.1992 - accuracy: 0.5619 - val_loss: 1.3875 - val_accuracy: 0.1778 - 297ms/epoch - 74ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 1.38633\n",
      "4/4 - 0s - loss: 1.1388 - accuracy: 0.5810 - val_loss: 1.3877 - val_accuracy: 0.2444 - 299ms/epoch - 75ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 1.38633\n",
      "4/4 - 0s - loss: 1.1325 - accuracy: 0.6000 - val_loss: 1.3877 - val_accuracy: 0.1556 - 298ms/epoch - 74ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 1.38633\n",
      "4/4 - 0s - loss: 1.1365 - accuracy: 0.5810 - val_loss: 1.3873 - val_accuracy: 0.2222 - 294ms/epoch - 74ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.38633\n",
      "4/4 - 0s - loss: 1.1139 - accuracy: 0.6286 - val_loss: 1.3873 - val_accuracy: 0.2000 - 309ms/epoch - 77ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.38633\n",
      "4/4 - 0s - loss: 1.0671 - accuracy: 0.6476 - val_loss: 1.3878 - val_accuracy: 0.2000 - 313ms/epoch - 78ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.38633\n",
      "4/4 - 0s - loss: 1.0458 - accuracy: 0.7333 - val_loss: 1.3883 - val_accuracy: 0.2000 - 311ms/epoch - 78ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.38633\n",
      "4/4 - 0s - loss: 1.0397 - accuracy: 0.6476 - val_loss: 1.3888 - val_accuracy: 0.2222 - 301ms/epoch - 75ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 1.38633\n",
      "4/4 - 0s - loss: 1.0301 - accuracy: 0.7333 - val_loss: 1.3883 - val_accuracy: 0.2222 - 294ms/epoch - 73ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.38633\n",
      "4/4 - 0s - loss: 1.0325 - accuracy: 0.6571 - val_loss: 1.3885 - val_accuracy: 0.2222 - 290ms/epoch - 72ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 1.38633\n",
      "4/4 - 0s - loss: 0.9724 - accuracy: 0.7619 - val_loss: 1.3905 - val_accuracy: 0.2222 - 302ms/epoch - 75ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 1.38633\n",
      "4/4 - 0s - loss: 0.9712 - accuracy: 0.7333 - val_loss: 1.3900 - val_accuracy: 0.2222 - 307ms/epoch - 77ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 1.38633\n",
      "4/4 - 0s - loss: 0.9767 - accuracy: 0.6952 - val_loss: 1.3886 - val_accuracy: 0.2222 - 296ms/epoch - 74ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 1.38633\n",
      "4/4 - 0s - loss: 0.9754 - accuracy: 0.6857 - val_loss: 1.3886 - val_accuracy: 0.1333 - 294ms/epoch - 73ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 1.38633\n",
      "4/4 - 0s - loss: 0.9565 - accuracy: 0.6762 - val_loss: 1.3876 - val_accuracy: 0.1778 - 293ms/epoch - 73ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 1.38633\n",
      "4/4 - 0s - loss: 0.9823 - accuracy: 0.6667 - val_loss: 1.3887 - val_accuracy: 0.2000 - 297ms/epoch - 74ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 1.38633\n",
      "4/4 - 0s - loss: 0.9547 - accuracy: 0.6667 - val_loss: 1.3903 - val_accuracy: 0.2000 - 300ms/epoch - 75ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 1.38633\n",
      "4/4 - 0s - loss: 0.9565 - accuracy: 0.7143 - val_loss: 1.3901 - val_accuracy: 0.2000 - 299ms/epoch - 75ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 1.38633\n",
      "4/4 - 0s - loss: 0.9258 - accuracy: 0.7619 - val_loss: 1.3873 - val_accuracy: 0.1556 - 290ms/epoch - 72ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.38633\n",
      "4/4 - 0s - loss: 0.9367 - accuracy: 0.7619 - val_loss: 1.3866 - val_accuracy: 0.2000 - 292ms/epoch - 73ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 1.38633\n",
      "4/4 - 0s - loss: 0.9080 - accuracy: 0.7524 - val_loss: 1.3881 - val_accuracy: 0.1778 - 290ms/epoch - 72ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 1.38633\n",
      "4/4 - 0s - loss: 0.8972 - accuracy: 0.7333 - val_loss: 1.3916 - val_accuracy: 0.2222 - 304ms/epoch - 76ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 1.38633\n",
      "4/4 - 0s - loss: 0.8756 - accuracy: 0.8000 - val_loss: 1.3941 - val_accuracy: 0.2000 - 298ms/epoch - 74ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 1.38633\n",
      "4/4 - 0s - loss: 0.9068 - accuracy: 0.7905 - val_loss: 1.3893 - val_accuracy: 0.2222 - 298ms/epoch - 74ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss improved from 1.38633 to 1.38616, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.8316 - accuracy: 0.8095 - val_loss: 1.3862 - val_accuracy: 0.2000 - 351ms/epoch - 88ms/step\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 1.38616\n",
      "4/4 - 0s - loss: 0.8447 - accuracy: 0.7810 - val_loss: 1.3903 - val_accuracy: 0.1556 - 292ms/epoch - 73ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 1.38616\n",
      "4/4 - 0s - loss: 0.8486 - accuracy: 0.7905 - val_loss: 1.3914 - val_accuracy: 0.2000 - 314ms/epoch - 79ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 1.38616\n",
      "4/4 - 0s - loss: 0.8939 - accuracy: 0.7524 - val_loss: 1.3885 - val_accuracy: 0.2000 - 291ms/epoch - 73ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 1.38616\n",
      "4/4 - 0s - loss: 0.8408 - accuracy: 0.7905 - val_loss: 1.3974 - val_accuracy: 0.1556 - 305ms/epoch - 76ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 1.38616\n",
      "4/4 - 0s - loss: 0.8480 - accuracy: 0.7714 - val_loss: 1.3957 - val_accuracy: 0.1556 - 303ms/epoch - 76ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss improved from 1.38616 to 1.37948, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.7999 - accuracy: 0.8095 - val_loss: 1.3795 - val_accuracy: 0.3111 - 349ms/epoch - 87ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.8284 - accuracy: 0.7905 - val_loss: 1.3843 - val_accuracy: 0.3333 - 297ms/epoch - 74ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.8112 - accuracy: 0.8190 - val_loss: 1.4012 - val_accuracy: 0.1111 - 320ms/epoch - 80ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.8289 - accuracy: 0.7905 - val_loss: 1.3940 - val_accuracy: 0.2000 - 295ms/epoch - 74ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.7706 - accuracy: 0.8476 - val_loss: 1.3860 - val_accuracy: 0.2444 - 295ms/epoch - 74ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.7790 - accuracy: 0.8095 - val_loss: 1.3899 - val_accuracy: 0.2667 - 314ms/epoch - 78ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.8036 - accuracy: 0.8095 - val_loss: 1.3905 - val_accuracy: 0.2444 - 292ms/epoch - 73ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.7804 - accuracy: 0.7905 - val_loss: 1.3852 - val_accuracy: 0.2667 - 306ms/epoch - 77ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.7642 - accuracy: 0.8476 - val_loss: 1.3945 - val_accuracy: 0.1778 - 292ms/epoch - 73ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.7466 - accuracy: 0.8667 - val_loss: 1.3949 - val_accuracy: 0.2000 - 304ms/epoch - 76ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.7455 - accuracy: 0.8571 - val_loss: 1.3828 - val_accuracy: 0.3333 - 306ms/epoch - 76ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.7365 - accuracy: 0.8571 - val_loss: 1.3926 - val_accuracy: 0.2889 - 310ms/epoch - 78ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.7494 - accuracy: 0.8095 - val_loss: 1.3920 - val_accuracy: 0.2889 - 297ms/epoch - 74ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.6950 - accuracy: 0.8571 - val_loss: 1.3980 - val_accuracy: 0.2222 - 297ms/epoch - 74ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.6979 - accuracy: 0.8857 - val_loss: 1.3966 - val_accuracy: 0.3111 - 304ms/epoch - 76ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.7005 - accuracy: 0.8667 - val_loss: 1.3917 - val_accuracy: 0.2889 - 293ms/epoch - 73ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.7001 - accuracy: 0.8381 - val_loss: 1.4037 - val_accuracy: 0.2667 - 300ms/epoch - 75ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.6941 - accuracy: 0.9048 - val_loss: 1.3849 - val_accuracy: 0.3333 - 307ms/epoch - 77ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.6747 - accuracy: 0.9143 - val_loss: 1.3969 - val_accuracy: 0.2889 - 307ms/epoch - 77ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.6679 - accuracy: 0.9143 - val_loss: 1.3945 - val_accuracy: 0.3111 - 306ms/epoch - 77ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.6641 - accuracy: 0.9238 - val_loss: 1.3983 - val_accuracy: 0.2667 - 307ms/epoch - 77ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.6307 - accuracy: 0.9333 - val_loss: 1.3916 - val_accuracy: 0.2667 - 305ms/epoch - 76ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.6263 - accuracy: 0.9048 - val_loss: 1.3978 - val_accuracy: 0.2667 - 312ms/epoch - 78ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.6242 - accuracy: 0.9524 - val_loss: 1.4021 - val_accuracy: 0.2444 - 290ms/epoch - 73ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.5866 - accuracy: 0.9429 - val_loss: 1.3846 - val_accuracy: 0.2444 - 294ms/epoch - 74ms/step\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.5592 - accuracy: 0.9333 - val_loss: 1.3955 - val_accuracy: 0.2444 - 318ms/epoch - 79ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.6047 - accuracy: 0.9048 - val_loss: 1.4246 - val_accuracy: 0.1778 - 297ms/epoch - 74ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.5511 - accuracy: 0.9429 - val_loss: 1.3901 - val_accuracy: 0.2889 - 297ms/epoch - 74ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.5844 - accuracy: 0.9333 - val_loss: 1.3998 - val_accuracy: 0.2222 - 309ms/epoch - 77ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.5400 - accuracy: 0.9714 - val_loss: 1.4002 - val_accuracy: 0.3111 - 299ms/epoch - 75ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.5419 - accuracy: 0.9429 - val_loss: 1.4154 - val_accuracy: 0.2000 - 293ms/epoch - 73ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.5326 - accuracy: 0.9429 - val_loss: 1.3885 - val_accuracy: 0.3333 - 316ms/epoch - 79ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.5490 - accuracy: 0.9524 - val_loss: 1.4158 - val_accuracy: 0.2667 - 310ms/epoch - 78ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.5367 - accuracy: 0.9429 - val_loss: 1.4150 - val_accuracy: 0.3333 - 301ms/epoch - 75ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.5300 - accuracy: 0.9619 - val_loss: 1.5044 - val_accuracy: 0.1111 - 306ms/epoch - 76ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.5353 - accuracy: 0.9429 - val_loss: 1.4128 - val_accuracy: 0.2444 - 309ms/epoch - 77ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.4937 - accuracy: 0.9619 - val_loss: 1.4312 - val_accuracy: 0.2000 - 304ms/epoch - 76ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.5379 - accuracy: 0.9429 - val_loss: 1.4243 - val_accuracy: 0.2667 - 298ms/epoch - 75ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.4715 - accuracy: 0.9619 - val_loss: 1.3948 - val_accuracy: 0.2667 - 306ms/epoch - 77ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.5522 - accuracy: 0.9429 - val_loss: 1.4580 - val_accuracy: 0.2222 - 296ms/epoch - 74ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.5231 - accuracy: 0.9333 - val_loss: 1.4746 - val_accuracy: 0.2889 - 313ms/epoch - 78ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.4994 - accuracy: 0.9619 - val_loss: 1.4223 - val_accuracy: 0.3111 - 327ms/epoch - 82ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.4954 - accuracy: 0.9714 - val_loss: 1.5095 - val_accuracy: 0.2000 - 307ms/epoch - 77ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.5102 - accuracy: 0.9714 - val_loss: 1.4423 - val_accuracy: 0.2889 - 299ms/epoch - 75ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.5023 - accuracy: 0.9714 - val_loss: 1.4609 - val_accuracy: 0.1778 - 306ms/epoch - 76ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.4811 - accuracy: 0.9619 - val_loss: 1.5154 - val_accuracy: 0.2222 - 307ms/epoch - 77ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.4641 - accuracy: 0.9714 - val_loss: 1.6150 - val_accuracy: 0.1556 - 294ms/epoch - 73ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.4704 - accuracy: 0.9619 - val_loss: 1.4496 - val_accuracy: 0.3111 - 309ms/epoch - 77ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.4471 - accuracy: 0.9619 - val_loss: 1.4840 - val_accuracy: 0.2222 - 310ms/epoch - 77ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.4371 - accuracy: 0.9810 - val_loss: 1.4725 - val_accuracy: 0.2667 - 297ms/epoch - 74ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.4156 - accuracy: 0.9810 - val_loss: 1.4650 - val_accuracy: 0.3111 - 302ms/epoch - 75ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.3842 - accuracy: 0.9905 - val_loss: 1.4994 - val_accuracy: 0.2444 - 310ms/epoch - 77ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.4115 - accuracy: 0.9714 - val_loss: 1.4477 - val_accuracy: 0.3333 - 293ms/epoch - 73ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.4011 - accuracy: 0.9905 - val_loss: 1.4478 - val_accuracy: 0.3111 - 300ms/epoch - 75ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.4064 - accuracy: 0.9714 - val_loss: 1.4703 - val_accuracy: 0.2444 - 298ms/epoch - 75ms/step\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.3603 - accuracy: 1.0000 - val_loss: 1.4606 - val_accuracy: 0.2889 - 295ms/epoch - 74ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.3843 - accuracy: 0.9905 - val_loss: 1.5069 - val_accuracy: 0.1778 - 306ms/epoch - 77ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.3715 - accuracy: 0.9905 - val_loss: 1.6123 - val_accuracy: 0.1333 - 304ms/epoch - 76ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.4038 - accuracy: 1.0000 - val_loss: 1.5475 - val_accuracy: 0.2222 - 300ms/epoch - 75ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 1.37948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.4071 - accuracy: 0.9905 - val_loss: 1.5145 - val_accuracy: 0.2222 - 302ms/epoch - 75ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.4257 - accuracy: 0.9810 - val_loss: 1.5816 - val_accuracy: 0.2222 - 298ms/epoch - 74ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.3993 - accuracy: 0.9905 - val_loss: 1.5119 - val_accuracy: 0.2667 - 291ms/epoch - 73ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.4238 - accuracy: 0.9810 - val_loss: 1.6158 - val_accuracy: 0.2444 - 305ms/epoch - 76ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.3713 - accuracy: 0.9905 - val_loss: 1.5458 - val_accuracy: 0.2444 - 293ms/epoch - 73ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.3922 - accuracy: 0.9714 - val_loss: 1.5244 - val_accuracy: 0.2444 - 311ms/epoch - 78ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.3406 - accuracy: 0.9905 - val_loss: 1.5404 - val_accuracy: 0.2222 - 307ms/epoch - 77ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.3556 - accuracy: 0.9619 - val_loss: 1.6134 - val_accuracy: 0.1556 - 297ms/epoch - 74ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.3946 - accuracy: 0.9619 - val_loss: 1.5661 - val_accuracy: 0.2222 - 308ms/epoch - 77ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.3809 - accuracy: 0.9810 - val_loss: 1.8173 - val_accuracy: 0.2222 - 304ms/epoch - 76ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.4034 - accuracy: 0.9524 - val_loss: 1.6601 - val_accuracy: 0.2000 - 294ms/epoch - 74ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.4328 - accuracy: 0.9619 - val_loss: 1.4765 - val_accuracy: 0.3556 - 300ms/epoch - 75ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.4300 - accuracy: 0.9905 - val_loss: 1.9892 - val_accuracy: 0.2222 - 324ms/epoch - 81ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.4328 - accuracy: 0.9524 - val_loss: 2.0245 - val_accuracy: 0.1778 - 314ms/epoch - 78ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.4177 - accuracy: 0.9619 - val_loss: 1.5960 - val_accuracy: 0.3111 - 304ms/epoch - 76ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.4264 - accuracy: 0.9619 - val_loss: 1.8142 - val_accuracy: 0.2000 - 297ms/epoch - 74ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.3715 - accuracy: 0.9905 - val_loss: 1.5550 - val_accuracy: 0.3111 - 302ms/epoch - 76ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.3279 - accuracy: 1.0000 - val_loss: 1.6391 - val_accuracy: 0.2444 - 298ms/epoch - 75ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.3275 - accuracy: 0.9905 - val_loss: 1.6012 - val_accuracy: 0.3111 - 311ms/epoch - 78ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 1.37948\n",
      "4/4 - 1s - loss: 0.3544 - accuracy: 0.9810 - val_loss: 1.6165 - val_accuracy: 0.3333 - 668ms/epoch - 167ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.3318 - accuracy: 0.9714 - val_loss: 1.6154 - val_accuracy: 0.2444 - 311ms/epoch - 78ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.3088 - accuracy: 0.9905 - val_loss: 1.6763 - val_accuracy: 0.2222 - 303ms/epoch - 76ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.3107 - accuracy: 1.0000 - val_loss: 1.6984 - val_accuracy: 0.2222 - 306ms/epoch - 76ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.3226 - accuracy: 1.0000 - val_loss: 1.7934 - val_accuracy: 0.2667 - 324ms/epoch - 81ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.3073 - accuracy: 1.0000 - val_loss: 1.6905 - val_accuracy: 0.2667 - 312ms/epoch - 78ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2789 - accuracy: 1.0000 - val_loss: 1.6494 - val_accuracy: 0.2667 - 314ms/epoch - 79ms/step\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2638 - accuracy: 1.0000 - val_loss: 1.6843 - val_accuracy: 0.2222 - 318ms/epoch - 80ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2946 - accuracy: 0.9905 - val_loss: 1.6619 - val_accuracy: 0.2889 - 320ms/epoch - 80ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.3031 - accuracy: 0.9714 - val_loss: 1.7053 - val_accuracy: 0.2667 - 304ms/epoch - 76ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2911 - accuracy: 0.9810 - val_loss: 1.6921 - val_accuracy: 0.2000 - 304ms/epoch - 76ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.3412 - accuracy: 1.0000 - val_loss: 1.6748 - val_accuracy: 0.2444 - 306ms/epoch - 76ms/step\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2756 - accuracy: 1.0000 - val_loss: 1.8031 - val_accuracy: 0.2444 - 310ms/epoch - 78ms/step\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2682 - accuracy: 1.0000 - val_loss: 1.8268 - val_accuracy: 0.3333 - 305ms/epoch - 76ms/step\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2818 - accuracy: 0.9905 - val_loss: 2.0044 - val_accuracy: 0.3111 - 313ms/epoch - 78ms/step\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2752 - accuracy: 0.9905 - val_loss: 1.7923 - val_accuracy: 0.2444 - 300ms/epoch - 75ms/step\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2823 - accuracy: 1.0000 - val_loss: 1.7052 - val_accuracy: 0.2889 - 310ms/epoch - 77ms/step\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2761 - accuracy: 1.0000 - val_loss: 1.7872 - val_accuracy: 0.2889 - 303ms/epoch - 76ms/step\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2612 - accuracy: 1.0000 - val_loss: 1.7539 - val_accuracy: 0.3111 - 320ms/epoch - 80ms/step\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2609 - accuracy: 0.9905 - val_loss: 1.7461 - val_accuracy: 0.2667 - 313ms/epoch - 78ms/step\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2765 - accuracy: 0.9905 - val_loss: 1.7371 - val_accuracy: 0.2889 - 314ms/epoch - 79ms/step\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 135: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2208 - accuracy: 1.0000 - val_loss: 1.9118 - val_accuracy: 0.2889 - 306ms/epoch - 77ms/step\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 136: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2601 - accuracy: 1.0000 - val_loss: 1.8301 - val_accuracy: 0.1778 - 302ms/epoch - 75ms/step\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 137: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2387 - accuracy: 1.0000 - val_loss: 1.9220 - val_accuracy: 0.1778 - 305ms/epoch - 76ms/step\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 138: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2539 - accuracy: 0.9905 - val_loss: 1.7220 - val_accuracy: 0.2444 - 302ms/epoch - 75ms/step\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 139: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2810 - accuracy: 1.0000 - val_loss: 1.8280 - val_accuracy: 0.3111 - 318ms/epoch - 79ms/step\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 140: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2579 - accuracy: 0.9905 - val_loss: 2.0173 - val_accuracy: 0.2444 - 303ms/epoch - 76ms/step\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 141: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2509 - accuracy: 0.9905 - val_loss: 1.9136 - val_accuracy: 0.2889 - 319ms/epoch - 80ms/step\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 142: val_loss did not improve from 1.37948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.2347 - accuracy: 1.0000 - val_loss: 2.0352 - val_accuracy: 0.2000 - 314ms/epoch - 79ms/step\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 143: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2634 - accuracy: 1.0000 - val_loss: 1.7201 - val_accuracy: 0.2444 - 304ms/epoch - 76ms/step\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 144: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2292 - accuracy: 0.9905 - val_loss: 1.8290 - val_accuracy: 0.3111 - 322ms/epoch - 81ms/step\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 145: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2501 - accuracy: 1.0000 - val_loss: 1.6648 - val_accuracy: 0.3111 - 328ms/epoch - 82ms/step\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 146: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2454 - accuracy: 1.0000 - val_loss: 1.7897 - val_accuracy: 0.2667 - 307ms/epoch - 77ms/step\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 147: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2692 - accuracy: 0.9905 - val_loss: 1.8243 - val_accuracy: 0.2444 - 318ms/epoch - 79ms/step\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 148: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 1.8612 - val_accuracy: 0.2444 - 312ms/epoch - 78ms/step\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 149: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2558 - accuracy: 1.0000 - val_loss: 1.8992 - val_accuracy: 0.2444 - 325ms/epoch - 81ms/step\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 150: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2493 - accuracy: 0.9905 - val_loss: 2.1392 - val_accuracy: 0.2444 - 302ms/epoch - 75ms/step\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 151: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2906 - accuracy: 0.9714 - val_loss: 1.9289 - val_accuracy: 0.2000 - 306ms/epoch - 76ms/step\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 152: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2617 - accuracy: 0.9905 - val_loss: 1.8523 - val_accuracy: 0.3111 - 309ms/epoch - 77ms/step\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 153: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2434 - accuracy: 0.9905 - val_loss: 1.9108 - val_accuracy: 0.2444 - 302ms/epoch - 75ms/step\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 154: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2423 - accuracy: 1.0000 - val_loss: 1.7498 - val_accuracy: 0.3111 - 307ms/epoch - 77ms/step\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 155: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2053 - accuracy: 1.0000 - val_loss: 1.9502 - val_accuracy: 0.2222 - 308ms/epoch - 77ms/step\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 156: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2059 - accuracy: 0.9905 - val_loss: 1.7550 - val_accuracy: 0.2889 - 301ms/epoch - 75ms/step\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 157: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2139 - accuracy: 1.0000 - val_loss: 1.8634 - val_accuracy: 0.2222 - 303ms/epoch - 76ms/step\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 158: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 1.8414 - val_accuracy: 0.2444 - 315ms/epoch - 79ms/step\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 159: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2401 - accuracy: 0.9905 - val_loss: 1.8422 - val_accuracy: 0.2889 - 305ms/epoch - 76ms/step\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 160: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 1.9520 - val_accuracy: 0.2444 - 305ms/epoch - 76ms/step\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 161: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2036 - accuracy: 1.0000 - val_loss: 1.9260 - val_accuracy: 0.2667 - 305ms/epoch - 76ms/step\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 162: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2038 - accuracy: 1.0000 - val_loss: 2.0337 - val_accuracy: 0.2444 - 313ms/epoch - 78ms/step\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 163: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2059 - accuracy: 1.0000 - val_loss: 2.3020 - val_accuracy: 0.2222 - 313ms/epoch - 78ms/step\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 164: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.2015 - accuracy: 1.0000 - val_loss: 2.0244 - val_accuracy: 0.2000 - 305ms/epoch - 76ms/step\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 165: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1838 - accuracy: 1.0000 - val_loss: 1.9202 - val_accuracy: 0.2444 - 316ms/epoch - 79ms/step\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 166: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1815 - accuracy: 1.0000 - val_loss: 2.1160 - val_accuracy: 0.2889 - 321ms/epoch - 80ms/step\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 167: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1761 - accuracy: 1.0000 - val_loss: 2.0840 - val_accuracy: 0.2444 - 324ms/epoch - 81ms/step\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 168: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1782 - accuracy: 1.0000 - val_loss: 2.0509 - val_accuracy: 0.2222 - 315ms/epoch - 79ms/step\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 169: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1854 - accuracy: 1.0000 - val_loss: 1.8023 - val_accuracy: 0.2667 - 321ms/epoch - 80ms/step\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 170: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1616 - accuracy: 1.0000 - val_loss: 1.8458 - val_accuracy: 0.3333 - 317ms/epoch - 79ms/step\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 171: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1796 - accuracy: 1.0000 - val_loss: 2.0555 - val_accuracy: 0.2222 - 307ms/epoch - 77ms/step\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 172: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1667 - accuracy: 1.0000 - val_loss: 1.8876 - val_accuracy: 0.3111 - 326ms/epoch - 82ms/step\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 173: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1711 - accuracy: 1.0000 - val_loss: 1.9037 - val_accuracy: 0.2444 - 321ms/epoch - 80ms/step\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 174: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1713 - accuracy: 1.0000 - val_loss: 1.9995 - val_accuracy: 0.2000 - 313ms/epoch - 78ms/step\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 175: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1814 - accuracy: 0.9905 - val_loss: 1.8858 - val_accuracy: 0.2222 - 308ms/epoch - 77ms/step\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 176: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1744 - accuracy: 1.0000 - val_loss: 1.9648 - val_accuracy: 0.1778 - 313ms/epoch - 78ms/step\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 177: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1829 - accuracy: 1.0000 - val_loss: 1.8507 - val_accuracy: 0.2222 - 313ms/epoch - 78ms/step\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 178: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1927 - accuracy: 0.9905 - val_loss: 1.8954 - val_accuracy: 0.2000 - 321ms/epoch - 80ms/step\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 179: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1723 - accuracy: 1.0000 - val_loss: 1.9534 - val_accuracy: 0.2000 - 317ms/epoch - 79ms/step\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 180: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1829 - accuracy: 1.0000 - val_loss: 1.7877 - val_accuracy: 0.2889 - 310ms/epoch - 77ms/step\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 181: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1906 - accuracy: 1.0000 - val_loss: 2.0731 - val_accuracy: 0.2222 - 310ms/epoch - 77ms/step\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 182: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1695 - accuracy: 1.0000 - val_loss: 1.7914 - val_accuracy: 0.2889 - 302ms/epoch - 76ms/step\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 183: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1630 - accuracy: 1.0000 - val_loss: 1.8466 - val_accuracy: 0.2444 - 311ms/epoch - 78ms/step\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 184: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1675 - accuracy: 1.0000 - val_loss: 1.9056 - val_accuracy: 0.2444 - 317ms/epoch - 79ms/step\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 185: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1599 - accuracy: 1.0000 - val_loss: 1.7499 - val_accuracy: 0.2889 - 314ms/epoch - 78ms/step\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 186: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1653 - accuracy: 1.0000 - val_loss: 1.8754 - val_accuracy: 0.2667 - 302ms/epoch - 75ms/step\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 187: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1807 - accuracy: 1.0000 - val_loss: 1.8686 - val_accuracy: 0.3333 - 300ms/epoch - 75ms/step\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 188: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1724 - accuracy: 1.0000 - val_loss: 1.8817 - val_accuracy: 0.2667 - 328ms/epoch - 82ms/step\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 189: val_loss did not improve from 1.37948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.1648 - accuracy: 1.0000 - val_loss: 2.0962 - val_accuracy: 0.1778 - 308ms/epoch - 77ms/step\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 190: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1631 - accuracy: 1.0000 - val_loss: 1.7535 - val_accuracy: 0.2889 - 307ms/epoch - 77ms/step\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 191: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1679 - accuracy: 1.0000 - val_loss: 1.9255 - val_accuracy: 0.3333 - 310ms/epoch - 78ms/step\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 192: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1581 - accuracy: 1.0000 - val_loss: 2.0890 - val_accuracy: 0.2889 - 313ms/epoch - 78ms/step\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 193: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1408 - accuracy: 1.0000 - val_loss: 2.0353 - val_accuracy: 0.2667 - 303ms/epoch - 76ms/step\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 194: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1601 - accuracy: 1.0000 - val_loss: 1.9073 - val_accuracy: 0.3111 - 303ms/epoch - 76ms/step\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 195: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1517 - accuracy: 1.0000 - val_loss: 1.8030 - val_accuracy: 0.3556 - 302ms/epoch - 76ms/step\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 196: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1347 - accuracy: 1.0000 - val_loss: 1.8618 - val_accuracy: 0.3111 - 309ms/epoch - 77ms/step\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 197: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1628 - accuracy: 1.0000 - val_loss: 1.8624 - val_accuracy: 0.3111 - 303ms/epoch - 76ms/step\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 198: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1472 - accuracy: 1.0000 - val_loss: 2.0337 - val_accuracy: 0.2222 - 310ms/epoch - 77ms/step\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 199: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1431 - accuracy: 1.0000 - val_loss: 1.9530 - val_accuracy: 0.2667 - 304ms/epoch - 76ms/step\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 200: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1487 - accuracy: 1.0000 - val_loss: 1.9785 - val_accuracy: 0.2667 - 300ms/epoch - 75ms/step\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 201: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1454 - accuracy: 1.0000 - val_loss: 2.0363 - val_accuracy: 0.2889 - 311ms/epoch - 78ms/step\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 202: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1507 - accuracy: 1.0000 - val_loss: 1.8775 - val_accuracy: 0.2889 - 312ms/epoch - 78ms/step\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 203: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1418 - accuracy: 1.0000 - val_loss: 2.1356 - val_accuracy: 0.2222 - 307ms/epoch - 77ms/step\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 204: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1385 - accuracy: 1.0000 - val_loss: 1.9761 - val_accuracy: 0.3111 - 302ms/epoch - 75ms/step\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 205: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1278 - accuracy: 1.0000 - val_loss: 2.1045 - val_accuracy: 0.2667 - 318ms/epoch - 80ms/step\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 206: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1406 - accuracy: 1.0000 - val_loss: 2.1232 - val_accuracy: 0.1778 - 304ms/epoch - 76ms/step\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 207: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1674 - accuracy: 0.9905 - val_loss: 1.9812 - val_accuracy: 0.2222 - 309ms/epoch - 77ms/step\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 208: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1246 - accuracy: 1.0000 - val_loss: 1.9451 - val_accuracy: 0.2667 - 322ms/epoch - 80ms/step\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 209: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1381 - accuracy: 1.0000 - val_loss: 1.9477 - val_accuracy: 0.2444 - 301ms/epoch - 75ms/step\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 210: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1470 - accuracy: 1.0000 - val_loss: 2.2032 - val_accuracy: 0.2222 - 303ms/epoch - 76ms/step\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 211: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1559 - accuracy: 1.0000 - val_loss: 2.1305 - val_accuracy: 0.2222 - 305ms/epoch - 76ms/step\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 212: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1639 - accuracy: 1.0000 - val_loss: 2.4553 - val_accuracy: 0.1556 - 301ms/epoch - 75ms/step\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 213: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1568 - accuracy: 1.0000 - val_loss: 2.4586 - val_accuracy: 0.2444 - 309ms/epoch - 77ms/step\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 214: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1522 - accuracy: 1.0000 - val_loss: 2.5086 - val_accuracy: 0.2444 - 323ms/epoch - 81ms/step\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 215: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1452 - accuracy: 1.0000 - val_loss: 2.3165 - val_accuracy: 0.2000 - 296ms/epoch - 74ms/step\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 216: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1638 - accuracy: 0.9905 - val_loss: 2.0154 - val_accuracy: 0.2444 - 315ms/epoch - 79ms/step\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 217: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1442 - accuracy: 1.0000 - val_loss: 2.2625 - val_accuracy: 0.1778 - 309ms/epoch - 77ms/step\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 218: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1669 - accuracy: 0.9905 - val_loss: 1.9513 - val_accuracy: 0.2667 - 303ms/epoch - 76ms/step\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 219: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1652 - accuracy: 1.0000 - val_loss: 1.9226 - val_accuracy: 0.3111 - 311ms/epoch - 78ms/step\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 220: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1635 - accuracy: 1.0000 - val_loss: 1.9980 - val_accuracy: 0.3556 - 306ms/epoch - 76ms/step\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 221: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1355 - accuracy: 1.0000 - val_loss: 2.0994 - val_accuracy: 0.2889 - 309ms/epoch - 77ms/step\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 222: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1410 - accuracy: 1.0000 - val_loss: 2.6033 - val_accuracy: 0.2000 - 301ms/epoch - 75ms/step\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 223: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1457 - accuracy: 1.0000 - val_loss: 1.9734 - val_accuracy: 0.3111 - 302ms/epoch - 75ms/step\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 224: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1495 - accuracy: 1.0000 - val_loss: 1.8761 - val_accuracy: 0.2889 - 301ms/epoch - 75ms/step\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 225: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1333 - accuracy: 1.0000 - val_loss: 1.9864 - val_accuracy: 0.2444 - 317ms/epoch - 79ms/step\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 226: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1341 - accuracy: 1.0000 - val_loss: 2.0340 - val_accuracy: 0.2222 - 327ms/epoch - 82ms/step\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 227: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1306 - accuracy: 1.0000 - val_loss: 1.9975 - val_accuracy: 0.2222 - 303ms/epoch - 76ms/step\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 228: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1068 - accuracy: 1.0000 - val_loss: 2.2826 - val_accuracy: 0.2000 - 309ms/epoch - 77ms/step\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 229: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1237 - accuracy: 1.0000 - val_loss: 2.2367 - val_accuracy: 0.2444 - 306ms/epoch - 77ms/step\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 230: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1260 - accuracy: 1.0000 - val_loss: 2.3355 - val_accuracy: 0.2444 - 299ms/epoch - 75ms/step\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 231: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1189 - accuracy: 1.0000 - val_loss: 2.3528 - val_accuracy: 0.2000 - 314ms/epoch - 78ms/step\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 232: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1211 - accuracy: 1.0000 - val_loss: 1.9813 - val_accuracy: 0.2667 - 303ms/epoch - 76ms/step\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 233: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1159 - accuracy: 1.0000 - val_loss: 2.0343 - val_accuracy: 0.2222 - 301ms/epoch - 75ms/step\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 234: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1201 - accuracy: 1.0000 - val_loss: 2.1682 - val_accuracy: 0.2444 - 320ms/epoch - 80ms/step\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 235: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1244 - accuracy: 1.0000 - val_loss: 2.1889 - val_accuracy: 0.2444 - 302ms/epoch - 75ms/step\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 236: val_loss did not improve from 1.37948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.1347 - accuracy: 1.0000 - val_loss: 2.0879 - val_accuracy: 0.2667 - 304ms/epoch - 76ms/step\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 237: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1197 - accuracy: 1.0000 - val_loss: 2.0158 - val_accuracy: 0.2444 - 317ms/epoch - 79ms/step\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 238: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1156 - accuracy: 1.0000 - val_loss: 1.8949 - val_accuracy: 0.3111 - 308ms/epoch - 77ms/step\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 239: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1178 - accuracy: 1.0000 - val_loss: 1.8532 - val_accuracy: 0.3111 - 312ms/epoch - 78ms/step\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 240: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1091 - accuracy: 1.0000 - val_loss: 1.9003 - val_accuracy: 0.2889 - 310ms/epoch - 78ms/step\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 241: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1073 - accuracy: 1.0000 - val_loss: 2.0015 - val_accuracy: 0.2000 - 319ms/epoch - 80ms/step\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 242: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1206 - accuracy: 1.0000 - val_loss: 1.9315 - val_accuracy: 0.2667 - 312ms/epoch - 78ms/step\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 243: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1376 - accuracy: 1.0000 - val_loss: 1.9554 - val_accuracy: 0.2889 - 308ms/epoch - 77ms/step\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 244: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1294 - accuracy: 1.0000 - val_loss: 2.0661 - val_accuracy: 0.3111 - 307ms/epoch - 77ms/step\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 245: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1218 - accuracy: 1.0000 - val_loss: 1.9209 - val_accuracy: 0.3333 - 306ms/epoch - 76ms/step\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 246: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1104 - accuracy: 1.0000 - val_loss: 2.0039 - val_accuracy: 0.2000 - 301ms/epoch - 75ms/step\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 247: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1338 - accuracy: 1.0000 - val_loss: 1.9803 - val_accuracy: 0.2444 - 306ms/epoch - 77ms/step\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 248: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1218 - accuracy: 1.0000 - val_loss: 1.8557 - val_accuracy: 0.2667 - 297ms/epoch - 74ms/step\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 249: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1130 - accuracy: 1.0000 - val_loss: 1.8928 - val_accuracy: 0.2444 - 295ms/epoch - 74ms/step\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 250: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1280 - accuracy: 1.0000 - val_loss: 1.8310 - val_accuracy: 0.3333 - 322ms/epoch - 81ms/step\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 251: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1169 - accuracy: 1.0000 - val_loss: 1.9664 - val_accuracy: 0.2667 - 303ms/epoch - 76ms/step\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 252: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1045 - accuracy: 1.0000 - val_loss: 1.8712 - val_accuracy: 0.2889 - 305ms/epoch - 76ms/step\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 253: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.0963 - accuracy: 1.0000 - val_loss: 1.8660 - val_accuracy: 0.2889 - 303ms/epoch - 76ms/step\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 254: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1078 - accuracy: 1.0000 - val_loss: 1.9339 - val_accuracy: 0.3333 - 305ms/epoch - 76ms/step\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 255: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.0996 - accuracy: 1.0000 - val_loss: 1.9323 - val_accuracy: 0.3111 - 298ms/epoch - 74ms/step\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 256: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1058 - accuracy: 1.0000 - val_loss: 2.0118 - val_accuracy: 0.2444 - 315ms/epoch - 79ms/step\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 257: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1057 - accuracy: 1.0000 - val_loss: 2.0258 - val_accuracy: 0.2667 - 309ms/epoch - 77ms/step\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 258: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1067 - accuracy: 1.0000 - val_loss: 1.9972 - val_accuracy: 0.2667 - 310ms/epoch - 77ms/step\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 259: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1078 - accuracy: 1.0000 - val_loss: 2.0587 - val_accuracy: 0.2889 - 319ms/epoch - 80ms/step\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 260: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1200 - accuracy: 1.0000 - val_loss: 1.9856 - val_accuracy: 0.2667 - 308ms/epoch - 77ms/step\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 261: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1248 - accuracy: 1.0000 - val_loss: 2.1994 - val_accuracy: 0.2444 - 305ms/epoch - 76ms/step\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 262: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1444 - accuracy: 1.0000 - val_loss: 2.2592 - val_accuracy: 0.2444 - 317ms/epoch - 79ms/step\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 263: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1262 - accuracy: 1.0000 - val_loss: 1.9021 - val_accuracy: 0.3333 - 300ms/epoch - 75ms/step\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 264: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1161 - accuracy: 1.0000 - val_loss: 2.0544 - val_accuracy: 0.2222 - 302ms/epoch - 76ms/step\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 265: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1149 - accuracy: 1.0000 - val_loss: 2.0436 - val_accuracy: 0.1778 - 310ms/epoch - 77ms/step\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 266: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1229 - accuracy: 1.0000 - val_loss: 2.0164 - val_accuracy: 0.2667 - 305ms/epoch - 76ms/step\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 267: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1075 - accuracy: 1.0000 - val_loss: 2.0802 - val_accuracy: 0.1333 - 294ms/epoch - 74ms/step\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 268: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1109 - accuracy: 1.0000 - val_loss: 2.0777 - val_accuracy: 0.2444 - 309ms/epoch - 77ms/step\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 269: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.1015 - accuracy: 1.0000 - val_loss: 2.0875 - val_accuracy: 0.2222 - 300ms/epoch - 75ms/step\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 270: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.0882 - accuracy: 1.0000 - val_loss: 2.1993 - val_accuracy: 0.2222 - 305ms/epoch - 76ms/step\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 271: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.0851 - accuracy: 1.0000 - val_loss: 2.1853 - val_accuracy: 0.1778 - 301ms/epoch - 75ms/step\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 272: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.0939 - accuracy: 1.0000 - val_loss: 2.1756 - val_accuracy: 0.2000 - 310ms/epoch - 78ms/step\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 273: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.0868 - accuracy: 1.0000 - val_loss: 2.1849 - val_accuracy: 0.2000 - 312ms/epoch - 78ms/step\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 274: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.0885 - accuracy: 1.0000 - val_loss: 2.0507 - val_accuracy: 0.2444 - 308ms/epoch - 77ms/step\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 275: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.0917 - accuracy: 1.0000 - val_loss: 2.0201 - val_accuracy: 0.1778 - 319ms/epoch - 80ms/step\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 276: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.0926 - accuracy: 1.0000 - val_loss: 1.9058 - val_accuracy: 0.2667 - 311ms/epoch - 78ms/step\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 277: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.0945 - accuracy: 1.0000 - val_loss: 1.9675 - val_accuracy: 0.2222 - 327ms/epoch - 82ms/step\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 278: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.0880 - accuracy: 1.0000 - val_loss: 1.9735 - val_accuracy: 0.2444 - 303ms/epoch - 76ms/step\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 279: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.0773 - accuracy: 1.0000 - val_loss: 1.9740 - val_accuracy: 0.2667 - 302ms/epoch - 75ms/step\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 280: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.0922 - accuracy: 1.0000 - val_loss: 1.9599 - val_accuracy: 0.2889 - 322ms/epoch - 81ms/step\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 281: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.0830 - accuracy: 1.0000 - val_loss: 2.0188 - val_accuracy: 0.2222 - 306ms/epoch - 77ms/step\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 282: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.0717 - accuracy: 1.0000 - val_loss: 2.2285 - val_accuracy: 0.2000 - 310ms/epoch - 77ms/step\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 283: val_loss did not improve from 1.37948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.0947 - accuracy: 1.0000 - val_loss: 2.1562 - val_accuracy: 0.2222 - 306ms/epoch - 77ms/step\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 284: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.0934 - accuracy: 1.0000 - val_loss: 1.9745 - val_accuracy: 0.2444 - 291ms/epoch - 73ms/step\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 285: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.0809 - accuracy: 1.0000 - val_loss: 2.1109 - val_accuracy: 0.1778 - 300ms/epoch - 75ms/step\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 286: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.0914 - accuracy: 1.0000 - val_loss: 2.2975 - val_accuracy: 0.1556 - 305ms/epoch - 76ms/step\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 287: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.0830 - accuracy: 1.0000 - val_loss: 2.1078 - val_accuracy: 0.2222 - 307ms/epoch - 77ms/step\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 288: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.0869 - accuracy: 1.0000 - val_loss: 2.0461 - val_accuracy: 0.2444 - 305ms/epoch - 76ms/step\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 289: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.0951 - accuracy: 0.9905 - val_loss: 1.9639 - val_accuracy: 0.2444 - 312ms/epoch - 78ms/step\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 290: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.0880 - accuracy: 1.0000 - val_loss: 1.9690 - val_accuracy: 0.2889 - 298ms/epoch - 75ms/step\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 291: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.0859 - accuracy: 1.0000 - val_loss: 2.2706 - val_accuracy: 0.2889 - 298ms/epoch - 75ms/step\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 292: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.0829 - accuracy: 1.0000 - val_loss: 2.0940 - val_accuracy: 0.2667 - 327ms/epoch - 82ms/step\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 293: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.0867 - accuracy: 1.0000 - val_loss: 2.0530 - val_accuracy: 0.2444 - 305ms/epoch - 76ms/step\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 294: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.0870 - accuracy: 1.0000 - val_loss: 2.0226 - val_accuracy: 0.2444 - 305ms/epoch - 76ms/step\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 295: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.0703 - accuracy: 1.0000 - val_loss: 2.0823 - val_accuracy: 0.2444 - 302ms/epoch - 76ms/step\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 296: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.0872 - accuracy: 1.0000 - val_loss: 2.1187 - val_accuracy: 0.2000 - 317ms/epoch - 79ms/step\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 297: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.0863 - accuracy: 1.0000 - val_loss: 1.9824 - val_accuracy: 0.2889 - 303ms/epoch - 76ms/step\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 298: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.0793 - accuracy: 1.0000 - val_loss: 2.0870 - val_accuracy: 0.2000 - 309ms/epoch - 77ms/step\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 299: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.0768 - accuracy: 1.0000 - val_loss: 2.0747 - val_accuracy: 0.2444 - 310ms/epoch - 78ms/step\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 300: val_loss did not improve from 1.37948\n",
      "4/4 - 0s - loss: 0.0963 - accuracy: 1.0000 - val_loss: 2.2273 - val_accuracy: 0.2667 - 299ms/epoch - 75ms/step\n",
      "2/2 [==============================] - 0s 43ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2022-11-11 09:09:05.976276: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_8349944\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:548770\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 09:09:09.921175: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_8353014\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:548812\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38648, saving model to checkpoint1.h5\n",
      "4/4 - 5s - loss: 1.4732 - accuracy: 0.2286 - val_loss: 1.3865 - val_accuracy: 0.2000 - 5s/epoch - 1s/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss did not improve from 1.38648\n",
      "4/4 - 0s - loss: 1.3328 - accuracy: 0.4095 - val_loss: 1.3867 - val_accuracy: 0.2000 - 309ms/epoch - 77ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss did not improve from 1.38648\n",
      "4/4 - 0s - loss: 1.2820 - accuracy: 0.3810 - val_loss: 1.3868 - val_accuracy: 0.2000 - 298ms/epoch - 74ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss did not improve from 1.38648\n",
      "4/4 - 0s - loss: 1.2874 - accuracy: 0.4381 - val_loss: 1.3870 - val_accuracy: 0.2000 - 295ms/epoch - 74ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss did not improve from 1.38648\n",
      "4/4 - 0s - loss: 1.2534 - accuracy: 0.4571 - val_loss: 1.3870 - val_accuracy: 0.2000 - 296ms/epoch - 74ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.38648\n",
      "4/4 - 0s - loss: 1.1990 - accuracy: 0.5524 - val_loss: 1.3871 - val_accuracy: 0.2000 - 301ms/epoch - 75ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 1.38648\n",
      "4/4 - 0s - loss: 1.1781 - accuracy: 0.6000 - val_loss: 1.3872 - val_accuracy: 0.2000 - 295ms/epoch - 74ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 1.38648\n",
      "4/4 - 0s - loss: 1.1432 - accuracy: 0.6476 - val_loss: 1.3874 - val_accuracy: 0.2000 - 317ms/epoch - 79ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 1.38648\n",
      "4/4 - 0s - loss: 1.1503 - accuracy: 0.6286 - val_loss: 1.3874 - val_accuracy: 0.2000 - 297ms/epoch - 74ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.38648\n",
      "4/4 - 0s - loss: 1.1128 - accuracy: 0.6762 - val_loss: 1.3872 - val_accuracy: 0.2000 - 294ms/epoch - 74ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.38648\n",
      "4/4 - 0s - loss: 1.0805 - accuracy: 0.7143 - val_loss: 1.3872 - val_accuracy: 0.2000 - 306ms/epoch - 77ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.38648\n",
      "4/4 - 0s - loss: 1.0591 - accuracy: 0.6667 - val_loss: 1.3872 - val_accuracy: 0.2000 - 301ms/epoch - 75ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.38648\n",
      "4/4 - 0s - loss: 1.0505 - accuracy: 0.6857 - val_loss: 1.3873 - val_accuracy: 0.2000 - 301ms/epoch - 75ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 1.38648\n",
      "4/4 - 0s - loss: 1.0515 - accuracy: 0.6667 - val_loss: 1.3873 - val_accuracy: 0.2000 - 310ms/epoch - 78ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.38648\n",
      "4/4 - 0s - loss: 1.0151 - accuracy: 0.7333 - val_loss: 1.3872 - val_accuracy: 0.2000 - 295ms/epoch - 74ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 1.38648\n",
      "4/4 - 0s - loss: 1.0397 - accuracy: 0.6952 - val_loss: 1.3875 - val_accuracy: 0.2000 - 294ms/epoch - 73ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 1.38648\n",
      "4/4 - 0s - loss: 0.9939 - accuracy: 0.6762 - val_loss: 1.3878 - val_accuracy: 0.2000 - 313ms/epoch - 78ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 1.38648\n",
      "4/4 - 0s - loss: 0.9577 - accuracy: 0.7524 - val_loss: 1.3875 - val_accuracy: 0.2000 - 306ms/epoch - 76ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 1.38648\n",
      "4/4 - 0s - loss: 1.0034 - accuracy: 0.7429 - val_loss: 1.3871 - val_accuracy: 0.2000 - 303ms/epoch - 76ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 1.38648\n",
      "4/4 - 0s - loss: 0.9448 - accuracy: 0.7714 - val_loss: 1.3874 - val_accuracy: 0.2000 - 292ms/epoch - 73ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 1.38648\n",
      "4/4 - 0s - loss: 0.9342 - accuracy: 0.7905 - val_loss: 1.3880 - val_accuracy: 0.2000 - 294ms/epoch - 74ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 1.38648\n",
      "4/4 - 0s - loss: 0.9265 - accuracy: 0.7619 - val_loss: 1.3880 - val_accuracy: 0.2000 - 316ms/epoch - 79ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 1.38648\n",
      "4/4 - 0s - loss: 0.9033 - accuracy: 0.8095 - val_loss: 1.3873 - val_accuracy: 0.2000 - 298ms/epoch - 75ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 1.38648\n",
      "4/4 - 0s - loss: 0.8659 - accuracy: 0.8667 - val_loss: 1.3875 - val_accuracy: 0.2667 - 297ms/epoch - 74ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.38648\n",
      "4/4 - 0s - loss: 0.8826 - accuracy: 0.8667 - val_loss: 1.3885 - val_accuracy: 0.2667 - 296ms/epoch - 74ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 1.38648\n",
      "4/4 - 0s - loss: 0.8723 - accuracy: 0.7524 - val_loss: 1.3872 - val_accuracy: 0.2667 - 294ms/epoch - 74ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 1.38648\n",
      "4/4 - 0s - loss: 0.8742 - accuracy: 0.8190 - val_loss: 1.3877 - val_accuracy: 0.2667 - 294ms/epoch - 74ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 1.38648\n",
      "4/4 - 0s - loss: 0.8232 - accuracy: 0.8190 - val_loss: 1.3892 - val_accuracy: 0.2667 - 294ms/epoch - 73ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 1.38648\n",
      "4/4 - 0s - loss: 0.8677 - accuracy: 0.8095 - val_loss: 1.3876 - val_accuracy: 0.2667 - 297ms/epoch - 74ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 1.38648\n",
      "4/4 - 0s - loss: 0.8169 - accuracy: 0.8476 - val_loss: 1.3874 - val_accuracy: 0.2667 - 296ms/epoch - 74ms/step\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 1.38648\n",
      "4/4 - 0s - loss: 0.8234 - accuracy: 0.8381 - val_loss: 1.3878 - val_accuracy: 0.2667 - 295ms/epoch - 74ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 1.38648\n",
      "4/4 - 0s - loss: 0.8071 - accuracy: 0.8381 - val_loss: 1.3873 - val_accuracy: 0.2889 - 307ms/epoch - 77ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 1.38648\n",
      "4/4 - 0s - loss: 0.8332 - accuracy: 0.8476 - val_loss: 1.3877 - val_accuracy: 0.2444 - 293ms/epoch - 73ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 1.38648\n",
      "4/4 - 0s - loss: 0.7848 - accuracy: 0.8190 - val_loss: 1.3903 - val_accuracy: 0.2444 - 297ms/epoch - 74ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 1.38648\n",
      "4/4 - 0s - loss: 0.8128 - accuracy: 0.8190 - val_loss: 1.3882 - val_accuracy: 0.2667 - 319ms/epoch - 80ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss improved from 1.38648 to 1.38632, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.8096 - accuracy: 0.8476 - val_loss: 1.3863 - val_accuracy: 0.2889 - 357ms/epoch - 89ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.7549 - accuracy: 0.8857 - val_loss: 1.3890 - val_accuracy: 0.2889 - 296ms/epoch - 74ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.7967 - accuracy: 0.8857 - val_loss: 1.3885 - val_accuracy: 0.2667 - 306ms/epoch - 77ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.7665 - accuracy: 0.8762 - val_loss: 1.3897 - val_accuracy: 0.2444 - 289ms/epoch - 72ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.7533 - accuracy: 0.9048 - val_loss: 1.3910 - val_accuracy: 0.2667 - 297ms/epoch - 74ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.7276 - accuracy: 0.9238 - val_loss: 1.3919 - val_accuracy: 0.2444 - 301ms/epoch - 75ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.7448 - accuracy: 0.8571 - val_loss: 1.3913 - val_accuracy: 0.2444 - 304ms/epoch - 76ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.7299 - accuracy: 0.8857 - val_loss: 1.3892 - val_accuracy: 0.2222 - 302ms/epoch - 76ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.7335 - accuracy: 0.9048 - val_loss: 1.3914 - val_accuracy: 0.2444 - 306ms/epoch - 76ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.7106 - accuracy: 0.9048 - val_loss: 1.3903 - val_accuracy: 0.2444 - 319ms/epoch - 80ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.7032 - accuracy: 0.8857 - val_loss: 1.3945 - val_accuracy: 0.1556 - 300ms/epoch - 75ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss improved from 1.38632 to 1.38552, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.6963 - accuracy: 0.9333 - val_loss: 1.3855 - val_accuracy: 0.2667 - 356ms/epoch - 89ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 1.38552\n",
      "4/4 - 0s - loss: 0.7101 - accuracy: 0.9143 - val_loss: 1.3869 - val_accuracy: 0.2667 - 296ms/epoch - 74ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 1.38552\n",
      "4/4 - 0s - loss: 0.6816 - accuracy: 0.9048 - val_loss: 1.3882 - val_accuracy: 0.2667 - 305ms/epoch - 76ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 1.38552\n",
      "4/4 - 0s - loss: 0.6632 - accuracy: 0.9333 - val_loss: 1.3935 - val_accuracy: 0.2667 - 314ms/epoch - 78ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 1.38552\n",
      "4/4 - 0s - loss: 0.6630 - accuracy: 0.9238 - val_loss: 1.3981 - val_accuracy: 0.1778 - 320ms/epoch - 80ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss improved from 1.38552 to 1.38340, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.6882 - accuracy: 0.9238 - val_loss: 1.3834 - val_accuracy: 0.2667 - 371ms/epoch - 93ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 1.38340\n",
      "4/4 - 0s - loss: 0.6546 - accuracy: 0.9429 - val_loss: 1.3923 - val_accuracy: 0.2889 - 302ms/epoch - 76ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 1.38340\n",
      "4/4 - 0s - loss: 0.6879 - accuracy: 0.8857 - val_loss: 1.4190 - val_accuracy: 0.1778 - 303ms/epoch - 76ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss improved from 1.38340 to 1.38104, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.6612 - accuracy: 0.8952 - val_loss: 1.3810 - val_accuracy: 0.2667 - 370ms/epoch - 92ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss improved from 1.38104 to 1.38046, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.6862 - accuracy: 0.9238 - val_loss: 1.3805 - val_accuracy: 0.2444 - 359ms/epoch - 90ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 1.38046\n",
      "4/4 - 0s - loss: 0.6247 - accuracy: 0.9619 - val_loss: 1.3879 - val_accuracy: 0.2222 - 294ms/epoch - 73ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 1.38046\n",
      "4/4 - 0s - loss: 0.6100 - accuracy: 0.9619 - val_loss: 1.3862 - val_accuracy: 0.2667 - 302ms/epoch - 75ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 1.38046\n",
      "4/4 - 0s - loss: 0.6367 - accuracy: 0.9524 - val_loss: 1.3959 - val_accuracy: 0.2222 - 301ms/epoch - 75ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 1.38046\n",
      "4/4 - 0s - loss: 0.6203 - accuracy: 0.9333 - val_loss: 1.3812 - val_accuracy: 0.2444 - 298ms/epoch - 75ms/step\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 1.38046\n",
      "4/4 - 0s - loss: 0.6305 - accuracy: 0.9429 - val_loss: 1.4109 - val_accuracy: 0.2000 - 300ms/epoch - 75ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 1.38046\n",
      "4/4 - 0s - loss: 0.6036 - accuracy: 0.9619 - val_loss: 1.3996 - val_accuracy: 0.2222 - 294ms/epoch - 74ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss improved from 1.38046 to 1.36945, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.6102 - accuracy: 0.8952 - val_loss: 1.3695 - val_accuracy: 0.2667 - 344ms/epoch - 86ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 1.36945\n",
      "4/4 - 0s - loss: 0.6000 - accuracy: 0.9143 - val_loss: 1.4270 - val_accuracy: 0.2000 - 298ms/epoch - 74ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 1.36945\n",
      "4/4 - 0s - loss: 0.5612 - accuracy: 0.9714 - val_loss: 1.3801 - val_accuracy: 0.2667 - 311ms/epoch - 78ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 1.36945\n",
      "4/4 - 0s - loss: 0.5788 - accuracy: 0.9429 - val_loss: 1.3870 - val_accuracy: 0.2444 - 296ms/epoch - 74ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 1.36945\n",
      "4/4 - 0s - loss: 0.5290 - accuracy: 0.9524 - val_loss: 1.3962 - val_accuracy: 0.2444 - 303ms/epoch - 76ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 1.36945\n",
      "4/4 - 0s - loss: 0.5535 - accuracy: 0.9810 - val_loss: 1.3847 - val_accuracy: 0.2667 - 310ms/epoch - 77ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 1.36945\n",
      "4/4 - 0s - loss: 0.5169 - accuracy: 0.9619 - val_loss: 1.3702 - val_accuracy: 0.2667 - 297ms/epoch - 74ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 1.36945\n",
      "4/4 - 0s - loss: 0.4778 - accuracy: 0.9905 - val_loss: 1.3788 - val_accuracy: 0.2444 - 294ms/epoch - 74ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 1.36945\n",
      "4/4 - 0s - loss: 0.5303 - accuracy: 0.9810 - val_loss: 1.3909 - val_accuracy: 0.2222 - 302ms/epoch - 75ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 1.36945\n",
      "4/4 - 0s - loss: 0.5141 - accuracy: 0.9810 - val_loss: 1.3809 - val_accuracy: 0.2000 - 307ms/epoch - 77ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 1.36945\n",
      "4/4 - 0s - loss: 0.4746 - accuracy: 0.9619 - val_loss: 1.3867 - val_accuracy: 0.2222 - 290ms/epoch - 72ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 1.36945\n",
      "4/4 - 0s - loss: 0.5324 - accuracy: 0.9619 - val_loss: 1.3853 - val_accuracy: 0.3111 - 292ms/epoch - 73ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 1.36945\n",
      "4/4 - 0s - loss: 0.5141 - accuracy: 0.9810 - val_loss: 1.3954 - val_accuracy: 0.2222 - 298ms/epoch - 74ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 1.36945\n",
      "4/4 - 0s - loss: 0.4849 - accuracy: 0.9810 - val_loss: 1.3696 - val_accuracy: 0.3111 - 297ms/epoch - 74ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 1.36945\n",
      "4/4 - 0s - loss: 0.4420 - accuracy: 0.9905 - val_loss: 1.3998 - val_accuracy: 0.2222 - 298ms/epoch - 74ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 1.36945\n",
      "4/4 - 0s - loss: 0.4829 - accuracy: 0.9810 - val_loss: 1.3793 - val_accuracy: 0.2667 - 309ms/epoch - 77ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 1.36945\n",
      "4/4 - 0s - loss: 0.4550 - accuracy: 1.0000 - val_loss: 1.4057 - val_accuracy: 0.2444 - 307ms/epoch - 77ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 1.36945\n",
      "4/4 - 0s - loss: 0.4428 - accuracy: 0.9905 - val_loss: 1.3808 - val_accuracy: 0.3556 - 301ms/epoch - 75ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 1.36945\n",
      "4/4 - 0s - loss: 0.4679 - accuracy: 0.9810 - val_loss: 1.4021 - val_accuracy: 0.2222 - 297ms/epoch - 74ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss improved from 1.36945 to 1.36878, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.4616 - accuracy: 0.9905 - val_loss: 1.3688 - val_accuracy: 0.4000 - 343ms/epoch - 86ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 1.36878\n",
      "4/4 - 0s - loss: 0.4288 - accuracy: 1.0000 - val_loss: 1.4262 - val_accuracy: 0.2222 - 296ms/epoch - 74ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 1.36878\n",
      "4/4 - 0s - loss: 0.4391 - accuracy: 0.9905 - val_loss: 1.3931 - val_accuracy: 0.3333 - 295ms/epoch - 74ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 1.36878\n",
      "4/4 - 0s - loss: 0.4630 - accuracy: 0.9429 - val_loss: 1.4354 - val_accuracy: 0.2222 - 301ms/epoch - 75ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss improved from 1.36878 to 1.36497, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.4191 - accuracy: 0.9905 - val_loss: 1.3650 - val_accuracy: 0.3556 - 347ms/epoch - 87ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 1.36497\n",
      "4/4 - 0s - loss: 0.4163 - accuracy: 0.9810 - val_loss: 1.4411 - val_accuracy: 0.2222 - 298ms/epoch - 74ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 1.36497\n",
      "4/4 - 0s - loss: 0.4487 - accuracy: 0.9714 - val_loss: 1.3793 - val_accuracy: 0.2889 - 289ms/epoch - 72ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 1.36497\n",
      "4/4 - 0s - loss: 0.4401 - accuracy: 0.9714 - val_loss: 1.3950 - val_accuracy: 0.2667 - 301ms/epoch - 75ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss improved from 1.36497 to 1.36180, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.4188 - accuracy: 0.9714 - val_loss: 1.3618 - val_accuracy: 0.2889 - 350ms/epoch - 88ms/step\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 1.36180\n",
      "4/4 - 0s - loss: 0.4145 - accuracy: 0.9810 - val_loss: 1.3799 - val_accuracy: 0.2889 - 299ms/epoch - 75ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss improved from 1.36180 to 1.34774, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.3756 - accuracy: 0.9905 - val_loss: 1.3477 - val_accuracy: 0.3333 - 346ms/epoch - 87ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.3902 - accuracy: 1.0000 - val_loss: 1.4032 - val_accuracy: 0.2667 - 296ms/epoch - 74ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.3672 - accuracy: 0.9810 - val_loss: 1.3919 - val_accuracy: 0.2889 - 301ms/epoch - 75ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.3898 - accuracy: 0.9905 - val_loss: 1.4146 - val_accuracy: 0.2222 - 309ms/epoch - 77ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.3764 - accuracy: 1.0000 - val_loss: 1.3743 - val_accuracy: 0.2444 - 308ms/epoch - 77ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.3703 - accuracy: 0.9810 - val_loss: 1.3676 - val_accuracy: 0.3333 - 295ms/epoch - 74ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.3512 - accuracy: 1.0000 - val_loss: 1.4189 - val_accuracy: 0.2222 - 300ms/epoch - 75ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.3755 - accuracy: 0.9905 - val_loss: 1.3665 - val_accuracy: 0.3333 - 294ms/epoch - 74ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.3286 - accuracy: 1.0000 - val_loss: 1.3800 - val_accuracy: 0.3111 - 301ms/epoch - 75ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.3479 - accuracy: 0.9810 - val_loss: 1.3890 - val_accuracy: 0.4000 - 300ms/epoch - 75ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.3480 - accuracy: 1.0000 - val_loss: 1.3962 - val_accuracy: 0.3111 - 300ms/epoch - 75ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.3362 - accuracy: 0.9714 - val_loss: 1.3689 - val_accuracy: 0.4222 - 295ms/epoch - 74ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.3342 - accuracy: 0.9905 - val_loss: 1.3489 - val_accuracy: 0.3556 - 301ms/epoch - 75ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.3649 - accuracy: 0.9619 - val_loss: 1.3834 - val_accuracy: 0.3111 - 291ms/epoch - 73ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.3272 - accuracy: 1.0000 - val_loss: 1.4013 - val_accuracy: 0.3111 - 290ms/epoch - 72ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.3415 - accuracy: 0.9810 - val_loss: 1.4533 - val_accuracy: 0.2667 - 300ms/epoch - 75ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.3353 - accuracy: 0.9905 - val_loss: 1.4191 - val_accuracy: 0.4000 - 304ms/epoch - 76ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.3553 - accuracy: 1.0000 - val_loss: 1.4217 - val_accuracy: 0.3778 - 295ms/epoch - 74ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.3396 - accuracy: 0.9905 - val_loss: 1.4473 - val_accuracy: 0.3333 - 318ms/epoch - 80ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.2926 - accuracy: 1.0000 - val_loss: 1.4496 - val_accuracy: 0.2667 - 293ms/epoch - 73ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.3478 - accuracy: 1.0000 - val_loss: 1.4347 - val_accuracy: 0.3556 - 294ms/epoch - 74ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.3448 - accuracy: 0.9905 - val_loss: 1.4168 - val_accuracy: 0.4000 - 299ms/epoch - 75ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.3291 - accuracy: 0.9905 - val_loss: 1.3875 - val_accuracy: 0.3111 - 303ms/epoch - 76ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.3349 - accuracy: 1.0000 - val_loss: 1.4066 - val_accuracy: 0.4000 - 303ms/epoch - 76ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.3481 - accuracy: 0.9810 - val_loss: 1.4955 - val_accuracy: 0.2889 - 308ms/epoch - 77ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.3117 - accuracy: 0.9905 - val_loss: 1.3892 - val_accuracy: 0.3778 - 298ms/epoch - 75ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.3717 - accuracy: 0.9810 - val_loss: 1.4186 - val_accuracy: 0.3111 - 311ms/epoch - 78ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.3347 - accuracy: 0.9714 - val_loss: 1.4452 - val_accuracy: 0.4000 - 306ms/epoch - 77ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.3250 - accuracy: 0.9810 - val_loss: 1.3788 - val_accuracy: 0.4667 - 302ms/epoch - 76ms/step\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.2893 - accuracy: 1.0000 - val_loss: 1.3891 - val_accuracy: 0.3333 - 301ms/epoch - 75ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.2772 - accuracy: 1.0000 - val_loss: 1.4355 - val_accuracy: 0.3333 - 312ms/epoch - 78ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.2799 - accuracy: 1.0000 - val_loss: 1.4279 - val_accuracy: 0.4000 - 286ms/epoch - 71ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.3152 - accuracy: 0.9905 - val_loss: 1.4011 - val_accuracy: 0.4667 - 300ms/epoch - 75ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.3029 - accuracy: 0.9905 - val_loss: 1.4695 - val_accuracy: 0.4222 - 312ms/epoch - 78ms/step\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.2834 - accuracy: 0.9905 - val_loss: 1.5239 - val_accuracy: 0.3333 - 296ms/epoch - 74ms/step\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.3010 - accuracy: 0.9905 - val_loss: 1.5693 - val_accuracy: 0.2667 - 301ms/epoch - 75ms/step\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.2742 - accuracy: 1.0000 - val_loss: 1.4701 - val_accuracy: 0.3778 - 305ms/epoch - 76ms/step\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.2852 - accuracy: 0.9905 - val_loss: 1.3967 - val_accuracy: 0.4000 - 304ms/epoch - 76ms/step\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.2919 - accuracy: 1.0000 - val_loss: 1.4019 - val_accuracy: 0.3556 - 294ms/epoch - 73ms/step\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.2575 - accuracy: 1.0000 - val_loss: 1.4315 - val_accuracy: 0.3556 - 297ms/epoch - 74ms/step\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.2351 - accuracy: 1.0000 - val_loss: 1.4449 - val_accuracy: 0.4000 - 292ms/epoch - 73ms/step\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.2369 - accuracy: 1.0000 - val_loss: 1.4120 - val_accuracy: 0.4444 - 298ms/epoch - 74ms/step\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.2488 - accuracy: 1.0000 - val_loss: 1.3998 - val_accuracy: 0.4444 - 298ms/epoch - 75ms/step\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 135: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 1.4061 - val_accuracy: 0.3778 - 293ms/epoch - 73ms/step\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 136: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.2337 - accuracy: 0.9905 - val_loss: 1.3833 - val_accuracy: 0.4000 - 297ms/epoch - 74ms/step\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 137: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.2317 - accuracy: 1.0000 - val_loss: 1.3888 - val_accuracy: 0.4000 - 302ms/epoch - 75ms/step\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 138: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.2372 - accuracy: 1.0000 - val_loss: 1.4036 - val_accuracy: 0.4222 - 290ms/epoch - 72ms/step\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 139: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.2283 - accuracy: 1.0000 - val_loss: 1.3963 - val_accuracy: 0.4000 - 310ms/epoch - 77ms/step\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 140: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.2231 - accuracy: 0.9905 - val_loss: 1.4699 - val_accuracy: 0.3556 - 314ms/epoch - 78ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/300\n",
      "\n",
      "Epoch 141: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.2351 - accuracy: 0.9905 - val_loss: 1.3814 - val_accuracy: 0.4000 - 298ms/epoch - 74ms/step\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 142: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 1.4334 - val_accuracy: 0.4000 - 311ms/epoch - 78ms/step\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 143: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.2292 - accuracy: 0.9810 - val_loss: 1.3942 - val_accuracy: 0.4444 - 296ms/epoch - 74ms/step\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 144: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.2189 - accuracy: 0.9905 - val_loss: 1.3778 - val_accuracy: 0.4444 - 302ms/epoch - 75ms/step\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 145: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 1.3915 - val_accuracy: 0.3778 - 293ms/epoch - 73ms/step\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 146: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 1.4459 - val_accuracy: 0.3333 - 295ms/epoch - 74ms/step\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 147: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.2280 - accuracy: 0.9905 - val_loss: 1.4181 - val_accuracy: 0.4000 - 300ms/epoch - 75ms/step\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 148: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.2287 - accuracy: 1.0000 - val_loss: 1.4603 - val_accuracy: 0.3556 - 301ms/epoch - 75ms/step\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 149: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 1.4681 - val_accuracy: 0.4000 - 313ms/epoch - 78ms/step\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 150: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.2198 - accuracy: 1.0000 - val_loss: 1.4993 - val_accuracy: 0.3556 - 296ms/epoch - 74ms/step\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 151: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.2201 - accuracy: 1.0000 - val_loss: 1.5163 - val_accuracy: 0.3111 - 298ms/epoch - 75ms/step\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 152: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1969 - accuracy: 1.0000 - val_loss: 1.5088 - val_accuracy: 0.3556 - 302ms/epoch - 76ms/step\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 153: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1916 - accuracy: 1.0000 - val_loss: 1.4792 - val_accuracy: 0.3333 - 311ms/epoch - 78ms/step\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 154: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.2049 - accuracy: 1.0000 - val_loss: 1.4612 - val_accuracy: 0.2889 - 299ms/epoch - 75ms/step\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 155: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1877 - accuracy: 1.0000 - val_loss: 1.4655 - val_accuracy: 0.4000 - 313ms/epoch - 78ms/step\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 156: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1890 - accuracy: 1.0000 - val_loss: 1.4249 - val_accuracy: 0.3333 - 293ms/epoch - 73ms/step\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 157: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.2063 - accuracy: 1.0000 - val_loss: 1.4281 - val_accuracy: 0.3778 - 299ms/epoch - 75ms/step\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 158: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1993 - accuracy: 1.0000 - val_loss: 1.5072 - val_accuracy: 0.3111 - 308ms/epoch - 77ms/step\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 159: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.2228 - accuracy: 0.9905 - val_loss: 1.5518 - val_accuracy: 0.2889 - 300ms/epoch - 75ms/step\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 160: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.2238 - accuracy: 1.0000 - val_loss: 1.5693 - val_accuracy: 0.3778 - 295ms/epoch - 74ms/step\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 161: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.2041 - accuracy: 0.9905 - val_loss: 1.5153 - val_accuracy: 0.2667 - 314ms/epoch - 79ms/step\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 162: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1704 - accuracy: 1.0000 - val_loss: 1.4464 - val_accuracy: 0.3333 - 309ms/epoch - 77ms/step\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 163: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1954 - accuracy: 0.9905 - val_loss: 1.3857 - val_accuracy: 0.3111 - 300ms/epoch - 75ms/step\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 164: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1768 - accuracy: 1.0000 - val_loss: 1.4133 - val_accuracy: 0.3556 - 301ms/epoch - 75ms/step\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 165: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1673 - accuracy: 1.0000 - val_loss: 1.4164 - val_accuracy: 0.3333 - 308ms/epoch - 77ms/step\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 166: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1877 - accuracy: 1.0000 - val_loss: 1.4662 - val_accuracy: 0.3778 - 293ms/epoch - 73ms/step\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 167: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1548 - accuracy: 1.0000 - val_loss: 1.4810 - val_accuracy: 0.3778 - 311ms/epoch - 78ms/step\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 168: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1695 - accuracy: 1.0000 - val_loss: 1.4390 - val_accuracy: 0.4000 - 307ms/epoch - 77ms/step\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 169: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1546 - accuracy: 1.0000 - val_loss: 1.4331 - val_accuracy: 0.3778 - 292ms/epoch - 73ms/step\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 170: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1515 - accuracy: 1.0000 - val_loss: 1.4782 - val_accuracy: 0.2444 - 310ms/epoch - 78ms/step\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 171: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1394 - accuracy: 1.0000 - val_loss: 1.4353 - val_accuracy: 0.3111 - 298ms/epoch - 75ms/step\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 172: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1648 - accuracy: 1.0000 - val_loss: 1.4112 - val_accuracy: 0.4000 - 297ms/epoch - 74ms/step\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 173: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1728 - accuracy: 1.0000 - val_loss: 1.4086 - val_accuracy: 0.3778 - 310ms/epoch - 77ms/step\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 174: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1422 - accuracy: 1.0000 - val_loss: 1.4538 - val_accuracy: 0.3778 - 296ms/epoch - 74ms/step\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 175: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1564 - accuracy: 1.0000 - val_loss: 1.4982 - val_accuracy: 0.3333 - 322ms/epoch - 80ms/step\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 176: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1452 - accuracy: 1.0000 - val_loss: 1.4759 - val_accuracy: 0.3111 - 296ms/epoch - 74ms/step\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 177: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1438 - accuracy: 1.0000 - val_loss: 1.4609 - val_accuracy: 0.2889 - 306ms/epoch - 77ms/step\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 178: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1447 - accuracy: 1.0000 - val_loss: 1.4813 - val_accuracy: 0.3111 - 305ms/epoch - 76ms/step\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 179: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1677 - accuracy: 1.0000 - val_loss: 1.4911 - val_accuracy: 0.2889 - 308ms/epoch - 77ms/step\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 180: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1490 - accuracy: 1.0000 - val_loss: 1.5194 - val_accuracy: 0.3333 - 302ms/epoch - 75ms/step\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 181: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1688 - accuracy: 1.0000 - val_loss: 1.4761 - val_accuracy: 0.3556 - 306ms/epoch - 76ms/step\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 182: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1595 - accuracy: 1.0000 - val_loss: 1.4805 - val_accuracy: 0.3556 - 298ms/epoch - 74ms/step\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 183: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1544 - accuracy: 1.0000 - val_loss: 1.5181 - val_accuracy: 0.3556 - 305ms/epoch - 76ms/step\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 184: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1511 - accuracy: 1.0000 - val_loss: 1.5062 - val_accuracy: 0.3111 - 296ms/epoch - 74ms/step\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 185: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1626 - accuracy: 1.0000 - val_loss: 1.5088 - val_accuracy: 0.3556 - 301ms/epoch - 75ms/step\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 186: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1604 - accuracy: 0.9905 - val_loss: 1.4970 - val_accuracy: 0.3556 - 297ms/epoch - 74ms/step\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 187: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1873 - accuracy: 0.9905 - val_loss: 1.4659 - val_accuracy: 0.3556 - 308ms/epoch - 77ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188/300\n",
      "\n",
      "Epoch 188: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1940 - accuracy: 0.9810 - val_loss: 1.4487 - val_accuracy: 0.4000 - 293ms/epoch - 73ms/step\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 189: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1650 - accuracy: 1.0000 - val_loss: 1.4838 - val_accuracy: 0.3333 - 290ms/epoch - 72ms/step\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 190: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1481 - accuracy: 0.9905 - val_loss: 1.6348 - val_accuracy: 0.4222 - 291ms/epoch - 73ms/step\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 191: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 1.7784 - val_accuracy: 0.2667 - 311ms/epoch - 78ms/step\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 192: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1836 - accuracy: 1.0000 - val_loss: 1.5502 - val_accuracy: 0.3333 - 294ms/epoch - 73ms/step\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 193: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1724 - accuracy: 0.9905 - val_loss: 1.5994 - val_accuracy: 0.4444 - 291ms/epoch - 73ms/step\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 194: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1473 - accuracy: 1.0000 - val_loss: 1.6809 - val_accuracy: 0.2444 - 305ms/epoch - 76ms/step\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 195: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1658 - accuracy: 1.0000 - val_loss: 1.5713 - val_accuracy: 0.3111 - 297ms/epoch - 74ms/step\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 196: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1714 - accuracy: 1.0000 - val_loss: 1.5374 - val_accuracy: 0.3333 - 299ms/epoch - 75ms/step\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 197: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1567 - accuracy: 1.0000 - val_loss: 1.6224 - val_accuracy: 0.4000 - 310ms/epoch - 78ms/step\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 198: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1970 - accuracy: 0.9905 - val_loss: 1.7714 - val_accuracy: 0.3111 - 297ms/epoch - 74ms/step\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 199: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1476 - accuracy: 1.0000 - val_loss: 1.5372 - val_accuracy: 0.3333 - 301ms/epoch - 75ms/step\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 200: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1685 - accuracy: 0.9905 - val_loss: 1.5609 - val_accuracy: 0.2444 - 304ms/epoch - 76ms/step\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 201: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1495 - accuracy: 1.0000 - val_loss: 1.6260 - val_accuracy: 0.2889 - 305ms/epoch - 76ms/step\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 202: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1654 - accuracy: 0.9905 - val_loss: 1.5237 - val_accuracy: 0.3333 - 296ms/epoch - 74ms/step\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 203: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1505 - accuracy: 1.0000 - val_loss: 1.5496 - val_accuracy: 0.3333 - 302ms/epoch - 75ms/step\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 204: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1372 - accuracy: 1.0000 - val_loss: 1.7378 - val_accuracy: 0.3778 - 310ms/epoch - 78ms/step\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 205: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1509 - accuracy: 0.9905 - val_loss: 1.5808 - val_accuracy: 0.2889 - 293ms/epoch - 73ms/step\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 206: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1341 - accuracy: 1.0000 - val_loss: 1.5573 - val_accuracy: 0.2889 - 294ms/epoch - 73ms/step\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 207: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1406 - accuracy: 0.9905 - val_loss: 1.6760 - val_accuracy: 0.3556 - 299ms/epoch - 75ms/step\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 208: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1345 - accuracy: 1.0000 - val_loss: 1.5502 - val_accuracy: 0.2667 - 295ms/epoch - 74ms/step\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 209: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1386 - accuracy: 0.9905 - val_loss: 1.5153 - val_accuracy: 0.4000 - 331ms/epoch - 83ms/step\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 210: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1630 - accuracy: 1.0000 - val_loss: 1.5094 - val_accuracy: 0.4222 - 301ms/epoch - 75ms/step\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 211: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1541 - accuracy: 1.0000 - val_loss: 1.5508 - val_accuracy: 0.2889 - 304ms/epoch - 76ms/step\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 212: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1528 - accuracy: 1.0000 - val_loss: 1.7561 - val_accuracy: 0.2444 - 292ms/epoch - 73ms/step\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 213: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1724 - accuracy: 0.9905 - val_loss: 1.5404 - val_accuracy: 0.3333 - 291ms/epoch - 73ms/step\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 214: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1346 - accuracy: 1.0000 - val_loss: 1.4979 - val_accuracy: 0.2889 - 305ms/epoch - 76ms/step\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 215: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1173 - accuracy: 1.0000 - val_loss: 1.4885 - val_accuracy: 0.2889 - 311ms/epoch - 78ms/step\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 216: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1255 - accuracy: 1.0000 - val_loss: 1.5322 - val_accuracy: 0.2667 - 295ms/epoch - 74ms/step\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 217: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1141 - accuracy: 1.0000 - val_loss: 1.4983 - val_accuracy: 0.3333 - 294ms/epoch - 73ms/step\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 218: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1203 - accuracy: 1.0000 - val_loss: 1.4954 - val_accuracy: 0.2889 - 308ms/epoch - 77ms/step\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 219: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1255 - accuracy: 1.0000 - val_loss: 1.5387 - val_accuracy: 0.2667 - 299ms/epoch - 75ms/step\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 220: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1149 - accuracy: 1.0000 - val_loss: 1.5850 - val_accuracy: 0.2667 - 299ms/epoch - 75ms/step\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 221: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1095 - accuracy: 1.0000 - val_loss: 1.5821 - val_accuracy: 0.2444 - 308ms/epoch - 77ms/step\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 222: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1122 - accuracy: 1.0000 - val_loss: 1.5621 - val_accuracy: 0.3556 - 294ms/epoch - 74ms/step\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 223: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0958 - accuracy: 1.0000 - val_loss: 1.6155 - val_accuracy: 0.3778 - 292ms/epoch - 73ms/step\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 224: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1230 - accuracy: 1.0000 - val_loss: 1.6088 - val_accuracy: 0.2889 - 306ms/epoch - 77ms/step\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 225: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1355 - accuracy: 1.0000 - val_loss: 1.5426 - val_accuracy: 0.2889 - 301ms/epoch - 75ms/step\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 226: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1101 - accuracy: 1.0000 - val_loss: 1.5143 - val_accuracy: 0.2889 - 301ms/epoch - 75ms/step\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 227: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1297 - accuracy: 1.0000 - val_loss: 1.4873 - val_accuracy: 0.2889 - 325ms/epoch - 81ms/step\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 228: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1172 - accuracy: 1.0000 - val_loss: 1.5431 - val_accuracy: 0.3333 - 313ms/epoch - 78ms/step\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 229: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1137 - accuracy: 1.0000 - val_loss: 1.7715 - val_accuracy: 0.2667 - 289ms/epoch - 72ms/step\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 230: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1179 - accuracy: 1.0000 - val_loss: 1.5299 - val_accuracy: 0.3333 - 295ms/epoch - 74ms/step\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 231: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1081 - accuracy: 1.0000 - val_loss: 1.4938 - val_accuracy: 0.4000 - 296ms/epoch - 74ms/step\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 232: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1185 - accuracy: 1.0000 - val_loss: 1.4974 - val_accuracy: 0.3556 - 296ms/epoch - 74ms/step\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 233: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1053 - accuracy: 1.0000 - val_loss: 1.4931 - val_accuracy: 0.3778 - 306ms/epoch - 77ms/step\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 234: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1043 - accuracy: 1.0000 - val_loss: 1.4734 - val_accuracy: 0.4000 - 293ms/epoch - 73ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235/300\n",
      "\n",
      "Epoch 235: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1043 - accuracy: 1.0000 - val_loss: 1.5106 - val_accuracy: 0.4444 - 306ms/epoch - 76ms/step\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 236: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1144 - accuracy: 1.0000 - val_loss: 1.5471 - val_accuracy: 0.3556 - 308ms/epoch - 77ms/step\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 237: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1157 - accuracy: 1.0000 - val_loss: 1.5882 - val_accuracy: 0.3333 - 293ms/epoch - 73ms/step\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 238: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1083 - accuracy: 1.0000 - val_loss: 1.6249 - val_accuracy: 0.2889 - 293ms/epoch - 73ms/step\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 239: val_loss did not improve from 1.34774\n",
      "4/4 - 1s - loss: 0.1087 - accuracy: 1.0000 - val_loss: 1.5732 - val_accuracy: 0.3111 - 645ms/epoch - 161ms/step\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 240: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1120 - accuracy: 1.0000 - val_loss: 1.5690 - val_accuracy: 0.3778 - 303ms/epoch - 76ms/step\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 241: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1030 - accuracy: 1.0000 - val_loss: 1.5508 - val_accuracy: 0.4444 - 309ms/epoch - 77ms/step\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 242: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1030 - accuracy: 1.0000 - val_loss: 1.5173 - val_accuracy: 0.4000 - 313ms/epoch - 78ms/step\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 243: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1153 - accuracy: 1.0000 - val_loss: 1.5687 - val_accuracy: 0.3111 - 318ms/epoch - 80ms/step\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 244: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1097 - accuracy: 1.0000 - val_loss: 1.5980 - val_accuracy: 0.3111 - 309ms/epoch - 77ms/step\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 245: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1199 - accuracy: 1.0000 - val_loss: 1.5625 - val_accuracy: 0.3111 - 306ms/epoch - 76ms/step\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 246: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1119 - accuracy: 1.0000 - val_loss: 1.5628 - val_accuracy: 0.4000 - 303ms/epoch - 76ms/step\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 247: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1112 - accuracy: 0.9905 - val_loss: 1.5313 - val_accuracy: 0.3778 - 304ms/epoch - 76ms/step\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 248: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1402 - accuracy: 0.9905 - val_loss: 1.5393 - val_accuracy: 0.3778 - 306ms/epoch - 76ms/step\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 249: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1656 - accuracy: 1.0000 - val_loss: 1.5467 - val_accuracy: 0.4222 - 301ms/epoch - 75ms/step\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 250: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1475 - accuracy: 1.0000 - val_loss: 1.8184 - val_accuracy: 0.2889 - 305ms/epoch - 76ms/step\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 251: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1473 - accuracy: 1.0000 - val_loss: 1.7270 - val_accuracy: 0.3111 - 308ms/epoch - 77ms/step\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 252: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1285 - accuracy: 1.0000 - val_loss: 1.5102 - val_accuracy: 0.4444 - 300ms/epoch - 75ms/step\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 253: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1076 - accuracy: 1.0000 - val_loss: 1.5537 - val_accuracy: 0.3333 - 316ms/epoch - 79ms/step\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 254: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1084 - accuracy: 1.0000 - val_loss: 1.6827 - val_accuracy: 0.3333 - 306ms/epoch - 76ms/step\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 255: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0971 - accuracy: 1.0000 - val_loss: 1.6682 - val_accuracy: 0.3333 - 310ms/epoch - 78ms/step\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 256: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0907 - accuracy: 1.0000 - val_loss: 1.5958 - val_accuracy: 0.3111 - 319ms/epoch - 80ms/step\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 257: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0903 - accuracy: 1.0000 - val_loss: 1.6017 - val_accuracy: 0.3111 - 310ms/epoch - 77ms/step\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 258: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0996 - accuracy: 1.0000 - val_loss: 1.6197 - val_accuracy: 0.2667 - 300ms/epoch - 75ms/step\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 259: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0898 - accuracy: 1.0000 - val_loss: 1.6520 - val_accuracy: 0.2889 - 316ms/epoch - 79ms/step\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 260: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1097 - accuracy: 1.0000 - val_loss: 1.6137 - val_accuracy: 0.3333 - 305ms/epoch - 76ms/step\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 261: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0975 - accuracy: 1.0000 - val_loss: 1.5783 - val_accuracy: 0.3333 - 310ms/epoch - 78ms/step\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 262: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1072 - accuracy: 1.0000 - val_loss: 1.5175 - val_accuracy: 0.3111 - 312ms/epoch - 78ms/step\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 263: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1105 - accuracy: 1.0000 - val_loss: 1.4864 - val_accuracy: 0.3333 - 304ms/epoch - 76ms/step\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 264: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1020 - accuracy: 1.0000 - val_loss: 1.5380 - val_accuracy: 0.2889 - 306ms/epoch - 76ms/step\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 265: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0914 - accuracy: 1.0000 - val_loss: 1.4771 - val_accuracy: 0.3778 - 304ms/epoch - 76ms/step\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 266: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1022 - accuracy: 1.0000 - val_loss: 1.4785 - val_accuracy: 0.3333 - 304ms/epoch - 76ms/step\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 267: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0991 - accuracy: 1.0000 - val_loss: 1.4821 - val_accuracy: 0.3778 - 305ms/epoch - 76ms/step\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 268: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0862 - accuracy: 1.0000 - val_loss: 1.4849 - val_accuracy: 0.3556 - 313ms/epoch - 78ms/step\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 269: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0951 - accuracy: 1.0000 - val_loss: 1.5236 - val_accuracy: 0.3333 - 313ms/epoch - 78ms/step\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 270: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0809 - accuracy: 1.0000 - val_loss: 1.5415 - val_accuracy: 0.4222 - 312ms/epoch - 78ms/step\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 271: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0951 - accuracy: 1.0000 - val_loss: 1.5517 - val_accuracy: 0.3556 - 312ms/epoch - 78ms/step\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 272: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0939 - accuracy: 1.0000 - val_loss: 1.5245 - val_accuracy: 0.3111 - 305ms/epoch - 76ms/step\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 273: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0793 - accuracy: 1.0000 - val_loss: 1.4758 - val_accuracy: 0.4000 - 301ms/epoch - 75ms/step\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 274: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0778 - accuracy: 1.0000 - val_loss: 1.4849 - val_accuracy: 0.4444 - 314ms/epoch - 79ms/step\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 275: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0864 - accuracy: 1.0000 - val_loss: 1.5341 - val_accuracy: 0.3333 - 300ms/epoch - 75ms/step\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 276: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0930 - accuracy: 1.0000 - val_loss: 1.6050 - val_accuracy: 0.2889 - 303ms/epoch - 76ms/step\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 277: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0793 - accuracy: 1.0000 - val_loss: 1.6509 - val_accuracy: 0.3111 - 307ms/epoch - 77ms/step\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 278: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0822 - accuracy: 1.0000 - val_loss: 1.6332 - val_accuracy: 0.2889 - 303ms/epoch - 76ms/step\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 279: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0812 - accuracy: 1.0000 - val_loss: 1.6487 - val_accuracy: 0.2667 - 319ms/epoch - 80ms/step\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 280: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0929 - accuracy: 1.0000 - val_loss: 1.5522 - val_accuracy: 0.4000 - 302ms/epoch - 76ms/step\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 281: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1054 - accuracy: 1.0000 - val_loss: 1.5803 - val_accuracy: 0.3333 - 304ms/epoch - 76ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 282/300\n",
      "\n",
      "Epoch 282: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0940 - accuracy: 1.0000 - val_loss: 1.5768 - val_accuracy: 0.3778 - 308ms/epoch - 77ms/step\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 283: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0842 - accuracy: 1.0000 - val_loss: 1.5519 - val_accuracy: 0.3333 - 301ms/epoch - 75ms/step\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 284: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0826 - accuracy: 1.0000 - val_loss: 1.5201 - val_accuracy: 0.3556 - 323ms/epoch - 81ms/step\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 285: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0876 - accuracy: 1.0000 - val_loss: 1.5207 - val_accuracy: 0.3778 - 310ms/epoch - 77ms/step\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 286: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1066 - accuracy: 0.9905 - val_loss: 1.5982 - val_accuracy: 0.2889 - 303ms/epoch - 76ms/step\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 287: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.1059 - accuracy: 1.0000 - val_loss: 1.6656 - val_accuracy: 0.3333 - 310ms/epoch - 77ms/step\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 288: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0994 - accuracy: 1.0000 - val_loss: 1.6506 - val_accuracy: 0.3333 - 313ms/epoch - 78ms/step\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 289: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0948 - accuracy: 1.0000 - val_loss: 1.6037 - val_accuracy: 0.2889 - 302ms/epoch - 76ms/step\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 290: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0775 - accuracy: 1.0000 - val_loss: 1.5670 - val_accuracy: 0.3778 - 300ms/epoch - 75ms/step\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 291: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0831 - accuracy: 1.0000 - val_loss: 1.5988 - val_accuracy: 0.2667 - 323ms/epoch - 81ms/step\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 292: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0829 - accuracy: 1.0000 - val_loss: 1.5431 - val_accuracy: 0.3333 - 306ms/epoch - 77ms/step\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 293: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0849 - accuracy: 1.0000 - val_loss: 1.4927 - val_accuracy: 0.3333 - 309ms/epoch - 77ms/step\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 294: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0874 - accuracy: 1.0000 - val_loss: 1.5633 - val_accuracy: 0.3333 - 306ms/epoch - 76ms/step\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 295: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0732 - accuracy: 1.0000 - val_loss: 1.6009 - val_accuracy: 0.4222 - 303ms/epoch - 76ms/step\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 296: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0830 - accuracy: 1.0000 - val_loss: 1.6465 - val_accuracy: 0.3556 - 315ms/epoch - 79ms/step\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 297: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0776 - accuracy: 1.0000 - val_loss: 1.5853 - val_accuracy: 0.3333 - 306ms/epoch - 77ms/step\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 298: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0809 - accuracy: 1.0000 - val_loss: 1.5663 - val_accuracy: 0.4000 - 304ms/epoch - 76ms/step\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 299: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0754 - accuracy: 1.0000 - val_loss: 1.5940 - val_accuracy: 0.3556 - 306ms/epoch - 76ms/step\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 300: val_loss did not improve from 1.34774\n",
      "4/4 - 0s - loss: 0.0728 - accuracy: 1.0000 - val_loss: 1.6561 - val_accuracy: 0.2889 - 303ms/epoch - 76ms/step\n",
      "2/2 [==============================] - 0s 22ms/step\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 09:10:45.915369: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_8415872\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:553024\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
      "2022-11-11 09:10:49.896103: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_8418942\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:553066\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38747, saving model to checkpoint1.h5\n",
      "4/4 - 5s - loss: 1.4531 - accuracy: 0.3143 - val_loss: 1.3875 - val_accuracy: 0.2000 - 5s/epoch - 1s/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss did not improve from 1.38747\n",
      "4/4 - 0s - loss: 1.3436 - accuracy: 0.3905 - val_loss: 1.3880 - val_accuracy: 0.2000 - 312ms/epoch - 78ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss did not improve from 1.38747\n",
      "4/4 - 0s - loss: 1.3244 - accuracy: 0.3810 - val_loss: 1.3883 - val_accuracy: 0.2000 - 303ms/epoch - 76ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss did not improve from 1.38747\n",
      "4/4 - 0s - loss: 1.2764 - accuracy: 0.5143 - val_loss: 1.3883 - val_accuracy: 0.2000 - 311ms/epoch - 78ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss did not improve from 1.38747\n",
      "4/4 - 0s - loss: 1.2560 - accuracy: 0.4190 - val_loss: 1.3881 - val_accuracy: 0.2000 - 298ms/epoch - 74ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.38747\n",
      "4/4 - 0s - loss: 1.2276 - accuracy: 0.4762 - val_loss: 1.3879 - val_accuracy: 0.2000 - 291ms/epoch - 73ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 1.38747\n",
      "4/4 - 0s - loss: 1.2301 - accuracy: 0.4857 - val_loss: 1.3881 - val_accuracy: 0.2444 - 297ms/epoch - 74ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 1.38747\n",
      "4/4 - 0s - loss: 1.1805 - accuracy: 0.5619 - val_loss: 1.3882 - val_accuracy: 0.1778 - 311ms/epoch - 78ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 1.38747\n",
      "4/4 - 0s - loss: 1.1765 - accuracy: 0.5238 - val_loss: 1.3882 - val_accuracy: 0.1778 - 302ms/epoch - 75ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.38747\n",
      "4/4 - 0s - loss: 1.1480 - accuracy: 0.5619 - val_loss: 1.3885 - val_accuracy: 0.1778 - 304ms/epoch - 76ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.38747\n",
      "4/4 - 0s - loss: 1.1396 - accuracy: 0.5619 - val_loss: 1.3888 - val_accuracy: 0.1778 - 309ms/epoch - 77ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.38747\n",
      "4/4 - 0s - loss: 1.0994 - accuracy: 0.6095 - val_loss: 1.3895 - val_accuracy: 0.1556 - 311ms/epoch - 78ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.38747\n",
      "4/4 - 0s - loss: 1.0956 - accuracy: 0.7143 - val_loss: 1.3897 - val_accuracy: 0.1556 - 312ms/epoch - 78ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 1.38747\n",
      "4/4 - 0s - loss: 1.0785 - accuracy: 0.6857 - val_loss: 1.3896 - val_accuracy: 0.1556 - 295ms/epoch - 74ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.38747\n",
      "4/4 - 0s - loss: 1.0656 - accuracy: 0.6190 - val_loss: 1.3890 - val_accuracy: 0.1556 - 312ms/epoch - 78ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 1.38747\n",
      "4/4 - 0s - loss: 1.0565 - accuracy: 0.7048 - val_loss: 1.3894 - val_accuracy: 0.1778 - 297ms/epoch - 74ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 1.38747\n",
      "4/4 - 0s - loss: 1.0490 - accuracy: 0.6667 - val_loss: 1.3910 - val_accuracy: 0.1556 - 311ms/epoch - 78ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 1.38747\n",
      "4/4 - 0s - loss: 1.0433 - accuracy: 0.6952 - val_loss: 1.3916 - val_accuracy: 0.1556 - 303ms/epoch - 76ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 1.38747\n",
      "4/4 - 0s - loss: 1.0206 - accuracy: 0.7048 - val_loss: 1.3913 - val_accuracy: 0.1556 - 305ms/epoch - 76ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 1.38747\n",
      "4/4 - 0s - loss: 1.0060 - accuracy: 0.7524 - val_loss: 1.3912 - val_accuracy: 0.1556 - 299ms/epoch - 75ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 1.38747\n",
      "4/4 - 0s - loss: 0.9541 - accuracy: 0.7143 - val_loss: 1.3922 - val_accuracy: 0.1556 - 306ms/epoch - 76ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 1.38747\n",
      "4/4 - 0s - loss: 0.9724 - accuracy: 0.6952 - val_loss: 1.3923 - val_accuracy: 0.1556 - 305ms/epoch - 76ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 1.38747\n",
      "4/4 - 0s - loss: 0.9735 - accuracy: 0.7429 - val_loss: 1.3910 - val_accuracy: 0.1556 - 300ms/epoch - 75ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 1.38747\n",
      "4/4 - 0s - loss: 0.9397 - accuracy: 0.8476 - val_loss: 1.3906 - val_accuracy: 0.1556 - 294ms/epoch - 74ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.38747\n",
      "4/4 - 0s - loss: 0.9393 - accuracy: 0.7714 - val_loss: 1.3923 - val_accuracy: 0.1556 - 297ms/epoch - 74ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 1.38747\n",
      "4/4 - 0s - loss: 0.9119 - accuracy: 0.8190 - val_loss: 1.3923 - val_accuracy: 0.1556 - 305ms/epoch - 76ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 1.38747\n",
      "4/4 - 0s - loss: 0.9561 - accuracy: 0.7333 - val_loss: 1.3923 - val_accuracy: 0.1556 - 299ms/epoch - 75ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 1.38747\n",
      "4/4 - 0s - loss: 0.9250 - accuracy: 0.7810 - val_loss: 1.3935 - val_accuracy: 0.1556 - 316ms/epoch - 79ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 1.38747\n",
      "4/4 - 0s - loss: 0.9209 - accuracy: 0.7905 - val_loss: 1.3922 - val_accuracy: 0.1556 - 311ms/epoch - 78ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 1.38747\n",
      "4/4 - 0s - loss: 0.8784 - accuracy: 0.8476 - val_loss: 1.3906 - val_accuracy: 0.1556 - 299ms/epoch - 75ms/step\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 1.38747\n",
      "4/4 - 0s - loss: 0.8545 - accuracy: 0.8190 - val_loss: 1.3913 - val_accuracy: 0.1556 - 298ms/epoch - 75ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 1.38747\n",
      "4/4 - 0s - loss: 0.8686 - accuracy: 0.8190 - val_loss: 1.3926 - val_accuracy: 0.1556 - 294ms/epoch - 73ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 1.38747\n",
      "4/4 - 0s - loss: 0.8442 - accuracy: 0.8571 - val_loss: 1.3929 - val_accuracy: 0.1556 - 302ms/epoch - 76ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 1.38747\n",
      "4/4 - 0s - loss: 0.8321 - accuracy: 0.8190 - val_loss: 1.3966 - val_accuracy: 0.1556 - 301ms/epoch - 75ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 1.38747\n",
      "4/4 - 0s - loss: 0.8285 - accuracy: 0.8476 - val_loss: 1.3897 - val_accuracy: 0.1556 - 301ms/epoch - 75ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 1.38747\n",
      "4/4 - 0s - loss: 0.8498 - accuracy: 0.8476 - val_loss: 1.3904 - val_accuracy: 0.1556 - 310ms/epoch - 77ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 1.38747\n",
      "4/4 - 0s - loss: 0.8138 - accuracy: 0.8476 - val_loss: 1.3920 - val_accuracy: 0.1556 - 296ms/epoch - 74ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss improved from 1.38747 to 1.38695, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.8204 - accuracy: 0.8667 - val_loss: 1.3869 - val_accuracy: 0.2222 - 350ms/epoch - 87ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss improved from 1.38695 to 1.38501, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.7843 - accuracy: 0.8286 - val_loss: 1.3850 - val_accuracy: 0.2444 - 362ms/epoch - 91ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 1.38501\n",
      "4/4 - 0s - loss: 0.7771 - accuracy: 0.9238 - val_loss: 1.3886 - val_accuracy: 0.1556 - 302ms/epoch - 76ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 1.38501\n",
      "4/4 - 0s - loss: 0.7865 - accuracy: 0.8952 - val_loss: 1.3918 - val_accuracy: 0.1556 - 296ms/epoch - 74ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 1.38501\n",
      "4/4 - 0s - loss: 0.7775 - accuracy: 0.8857 - val_loss: 1.3860 - val_accuracy: 0.1556 - 296ms/epoch - 74ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss improved from 1.38501 to 1.38414, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.7669 - accuracy: 0.8857 - val_loss: 1.3841 - val_accuracy: 0.2000 - 348ms/epoch - 87ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 1.38414\n",
      "4/4 - 0s - loss: 0.7599 - accuracy: 0.8952 - val_loss: 1.3899 - val_accuracy: 0.1778 - 297ms/epoch - 74ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 1.38414\n",
      "4/4 - 0s - loss: 0.7501 - accuracy: 0.8571 - val_loss: 1.3952 - val_accuracy: 0.1556 - 303ms/epoch - 76ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 1.38414\n",
      "4/4 - 0s - loss: 0.7466 - accuracy: 0.8667 - val_loss: 1.3894 - val_accuracy: 0.2000 - 312ms/epoch - 78ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 1.38414\n",
      "4/4 - 0s - loss: 0.7297 - accuracy: 0.8857 - val_loss: 1.3860 - val_accuracy: 0.2000 - 305ms/epoch - 76ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 1.38414\n",
      "4/4 - 0s - loss: 0.7205 - accuracy: 0.9238 - val_loss: 1.3861 - val_accuracy: 0.2222 - 310ms/epoch - 77ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss improved from 1.38414 to 1.37621, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.7108 - accuracy: 0.9048 - val_loss: 1.3762 - val_accuracy: 0.3333 - 351ms/epoch - 88ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 1.37621\n",
      "4/4 - 0s - loss: 0.7068 - accuracy: 0.9048 - val_loss: 1.3809 - val_accuracy: 0.1556 - 310ms/epoch - 77ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 1.37621\n",
      "4/4 - 0s - loss: 0.6710 - accuracy: 0.9524 - val_loss: 1.3850 - val_accuracy: 0.1556 - 301ms/epoch - 75ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 1.37621\n",
      "4/4 - 0s - loss: 0.6943 - accuracy: 0.9333 - val_loss: 1.3778 - val_accuracy: 0.2667 - 296ms/epoch - 74ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 1.37621\n",
      "4/4 - 0s - loss: 0.6388 - accuracy: 0.9524 - val_loss: 1.3815 - val_accuracy: 0.1556 - 311ms/epoch - 78ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 1.37621\n",
      "4/4 - 0s - loss: 0.6627 - accuracy: 0.9333 - val_loss: 1.3842 - val_accuracy: 0.1333 - 313ms/epoch - 78ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 1.37621\n",
      "4/4 - 0s - loss: 0.6651 - accuracy: 0.9429 - val_loss: 1.3798 - val_accuracy: 0.2222 - 294ms/epoch - 73ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 1.37621\n",
      "4/4 - 0s - loss: 0.6155 - accuracy: 0.9333 - val_loss: 1.3886 - val_accuracy: 0.2889 - 296ms/epoch - 74ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 1.37621\n",
      "4/4 - 0s - loss: 0.6192 - accuracy: 0.9619 - val_loss: 1.3921 - val_accuracy: 0.1333 - 295ms/epoch - 74ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 1.37621\n",
      "4/4 - 0s - loss: 0.5964 - accuracy: 0.9810 - val_loss: 1.3795 - val_accuracy: 0.2444 - 303ms/epoch - 76ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 1.37621\n",
      "4/4 - 0s - loss: 0.6078 - accuracy: 0.9714 - val_loss: 1.3867 - val_accuracy: 0.1778 - 308ms/epoch - 77ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 1.37621\n",
      "4/4 - 0s - loss: 0.5683 - accuracy: 0.9524 - val_loss: 1.3798 - val_accuracy: 0.1778 - 292ms/epoch - 73ms/step\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 1.37621\n",
      "4/4 - 0s - loss: 0.6075 - accuracy: 0.9333 - val_loss: 1.3815 - val_accuracy: 0.2000 - 301ms/epoch - 75ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 1.37621\n",
      "4/4 - 0s - loss: 0.5576 - accuracy: 0.9429 - val_loss: 1.3892 - val_accuracy: 0.1556 - 306ms/epoch - 77ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss improved from 1.37621 to 1.37072, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.5328 - accuracy: 0.9810 - val_loss: 1.3707 - val_accuracy: 0.2000 - 353ms/epoch - 88ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 1.37072\n",
      "4/4 - 0s - loss: 0.5753 - accuracy: 0.9333 - val_loss: 1.3791 - val_accuracy: 0.2222 - 301ms/epoch - 75ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 1.37072\n",
      "4/4 - 0s - loss: 0.5665 - accuracy: 0.9524 - val_loss: 1.3972 - val_accuracy: 0.1556 - 305ms/epoch - 76ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 1.37072\n",
      "4/4 - 0s - loss: 0.5300 - accuracy: 0.9810 - val_loss: 1.3888 - val_accuracy: 0.2667 - 302ms/epoch - 75ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 1.37072\n",
      "4/4 - 0s - loss: 0.5373 - accuracy: 0.9429 - val_loss: 1.3819 - val_accuracy: 0.2000 - 298ms/epoch - 74ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 1.37072\n",
      "4/4 - 0s - loss: 0.5387 - accuracy: 0.9524 - val_loss: 1.4316 - val_accuracy: 0.1556 - 296ms/epoch - 74ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss improved from 1.37072 to 1.36921, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.5990 - accuracy: 0.9524 - val_loss: 1.3692 - val_accuracy: 0.3333 - 361ms/epoch - 90ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss improved from 1.36921 to 1.34290, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.5513 - accuracy: 0.9429 - val_loss: 1.3429 - val_accuracy: 0.4000 - 356ms/epoch - 89ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.5072 - accuracy: 0.9905 - val_loss: 1.4053 - val_accuracy: 0.2889 - 298ms/epoch - 74ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.5078 - accuracy: 0.9524 - val_loss: 1.3945 - val_accuracy: 0.2444 - 302ms/epoch - 75ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.5282 - accuracy: 0.9714 - val_loss: 1.3881 - val_accuracy: 0.2889 - 307ms/epoch - 77ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.5191 - accuracy: 0.9714 - val_loss: 1.4267 - val_accuracy: 0.1778 - 306ms/epoch - 76ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.5307 - accuracy: 0.9524 - val_loss: 1.4165 - val_accuracy: 0.2444 - 294ms/epoch - 73ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.5529 - accuracy: 0.9714 - val_loss: 1.4018 - val_accuracy: 0.2444 - 312ms/epoch - 78ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.4896 - accuracy: 0.9905 - val_loss: 1.4399 - val_accuracy: 0.2444 - 295ms/epoch - 74ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.4478 - accuracy: 0.9619 - val_loss: 1.3905 - val_accuracy: 0.2444 - 312ms/epoch - 78ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.4424 - accuracy: 0.9714 - val_loss: 1.4005 - val_accuracy: 0.2222 - 310ms/epoch - 77ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.4481 - accuracy: 0.9905 - val_loss: 1.4281 - val_accuracy: 0.2222 - 323ms/epoch - 81ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.4533 - accuracy: 0.9810 - val_loss: 1.4922 - val_accuracy: 0.2444 - 295ms/epoch - 74ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.4443 - accuracy: 0.9905 - val_loss: 1.4804 - val_accuracy: 0.1778 - 316ms/epoch - 79ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.4396 - accuracy: 0.9810 - val_loss: 1.4285 - val_accuracy: 0.2000 - 309ms/epoch - 77ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.4563 - accuracy: 0.9905 - val_loss: 1.4648 - val_accuracy: 0.2667 - 298ms/epoch - 75ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.4595 - accuracy: 0.9714 - val_loss: 1.4254 - val_accuracy: 0.2667 - 319ms/epoch - 80ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.3963 - accuracy: 0.9905 - val_loss: 1.4334 - val_accuracy: 0.2889 - 338ms/epoch - 85ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.4439 - accuracy: 0.9905 - val_loss: 1.4567 - val_accuracy: 0.2000 - 291ms/epoch - 73ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.4341 - accuracy: 0.9714 - val_loss: 1.5457 - val_accuracy: 0.2222 - 301ms/epoch - 75ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.4091 - accuracy: 0.9905 - val_loss: 1.6266 - val_accuracy: 0.2444 - 298ms/epoch - 75ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.3873 - accuracy: 1.0000 - val_loss: 1.4694 - val_accuracy: 0.1778 - 306ms/epoch - 77ms/step\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.3955 - accuracy: 0.9905 - val_loss: 1.4810 - val_accuracy: 0.3111 - 310ms/epoch - 77ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.4112 - accuracy: 0.9714 - val_loss: 1.4668 - val_accuracy: 0.2444 - 306ms/epoch - 77ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.3695 - accuracy: 1.0000 - val_loss: 1.5365 - val_accuracy: 0.1556 - 306ms/epoch - 76ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.3711 - accuracy: 0.9905 - val_loss: 1.4428 - val_accuracy: 0.2000 - 298ms/epoch - 75ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.3723 - accuracy: 0.9905 - val_loss: 1.4697 - val_accuracy: 0.2444 - 296ms/epoch - 74ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.3608 - accuracy: 1.0000 - val_loss: 1.5338 - val_accuracy: 0.2222 - 316ms/epoch - 79ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.4070 - accuracy: 0.9905 - val_loss: 1.4827 - val_accuracy: 0.2000 - 311ms/epoch - 78ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.3359 - accuracy: 0.9905 - val_loss: 1.4676 - val_accuracy: 0.2222 - 293ms/epoch - 73ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.3265 - accuracy: 1.0000 - val_loss: 1.4926 - val_accuracy: 0.2000 - 298ms/epoch - 75ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.3047 - accuracy: 1.0000 - val_loss: 1.5023 - val_accuracy: 0.2444 - 303ms/epoch - 76ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.3094 - accuracy: 1.0000 - val_loss: 1.4773 - val_accuracy: 0.2444 - 293ms/epoch - 73ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.2755 - accuracy: 1.0000 - val_loss: 1.5413 - val_accuracy: 0.2000 - 297ms/epoch - 74ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.3058 - accuracy: 0.9810 - val_loss: 1.4894 - val_accuracy: 0.2444 - 297ms/epoch - 74ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.2940 - accuracy: 1.0000 - val_loss: 1.4745 - val_accuracy: 0.2889 - 303ms/epoch - 76ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.3014 - accuracy: 1.0000 - val_loss: 1.4864 - val_accuracy: 0.2889 - 297ms/epoch - 74ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.2925 - accuracy: 0.9810 - val_loss: 1.5046 - val_accuracy: 0.2000 - 304ms/epoch - 76ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.3034 - accuracy: 1.0000 - val_loss: 1.5410 - val_accuracy: 0.2222 - 301ms/epoch - 75ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.3106 - accuracy: 0.9905 - val_loss: 1.5014 - val_accuracy: 0.2444 - 303ms/epoch - 76ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.3117 - accuracy: 1.0000 - val_loss: 1.5096 - val_accuracy: 0.2222 - 309ms/epoch - 77ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.3180 - accuracy: 1.0000 - val_loss: 1.5147 - val_accuracy: 0.2444 - 294ms/epoch - 74ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.2920 - accuracy: 1.0000 - val_loss: 1.5874 - val_accuracy: 0.2444 - 314ms/epoch - 78ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.3003 - accuracy: 1.0000 - val_loss: 1.5671 - val_accuracy: 0.2222 - 304ms/epoch - 76ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.3224 - accuracy: 0.9810 - val_loss: 1.5124 - val_accuracy: 0.3333 - 317ms/epoch - 79ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.3247 - accuracy: 0.9905 - val_loss: 1.4312 - val_accuracy: 0.2667 - 297ms/epoch - 74ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.2836 - accuracy: 1.0000 - val_loss: 1.5393 - val_accuracy: 0.2444 - 296ms/epoch - 74ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.2982 - accuracy: 1.0000 - val_loss: 1.6079 - val_accuracy: 0.2000 - 305ms/epoch - 76ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.2725 - accuracy: 0.9905 - val_loss: 1.5650 - val_accuracy: 0.2667 - 297ms/epoch - 74ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.2825 - accuracy: 1.0000 - val_loss: 1.5504 - val_accuracy: 0.2889 - 304ms/epoch - 76ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.2602 - accuracy: 1.0000 - val_loss: 1.7275 - val_accuracy: 0.1778 - 305ms/epoch - 76ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.2804 - accuracy: 1.0000 - val_loss: 1.5759 - val_accuracy: 0.2889 - 304ms/epoch - 76ms/step\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.3055 - accuracy: 0.9810 - val_loss: 1.5247 - val_accuracy: 0.3111 - 311ms/epoch - 78ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.2867 - accuracy: 0.9905 - val_loss: 1.6382 - val_accuracy: 0.2222 - 295ms/epoch - 74ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.2762 - accuracy: 0.9905 - val_loss: 1.7771 - val_accuracy: 0.2444 - 305ms/epoch - 76ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.2630 - accuracy: 1.0000 - val_loss: 1.6897 - val_accuracy: 0.2667 - 305ms/epoch - 76ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.2413 - accuracy: 1.0000 - val_loss: 1.8549 - val_accuracy: 0.2444 - 296ms/epoch - 74ms/step\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.2754 - accuracy: 0.9905 - val_loss: 1.7070 - val_accuracy: 0.2222 - 310ms/epoch - 77ms/step\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.2639 - accuracy: 1.0000 - val_loss: 1.7391 - val_accuracy: 0.2222 - 306ms/epoch - 76ms/step\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.2530 - accuracy: 1.0000 - val_loss: 1.7078 - val_accuracy: 0.2444 - 301ms/epoch - 75ms/step\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.2555 - accuracy: 1.0000 - val_loss: 1.6077 - val_accuracy: 0.2889 - 307ms/epoch - 77ms/step\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.2404 - accuracy: 1.0000 - val_loss: 1.6191 - val_accuracy: 0.2222 - 308ms/epoch - 77ms/step\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.2234 - accuracy: 1.0000 - val_loss: 1.5876 - val_accuracy: 0.2667 - 307ms/epoch - 77ms/step\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.5668 - val_accuracy: 0.3333 - 305ms/epoch - 76ms/step\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1782 - accuracy: 1.0000 - val_loss: 1.6127 - val_accuracy: 0.2000 - 303ms/epoch - 76ms/step\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.2195 - accuracy: 1.0000 - val_loss: 1.5701 - val_accuracy: 0.2444 - 296ms/epoch - 74ms/step\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 135: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.2394 - accuracy: 1.0000 - val_loss: 1.6077 - val_accuracy: 0.2889 - 315ms/epoch - 79ms/step\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 136: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.2365 - accuracy: 1.0000 - val_loss: 1.6406 - val_accuracy: 0.2444 - 295ms/epoch - 74ms/step\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 137: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.2360 - accuracy: 1.0000 - val_loss: 1.6139 - val_accuracy: 0.2000 - 300ms/epoch - 75ms/step\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 138: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 1.6439 - val_accuracy: 0.2444 - 313ms/epoch - 78ms/step\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 139: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 1.6991 - val_accuracy: 0.2889 - 302ms/epoch - 75ms/step\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 140: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 1.6879 - val_accuracy: 0.2667 - 294ms/epoch - 74ms/step\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 141: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1823 - accuracy: 1.0000 - val_loss: 1.6116 - val_accuracy: 0.2444 - 311ms/epoch - 78ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/300\n",
      "\n",
      "Epoch 142: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1832 - accuracy: 1.0000 - val_loss: 1.5968 - val_accuracy: 0.3333 - 300ms/epoch - 75ms/step\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 143: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1883 - accuracy: 1.0000 - val_loss: 1.6141 - val_accuracy: 0.2889 - 307ms/epoch - 77ms/step\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 144: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.2161 - accuracy: 0.9905 - val_loss: 1.6159 - val_accuracy: 0.2667 - 303ms/epoch - 76ms/step\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 145: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.2394 - accuracy: 1.0000 - val_loss: 1.5913 - val_accuracy: 0.3111 - 309ms/epoch - 77ms/step\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 146: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.2216 - accuracy: 0.9905 - val_loss: 1.6688 - val_accuracy: 0.2667 - 302ms/epoch - 75ms/step\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 147: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1952 - accuracy: 1.0000 - val_loss: 1.7048 - val_accuracy: 0.2889 - 296ms/epoch - 74ms/step\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 148: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1941 - accuracy: 1.0000 - val_loss: 1.7096 - val_accuracy: 0.2889 - 302ms/epoch - 76ms/step\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 149: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.2027 - accuracy: 1.0000 - val_loss: 1.8324 - val_accuracy: 0.2000 - 299ms/epoch - 75ms/step\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 150: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1805 - accuracy: 1.0000 - val_loss: 1.7051 - val_accuracy: 0.2000 - 299ms/epoch - 75ms/step\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 151: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.2042 - accuracy: 1.0000 - val_loss: 1.6898 - val_accuracy: 0.2000 - 305ms/epoch - 76ms/step\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 152: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1789 - accuracy: 1.0000 - val_loss: 1.6507 - val_accuracy: 0.2000 - 303ms/epoch - 76ms/step\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 153: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1745 - accuracy: 1.0000 - val_loss: 1.6562 - val_accuracy: 0.2444 - 301ms/epoch - 75ms/step\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 154: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1877 - accuracy: 1.0000 - val_loss: 1.6466 - val_accuracy: 0.2444 - 312ms/epoch - 78ms/step\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 155: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1736 - accuracy: 1.0000 - val_loss: 1.6527 - val_accuracy: 0.2222 - 314ms/epoch - 78ms/step\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 156: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1804 - accuracy: 1.0000 - val_loss: 1.7310 - val_accuracy: 0.2000 - 296ms/epoch - 74ms/step\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 157: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1578 - accuracy: 1.0000 - val_loss: 1.8129 - val_accuracy: 0.1778 - 304ms/epoch - 76ms/step\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 158: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1742 - accuracy: 1.0000 - val_loss: 1.7697 - val_accuracy: 0.2222 - 297ms/epoch - 74ms/step\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 159: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1854 - accuracy: 1.0000 - val_loss: 1.7502 - val_accuracy: 0.2667 - 300ms/epoch - 75ms/step\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 160: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1956 - accuracy: 1.0000 - val_loss: 1.7467 - val_accuracy: 0.1778 - 311ms/epoch - 78ms/step\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 161: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1682 - accuracy: 1.0000 - val_loss: 1.6970 - val_accuracy: 0.2222 - 326ms/epoch - 81ms/step\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 162: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1926 - accuracy: 1.0000 - val_loss: 1.7508 - val_accuracy: 0.2000 - 304ms/epoch - 76ms/step\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 163: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1587 - accuracy: 1.0000 - val_loss: 1.7336 - val_accuracy: 0.2222 - 299ms/epoch - 75ms/step\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 164: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1591 - accuracy: 1.0000 - val_loss: 1.7528 - val_accuracy: 0.3111 - 297ms/epoch - 74ms/step\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 165: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1599 - accuracy: 1.0000 - val_loss: 1.6476 - val_accuracy: 0.3111 - 296ms/epoch - 74ms/step\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 166: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1702 - accuracy: 1.0000 - val_loss: 1.6645 - val_accuracy: 0.2889 - 297ms/epoch - 74ms/step\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 167: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1600 - accuracy: 1.0000 - val_loss: 1.7087 - val_accuracy: 0.2667 - 307ms/epoch - 77ms/step\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 168: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1825 - accuracy: 1.0000 - val_loss: 1.7927 - val_accuracy: 0.2222 - 317ms/epoch - 79ms/step\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 169: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1785 - accuracy: 1.0000 - val_loss: 1.9110 - val_accuracy: 0.2222 - 312ms/epoch - 78ms/step\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 170: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1740 - accuracy: 1.0000 - val_loss: 1.9630 - val_accuracy: 0.2222 - 295ms/epoch - 74ms/step\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 171: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1505 - accuracy: 1.0000 - val_loss: 1.7459 - val_accuracy: 0.2444 - 303ms/epoch - 76ms/step\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 172: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1703 - accuracy: 0.9905 - val_loss: 1.6985 - val_accuracy: 0.2889 - 302ms/epoch - 75ms/step\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 173: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1548 - accuracy: 1.0000 - val_loss: 1.6824 - val_accuracy: 0.2222 - 299ms/epoch - 75ms/step\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 174: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1740 - accuracy: 1.0000 - val_loss: 1.6988 - val_accuracy: 0.2667 - 311ms/epoch - 78ms/step\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 175: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1650 - accuracy: 1.0000 - val_loss: 1.7177 - val_accuracy: 0.2667 - 293ms/epoch - 73ms/step\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 176: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1519 - accuracy: 1.0000 - val_loss: 1.7130 - val_accuracy: 0.2000 - 294ms/epoch - 73ms/step\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 177: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1560 - accuracy: 1.0000 - val_loss: 1.7172 - val_accuracy: 0.2667 - 300ms/epoch - 75ms/step\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 178: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1341 - accuracy: 1.0000 - val_loss: 1.6623 - val_accuracy: 0.2444 - 300ms/epoch - 75ms/step\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 179: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1429 - accuracy: 1.0000 - val_loss: 1.6960 - val_accuracy: 0.3111 - 303ms/epoch - 76ms/step\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 180: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1356 - accuracy: 1.0000 - val_loss: 1.7788 - val_accuracy: 0.2222 - 299ms/epoch - 75ms/step\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 181: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1445 - accuracy: 1.0000 - val_loss: 1.7534 - val_accuracy: 0.2667 - 291ms/epoch - 73ms/step\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 182: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1375 - accuracy: 1.0000 - val_loss: 1.7586 - val_accuracy: 0.2222 - 302ms/epoch - 75ms/step\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 183: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1373 - accuracy: 1.0000 - val_loss: 1.8331 - val_accuracy: 0.2444 - 329ms/epoch - 82ms/step\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 184: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1405 - accuracy: 1.0000 - val_loss: 1.8316 - val_accuracy: 0.2444 - 307ms/epoch - 77ms/step\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 185: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1351 - accuracy: 1.0000 - val_loss: 1.8317 - val_accuracy: 0.2222 - 294ms/epoch - 73ms/step\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 186: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1329 - accuracy: 1.0000 - val_loss: 1.8219 - val_accuracy: 0.2000 - 298ms/epoch - 74ms/step\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 187: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1417 - accuracy: 1.0000 - val_loss: 1.7075 - val_accuracy: 0.2889 - 311ms/epoch - 78ms/step\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 188: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1263 - accuracy: 1.0000 - val_loss: 1.7545 - val_accuracy: 0.2889 - 303ms/epoch - 76ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189/300\n",
      "\n",
      "Epoch 189: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1232 - accuracy: 1.0000 - val_loss: 1.7952 - val_accuracy: 0.3111 - 295ms/epoch - 74ms/step\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 190: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1265 - accuracy: 1.0000 - val_loss: 1.8225 - val_accuracy: 0.2889 - 306ms/epoch - 76ms/step\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 191: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1281 - accuracy: 1.0000 - val_loss: 1.9066 - val_accuracy: 0.2000 - 303ms/epoch - 76ms/step\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 192: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1201 - accuracy: 1.0000 - val_loss: 2.0154 - val_accuracy: 0.1778 - 294ms/epoch - 73ms/step\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 193: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1525 - accuracy: 0.9905 - val_loss: 1.8987 - val_accuracy: 0.2000 - 303ms/epoch - 76ms/step\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 194: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1335 - accuracy: 1.0000 - val_loss: 1.8217 - val_accuracy: 0.2444 - 296ms/epoch - 74ms/step\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 195: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1652 - accuracy: 0.9810 - val_loss: 1.7923 - val_accuracy: 0.2000 - 312ms/epoch - 78ms/step\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 196: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1531 - accuracy: 1.0000 - val_loss: 1.8482 - val_accuracy: 0.1556 - 314ms/epoch - 79ms/step\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 197: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1283 - accuracy: 1.0000 - val_loss: 1.9836 - val_accuracy: 0.1778 - 302ms/epoch - 76ms/step\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 198: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1363 - accuracy: 1.0000 - val_loss: 1.9874 - val_accuracy: 0.2000 - 294ms/epoch - 73ms/step\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 199: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1467 - accuracy: 1.0000 - val_loss: 2.0051 - val_accuracy: 0.2000 - 294ms/epoch - 74ms/step\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 200: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1335 - accuracy: 1.0000 - val_loss: 1.9352 - val_accuracy: 0.2667 - 300ms/epoch - 75ms/step\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 201: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1495 - accuracy: 1.0000 - val_loss: 1.8073 - val_accuracy: 0.2444 - 292ms/epoch - 73ms/step\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 202: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1335 - accuracy: 1.0000 - val_loss: 1.7749 - val_accuracy: 0.2000 - 305ms/epoch - 76ms/step\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 203: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1242 - accuracy: 1.0000 - val_loss: 1.8057 - val_accuracy: 0.2889 - 298ms/epoch - 75ms/step\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 204: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1241 - accuracy: 1.0000 - val_loss: 1.7655 - val_accuracy: 0.2667 - 305ms/epoch - 76ms/step\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 205: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1130 - accuracy: 1.0000 - val_loss: 1.7894 - val_accuracy: 0.2000 - 297ms/epoch - 74ms/step\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 206: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1125 - accuracy: 1.0000 - val_loss: 1.7711 - val_accuracy: 0.1778 - 302ms/epoch - 75ms/step\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 207: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1120 - accuracy: 1.0000 - val_loss: 1.8549 - val_accuracy: 0.2000 - 300ms/epoch - 75ms/step\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 208: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0959 - accuracy: 1.0000 - val_loss: 1.9003 - val_accuracy: 0.1111 - 302ms/epoch - 75ms/step\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 209: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1133 - accuracy: 1.0000 - val_loss: 1.8239 - val_accuracy: 0.1556 - 309ms/epoch - 77ms/step\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 210: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1215 - accuracy: 1.0000 - val_loss: 1.7624 - val_accuracy: 0.2222 - 296ms/epoch - 74ms/step\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 211: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0997 - accuracy: 1.0000 - val_loss: 1.7623 - val_accuracy: 0.2000 - 295ms/epoch - 74ms/step\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 212: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1151 - accuracy: 1.0000 - val_loss: 1.7828 - val_accuracy: 0.2444 - 295ms/epoch - 74ms/step\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 213: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1116 - accuracy: 1.0000 - val_loss: 1.7645 - val_accuracy: 0.2222 - 297ms/epoch - 74ms/step\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 214: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1204 - accuracy: 0.9905 - val_loss: 1.7755 - val_accuracy: 0.2667 - 312ms/epoch - 78ms/step\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 215: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1081 - accuracy: 1.0000 - val_loss: 1.8374 - val_accuracy: 0.2889 - 293ms/epoch - 73ms/step\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 216: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1414 - accuracy: 1.0000 - val_loss: 1.8612 - val_accuracy: 0.2667 - 320ms/epoch - 80ms/step\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 217: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1326 - accuracy: 1.0000 - val_loss: 1.8806 - val_accuracy: 0.1778 - 309ms/epoch - 77ms/step\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 218: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1480 - accuracy: 1.0000 - val_loss: 1.9048 - val_accuracy: 0.1778 - 295ms/epoch - 74ms/step\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 219: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1138 - accuracy: 1.0000 - val_loss: 2.0593 - val_accuracy: 0.1778 - 308ms/epoch - 77ms/step\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 220: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1133 - accuracy: 1.0000 - val_loss: 1.9057 - val_accuracy: 0.2000 - 301ms/epoch - 75ms/step\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 221: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1081 - accuracy: 1.0000 - val_loss: 1.8102 - val_accuracy: 0.2444 - 312ms/epoch - 78ms/step\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 222: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1118 - accuracy: 1.0000 - val_loss: 1.8610 - val_accuracy: 0.2222 - 298ms/epoch - 75ms/step\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 223: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1164 - accuracy: 1.0000 - val_loss: 1.7849 - val_accuracy: 0.2889 - 309ms/epoch - 77ms/step\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 224: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0929 - accuracy: 1.0000 - val_loss: 1.7834 - val_accuracy: 0.2444 - 311ms/epoch - 78ms/step\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 225: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1010 - accuracy: 1.0000 - val_loss: 1.8233 - val_accuracy: 0.2444 - 303ms/epoch - 76ms/step\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 226: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0994 - accuracy: 1.0000 - val_loss: 1.8019 - val_accuracy: 0.2000 - 300ms/epoch - 75ms/step\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 227: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0944 - accuracy: 1.0000 - val_loss: 1.8135 - val_accuracy: 0.2222 - 313ms/epoch - 78ms/step\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 228: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1082 - accuracy: 1.0000 - val_loss: 1.8680 - val_accuracy: 0.2222 - 301ms/epoch - 75ms/step\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 229: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1245 - accuracy: 1.0000 - val_loss: 1.8333 - val_accuracy: 0.2222 - 315ms/epoch - 79ms/step\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 230: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0997 - accuracy: 1.0000 - val_loss: 1.8009 - val_accuracy: 0.2444 - 308ms/epoch - 77ms/step\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 231: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1252 - accuracy: 1.0000 - val_loss: 1.8898 - val_accuracy: 0.2667 - 297ms/epoch - 74ms/step\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 232: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1056 - accuracy: 1.0000 - val_loss: 1.9579 - val_accuracy: 0.2222 - 299ms/epoch - 75ms/step\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 233: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1086 - accuracy: 1.0000 - val_loss: 1.8661 - val_accuracy: 0.2889 - 306ms/epoch - 76ms/step\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 234: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1016 - accuracy: 1.0000 - val_loss: 1.8419 - val_accuracy: 0.2222 - 299ms/epoch - 75ms/step\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 235: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1039 - accuracy: 1.0000 - val_loss: 1.8387 - val_accuracy: 0.2000 - 286ms/epoch - 72ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 236/300\n",
      "\n",
      "Epoch 236: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1063 - accuracy: 1.0000 - val_loss: 1.8117 - val_accuracy: 0.2222 - 303ms/epoch - 76ms/step\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 237: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0858 - accuracy: 1.0000 - val_loss: 1.8139 - val_accuracy: 0.2667 - 291ms/epoch - 73ms/step\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 238: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0926 - accuracy: 1.0000 - val_loss: 1.8634 - val_accuracy: 0.2889 - 307ms/epoch - 77ms/step\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 239: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0889 - accuracy: 1.0000 - val_loss: 1.8560 - val_accuracy: 0.2667 - 306ms/epoch - 77ms/step\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 240: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0938 - accuracy: 1.0000 - val_loss: 1.7978 - val_accuracy: 0.2444 - 318ms/epoch - 79ms/step\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 241: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0921 - accuracy: 1.0000 - val_loss: 1.8630 - val_accuracy: 0.2444 - 307ms/epoch - 77ms/step\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 242: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0942 - accuracy: 1.0000 - val_loss: 2.0317 - val_accuracy: 0.2000 - 293ms/epoch - 73ms/step\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 243: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1032 - accuracy: 1.0000 - val_loss: 2.0947 - val_accuracy: 0.1556 - 305ms/epoch - 76ms/step\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 244: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1099 - accuracy: 1.0000 - val_loss: 2.0525 - val_accuracy: 0.1333 - 308ms/epoch - 77ms/step\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 245: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0928 - accuracy: 1.0000 - val_loss: 1.9398 - val_accuracy: 0.1778 - 308ms/epoch - 77ms/step\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 246: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0875 - accuracy: 1.0000 - val_loss: 1.9442 - val_accuracy: 0.1778 - 294ms/epoch - 73ms/step\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 247: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.1069 - accuracy: 1.0000 - val_loss: 1.8694 - val_accuracy: 0.1333 - 292ms/epoch - 73ms/step\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 248: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0911 - accuracy: 1.0000 - val_loss: 1.9148 - val_accuracy: 0.1778 - 295ms/epoch - 74ms/step\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 249: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0926 - accuracy: 1.0000 - val_loss: 1.9564 - val_accuracy: 0.2000 - 306ms/epoch - 76ms/step\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 250: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0958 - accuracy: 1.0000 - val_loss: 1.9022 - val_accuracy: 0.2667 - 311ms/epoch - 78ms/step\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 251: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0898 - accuracy: 1.0000 - val_loss: 1.9302 - val_accuracy: 0.2000 - 300ms/epoch - 75ms/step\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 252: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0817 - accuracy: 1.0000 - val_loss: 1.8799 - val_accuracy: 0.2667 - 309ms/epoch - 77ms/step\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 253: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0975 - accuracy: 1.0000 - val_loss: 1.8778 - val_accuracy: 0.2667 - 311ms/epoch - 78ms/step\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 254: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0857 - accuracy: 1.0000 - val_loss: 1.8456 - val_accuracy: 0.1778 - 294ms/epoch - 73ms/step\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 255: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0957 - accuracy: 1.0000 - val_loss: 1.8920 - val_accuracy: 0.2222 - 293ms/epoch - 73ms/step\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 256: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0885 - accuracy: 1.0000 - val_loss: 1.9588 - val_accuracy: 0.2000 - 302ms/epoch - 75ms/step\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 257: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0913 - accuracy: 1.0000 - val_loss: 1.8702 - val_accuracy: 0.1556 - 307ms/epoch - 77ms/step\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 258: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0927 - accuracy: 1.0000 - val_loss: 1.8237 - val_accuracy: 0.2222 - 300ms/epoch - 75ms/step\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 259: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0769 - accuracy: 1.0000 - val_loss: 1.8608 - val_accuracy: 0.2222 - 297ms/epoch - 74ms/step\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 260: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0925 - accuracy: 1.0000 - val_loss: 1.8739 - val_accuracy: 0.1778 - 314ms/epoch - 78ms/step\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 261: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0893 - accuracy: 1.0000 - val_loss: 1.8574 - val_accuracy: 0.2000 - 294ms/epoch - 73ms/step\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 262: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0831 - accuracy: 1.0000 - val_loss: 1.8193 - val_accuracy: 0.2000 - 301ms/epoch - 75ms/step\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 263: val_loss did not improve from 1.34290\n",
      "4/4 - 1s - loss: 0.0791 - accuracy: 1.0000 - val_loss: 1.8542 - val_accuracy: 0.2000 - 658ms/epoch - 165ms/step\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 264: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0846 - accuracy: 1.0000 - val_loss: 1.9147 - val_accuracy: 0.1778 - 307ms/epoch - 77ms/step\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 265: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0697 - accuracy: 1.0000 - val_loss: 1.8870 - val_accuracy: 0.2000 - 321ms/epoch - 80ms/step\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 266: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0853 - accuracy: 1.0000 - val_loss: 1.9339 - val_accuracy: 0.1778 - 307ms/epoch - 77ms/step\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 267: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0815 - accuracy: 1.0000 - val_loss: 1.8517 - val_accuracy: 0.1556 - 309ms/epoch - 77ms/step\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 268: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0757 - accuracy: 1.0000 - val_loss: 1.8584 - val_accuracy: 0.2222 - 312ms/epoch - 78ms/step\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 269: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0710 - accuracy: 1.0000 - val_loss: 1.8105 - val_accuracy: 0.2667 - 302ms/epoch - 76ms/step\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 270: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0731 - accuracy: 1.0000 - val_loss: 1.8199 - val_accuracy: 0.2222 - 306ms/epoch - 77ms/step\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 271: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0737 - accuracy: 1.0000 - val_loss: 1.8447 - val_accuracy: 0.1778 - 309ms/epoch - 77ms/step\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 272: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0818 - accuracy: 1.0000 - val_loss: 1.8267 - val_accuracy: 0.1778 - 321ms/epoch - 80ms/step\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 273: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0855 - accuracy: 1.0000 - val_loss: 1.9409 - val_accuracy: 0.1556 - 300ms/epoch - 75ms/step\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 274: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0814 - accuracy: 1.0000 - val_loss: 1.9619 - val_accuracy: 0.1333 - 310ms/epoch - 77ms/step\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 275: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0749 - accuracy: 1.0000 - val_loss: 1.8866 - val_accuracy: 0.2222 - 305ms/epoch - 76ms/step\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 276: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0945 - accuracy: 1.0000 - val_loss: 1.8591 - val_accuracy: 0.2000 - 313ms/epoch - 78ms/step\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 277: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0915 - accuracy: 1.0000 - val_loss: 1.8604 - val_accuracy: 0.1778 - 312ms/epoch - 78ms/step\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 278: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0708 - accuracy: 1.0000 - val_loss: 1.8881 - val_accuracy: 0.1778 - 307ms/epoch - 77ms/step\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 279: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0772 - accuracy: 1.0000 - val_loss: 1.8746 - val_accuracy: 0.2000 - 308ms/epoch - 77ms/step\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 280: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0916 - accuracy: 1.0000 - val_loss: 1.8690 - val_accuracy: 0.2000 - 306ms/epoch - 76ms/step\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 281: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0709 - accuracy: 1.0000 - val_loss: 1.8011 - val_accuracy: 0.2000 - 305ms/epoch - 76ms/step\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 282: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0785 - accuracy: 1.0000 - val_loss: 1.8848 - val_accuracy: 0.1556 - 318ms/epoch - 80ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 283/300\n",
      "\n",
      "Epoch 283: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0825 - accuracy: 1.0000 - val_loss: 1.8438 - val_accuracy: 0.1333 - 321ms/epoch - 80ms/step\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 284: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0966 - accuracy: 1.0000 - val_loss: 1.8745 - val_accuracy: 0.1778 - 307ms/epoch - 77ms/step\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 285: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0952 - accuracy: 1.0000 - val_loss: 1.9848 - val_accuracy: 0.2222 - 318ms/epoch - 79ms/step\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 286: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0891 - accuracy: 1.0000 - val_loss: 1.9281 - val_accuracy: 0.1778 - 311ms/epoch - 78ms/step\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 287: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0946 - accuracy: 1.0000 - val_loss: 1.9415 - val_accuracy: 0.1778 - 311ms/epoch - 78ms/step\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 288: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0821 - accuracy: 1.0000 - val_loss: 1.9486 - val_accuracy: 0.2222 - 306ms/epoch - 76ms/step\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 289: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0749 - accuracy: 1.0000 - val_loss: 1.8839 - val_accuracy: 0.2000 - 310ms/epoch - 77ms/step\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 290: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0840 - accuracy: 1.0000 - val_loss: 1.9376 - val_accuracy: 0.2667 - 299ms/epoch - 75ms/step\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 291: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0815 - accuracy: 1.0000 - val_loss: 2.0957 - val_accuracy: 0.3333 - 332ms/epoch - 83ms/step\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 292: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0798 - accuracy: 1.0000 - val_loss: 1.9115 - val_accuracy: 0.2667 - 299ms/epoch - 75ms/step\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 293: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0863 - accuracy: 1.0000 - val_loss: 1.8473 - val_accuracy: 0.2444 - 304ms/epoch - 76ms/step\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 294: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0769 - accuracy: 1.0000 - val_loss: 1.9334 - val_accuracy: 0.2667 - 312ms/epoch - 78ms/step\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 295: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0732 - accuracy: 1.0000 - val_loss: 1.9682 - val_accuracy: 0.2222 - 299ms/epoch - 75ms/step\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 296: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0678 - accuracy: 1.0000 - val_loss: 2.0459 - val_accuracy: 0.2000 - 314ms/epoch - 79ms/step\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 297: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0693 - accuracy: 1.0000 - val_loss: 2.1082 - val_accuracy: 0.2000 - 305ms/epoch - 76ms/step\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 298: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0790 - accuracy: 1.0000 - val_loss: 1.9194 - val_accuracy: 0.2444 - 312ms/epoch - 78ms/step\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 299: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0672 - accuracy: 1.0000 - val_loss: 1.8375 - val_accuracy: 0.2000 - 303ms/epoch - 76ms/step\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 300: val_loss did not improve from 1.34290\n",
      "4/4 - 0s - loss: 0.0874 - accuracy: 1.0000 - val_loss: 1.8470 - val_accuracy: 0.2889 - 311ms/epoch - 78ms/step\n",
      "2/2 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2022-11-11 09:12:26.238283: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_8481314\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:557278\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 09:12:30.206373: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_8484384\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:557320\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38613, saving model to checkpoint1.h5\n",
      "4/4 - 5s - loss: 1.4655 - accuracy: 0.1905 - val_loss: 1.3861 - val_accuracy: 0.2667 - 5s/epoch - 1s/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss improved from 1.38613 to 1.38612, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 1.3220 - accuracy: 0.3905 - val_loss: 1.3861 - val_accuracy: 0.2667 - 358ms/epoch - 90ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 1.2877 - accuracy: 0.4000 - val_loss: 1.3864 - val_accuracy: 0.2444 - 294ms/epoch - 73ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 1.2378 - accuracy: 0.4762 - val_loss: 1.3865 - val_accuracy: 0.1778 - 313ms/epoch - 78ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 1.2265 - accuracy: 0.5048 - val_loss: 1.3865 - val_accuracy: 0.1778 - 307ms/epoch - 77ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 1.1917 - accuracy: 0.5619 - val_loss: 1.3864 - val_accuracy: 0.2889 - 296ms/epoch - 74ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 1.1856 - accuracy: 0.5333 - val_loss: 1.3866 - val_accuracy: 0.3111 - 314ms/epoch - 79ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 1.1394 - accuracy: 0.5905 - val_loss: 1.3870 - val_accuracy: 0.2667 - 304ms/epoch - 76ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 1.1104 - accuracy: 0.6571 - val_loss: 1.3875 - val_accuracy: 0.1778 - 301ms/epoch - 75ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 1.1046 - accuracy: 0.6952 - val_loss: 1.3876 - val_accuracy: 0.1778 - 298ms/epoch - 74ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 1.0914 - accuracy: 0.6476 - val_loss: 1.3877 - val_accuracy: 0.2000 - 314ms/epoch - 79ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 1.0817 - accuracy: 0.6190 - val_loss: 1.3879 - val_accuracy: 0.2000 - 307ms/epoch - 77ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 1.0348 - accuracy: 0.7619 - val_loss: 1.3878 - val_accuracy: 0.2000 - 305ms/epoch - 76ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 1.0079 - accuracy: 0.7333 - val_loss: 1.3879 - val_accuracy: 0.1556 - 303ms/epoch - 76ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 1.0377 - accuracy: 0.6762 - val_loss: 1.3884 - val_accuracy: 0.2222 - 305ms/epoch - 76ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.9853 - accuracy: 0.7429 - val_loss: 1.3885 - val_accuracy: 0.2000 - 302ms/epoch - 76ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.9991 - accuracy: 0.6857 - val_loss: 1.3879 - val_accuracy: 0.2000 - 294ms/epoch - 74ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.9758 - accuracy: 0.7714 - val_loss: 1.3877 - val_accuracy: 0.2222 - 312ms/epoch - 78ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.9719 - accuracy: 0.7905 - val_loss: 1.3882 - val_accuracy: 0.1778 - 298ms/epoch - 75ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.9211 - accuracy: 0.8571 - val_loss: 1.3891 - val_accuracy: 0.2444 - 305ms/epoch - 76ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.9363 - accuracy: 0.8381 - val_loss: 1.3896 - val_accuracy: 0.2000 - 307ms/epoch - 77ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.9465 - accuracy: 0.7429 - val_loss: 1.3901 - val_accuracy: 0.2000 - 301ms/epoch - 75ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.9059 - accuracy: 0.8190 - val_loss: 1.3894 - val_accuracy: 0.2000 - 295ms/epoch - 74ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.9169 - accuracy: 0.8000 - val_loss: 1.3903 - val_accuracy: 0.2000 - 306ms/epoch - 76ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.8796 - accuracy: 0.8571 - val_loss: 1.3915 - val_accuracy: 0.1778 - 312ms/epoch - 78ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.8859 - accuracy: 0.8286 - val_loss: 1.3912 - val_accuracy: 0.2000 - 315ms/epoch - 79ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.9043 - accuracy: 0.8095 - val_loss: 1.3914 - val_accuracy: 0.2000 - 305ms/epoch - 76ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.8538 - accuracy: 0.8476 - val_loss: 1.3927 - val_accuracy: 0.1778 - 303ms/epoch - 76ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.8617 - accuracy: 0.8762 - val_loss: 1.3921 - val_accuracy: 0.1778 - 299ms/epoch - 75ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.8392 - accuracy: 0.8381 - val_loss: 1.3912 - val_accuracy: 0.2222 - 296ms/epoch - 74ms/step\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.8730 - accuracy: 0.8190 - val_loss: 1.3917 - val_accuracy: 0.2222 - 307ms/epoch - 77ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.8401 - accuracy: 0.8286 - val_loss: 1.3937 - val_accuracy: 0.2000 - 301ms/epoch - 75ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.8125 - accuracy: 0.8762 - val_loss: 1.3905 - val_accuracy: 0.1778 - 317ms/epoch - 79ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.8395 - accuracy: 0.8571 - val_loss: 1.3931 - val_accuracy: 0.2222 - 312ms/epoch - 78ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.8018 - accuracy: 0.8571 - val_loss: 1.3984 - val_accuracy: 0.2222 - 304ms/epoch - 76ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.8162 - accuracy: 0.8952 - val_loss: 1.3975 - val_accuracy: 0.1556 - 297ms/epoch - 74ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.7809 - accuracy: 0.8762 - val_loss: 1.3945 - val_accuracy: 0.1333 - 307ms/epoch - 77ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.7929 - accuracy: 0.8571 - val_loss: 1.3981 - val_accuracy: 0.2000 - 294ms/epoch - 74ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.7745 - accuracy: 0.8952 - val_loss: 1.4007 - val_accuracy: 0.2000 - 315ms/epoch - 79ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.7444 - accuracy: 0.9048 - val_loss: 1.3979 - val_accuracy: 0.1778 - 314ms/epoch - 78ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.7260 - accuracy: 0.8952 - val_loss: 1.4021 - val_accuracy: 0.1778 - 320ms/epoch - 80ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.7342 - accuracy: 0.9333 - val_loss: 1.4071 - val_accuracy: 0.1778 - 306ms/epoch - 76ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.7333 - accuracy: 0.9143 - val_loss: 1.3995 - val_accuracy: 0.2000 - 312ms/epoch - 78ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.7447 - accuracy: 0.9238 - val_loss: 1.4028 - val_accuracy: 0.1778 - 292ms/epoch - 73ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.7356 - accuracy: 0.9238 - val_loss: 1.4002 - val_accuracy: 0.1778 - 291ms/epoch - 73ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.6894 - accuracy: 0.9333 - val_loss: 1.4018 - val_accuracy: 0.2222 - 301ms/epoch - 75ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.7048 - accuracy: 0.9048 - val_loss: 1.4136 - val_accuracy: 0.1778 - 306ms/epoch - 76ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 1.38612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.6794 - accuracy: 0.9333 - val_loss: 1.4038 - val_accuracy: 0.1556 - 293ms/epoch - 73ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.7038 - accuracy: 0.9524 - val_loss: 1.4048 - val_accuracy: 0.1556 - 306ms/epoch - 77ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.6385 - accuracy: 0.9333 - val_loss: 1.3996 - val_accuracy: 0.1556 - 302ms/epoch - 76ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.6656 - accuracy: 0.9333 - val_loss: 1.4120 - val_accuracy: 0.1778 - 306ms/epoch - 77ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.6510 - accuracy: 0.9429 - val_loss: 1.4156 - val_accuracy: 0.1778 - 310ms/epoch - 78ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.6524 - accuracy: 0.9714 - val_loss: 1.4056 - val_accuracy: 0.1333 - 302ms/epoch - 76ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.6574 - accuracy: 0.9333 - val_loss: 1.3897 - val_accuracy: 0.1778 - 293ms/epoch - 73ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.6537 - accuracy: 0.9429 - val_loss: 1.4094 - val_accuracy: 0.1556 - 302ms/epoch - 75ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.6425 - accuracy: 0.9238 - val_loss: 1.4110 - val_accuracy: 0.1556 - 316ms/epoch - 79ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.6039 - accuracy: 0.9619 - val_loss: 1.3935 - val_accuracy: 0.1778 - 291ms/epoch - 73ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.6154 - accuracy: 0.9429 - val_loss: 1.3902 - val_accuracy: 0.2444 - 303ms/epoch - 76ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.6490 - accuracy: 0.9238 - val_loss: 1.4297 - val_accuracy: 0.1778 - 299ms/epoch - 75ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.6446 - accuracy: 0.9714 - val_loss: 1.4356 - val_accuracy: 0.1556 - 296ms/epoch - 74ms/step\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.5945 - accuracy: 0.9429 - val_loss: 1.4297 - val_accuracy: 0.1778 - 302ms/epoch - 75ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.6111 - accuracy: 0.9429 - val_loss: 1.4291 - val_accuracy: 0.1778 - 295ms/epoch - 74ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.5744 - accuracy: 0.9429 - val_loss: 1.4024 - val_accuracy: 0.2444 - 303ms/epoch - 76ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.6248 - accuracy: 0.9333 - val_loss: 1.4321 - val_accuracy: 0.1778 - 298ms/epoch - 75ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.5867 - accuracy: 0.9429 - val_loss: 1.4425 - val_accuracy: 0.1556 - 302ms/epoch - 75ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.5623 - accuracy: 0.9429 - val_loss: 1.4299 - val_accuracy: 0.1556 - 305ms/epoch - 76ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.5590 - accuracy: 0.9714 - val_loss: 1.4339 - val_accuracy: 0.1556 - 307ms/epoch - 77ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.5413 - accuracy: 0.9714 - val_loss: 1.4160 - val_accuracy: 0.2222 - 304ms/epoch - 76ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.5609 - accuracy: 0.9524 - val_loss: 1.4344 - val_accuracy: 0.1556 - 304ms/epoch - 76ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.5389 - accuracy: 0.9714 - val_loss: 1.4270 - val_accuracy: 0.2000 - 299ms/epoch - 75ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.5643 - accuracy: 0.9238 - val_loss: 1.4197 - val_accuracy: 0.2000 - 294ms/epoch - 73ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.5303 - accuracy: 0.9810 - val_loss: 1.4962 - val_accuracy: 0.2000 - 294ms/epoch - 73ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.5618 - accuracy: 0.9238 - val_loss: 1.4577 - val_accuracy: 0.1778 - 299ms/epoch - 75ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.5204 - accuracy: 0.9619 - val_loss: 1.4918 - val_accuracy: 0.2000 - 301ms/epoch - 75ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.4970 - accuracy: 0.9810 - val_loss: 1.4611 - val_accuracy: 0.2000 - 302ms/epoch - 75ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.5046 - accuracy: 0.9905 - val_loss: 1.4391 - val_accuracy: 0.1778 - 309ms/epoch - 77ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.4920 - accuracy: 0.9810 - val_loss: 1.4411 - val_accuracy: 0.2000 - 299ms/epoch - 75ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.4947 - accuracy: 0.9810 - val_loss: 1.4687 - val_accuracy: 0.1333 - 303ms/epoch - 76ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.4665 - accuracy: 0.9619 - val_loss: 1.5017 - val_accuracy: 0.1556 - 294ms/epoch - 74ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.4516 - accuracy: 1.0000 - val_loss: 1.4741 - val_accuracy: 0.1556 - 294ms/epoch - 73ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.4132 - accuracy: 0.9905 - val_loss: 1.4737 - val_accuracy: 0.1556 - 297ms/epoch - 74ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.4604 - accuracy: 0.9905 - val_loss: 1.4725 - val_accuracy: 0.1333 - 312ms/epoch - 78ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.4696 - accuracy: 0.9810 - val_loss: 1.4572 - val_accuracy: 0.1333 - 310ms/epoch - 78ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.4393 - accuracy: 0.9714 - val_loss: 1.5125 - val_accuracy: 0.1556 - 298ms/epoch - 75ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.4336 - accuracy: 1.0000 - val_loss: 1.5009 - val_accuracy: 0.1556 - 295ms/epoch - 74ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.4303 - accuracy: 0.9810 - val_loss: 1.5274 - val_accuracy: 0.1778 - 297ms/epoch - 74ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.4156 - accuracy: 0.9810 - val_loss: 1.4680 - val_accuracy: 0.2000 - 299ms/epoch - 75ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.4016 - accuracy: 0.9810 - val_loss: 1.4385 - val_accuracy: 0.2222 - 300ms/epoch - 75ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.4236 - accuracy: 1.0000 - val_loss: 1.4339 - val_accuracy: 0.1778 - 293ms/epoch - 73ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.3874 - accuracy: 1.0000 - val_loss: 1.5022 - val_accuracy: 0.1778 - 301ms/epoch - 75ms/step\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.4297 - accuracy: 0.9714 - val_loss: 1.5051 - val_accuracy: 0.2222 - 304ms/epoch - 76ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.3852 - accuracy: 0.9905 - val_loss: 1.4662 - val_accuracy: 0.2000 - 291ms/epoch - 73ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.4089 - accuracy: 0.9714 - val_loss: 1.4369 - val_accuracy: 0.1778 - 308ms/epoch - 77ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.3598 - accuracy: 0.9905 - val_loss: 1.4685 - val_accuracy: 0.1778 - 299ms/epoch - 75ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.3883 - accuracy: 1.0000 - val_loss: 1.4775 - val_accuracy: 0.2444 - 303ms/epoch - 76ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.3784 - accuracy: 1.0000 - val_loss: 1.4682 - val_accuracy: 0.2222 - 317ms/epoch - 79ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.3682 - accuracy: 1.0000 - val_loss: 1.4930 - val_accuracy: 0.1778 - 299ms/epoch - 75ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.3371 - accuracy: 0.9905 - val_loss: 1.4900 - val_accuracy: 0.2222 - 304ms/epoch - 76ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.3689 - accuracy: 0.9810 - val_loss: 1.4937 - val_accuracy: 0.1778 - 303ms/epoch - 76ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.3462 - accuracy: 1.0000 - val_loss: 1.4725 - val_accuracy: 0.1778 - 324ms/epoch - 81ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.3496 - accuracy: 0.9810 - val_loss: 1.4833 - val_accuracy: 0.2222 - 308ms/epoch - 77ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.3678 - accuracy: 1.0000 - val_loss: 1.5190 - val_accuracy: 0.1778 - 295ms/epoch - 74ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.3703 - accuracy: 1.0000 - val_loss: 1.4637 - val_accuracy: 0.2667 - 295ms/epoch - 74ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.3685 - accuracy: 0.9905 - val_loss: 1.5550 - val_accuracy: 0.1556 - 292ms/epoch - 73ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.3706 - accuracy: 0.9905 - val_loss: 1.5521 - val_accuracy: 0.1778 - 307ms/epoch - 77ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.4421 - accuracy: 0.9429 - val_loss: 1.4885 - val_accuracy: 0.2667 - 321ms/epoch - 80ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.3787 - accuracy: 1.0000 - val_loss: 1.5393 - val_accuracy: 0.2222 - 294ms/epoch - 73ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.3972 - accuracy: 0.9905 - val_loss: 1.5192 - val_accuracy: 0.2222 - 295ms/epoch - 74ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.3790 - accuracy: 0.9905 - val_loss: 1.5224 - val_accuracy: 0.1778 - 298ms/epoch - 75ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.3426 - accuracy: 1.0000 - val_loss: 1.5013 - val_accuracy: 0.2667 - 291ms/epoch - 73ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.3348 - accuracy: 1.0000 - val_loss: 1.5005 - val_accuracy: 0.2222 - 299ms/epoch - 75ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.3369 - accuracy: 0.9905 - val_loss: 1.4848 - val_accuracy: 0.2667 - 308ms/epoch - 77ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.3142 - accuracy: 1.0000 - val_loss: 1.5219 - val_accuracy: 0.2000 - 300ms/epoch - 75ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.3349 - accuracy: 0.9810 - val_loss: 1.5626 - val_accuracy: 0.2667 - 293ms/epoch - 73ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.3372 - accuracy: 0.9810 - val_loss: 1.6250 - val_accuracy: 0.2222 - 291ms/epoch - 73ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.3011 - accuracy: 1.0000 - val_loss: 1.6132 - val_accuracy: 0.2222 - 319ms/epoch - 80ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.3027 - accuracy: 1.0000 - val_loss: 1.5539 - val_accuracy: 0.2222 - 302ms/epoch - 75ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2986 - accuracy: 1.0000 - val_loss: 1.5914 - val_accuracy: 0.2222 - 309ms/epoch - 77ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2855 - accuracy: 0.9905 - val_loss: 1.5863 - val_accuracy: 0.1778 - 293ms/epoch - 73ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2589 - accuracy: 0.9905 - val_loss: 1.6026 - val_accuracy: 0.1333 - 312ms/epoch - 78ms/step\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2877 - accuracy: 1.0000 - val_loss: 1.6168 - val_accuracy: 0.1778 - 316ms/epoch - 79ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2802 - accuracy: 1.0000 - val_loss: 1.5592 - val_accuracy: 0.2889 - 307ms/epoch - 77ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2916 - accuracy: 0.9905 - val_loss: 1.6983 - val_accuracy: 0.2222 - 295ms/epoch - 74ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.3139 - accuracy: 1.0000 - val_loss: 1.5842 - val_accuracy: 0.3333 - 313ms/epoch - 78ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2953 - accuracy: 1.0000 - val_loss: 1.5097 - val_accuracy: 0.2222 - 296ms/epoch - 74ms/step\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2670 - accuracy: 1.0000 - val_loss: 1.5057 - val_accuracy: 0.3111 - 294ms/epoch - 74ms/step\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2695 - accuracy: 1.0000 - val_loss: 1.5598 - val_accuracy: 0.2222 - 295ms/epoch - 74ms/step\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2489 - accuracy: 1.0000 - val_loss: 1.6757 - val_accuracy: 0.2667 - 297ms/epoch - 74ms/step\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2248 - accuracy: 1.0000 - val_loss: 1.6357 - val_accuracy: 0.2000 - 307ms/epoch - 77ms/step\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2321 - accuracy: 1.0000 - val_loss: 1.5462 - val_accuracy: 0.2667 - 304ms/epoch - 76ms/step\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2549 - accuracy: 1.0000 - val_loss: 1.5602 - val_accuracy: 0.2444 - 302ms/epoch - 76ms/step\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2556 - accuracy: 1.0000 - val_loss: 1.6398 - val_accuracy: 0.2000 - 286ms/epoch - 72ms/step\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2752 - accuracy: 1.0000 - val_loss: 1.6876 - val_accuracy: 0.2222 - 292ms/epoch - 73ms/step\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2380 - accuracy: 1.0000 - val_loss: 1.6873 - val_accuracy: 0.2000 - 293ms/epoch - 73ms/step\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 135: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2619 - accuracy: 1.0000 - val_loss: 1.5857 - val_accuracy: 0.1778 - 294ms/epoch - 74ms/step\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 136: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2462 - accuracy: 1.0000 - val_loss: 1.6215 - val_accuracy: 0.2667 - 307ms/epoch - 77ms/step\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 137: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2541 - accuracy: 0.9905 - val_loss: 1.7016 - val_accuracy: 0.2222 - 294ms/epoch - 73ms/step\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 138: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2544 - accuracy: 0.9905 - val_loss: 1.7105 - val_accuracy: 0.2222 - 318ms/epoch - 79ms/step\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 139: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2378 - accuracy: 1.0000 - val_loss: 1.5641 - val_accuracy: 0.2889 - 307ms/epoch - 77ms/step\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 140: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2776 - accuracy: 1.0000 - val_loss: 1.7496 - val_accuracy: 0.1333 - 307ms/epoch - 77ms/step\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 141: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2313 - accuracy: 1.0000 - val_loss: 1.7809 - val_accuracy: 0.2222 - 305ms/epoch - 76ms/step\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 142: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2325 - accuracy: 1.0000 - val_loss: 1.7265 - val_accuracy: 0.1778 - 296ms/epoch - 74ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/300\n",
      "\n",
      "Epoch 143: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2224 - accuracy: 1.0000 - val_loss: 1.6448 - val_accuracy: 0.2667 - 304ms/epoch - 76ms/step\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 144: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2302 - accuracy: 1.0000 - val_loss: 1.5852 - val_accuracy: 0.2889 - 295ms/epoch - 74ms/step\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 145: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2395 - accuracy: 1.0000 - val_loss: 1.5928 - val_accuracy: 0.2889 - 296ms/epoch - 74ms/step\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 146: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2416 - accuracy: 1.0000 - val_loss: 1.5622 - val_accuracy: 0.2667 - 296ms/epoch - 74ms/step\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 147: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2607 - accuracy: 1.0000 - val_loss: 1.7577 - val_accuracy: 0.2000 - 304ms/epoch - 76ms/step\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 148: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2675 - accuracy: 1.0000 - val_loss: 1.5097 - val_accuracy: 0.2667 - 299ms/epoch - 75ms/step\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 149: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2277 - accuracy: 1.0000 - val_loss: 1.6162 - val_accuracy: 0.1556 - 297ms/epoch - 74ms/step\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 150: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2417 - accuracy: 1.0000 - val_loss: 1.6689 - val_accuracy: 0.1111 - 289ms/epoch - 72ms/step\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 151: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2558 - accuracy: 1.0000 - val_loss: 1.7188 - val_accuracy: 0.2000 - 297ms/epoch - 74ms/step\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 152: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2646 - accuracy: 1.0000 - val_loss: 1.7232 - val_accuracy: 0.1778 - 305ms/epoch - 76ms/step\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 153: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2464 - accuracy: 1.0000 - val_loss: 1.6502 - val_accuracy: 0.2667 - 299ms/epoch - 75ms/step\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 154: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2575 - accuracy: 0.9905 - val_loss: 1.6275 - val_accuracy: 0.3111 - 303ms/epoch - 76ms/step\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 155: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2476 - accuracy: 1.0000 - val_loss: 1.5683 - val_accuracy: 0.2667 - 298ms/epoch - 75ms/step\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 156: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2281 - accuracy: 1.0000 - val_loss: 1.6775 - val_accuracy: 0.2667 - 298ms/epoch - 74ms/step\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 157: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2221 - accuracy: 1.0000 - val_loss: 1.7352 - val_accuracy: 0.2444 - 291ms/epoch - 73ms/step\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 158: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2216 - accuracy: 1.0000 - val_loss: 1.6624 - val_accuracy: 0.2000 - 300ms/epoch - 75ms/step\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 159: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2071 - accuracy: 1.0000 - val_loss: 1.6634 - val_accuracy: 0.1556 - 304ms/epoch - 76ms/step\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 160: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2202 - accuracy: 0.9905 - val_loss: 1.7209 - val_accuracy: 0.2000 - 298ms/epoch - 74ms/step\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 161: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2410 - accuracy: 0.9905 - val_loss: 1.9933 - val_accuracy: 0.2000 - 307ms/epoch - 77ms/step\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 162: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2215 - accuracy: 1.0000 - val_loss: 1.8867 - val_accuracy: 0.2444 - 295ms/epoch - 74ms/step\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 163: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2521 - accuracy: 0.9905 - val_loss: 1.6291 - val_accuracy: 0.2889 - 293ms/epoch - 73ms/step\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 164: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2315 - accuracy: 1.0000 - val_loss: 1.6244 - val_accuracy: 0.3111 - 311ms/epoch - 78ms/step\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 165: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2286 - accuracy: 1.0000 - val_loss: 1.6213 - val_accuracy: 0.2444 - 300ms/epoch - 75ms/step\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 166: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1947 - accuracy: 1.0000 - val_loss: 1.6176 - val_accuracy: 0.3111 - 299ms/epoch - 75ms/step\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 167: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2190 - accuracy: 1.0000 - val_loss: 1.6620 - val_accuracy: 0.2889 - 299ms/epoch - 75ms/step\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 168: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1979 - accuracy: 1.0000 - val_loss: 1.7237 - val_accuracy: 0.2889 - 302ms/epoch - 75ms/step\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 169: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2004 - accuracy: 0.9905 - val_loss: 1.7918 - val_accuracy: 0.2000 - 305ms/epoch - 76ms/step\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 170: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1858 - accuracy: 1.0000 - val_loss: 1.8050 - val_accuracy: 0.2222 - 297ms/epoch - 74ms/step\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 171: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1918 - accuracy: 1.0000 - val_loss: 1.8227 - val_accuracy: 0.3556 - 307ms/epoch - 77ms/step\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 172: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2044 - accuracy: 0.9905 - val_loss: 1.9704 - val_accuracy: 0.2444 - 309ms/epoch - 77ms/step\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 173: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2030 - accuracy: 1.0000 - val_loss: 1.7840 - val_accuracy: 0.2667 - 302ms/epoch - 75ms/step\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 174: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1685 - accuracy: 1.0000 - val_loss: 1.7760 - val_accuracy: 0.2444 - 291ms/epoch - 73ms/step\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 175: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1838 - accuracy: 1.0000 - val_loss: 1.7344 - val_accuracy: 0.2444 - 298ms/epoch - 74ms/step\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 176: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1788 - accuracy: 1.0000 - val_loss: 1.6697 - val_accuracy: 0.1778 - 290ms/epoch - 73ms/step\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 177: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1558 - accuracy: 1.0000 - val_loss: 1.7320 - val_accuracy: 0.1556 - 307ms/epoch - 77ms/step\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 178: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1597 - accuracy: 1.0000 - val_loss: 1.7473 - val_accuracy: 0.1556 - 299ms/epoch - 75ms/step\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 179: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1760 - accuracy: 1.0000 - val_loss: 1.7137 - val_accuracy: 0.1778 - 295ms/epoch - 74ms/step\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 180: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1691 - accuracy: 1.0000 - val_loss: 1.7339 - val_accuracy: 0.2222 - 299ms/epoch - 75ms/step\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 181: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1498 - accuracy: 1.0000 - val_loss: 1.7404 - val_accuracy: 0.2222 - 302ms/epoch - 76ms/step\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 182: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1601 - accuracy: 1.0000 - val_loss: 1.8464 - val_accuracy: 0.2000 - 300ms/epoch - 75ms/step\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 183: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1797 - accuracy: 1.0000 - val_loss: 1.7834 - val_accuracy: 0.1556 - 301ms/epoch - 75ms/step\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 184: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1602 - accuracy: 1.0000 - val_loss: 1.7677 - val_accuracy: 0.2444 - 306ms/epoch - 77ms/step\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 185: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1698 - accuracy: 1.0000 - val_loss: 1.7137 - val_accuracy: 0.2667 - 302ms/epoch - 76ms/step\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 186: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1691 - accuracy: 1.0000 - val_loss: 1.6300 - val_accuracy: 0.3111 - 292ms/epoch - 73ms/step\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 187: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1920 - accuracy: 1.0000 - val_loss: 1.6919 - val_accuracy: 0.2222 - 302ms/epoch - 75ms/step\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 188: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1781 - accuracy: 0.9905 - val_loss: 1.7346 - val_accuracy: 0.2889 - 298ms/epoch - 75ms/step\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 189: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1638 - accuracy: 1.0000 - val_loss: 1.8154 - val_accuracy: 0.2222 - 294ms/epoch - 74ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190/300\n",
      "\n",
      "Epoch 190: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1818 - accuracy: 1.0000 - val_loss: 1.7840 - val_accuracy: 0.2889 - 324ms/epoch - 81ms/step\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 191: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1625 - accuracy: 1.0000 - val_loss: 1.7416 - val_accuracy: 0.2667 - 315ms/epoch - 79ms/step\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 192: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1787 - accuracy: 1.0000 - val_loss: 1.6865 - val_accuracy: 0.2000 - 297ms/epoch - 74ms/step\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 193: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1508 - accuracy: 1.0000 - val_loss: 1.6743 - val_accuracy: 0.2444 - 294ms/epoch - 74ms/step\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 194: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1753 - accuracy: 0.9905 - val_loss: 1.7135 - val_accuracy: 0.1778 - 298ms/epoch - 74ms/step\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 195: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1747 - accuracy: 0.9905 - val_loss: 1.9120 - val_accuracy: 0.2222 - 296ms/epoch - 74ms/step\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 196: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.2074 - accuracy: 0.9905 - val_loss: 2.7964 - val_accuracy: 0.2000 - 304ms/epoch - 76ms/step\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 197: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1739 - accuracy: 1.0000 - val_loss: 2.2678 - val_accuracy: 0.1556 - 297ms/epoch - 74ms/step\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 198: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1830 - accuracy: 0.9905 - val_loss: 2.2162 - val_accuracy: 0.2444 - 298ms/epoch - 74ms/step\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 199: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1632 - accuracy: 1.0000 - val_loss: 2.0529 - val_accuracy: 0.2667 - 297ms/epoch - 74ms/step\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 200: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1513 - accuracy: 1.0000 - val_loss: 1.8854 - val_accuracy: 0.2444 - 306ms/epoch - 77ms/step\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 201: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1358 - accuracy: 1.0000 - val_loss: 1.9276 - val_accuracy: 0.2000 - 302ms/epoch - 76ms/step\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 202: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1284 - accuracy: 1.0000 - val_loss: 1.9184 - val_accuracy: 0.2222 - 326ms/epoch - 81ms/step\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 203: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1567 - accuracy: 1.0000 - val_loss: 1.7765 - val_accuracy: 0.2444 - 306ms/epoch - 76ms/step\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 204: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1411 - accuracy: 1.0000 - val_loss: 1.7032 - val_accuracy: 0.2667 - 295ms/epoch - 74ms/step\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 205: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1623 - accuracy: 0.9905 - val_loss: 1.7796 - val_accuracy: 0.2889 - 309ms/epoch - 77ms/step\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 206: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1565 - accuracy: 1.0000 - val_loss: 1.8892 - val_accuracy: 0.2667 - 302ms/epoch - 76ms/step\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 207: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1381 - accuracy: 1.0000 - val_loss: 1.9116 - val_accuracy: 0.2222 - 304ms/epoch - 76ms/step\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 208: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1440 - accuracy: 1.0000 - val_loss: 1.8351 - val_accuracy: 0.1778 - 317ms/epoch - 79ms/step\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 209: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1197 - accuracy: 1.0000 - val_loss: 1.7905 - val_accuracy: 0.2000 - 304ms/epoch - 76ms/step\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 210: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1356 - accuracy: 1.0000 - val_loss: 1.7225 - val_accuracy: 0.2222 - 307ms/epoch - 77ms/step\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 211: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1354 - accuracy: 1.0000 - val_loss: 1.6945 - val_accuracy: 0.2667 - 316ms/epoch - 79ms/step\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 212: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1288 - accuracy: 0.9905 - val_loss: 1.7378 - val_accuracy: 0.2222 - 303ms/epoch - 76ms/step\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 213: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1433 - accuracy: 1.0000 - val_loss: 1.6816 - val_accuracy: 0.2889 - 300ms/epoch - 75ms/step\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 214: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1351 - accuracy: 1.0000 - val_loss: 1.6341 - val_accuracy: 0.2889 - 308ms/epoch - 77ms/step\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 215: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1344 - accuracy: 1.0000 - val_loss: 1.7047 - val_accuracy: 0.2444 - 294ms/epoch - 73ms/step\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 216: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1283 - accuracy: 1.0000 - val_loss: 1.8370 - val_accuracy: 0.2000 - 299ms/epoch - 75ms/step\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 217: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1382 - accuracy: 1.0000 - val_loss: 1.8741 - val_accuracy: 0.2222 - 301ms/epoch - 75ms/step\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 218: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1456 - accuracy: 1.0000 - val_loss: 1.8237 - val_accuracy: 0.2222 - 295ms/epoch - 74ms/step\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 219: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1336 - accuracy: 1.0000 - val_loss: 1.7046 - val_accuracy: 0.2667 - 297ms/epoch - 74ms/step\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 220: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1569 - accuracy: 1.0000 - val_loss: 1.6901 - val_accuracy: 0.2889 - 315ms/epoch - 79ms/step\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 221: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1468 - accuracy: 1.0000 - val_loss: 1.7708 - val_accuracy: 0.2667 - 320ms/epoch - 80ms/step\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 222: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1448 - accuracy: 0.9905 - val_loss: 1.7825 - val_accuracy: 0.3111 - 298ms/epoch - 74ms/step\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 223: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1528 - accuracy: 0.9905 - val_loss: 1.7269 - val_accuracy: 0.3333 - 299ms/epoch - 75ms/step\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 224: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1404 - accuracy: 1.0000 - val_loss: 1.6650 - val_accuracy: 0.2667 - 294ms/epoch - 73ms/step\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 225: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1270 - accuracy: 1.0000 - val_loss: 1.7127 - val_accuracy: 0.2000 - 311ms/epoch - 78ms/step\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 226: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1333 - accuracy: 1.0000 - val_loss: 1.7667 - val_accuracy: 0.2222 - 303ms/epoch - 76ms/step\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 227: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1262 - accuracy: 1.0000 - val_loss: 1.9217 - val_accuracy: 0.2000 - 293ms/epoch - 73ms/step\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 228: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1218 - accuracy: 1.0000 - val_loss: 1.9798 - val_accuracy: 0.2222 - 299ms/epoch - 75ms/step\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 229: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1111 - accuracy: 1.0000 - val_loss: 1.9688 - val_accuracy: 0.2222 - 294ms/epoch - 73ms/step\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 230: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1161 - accuracy: 1.0000 - val_loss: 1.9893 - val_accuracy: 0.2444 - 296ms/epoch - 74ms/step\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 231: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1111 - accuracy: 1.0000 - val_loss: 1.9444 - val_accuracy: 0.2000 - 300ms/epoch - 75ms/step\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 232: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1128 - accuracy: 1.0000 - val_loss: 1.9296 - val_accuracy: 0.2222 - 304ms/epoch - 76ms/step\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 233: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1061 - accuracy: 1.0000 - val_loss: 1.8742 - val_accuracy: 0.2667 - 295ms/epoch - 74ms/step\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 234: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1057 - accuracy: 1.0000 - val_loss: 1.8268 - val_accuracy: 0.1778 - 298ms/epoch - 74ms/step\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 235: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1184 - accuracy: 1.0000 - val_loss: 1.8150 - val_accuracy: 0.2222 - 296ms/epoch - 74ms/step\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 236: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1171 - accuracy: 1.0000 - val_loss: 1.7991 - val_accuracy: 0.2889 - 299ms/epoch - 75ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237/300\n",
      "\n",
      "Epoch 237: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1030 - accuracy: 1.0000 - val_loss: 1.8398 - val_accuracy: 0.2222 - 299ms/epoch - 75ms/step\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 238: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1192 - accuracy: 1.0000 - val_loss: 1.7830 - val_accuracy: 0.2444 - 301ms/epoch - 75ms/step\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 239: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.0878 - accuracy: 1.0000 - val_loss: 1.7334 - val_accuracy: 0.2444 - 292ms/epoch - 73ms/step\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 240: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1045 - accuracy: 1.0000 - val_loss: 1.7689 - val_accuracy: 0.1556 - 304ms/epoch - 76ms/step\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 241: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.0982 - accuracy: 1.0000 - val_loss: 1.7717 - val_accuracy: 0.1778 - 303ms/epoch - 76ms/step\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 242: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.0874 - accuracy: 1.0000 - val_loss: 1.7429 - val_accuracy: 0.2667 - 304ms/epoch - 76ms/step\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 243: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.0954 - accuracy: 1.0000 - val_loss: 1.7450 - val_accuracy: 0.2222 - 299ms/epoch - 75ms/step\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 244: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1119 - accuracy: 1.0000 - val_loss: 1.7690 - val_accuracy: 0.2667 - 312ms/epoch - 78ms/step\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 245: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1008 - accuracy: 1.0000 - val_loss: 1.7087 - val_accuracy: 0.3556 - 305ms/epoch - 76ms/step\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 246: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.0912 - accuracy: 1.0000 - val_loss: 1.6932 - val_accuracy: 0.3111 - 308ms/epoch - 77ms/step\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 247: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1029 - accuracy: 1.0000 - val_loss: 1.7102 - val_accuracy: 0.2889 - 307ms/epoch - 77ms/step\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 248: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1137 - accuracy: 1.0000 - val_loss: 1.7894 - val_accuracy: 0.2222 - 310ms/epoch - 77ms/step\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 249: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.0933 - accuracy: 1.0000 - val_loss: 1.8940 - val_accuracy: 0.2889 - 295ms/epoch - 74ms/step\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 250: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1107 - accuracy: 1.0000 - val_loss: 1.9736 - val_accuracy: 0.2444 - 323ms/epoch - 81ms/step\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 251: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.0984 - accuracy: 1.0000 - val_loss: 1.8995 - val_accuracy: 0.2889 - 296ms/epoch - 74ms/step\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 252: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1063 - accuracy: 1.0000 - val_loss: 1.7966 - val_accuracy: 0.2889 - 298ms/epoch - 75ms/step\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 253: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1024 - accuracy: 1.0000 - val_loss: 1.7784 - val_accuracy: 0.3111 - 306ms/epoch - 77ms/step\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 254: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1124 - accuracy: 1.0000 - val_loss: 1.7466 - val_accuracy: 0.2889 - 298ms/epoch - 75ms/step\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 255: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1147 - accuracy: 1.0000 - val_loss: 1.8293 - val_accuracy: 0.2667 - 298ms/epoch - 75ms/step\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 256: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1127 - accuracy: 1.0000 - val_loss: 1.8093 - val_accuracy: 0.3111 - 301ms/epoch - 75ms/step\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 257: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1103 - accuracy: 1.0000 - val_loss: 1.6547 - val_accuracy: 0.2889 - 302ms/epoch - 76ms/step\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 258: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1311 - accuracy: 0.9905 - val_loss: 1.6925 - val_accuracy: 0.2444 - 294ms/epoch - 74ms/step\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 259: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1131 - accuracy: 1.0000 - val_loss: 1.7660 - val_accuracy: 0.2889 - 307ms/epoch - 77ms/step\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 260: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1151 - accuracy: 1.0000 - val_loss: 1.8707 - val_accuracy: 0.3778 - 305ms/epoch - 76ms/step\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 261: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1123 - accuracy: 1.0000 - val_loss: 1.8977 - val_accuracy: 0.3111 - 290ms/epoch - 73ms/step\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 262: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1249 - accuracy: 1.0000 - val_loss: 1.7707 - val_accuracy: 0.3111 - 308ms/epoch - 77ms/step\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 263: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1023 - accuracy: 1.0000 - val_loss: 1.7007 - val_accuracy: 0.2667 - 296ms/epoch - 74ms/step\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 264: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.0954 - accuracy: 1.0000 - val_loss: 1.8187 - val_accuracy: 0.2889 - 303ms/epoch - 76ms/step\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 265: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1136 - accuracy: 1.0000 - val_loss: 1.8910 - val_accuracy: 0.2889 - 296ms/epoch - 74ms/step\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 266: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1114 - accuracy: 1.0000 - val_loss: 1.7928 - val_accuracy: 0.2667 - 290ms/epoch - 73ms/step\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 267: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1055 - accuracy: 1.0000 - val_loss: 1.7772 - val_accuracy: 0.3111 - 293ms/epoch - 73ms/step\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 268: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1042 - accuracy: 1.0000 - val_loss: 1.7682 - val_accuracy: 0.3111 - 309ms/epoch - 77ms/step\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 269: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1094 - accuracy: 1.0000 - val_loss: 1.7479 - val_accuracy: 0.2667 - 305ms/epoch - 76ms/step\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 270: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1014 - accuracy: 1.0000 - val_loss: 1.7716 - val_accuracy: 0.2889 - 300ms/epoch - 75ms/step\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 271: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1204 - accuracy: 1.0000 - val_loss: 1.7903 - val_accuracy: 0.2222 - 300ms/epoch - 75ms/step\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 272: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1126 - accuracy: 1.0000 - val_loss: 1.8418 - val_accuracy: 0.2667 - 307ms/epoch - 77ms/step\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 273: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.0907 - accuracy: 1.0000 - val_loss: 1.8907 - val_accuracy: 0.2000 - 293ms/epoch - 73ms/step\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 274: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.0969 - accuracy: 1.0000 - val_loss: 1.8708 - val_accuracy: 0.2222 - 309ms/epoch - 77ms/step\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 275: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.1092 - accuracy: 1.0000 - val_loss: 1.7788 - val_accuracy: 0.2444 - 312ms/epoch - 78ms/step\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 276: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.0827 - accuracy: 1.0000 - val_loss: 1.7619 - val_accuracy: 0.2889 - 293ms/epoch - 73ms/step\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 277: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.0979 - accuracy: 1.0000 - val_loss: 1.7728 - val_accuracy: 0.3111 - 293ms/epoch - 73ms/step\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 278: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.0899 - accuracy: 1.0000 - val_loss: 1.7992 - val_accuracy: 0.2889 - 316ms/epoch - 79ms/step\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 279: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.0982 - accuracy: 1.0000 - val_loss: 1.7518 - val_accuracy: 0.2667 - 310ms/epoch - 78ms/step\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 280: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.0943 - accuracy: 1.0000 - val_loss: 1.7721 - val_accuracy: 0.2444 - 297ms/epoch - 74ms/step\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 281: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.0902 - accuracy: 1.0000 - val_loss: 1.8444 - val_accuracy: 0.2444 - 295ms/epoch - 74ms/step\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 282: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.0788 - accuracy: 1.0000 - val_loss: 1.8651 - val_accuracy: 0.2667 - 302ms/epoch - 76ms/step\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 283: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.0734 - accuracy: 1.0000 - val_loss: 1.9205 - val_accuracy: 0.2889 - 301ms/epoch - 75ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284/300\n",
      "\n",
      "Epoch 284: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.0756 - accuracy: 1.0000 - val_loss: 1.9455 - val_accuracy: 0.2444 - 295ms/epoch - 74ms/step\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 285: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.0811 - accuracy: 1.0000 - val_loss: 1.9738 - val_accuracy: 0.2667 - 294ms/epoch - 74ms/step\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 286: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.0898 - accuracy: 1.0000 - val_loss: 1.9615 - val_accuracy: 0.3556 - 304ms/epoch - 76ms/step\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 287: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.0818 - accuracy: 1.0000 - val_loss: 1.9763 - val_accuracy: 0.2444 - 297ms/epoch - 74ms/step\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 288: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.0973 - accuracy: 1.0000 - val_loss: 1.9393 - val_accuracy: 0.3333 - 320ms/epoch - 80ms/step\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 289: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.0860 - accuracy: 1.0000 - val_loss: 1.9177 - val_accuracy: 0.2889 - 300ms/epoch - 75ms/step\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 290: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.0971 - accuracy: 1.0000 - val_loss: 1.8845 - val_accuracy: 0.2444 - 299ms/epoch - 75ms/step\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 291: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.0910 - accuracy: 1.0000 - val_loss: 1.8822 - val_accuracy: 0.2889 - 289ms/epoch - 72ms/step\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 292: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.0910 - accuracy: 1.0000 - val_loss: 1.7663 - val_accuracy: 0.2444 - 303ms/epoch - 76ms/step\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 293: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.0934 - accuracy: 1.0000 - val_loss: 1.6471 - val_accuracy: 0.2444 - 297ms/epoch - 74ms/step\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 294: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.0730 - accuracy: 1.0000 - val_loss: 1.7361 - val_accuracy: 0.2000 - 326ms/epoch - 81ms/step\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 295: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.0835 - accuracy: 1.0000 - val_loss: 1.8434 - val_accuracy: 0.2000 - 296ms/epoch - 74ms/step\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 296: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.0821 - accuracy: 1.0000 - val_loss: 1.8178 - val_accuracy: 0.2444 - 294ms/epoch - 73ms/step\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 297: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.0886 - accuracy: 1.0000 - val_loss: 1.7884 - val_accuracy: 0.2889 - 304ms/epoch - 76ms/step\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 298: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.0854 - accuracy: 1.0000 - val_loss: 1.8387 - val_accuracy: 0.2444 - 301ms/epoch - 75ms/step\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 299: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.0744 - accuracy: 1.0000 - val_loss: 1.8746 - val_accuracy: 0.2444 - 299ms/epoch - 75ms/step\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 300: val_loss did not improve from 1.38612\n",
      "4/4 - 0s - loss: 0.0684 - accuracy: 1.0000 - val_loss: 1.8656 - val_accuracy: 0.2667 - 293ms/epoch - 73ms/step\n",
      "2/2 [==============================] - 0s 22ms/step\n",
      "Lists\n",
      "[0.28, 0.26, 0.32, 0.26]\n",
      "[0.14430147058823528, 0.25788690476190473, 0.25232793522267205, 0.065]\n",
      "[0.30113636363636365, 0.2853174603174603, 0.30402930402930406, 0.25]\n",
      "[0.19041867954911434, 0.2560867293625914, 0.24996572055395588, 0.10317460317460318]\n",
      "dicts\n",
      "{1: 0.28, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0}\n",
      "{1: 0.179879077643203, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0}\n",
      "{1: 0.285120781995782, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0}\n",
      "{1: 0.19991143316006618, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Number of devices: 2\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 09:14:07.167558: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_8545790\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:561532\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
      "2022-11-11 09:14:11.674572: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_8548860\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:561574\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38641, saving model to checkpoint1.h5\n",
      "4/4 - 6s - loss: 1.4618 - accuracy: 0.1905 - val_loss: 1.3864 - val_accuracy: 0.2222 - 6s/epoch - 1s/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss did not improve from 1.38641\n",
      "4/4 - 0s - loss: 1.3208 - accuracy: 0.4206 - val_loss: 1.3865 - val_accuracy: 0.2222 - 339ms/epoch - 85ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss did not improve from 1.38641\n",
      "4/4 - 0s - loss: 1.3049 - accuracy: 0.4127 - val_loss: 1.3865 - val_accuracy: 0.2222 - 332ms/epoch - 83ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss did not improve from 1.38641\n",
      "4/4 - 0s - loss: 1.2787 - accuracy: 0.4286 - val_loss: 1.3865 - val_accuracy: 0.2222 - 327ms/epoch - 82ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss did not improve from 1.38641\n",
      "4/4 - 0s - loss: 1.2366 - accuracy: 0.5317 - val_loss: 1.3866 - val_accuracy: 0.2222 - 332ms/epoch - 83ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.38641\n",
      "4/4 - 0s - loss: 1.2209 - accuracy: 0.5476 - val_loss: 1.3865 - val_accuracy: 0.2222 - 325ms/epoch - 81ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss improved from 1.38641 to 1.38640, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 1.1817 - accuracy: 0.6111 - val_loss: 1.3864 - val_accuracy: 0.2222 - 387ms/epoch - 97ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss improved from 1.38640 to 1.38640, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 1.1753 - accuracy: 0.6270 - val_loss: 1.3864 - val_accuracy: 0.2222 - 392ms/epoch - 98ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 1.38640\n",
      "4/4 - 0s - loss: 1.1104 - accuracy: 0.7063 - val_loss: 1.3865 - val_accuracy: 0.2222 - 327ms/epoch - 82ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss improved from 1.38640 to 1.38639, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 1.1182 - accuracy: 0.6825 - val_loss: 1.3864 - val_accuracy: 0.2222 - 395ms/epoch - 99ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss improved from 1.38639 to 1.38609, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 1.0764 - accuracy: 0.6905 - val_loss: 1.3861 - val_accuracy: 0.2222 - 393ms/epoch - 98ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.38609\n",
      "4/4 - 0s - loss: 1.0770 - accuracy: 0.6746 - val_loss: 1.3861 - val_accuracy: 0.2222 - 326ms/epoch - 82ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.38609\n",
      "4/4 - 0s - loss: 1.0497 - accuracy: 0.6905 - val_loss: 1.3865 - val_accuracy: 0.2222 - 353ms/epoch - 88ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss improved from 1.38609 to 1.38607, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 1.0207 - accuracy: 0.7222 - val_loss: 1.3861 - val_accuracy: 0.2407 - 380ms/epoch - 95ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss improved from 1.38607 to 1.38584, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.9939 - accuracy: 0.7619 - val_loss: 1.3858 - val_accuracy: 0.2593 - 386ms/epoch - 97ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 1.38584\n",
      "4/4 - 0s - loss: 0.9601 - accuracy: 0.7857 - val_loss: 1.3859 - val_accuracy: 0.2407 - 331ms/epoch - 83ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss improved from 1.38584 to 1.38569, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.9690 - accuracy: 0.7778 - val_loss: 1.3857 - val_accuracy: 0.2963 - 400ms/epoch - 100ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss improved from 1.38569 to 1.38510, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.9593 - accuracy: 0.7698 - val_loss: 1.3851 - val_accuracy: 0.3148 - 395ms/epoch - 99ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss improved from 1.38510 to 1.38489, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.9538 - accuracy: 0.7619 - val_loss: 1.3849 - val_accuracy: 0.2778 - 389ms/epoch - 97ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 1.38489\n",
      "4/4 - 0s - loss: 0.9258 - accuracy: 0.7937 - val_loss: 1.3854 - val_accuracy: 0.2963 - 323ms/epoch - 81ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss improved from 1.38489 to 1.38486, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.8900 - accuracy: 0.7937 - val_loss: 1.3849 - val_accuracy: 0.2407 - 393ms/epoch - 98ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss improved from 1.38486 to 1.38450, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.8841 - accuracy: 0.8571 - val_loss: 1.3845 - val_accuracy: 0.3889 - 378ms/epoch - 94ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss improved from 1.38450 to 1.38415, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.8836 - accuracy: 0.8016 - val_loss: 1.3841 - val_accuracy: 0.2963 - 375ms/epoch - 94ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 1.38415\n",
      "4/4 - 0s - loss: 0.8606 - accuracy: 0.8571 - val_loss: 1.3843 - val_accuracy: 0.3148 - 323ms/epoch - 81ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.38415\n",
      "4/4 - 0s - loss: 0.8096 - accuracy: 0.8730 - val_loss: 1.3845 - val_accuracy: 0.3148 - 327ms/epoch - 82ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss improved from 1.38415 to 1.38362, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.8116 - accuracy: 0.8889 - val_loss: 1.3836 - val_accuracy: 0.3148 - 378ms/epoch - 95ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 1.38362\n",
      "4/4 - 0s - loss: 0.8116 - accuracy: 0.9206 - val_loss: 1.3839 - val_accuracy: 0.2778 - 334ms/epoch - 83ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 1.38362\n",
      "4/4 - 0s - loss: 0.8247 - accuracy: 0.8413 - val_loss: 1.3836 - val_accuracy: 0.2963 - 335ms/epoch - 84ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss improved from 1.38362 to 1.38348, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.7687 - accuracy: 0.9127 - val_loss: 1.3835 - val_accuracy: 0.2778 - 388ms/epoch - 97ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 1.38348\n",
      "4/4 - 0s - loss: 0.7768 - accuracy: 0.9048 - val_loss: 1.3849 - val_accuracy: 0.2963 - 336ms/epoch - 84ms/step\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 1.38348\n",
      "4/4 - 0s - loss: 0.7405 - accuracy: 0.8968 - val_loss: 1.3837 - val_accuracy: 0.2963 - 330ms/epoch - 82ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 1.38348\n",
      "4/4 - 0s - loss: 0.7405 - accuracy: 0.8968 - val_loss: 1.3837 - val_accuracy: 0.2407 - 327ms/epoch - 82ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss improved from 1.38348 to 1.38228, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.7776 - accuracy: 0.8889 - val_loss: 1.3823 - val_accuracy: 0.2778 - 386ms/epoch - 97ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 1.38228\n",
      "4/4 - 0s - loss: 0.7594 - accuracy: 0.8889 - val_loss: 1.3837 - val_accuracy: 0.2593 - 325ms/epoch - 81ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 1.38228\n",
      "4/4 - 0s - loss: 0.7055 - accuracy: 0.9127 - val_loss: 1.3829 - val_accuracy: 0.2963 - 325ms/epoch - 81ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss improved from 1.38228 to 1.38184, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.6964 - accuracy: 0.9444 - val_loss: 1.3818 - val_accuracy: 0.2593 - 388ms/epoch - 97ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss improved from 1.38184 to 1.38158, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.6718 - accuracy: 0.9524 - val_loss: 1.3816 - val_accuracy: 0.2407 - 379ms/epoch - 95ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 1.38158\n",
      "4/4 - 0s - loss: 0.6858 - accuracy: 0.9603 - val_loss: 1.3843 - val_accuracy: 0.2222 - 343ms/epoch - 86ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 1.38158\n",
      "4/4 - 0s - loss: 0.6818 - accuracy: 0.9127 - val_loss: 1.3833 - val_accuracy: 0.2963 - 336ms/epoch - 84ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss improved from 1.38158 to 1.38104, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.6272 - accuracy: 0.9762 - val_loss: 1.3810 - val_accuracy: 0.2407 - 378ms/epoch - 95ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 1.38104\n",
      "4/4 - 0s - loss: 0.6345 - accuracy: 0.9603 - val_loss: 1.3829 - val_accuracy: 0.2037 - 332ms/epoch - 83ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 1.38104\n",
      "4/4 - 0s - loss: 0.6543 - accuracy: 0.9524 - val_loss: 1.3824 - val_accuracy: 0.2778 - 339ms/epoch - 85ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 1.38104\n",
      "4/4 - 0s - loss: 0.6378 - accuracy: 0.9365 - val_loss: 1.3844 - val_accuracy: 0.2407 - 337ms/epoch - 84ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 1.38104\n",
      "4/4 - 0s - loss: 0.6504 - accuracy: 0.9365 - val_loss: 1.3817 - val_accuracy: 0.2778 - 324ms/epoch - 81ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss improved from 1.38104 to 1.38017, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.5827 - accuracy: 0.9921 - val_loss: 1.3802 - val_accuracy: 0.3148 - 381ms/epoch - 95ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 1.38017\n",
      "4/4 - 0s - loss: 0.5608 - accuracy: 0.9841 - val_loss: 1.3839 - val_accuracy: 0.2593 - 330ms/epoch - 83ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss improved from 1.38017 to 1.37984, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.5865 - accuracy: 0.9683 - val_loss: 1.3798 - val_accuracy: 0.2593 - 382ms/epoch - 96ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.5662 - accuracy: 0.9683 - val_loss: 1.3816 - val_accuracy: 0.2593 - 329ms/epoch - 82ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.5279 - accuracy: 1.0000 - val_loss: 1.3855 - val_accuracy: 0.2407 - 327ms/epoch - 82ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.5474 - accuracy: 0.9841 - val_loss: 1.3807 - val_accuracy: 0.2222 - 341ms/epoch - 85ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.5198 - accuracy: 0.9841 - val_loss: 1.3847 - val_accuracy: 0.2778 - 345ms/epoch - 86ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.5243 - accuracy: 0.9921 - val_loss: 1.3863 - val_accuracy: 0.2593 - 332ms/epoch - 83ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.5005 - accuracy: 0.9841 - val_loss: 1.3852 - val_accuracy: 0.2407 - 332ms/epoch - 83ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.4929 - accuracy: 1.0000 - val_loss: 1.3937 - val_accuracy: 0.1852 - 338ms/epoch - 85ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.4906 - accuracy: 0.9683 - val_loss: 1.3885 - val_accuracy: 0.2778 - 334ms/epoch - 83ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.4746 - accuracy: 0.9683 - val_loss: 1.3884 - val_accuracy: 0.2963 - 324ms/epoch - 81ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.4638 - accuracy: 0.9683 - val_loss: 1.3849 - val_accuracy: 0.2778 - 337ms/epoch - 84ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.4712 - accuracy: 0.9921 - val_loss: 1.3813 - val_accuracy: 0.2778 - 335ms/epoch - 84ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.4698 - accuracy: 0.9841 - val_loss: 1.3881 - val_accuracy: 0.2593 - 323ms/epoch - 81ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.4313 - accuracy: 0.9841 - val_loss: 1.3906 - val_accuracy: 0.2778 - 338ms/epoch - 84ms/step\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.4495 - accuracy: 0.9762 - val_loss: 1.3952 - val_accuracy: 0.2778 - 324ms/epoch - 81ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.4649 - accuracy: 1.0000 - val_loss: 1.3869 - val_accuracy: 0.2778 - 328ms/epoch - 82ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.4184 - accuracy: 0.9921 - val_loss: 1.3936 - val_accuracy: 0.2593 - 321ms/epoch - 80ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.4326 - accuracy: 0.9841 - val_loss: 1.4018 - val_accuracy: 0.2407 - 341ms/epoch - 85ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.4624 - accuracy: 0.9603 - val_loss: 1.3964 - val_accuracy: 0.2407 - 333ms/epoch - 83ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.3815 - accuracy: 0.9921 - val_loss: 1.3948 - val_accuracy: 0.2778 - 336ms/epoch - 84ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.4165 - accuracy: 0.9841 - val_loss: 1.3956 - val_accuracy: 0.3333 - 327ms/epoch - 82ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.3719 - accuracy: 0.9921 - val_loss: 1.3941 - val_accuracy: 0.2778 - 330ms/epoch - 83ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.3757 - accuracy: 1.0000 - val_loss: 1.3869 - val_accuracy: 0.2593 - 326ms/epoch - 82ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.3707 - accuracy: 0.9921 - val_loss: 1.3943 - val_accuracy: 0.2778 - 323ms/epoch - 81ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.3595 - accuracy: 1.0000 - val_loss: 1.3866 - val_accuracy: 0.2593 - 325ms/epoch - 81ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.3733 - accuracy: 1.0000 - val_loss: 1.4000 - val_accuracy: 0.2407 - 334ms/epoch - 84ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.3569 - accuracy: 1.0000 - val_loss: 1.4196 - val_accuracy: 0.2407 - 342ms/epoch - 85ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.3497 - accuracy: 1.0000 - val_loss: 1.3870 - val_accuracy: 0.2593 - 334ms/epoch - 84ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.3630 - accuracy: 1.0000 - val_loss: 1.3956 - val_accuracy: 0.2593 - 339ms/epoch - 85ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.3215 - accuracy: 0.9841 - val_loss: 1.4115 - val_accuracy: 0.2963 - 322ms/epoch - 81ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.3349 - accuracy: 1.0000 - val_loss: 1.4044 - val_accuracy: 0.2407 - 326ms/epoch - 81ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.3302 - accuracy: 1.0000 - val_loss: 1.4160 - val_accuracy: 0.3333 - 341ms/epoch - 85ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.3405 - accuracy: 1.0000 - val_loss: 1.4013 - val_accuracy: 0.2778 - 325ms/epoch - 81ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.3541 - accuracy: 0.9921 - val_loss: 1.4067 - val_accuracy: 0.2593 - 325ms/epoch - 81ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.3406 - accuracy: 0.9841 - val_loss: 1.4181 - val_accuracy: 0.2407 - 328ms/epoch - 82ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.3405 - accuracy: 1.0000 - val_loss: 1.4104 - val_accuracy: 0.2407 - 337ms/epoch - 84ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.3265 - accuracy: 0.9921 - val_loss: 1.4209 - val_accuracy: 0.2407 - 335ms/epoch - 84ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.2843 - accuracy: 1.0000 - val_loss: 1.4178 - val_accuracy: 0.2778 - 348ms/epoch - 87ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.3295 - accuracy: 0.9841 - val_loss: 1.4090 - val_accuracy: 0.2407 - 322ms/epoch - 81ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.3133 - accuracy: 0.9921 - val_loss: 1.4408 - val_accuracy: 0.2778 - 349ms/epoch - 87ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.3097 - accuracy: 0.9921 - val_loss: 1.4057 - val_accuracy: 0.2778 - 342ms/epoch - 86ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.3312 - accuracy: 0.9762 - val_loss: 1.4333 - val_accuracy: 0.3333 - 335ms/epoch - 84ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.3106 - accuracy: 1.0000 - val_loss: 1.4152 - val_accuracy: 0.2593 - 324ms/epoch - 81ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.2996 - accuracy: 1.0000 - val_loss: 1.4576 - val_accuracy: 0.2593 - 333ms/epoch - 83ms/step\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.3149 - accuracy: 1.0000 - val_loss: 1.4370 - val_accuracy: 0.2963 - 327ms/epoch - 82ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.2776 - accuracy: 1.0000 - val_loss: 1.4284 - val_accuracy: 0.2963 - 348ms/epoch - 87ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.3035 - accuracy: 0.9921 - val_loss: 1.4355 - val_accuracy: 0.2593 - 328ms/epoch - 82ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.2672 - accuracy: 0.9921 - val_loss: 1.4444 - val_accuracy: 0.2593 - 340ms/epoch - 85ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.2869 - accuracy: 0.9921 - val_loss: 1.4143 - val_accuracy: 0.2593 - 335ms/epoch - 84ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.2737 - accuracy: 0.9841 - val_loss: 1.4136 - val_accuracy: 0.2778 - 338ms/epoch - 85ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.2692 - accuracy: 1.0000 - val_loss: 1.4320 - val_accuracy: 0.2593 - 324ms/epoch - 81ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.2418 - accuracy: 1.0000 - val_loss: 1.4712 - val_accuracy: 0.2778 - 334ms/epoch - 84ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.2283 - accuracy: 1.0000 - val_loss: 1.4489 - val_accuracy: 0.2593 - 333ms/epoch - 83ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.2363 - accuracy: 1.0000 - val_loss: 1.4534 - val_accuracy: 0.2407 - 354ms/epoch - 89ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.2336 - accuracy: 1.0000 - val_loss: 1.4446 - val_accuracy: 0.2593 - 337ms/epoch - 84ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.2361 - accuracy: 1.0000 - val_loss: 1.4253 - val_accuracy: 0.2593 - 330ms/epoch - 82ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.2176 - accuracy: 1.0000 - val_loss: 1.4485 - val_accuracy: 0.2778 - 323ms/epoch - 81ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.2256 - accuracy: 1.0000 - val_loss: 1.4404 - val_accuracy: 0.2778 - 332ms/epoch - 83ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.2307 - accuracy: 1.0000 - val_loss: 1.4662 - val_accuracy: 0.2963 - 339ms/epoch - 85ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.2231 - accuracy: 1.0000 - val_loss: 1.4546 - val_accuracy: 0.2593 - 345ms/epoch - 86ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.2353 - accuracy: 1.0000 - val_loss: 1.4791 - val_accuracy: 0.3333 - 346ms/epoch - 87ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.2416 - accuracy: 1.0000 - val_loss: 1.4565 - val_accuracy: 0.2407 - 337ms/epoch - 84ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 1.4737 - val_accuracy: 0.2963 - 325ms/epoch - 81ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.2222 - accuracy: 1.0000 - val_loss: 1.4600 - val_accuracy: 0.2778 - 328ms/epoch - 82ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.2302 - accuracy: 1.0000 - val_loss: 1.4825 - val_accuracy: 0.2778 - 334ms/epoch - 83ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.2031 - accuracy: 1.0000 - val_loss: 1.4674 - val_accuracy: 0.2593 - 335ms/epoch - 84ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1972 - accuracy: 1.0000 - val_loss: 1.4654 - val_accuracy: 0.2963 - 329ms/epoch - 82ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.2074 - accuracy: 1.0000 - val_loss: 1.4792 - val_accuracy: 0.2407 - 344ms/epoch - 86ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1794 - accuracy: 1.0000 - val_loss: 1.4854 - val_accuracy: 0.2778 - 333ms/epoch - 83ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1904 - accuracy: 1.0000 - val_loss: 1.4824 - val_accuracy: 0.2963 - 342ms/epoch - 86ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.2076 - accuracy: 1.0000 - val_loss: 1.4934 - val_accuracy: 0.2778 - 348ms/epoch - 87ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.2236 - accuracy: 1.0000 - val_loss: 1.5364 - val_accuracy: 0.2593 - 325ms/epoch - 81ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.2027 - accuracy: 1.0000 - val_loss: 1.5431 - val_accuracy: 0.2407 - 329ms/epoch - 82ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.2190 - accuracy: 1.0000 - val_loss: 1.4689 - val_accuracy: 0.3148 - 333ms/epoch - 83ms/step\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.2070 - accuracy: 1.0000 - val_loss: 1.5072 - val_accuracy: 0.2778 - 326ms/epoch - 81ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.2058 - accuracy: 1.0000 - val_loss: 1.5414 - val_accuracy: 0.2222 - 326ms/epoch - 81ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1843 - accuracy: 1.0000 - val_loss: 1.5389 - val_accuracy: 0.2593 - 324ms/epoch - 81ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1767 - accuracy: 1.0000 - val_loss: 1.5309 - val_accuracy: 0.2593 - 343ms/epoch - 86ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1715 - accuracy: 1.0000 - val_loss: 1.4904 - val_accuracy: 0.2593 - 316ms/epoch - 79ms/step\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1763 - accuracy: 1.0000 - val_loss: 1.5052 - val_accuracy: 0.2778 - 339ms/epoch - 85ms/step\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1764 - accuracy: 1.0000 - val_loss: 1.5195 - val_accuracy: 0.2963 - 342ms/epoch - 85ms/step\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.2025 - accuracy: 1.0000 - val_loss: 1.5267 - val_accuracy: 0.2407 - 328ms/epoch - 82ms/step\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1817 - accuracy: 1.0000 - val_loss: 1.5747 - val_accuracy: 0.2593 - 330ms/epoch - 83ms/step\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1892 - accuracy: 1.0000 - val_loss: 1.5822 - val_accuracy: 0.2593 - 333ms/epoch - 83ms/step\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1809 - accuracy: 1.0000 - val_loss: 1.5115 - val_accuracy: 0.2778 - 335ms/epoch - 84ms/step\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1655 - accuracy: 1.0000 - val_loss: 1.5161 - val_accuracy: 0.2963 - 331ms/epoch - 83ms/step\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1724 - accuracy: 1.0000 - val_loss: 1.5682 - val_accuracy: 0.2593 - 332ms/epoch - 83ms/step\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1669 - accuracy: 1.0000 - val_loss: 1.5678 - val_accuracy: 0.2778 - 332ms/epoch - 83ms/step\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 135: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1648 - accuracy: 1.0000 - val_loss: 1.5749 - val_accuracy: 0.2593 - 342ms/epoch - 85ms/step\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 136: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1649 - accuracy: 1.0000 - val_loss: 1.5660 - val_accuracy: 0.2407 - 322ms/epoch - 81ms/step\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 137: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1699 - accuracy: 1.0000 - val_loss: 1.5558 - val_accuracy: 0.2593 - 334ms/epoch - 84ms/step\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 138: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1686 - accuracy: 1.0000 - val_loss: 1.6244 - val_accuracy: 0.2593 - 332ms/epoch - 83ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/300\n",
      "\n",
      "Epoch 139: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1722 - accuracy: 1.0000 - val_loss: 1.5907 - val_accuracy: 0.2593 - 344ms/epoch - 86ms/step\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 140: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1676 - accuracy: 1.0000 - val_loss: 1.5753 - val_accuracy: 0.2778 - 339ms/epoch - 85ms/step\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 141: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1671 - accuracy: 1.0000 - val_loss: 1.6195 - val_accuracy: 0.2593 - 319ms/epoch - 80ms/step\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 142: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1606 - accuracy: 1.0000 - val_loss: 1.5957 - val_accuracy: 0.2407 - 327ms/epoch - 82ms/step\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 143: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1536 - accuracy: 1.0000 - val_loss: 1.6299 - val_accuracy: 0.3148 - 323ms/epoch - 81ms/step\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 144: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1683 - accuracy: 1.0000 - val_loss: 1.6285 - val_accuracy: 0.2963 - 332ms/epoch - 83ms/step\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 145: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1419 - accuracy: 1.0000 - val_loss: 1.6490 - val_accuracy: 0.2778 - 339ms/epoch - 85ms/step\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 146: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1503 - accuracy: 1.0000 - val_loss: 1.6339 - val_accuracy: 0.2963 - 336ms/epoch - 84ms/step\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 147: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1444 - accuracy: 1.0000 - val_loss: 1.5926 - val_accuracy: 0.2778 - 325ms/epoch - 81ms/step\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 148: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1587 - accuracy: 1.0000 - val_loss: 1.6027 - val_accuracy: 0.2407 - 331ms/epoch - 83ms/step\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 149: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1438 - accuracy: 1.0000 - val_loss: 1.6229 - val_accuracy: 0.2222 - 331ms/epoch - 83ms/step\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 150: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1328 - accuracy: 1.0000 - val_loss: 1.5923 - val_accuracy: 0.2963 - 338ms/epoch - 85ms/step\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 151: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1381 - accuracy: 1.0000 - val_loss: 1.6433 - val_accuracy: 0.3148 - 332ms/epoch - 83ms/step\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 152: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1585 - accuracy: 1.0000 - val_loss: 1.6634 - val_accuracy: 0.2778 - 324ms/epoch - 81ms/step\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 153: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1412 - accuracy: 1.0000 - val_loss: 1.6468 - val_accuracy: 0.2778 - 327ms/epoch - 82ms/step\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 154: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1423 - accuracy: 1.0000 - val_loss: 1.6440 - val_accuracy: 0.2778 - 332ms/epoch - 83ms/step\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 155: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1367 - accuracy: 1.0000 - val_loss: 1.6049 - val_accuracy: 0.3148 - 323ms/epoch - 81ms/step\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 156: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1583 - accuracy: 1.0000 - val_loss: 1.6590 - val_accuracy: 0.3333 - 329ms/epoch - 82ms/step\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 157: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1387 - accuracy: 1.0000 - val_loss: 1.7143 - val_accuracy: 0.2222 - 327ms/epoch - 82ms/step\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 158: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1544 - accuracy: 1.0000 - val_loss: 1.6284 - val_accuracy: 0.2593 - 322ms/epoch - 80ms/step\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 159: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1426 - accuracy: 1.0000 - val_loss: 1.6560 - val_accuracy: 0.2778 - 336ms/epoch - 84ms/step\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 160: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1512 - accuracy: 1.0000 - val_loss: 1.7387 - val_accuracy: 0.2963 - 333ms/epoch - 83ms/step\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 161: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1421 - accuracy: 1.0000 - val_loss: 1.7715 - val_accuracy: 0.2778 - 322ms/epoch - 81ms/step\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 162: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1350 - accuracy: 1.0000 - val_loss: 1.6758 - val_accuracy: 0.2778 - 329ms/epoch - 82ms/step\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 163: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1278 - accuracy: 1.0000 - val_loss: 1.6695 - val_accuracy: 0.2778 - 328ms/epoch - 82ms/step\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 164: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1260 - accuracy: 1.0000 - val_loss: 1.6502 - val_accuracy: 0.2593 - 336ms/epoch - 84ms/step\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 165: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1157 - accuracy: 1.0000 - val_loss: 1.6642 - val_accuracy: 0.2407 - 325ms/epoch - 81ms/step\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 166: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1316 - accuracy: 1.0000 - val_loss: 1.6722 - val_accuracy: 0.2963 - 325ms/epoch - 81ms/step\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 167: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1383 - accuracy: 1.0000 - val_loss: 1.6101 - val_accuracy: 0.3148 - 322ms/epoch - 81ms/step\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 168: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1229 - accuracy: 1.0000 - val_loss: 1.6035 - val_accuracy: 0.2778 - 347ms/epoch - 87ms/step\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 169: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1227 - accuracy: 1.0000 - val_loss: 1.6913 - val_accuracy: 0.2593 - 331ms/epoch - 83ms/step\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 170: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1373 - accuracy: 1.0000 - val_loss: 1.6730 - val_accuracy: 0.2963 - 340ms/epoch - 85ms/step\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 171: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1231 - accuracy: 1.0000 - val_loss: 1.6301 - val_accuracy: 0.2963 - 328ms/epoch - 82ms/step\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 172: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1401 - accuracy: 1.0000 - val_loss: 1.7715 - val_accuracy: 0.2778 - 329ms/epoch - 82ms/step\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 173: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1267 - accuracy: 1.0000 - val_loss: 1.7873 - val_accuracy: 0.2593 - 346ms/epoch - 86ms/step\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 174: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1438 - accuracy: 1.0000 - val_loss: 1.8374 - val_accuracy: 0.2963 - 341ms/epoch - 85ms/step\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 175: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1679 - accuracy: 1.0000 - val_loss: 1.7476 - val_accuracy: 0.2778 - 339ms/epoch - 85ms/step\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 176: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1563 - accuracy: 1.0000 - val_loss: 1.7414 - val_accuracy: 0.2778 - 328ms/epoch - 82ms/step\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 177: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1329 - accuracy: 1.0000 - val_loss: 1.7594 - val_accuracy: 0.2963 - 329ms/epoch - 82ms/step\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 178: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1374 - accuracy: 1.0000 - val_loss: 1.7571 - val_accuracy: 0.2778 - 340ms/epoch - 85ms/step\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 179: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1394 - accuracy: 1.0000 - val_loss: 1.8613 - val_accuracy: 0.2593 - 329ms/epoch - 82ms/step\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 180: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1334 - accuracy: 1.0000 - val_loss: 1.7969 - val_accuracy: 0.2593 - 347ms/epoch - 87ms/step\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 181: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1289 - accuracy: 0.9921 - val_loss: 1.7534 - val_accuracy: 0.2593 - 327ms/epoch - 82ms/step\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 182: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1173 - accuracy: 1.0000 - val_loss: 1.6904 - val_accuracy: 0.2593 - 328ms/epoch - 82ms/step\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 183: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1317 - accuracy: 1.0000 - val_loss: 1.7062 - val_accuracy: 0.2593 - 327ms/epoch - 82ms/step\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 184: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1175 - accuracy: 1.0000 - val_loss: 1.7023 - val_accuracy: 0.2778 - 342ms/epoch - 85ms/step\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 185: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1255 - accuracy: 1.0000 - val_loss: 1.6771 - val_accuracy: 0.2778 - 334ms/epoch - 84ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186/300\n",
      "\n",
      "Epoch 186: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1095 - accuracy: 1.0000 - val_loss: 1.6989 - val_accuracy: 0.2593 - 333ms/epoch - 83ms/step\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 187: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1097 - accuracy: 1.0000 - val_loss: 1.6773 - val_accuracy: 0.2778 - 323ms/epoch - 81ms/step\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 188: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1195 - accuracy: 1.0000 - val_loss: 1.6450 - val_accuracy: 0.2963 - 339ms/epoch - 85ms/step\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 189: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1063 - accuracy: 1.0000 - val_loss: 1.7056 - val_accuracy: 0.2593 - 329ms/epoch - 82ms/step\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 190: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1050 - accuracy: 1.0000 - val_loss: 1.7140 - val_accuracy: 0.3148 - 326ms/epoch - 82ms/step\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 191: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1076 - accuracy: 1.0000 - val_loss: 1.6838 - val_accuracy: 0.2963 - 330ms/epoch - 82ms/step\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 192: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1157 - accuracy: 1.0000 - val_loss: 1.6836 - val_accuracy: 0.2963 - 343ms/epoch - 86ms/step\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 193: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1013 - accuracy: 1.0000 - val_loss: 1.7036 - val_accuracy: 0.2778 - 325ms/epoch - 81ms/step\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 194: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1234 - accuracy: 1.0000 - val_loss: 1.7142 - val_accuracy: 0.2593 - 326ms/epoch - 82ms/step\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 195: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1090 - accuracy: 1.0000 - val_loss: 1.7259 - val_accuracy: 0.2963 - 340ms/epoch - 85ms/step\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 196: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1119 - accuracy: 1.0000 - val_loss: 1.7005 - val_accuracy: 0.2778 - 340ms/epoch - 85ms/step\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 197: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1016 - accuracy: 1.0000 - val_loss: 1.6850 - val_accuracy: 0.2778 - 329ms/epoch - 82ms/step\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 198: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0990 - accuracy: 1.0000 - val_loss: 1.6549 - val_accuracy: 0.2407 - 345ms/epoch - 86ms/step\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 199: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0996 - accuracy: 1.0000 - val_loss: 1.6886 - val_accuracy: 0.2222 - 337ms/epoch - 84ms/step\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 200: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1005 - accuracy: 1.0000 - val_loss: 1.7048 - val_accuracy: 0.2778 - 333ms/epoch - 83ms/step\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 201: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0861 - accuracy: 1.0000 - val_loss: 1.6972 - val_accuracy: 0.2778 - 326ms/epoch - 82ms/step\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 202: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0937 - accuracy: 1.0000 - val_loss: 1.7457 - val_accuracy: 0.3333 - 343ms/epoch - 86ms/step\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 203: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0968 - accuracy: 1.0000 - val_loss: 1.7309 - val_accuracy: 0.2778 - 321ms/epoch - 80ms/step\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 204: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1104 - accuracy: 1.0000 - val_loss: 1.7624 - val_accuracy: 0.2407 - 338ms/epoch - 85ms/step\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 205: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0912 - accuracy: 1.0000 - val_loss: 1.7699 - val_accuracy: 0.2778 - 341ms/epoch - 85ms/step\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 206: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0965 - accuracy: 1.0000 - val_loss: 1.7727 - val_accuracy: 0.2593 - 326ms/epoch - 81ms/step\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 207: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0916 - accuracy: 1.0000 - val_loss: 1.7785 - val_accuracy: 0.2778 - 327ms/epoch - 82ms/step\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 208: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0971 - accuracy: 1.0000 - val_loss: 1.7671 - val_accuracy: 0.2593 - 326ms/epoch - 81ms/step\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 209: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0934 - accuracy: 1.0000 - val_loss: 1.7311 - val_accuracy: 0.2778 - 334ms/epoch - 84ms/step\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 210: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0877 - accuracy: 1.0000 - val_loss: 1.6914 - val_accuracy: 0.2778 - 329ms/epoch - 82ms/step\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 211: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0867 - accuracy: 1.0000 - val_loss: 1.6942 - val_accuracy: 0.2778 - 341ms/epoch - 85ms/step\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 212: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0868 - accuracy: 1.0000 - val_loss: 1.7505 - val_accuracy: 0.2778 - 328ms/epoch - 82ms/step\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 213: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0752 - accuracy: 1.0000 - val_loss: 1.7522 - val_accuracy: 0.2407 - 327ms/epoch - 82ms/step\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 214: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0866 - accuracy: 1.0000 - val_loss: 1.7233 - val_accuracy: 0.2778 - 330ms/epoch - 83ms/step\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 215: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1106 - accuracy: 0.9921 - val_loss: 1.6920 - val_accuracy: 0.2963 - 337ms/epoch - 84ms/step\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 216: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.1042 - accuracy: 1.0000 - val_loss: 1.7338 - val_accuracy: 0.3148 - 343ms/epoch - 86ms/step\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 217: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0993 - accuracy: 1.0000 - val_loss: 1.8159 - val_accuracy: 0.3148 - 337ms/epoch - 84ms/step\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 218: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0956 - accuracy: 1.0000 - val_loss: 1.8666 - val_accuracy: 0.2593 - 327ms/epoch - 82ms/step\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 219: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0855 - accuracy: 1.0000 - val_loss: 1.8199 - val_accuracy: 0.2963 - 323ms/epoch - 81ms/step\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 220: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0921 - accuracy: 1.0000 - val_loss: 1.7463 - val_accuracy: 0.2778 - 335ms/epoch - 84ms/step\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 221: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0837 - accuracy: 1.0000 - val_loss: 1.7387 - val_accuracy: 0.2778 - 341ms/epoch - 85ms/step\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 222: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0856 - accuracy: 1.0000 - val_loss: 1.7425 - val_accuracy: 0.2963 - 342ms/epoch - 85ms/step\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 223: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0866 - accuracy: 1.0000 - val_loss: 1.7823 - val_accuracy: 0.2778 - 323ms/epoch - 81ms/step\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 224: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0732 - accuracy: 1.0000 - val_loss: 1.7746 - val_accuracy: 0.2593 - 336ms/epoch - 84ms/step\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 225: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0875 - accuracy: 1.0000 - val_loss: 1.7129 - val_accuracy: 0.2593 - 329ms/epoch - 82ms/step\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 226: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0784 - accuracy: 1.0000 - val_loss: 1.7073 - val_accuracy: 0.2963 - 334ms/epoch - 84ms/step\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 227: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0861 - accuracy: 1.0000 - val_loss: 1.7112 - val_accuracy: 0.3148 - 326ms/epoch - 81ms/step\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 228: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0753 - accuracy: 1.0000 - val_loss: 1.7430 - val_accuracy: 0.2778 - 346ms/epoch - 86ms/step\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 229: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0910 - accuracy: 1.0000 - val_loss: 1.7844 - val_accuracy: 0.2778 - 332ms/epoch - 83ms/step\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 230: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0851 - accuracy: 1.0000 - val_loss: 1.7460 - val_accuracy: 0.3148 - 332ms/epoch - 83ms/step\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 231: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0781 - accuracy: 1.0000 - val_loss: 1.7528 - val_accuracy: 0.3333 - 329ms/epoch - 82ms/step\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 232: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0874 - accuracy: 1.0000 - val_loss: 1.7667 - val_accuracy: 0.2593 - 330ms/epoch - 83ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/300\n",
      "\n",
      "Epoch 233: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0746 - accuracy: 1.0000 - val_loss: 1.7615 - val_accuracy: 0.2778 - 344ms/epoch - 86ms/step\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 234: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0744 - accuracy: 1.0000 - val_loss: 1.7646 - val_accuracy: 0.2963 - 330ms/epoch - 83ms/step\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 235: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0758 - accuracy: 1.0000 - val_loss: 1.7857 - val_accuracy: 0.2963 - 349ms/epoch - 87ms/step\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 236: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0872 - accuracy: 1.0000 - val_loss: 1.7992 - val_accuracy: 0.2778 - 340ms/epoch - 85ms/step\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 237: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0814 - accuracy: 1.0000 - val_loss: 1.7468 - val_accuracy: 0.2593 - 329ms/epoch - 82ms/step\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 238: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0823 - accuracy: 1.0000 - val_loss: 1.7700 - val_accuracy: 0.2407 - 340ms/epoch - 85ms/step\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 239: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0800 - accuracy: 1.0000 - val_loss: 1.7196 - val_accuracy: 0.3148 - 339ms/epoch - 85ms/step\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 240: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0794 - accuracy: 1.0000 - val_loss: 1.8175 - val_accuracy: 0.3333 - 349ms/epoch - 87ms/step\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 241: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0861 - accuracy: 1.0000 - val_loss: 1.7592 - val_accuracy: 0.2593 - 347ms/epoch - 87ms/step\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 242: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0893 - accuracy: 1.0000 - val_loss: 1.7602 - val_accuracy: 0.2963 - 339ms/epoch - 85ms/step\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 243: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0832 - accuracy: 1.0000 - val_loss: 1.7004 - val_accuracy: 0.3148 - 339ms/epoch - 85ms/step\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 244: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0797 - accuracy: 1.0000 - val_loss: 1.7072 - val_accuracy: 0.3704 - 336ms/epoch - 84ms/step\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 245: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0742 - accuracy: 1.0000 - val_loss: 1.7551 - val_accuracy: 0.2407 - 326ms/epoch - 81ms/step\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 246: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0873 - accuracy: 1.0000 - val_loss: 1.7963 - val_accuracy: 0.2778 - 333ms/epoch - 83ms/step\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 247: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0858 - accuracy: 1.0000 - val_loss: 1.8115 - val_accuracy: 0.2963 - 335ms/epoch - 84ms/step\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 248: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0716 - accuracy: 1.0000 - val_loss: 1.7773 - val_accuracy: 0.2963 - 335ms/epoch - 84ms/step\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 249: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0765 - accuracy: 1.0000 - val_loss: 1.7165 - val_accuracy: 0.3148 - 338ms/epoch - 85ms/step\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 250: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0775 - accuracy: 1.0000 - val_loss: 1.8021 - val_accuracy: 0.4074 - 333ms/epoch - 83ms/step\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 251: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0931 - accuracy: 1.0000 - val_loss: 1.7409 - val_accuracy: 0.2963 - 321ms/epoch - 80ms/step\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 252: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0983 - accuracy: 1.0000 - val_loss: 1.7698 - val_accuracy: 0.3333 - 349ms/epoch - 87ms/step\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 253: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0811 - accuracy: 1.0000 - val_loss: 1.7699 - val_accuracy: 0.2778 - 346ms/epoch - 87ms/step\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 254: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0756 - accuracy: 1.0000 - val_loss: 1.8710 - val_accuracy: 0.2778 - 332ms/epoch - 83ms/step\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 255: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0861 - accuracy: 1.0000 - val_loss: 1.8981 - val_accuracy: 0.2963 - 334ms/epoch - 83ms/step\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 256: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0749 - accuracy: 1.0000 - val_loss: 1.8545 - val_accuracy: 0.2778 - 327ms/epoch - 82ms/step\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 257: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0703 - accuracy: 1.0000 - val_loss: 1.7843 - val_accuracy: 0.2778 - 321ms/epoch - 80ms/step\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 258: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0683 - accuracy: 1.0000 - val_loss: 1.8047 - val_accuracy: 0.2778 - 331ms/epoch - 83ms/step\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 259: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0738 - accuracy: 1.0000 - val_loss: 1.7481 - val_accuracy: 0.2778 - 336ms/epoch - 84ms/step\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 260: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0641 - accuracy: 1.0000 - val_loss: 1.7875 - val_accuracy: 0.3333 - 339ms/epoch - 85ms/step\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 261: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0658 - accuracy: 1.0000 - val_loss: 1.8138 - val_accuracy: 0.2963 - 338ms/epoch - 84ms/step\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 262: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0681 - accuracy: 1.0000 - val_loss: 1.8218 - val_accuracy: 0.2963 - 334ms/epoch - 84ms/step\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 263: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0666 - accuracy: 1.0000 - val_loss: 1.7821 - val_accuracy: 0.2778 - 322ms/epoch - 81ms/step\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 264: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0667 - accuracy: 1.0000 - val_loss: 1.7367 - val_accuracy: 0.3333 - 329ms/epoch - 82ms/step\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 265: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0675 - accuracy: 1.0000 - val_loss: 1.7461 - val_accuracy: 0.3519 - 332ms/epoch - 83ms/step\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 266: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0684 - accuracy: 1.0000 - val_loss: 1.8306 - val_accuracy: 0.2963 - 329ms/epoch - 82ms/step\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 267: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0700 - accuracy: 1.0000 - val_loss: 1.8159 - val_accuracy: 0.2407 - 325ms/epoch - 81ms/step\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 268: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0628 - accuracy: 1.0000 - val_loss: 1.7944 - val_accuracy: 0.3148 - 332ms/epoch - 83ms/step\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 269: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0718 - accuracy: 1.0000 - val_loss: 1.7767 - val_accuracy: 0.3148 - 327ms/epoch - 82ms/step\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 270: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0650 - accuracy: 1.0000 - val_loss: 1.7583 - val_accuracy: 0.2963 - 345ms/epoch - 86ms/step\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 271: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0521 - accuracy: 1.0000 - val_loss: 1.7456 - val_accuracy: 0.2963 - 341ms/epoch - 85ms/step\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 272: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0639 - accuracy: 1.0000 - val_loss: 1.7384 - val_accuracy: 0.3148 - 340ms/epoch - 85ms/step\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 273: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0683 - accuracy: 1.0000 - val_loss: 1.7632 - val_accuracy: 0.2963 - 325ms/epoch - 81ms/step\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 274: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0662 - accuracy: 1.0000 - val_loss: 1.7811 - val_accuracy: 0.3519 - 333ms/epoch - 83ms/step\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 275: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0668 - accuracy: 1.0000 - val_loss: 1.7732 - val_accuracy: 0.2963 - 332ms/epoch - 83ms/step\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 276: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0653 - accuracy: 1.0000 - val_loss: 1.7981 - val_accuracy: 0.3148 - 354ms/epoch - 88ms/step\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 277: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0639 - accuracy: 1.0000 - val_loss: 1.7631 - val_accuracy: 0.2963 - 327ms/epoch - 82ms/step\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 278: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0597 - accuracy: 1.0000 - val_loss: 1.8163 - val_accuracy: 0.2963 - 344ms/epoch - 86ms/step\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 279: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0675 - accuracy: 1.0000 - val_loss: 1.8189 - val_accuracy: 0.2222 - 351ms/epoch - 88ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280/300\n",
      "\n",
      "Epoch 280: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0619 - accuracy: 1.0000 - val_loss: 1.8250 - val_accuracy: 0.2778 - 328ms/epoch - 82ms/step\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 281: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0560 - accuracy: 1.0000 - val_loss: 1.7840 - val_accuracy: 0.2963 - 348ms/epoch - 87ms/step\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 282: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0591 - accuracy: 1.0000 - val_loss: 1.7843 - val_accuracy: 0.3519 - 335ms/epoch - 84ms/step\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 283: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0727 - accuracy: 1.0000 - val_loss: 1.7465 - val_accuracy: 0.3333 - 339ms/epoch - 85ms/step\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 284: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0541 - accuracy: 1.0000 - val_loss: 1.8329 - val_accuracy: 0.2778 - 327ms/epoch - 82ms/step\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 285: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0674 - accuracy: 1.0000 - val_loss: 1.7836 - val_accuracy: 0.3333 - 334ms/epoch - 84ms/step\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 286: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0608 - accuracy: 1.0000 - val_loss: 1.9013 - val_accuracy: 0.3333 - 324ms/epoch - 81ms/step\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 287: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0735 - accuracy: 1.0000 - val_loss: 1.8120 - val_accuracy: 0.2593 - 331ms/epoch - 83ms/step\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 288: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0702 - accuracy: 1.0000 - val_loss: 1.8111 - val_accuracy: 0.3519 - 335ms/epoch - 84ms/step\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 289: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0600 - accuracy: 1.0000 - val_loss: 1.8467 - val_accuracy: 0.3519 - 334ms/epoch - 83ms/step\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 290: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0664 - accuracy: 1.0000 - val_loss: 1.8109 - val_accuracy: 0.3519 - 334ms/epoch - 83ms/step\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 291: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0648 - accuracy: 1.0000 - val_loss: 1.7693 - val_accuracy: 0.3333 - 324ms/epoch - 81ms/step\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 292: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0595 - accuracy: 1.0000 - val_loss: 2.0239 - val_accuracy: 0.2593 - 334ms/epoch - 84ms/step\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 293: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0586 - accuracy: 1.0000 - val_loss: 1.9034 - val_accuracy: 0.2963 - 326ms/epoch - 81ms/step\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 294: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0706 - accuracy: 1.0000 - val_loss: 2.0448 - val_accuracy: 0.2778 - 332ms/epoch - 83ms/step\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 295: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0567 - accuracy: 1.0000 - val_loss: 1.8945 - val_accuracy: 0.2963 - 330ms/epoch - 82ms/step\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 296: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0601 - accuracy: 1.0000 - val_loss: 1.8408 - val_accuracy: 0.2778 - 334ms/epoch - 84ms/step\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 297: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0572 - accuracy: 1.0000 - val_loss: 1.7897 - val_accuracy: 0.2963 - 333ms/epoch - 83ms/step\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 298: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0608 - accuracy: 1.0000 - val_loss: 1.8446 - val_accuracy: 0.3704 - 328ms/epoch - 82ms/step\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 299: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0607 - accuracy: 1.0000 - val_loss: 1.8218 - val_accuracy: 0.2963 - 331ms/epoch - 83ms/step\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 300: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.0572 - accuracy: 1.0000 - val_loss: 1.8613 - val_accuracy: 0.2963 - 331ms/epoch - 83ms/step\n",
      "2/2 [==============================] - 0s 70ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2022-11-11 09:15:57.025308: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_8613338\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:565786\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 09:16:00.964567: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_8616408\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:565828\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38656, saving model to checkpoint1.h5\n",
      "4/4 - 5s - loss: 1.4635 - accuracy: 0.2222 - val_loss: 1.3866 - val_accuracy: 0.1667 - 5s/epoch - 1s/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss did not improve from 1.38656\n",
      "4/4 - 0s - loss: 1.3409 - accuracy: 0.3889 - val_loss: 1.3866 - val_accuracy: 0.1667 - 340ms/epoch - 85ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss did not improve from 1.38656\n",
      "4/4 - 0s - loss: 1.2680 - accuracy: 0.5079 - val_loss: 1.3868 - val_accuracy: 0.1667 - 324ms/epoch - 81ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss did not improve from 1.38656\n",
      "4/4 - 0s - loss: 1.2788 - accuracy: 0.4206 - val_loss: 1.3869 - val_accuracy: 0.1667 - 332ms/epoch - 83ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss did not improve from 1.38656\n",
      "4/4 - 0s - loss: 1.2306 - accuracy: 0.5000 - val_loss: 1.3869 - val_accuracy: 0.1667 - 325ms/epoch - 81ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.38656\n",
      "4/4 - 0s - loss: 1.1909 - accuracy: 0.5714 - val_loss: 1.3870 - val_accuracy: 0.1667 - 333ms/epoch - 83ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 1.38656\n",
      "4/4 - 0s - loss: 1.1674 - accuracy: 0.5714 - val_loss: 1.3869 - val_accuracy: 0.1481 - 338ms/epoch - 84ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 1.38656\n",
      "4/4 - 0s - loss: 1.1642 - accuracy: 0.5952 - val_loss: 1.3867 - val_accuracy: 0.2778 - 345ms/epoch - 86ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 1.38656\n",
      "4/4 - 0s - loss: 1.1225 - accuracy: 0.6270 - val_loss: 1.3868 - val_accuracy: 0.2593 - 321ms/epoch - 80ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.38656\n",
      "4/4 - 0s - loss: 1.1147 - accuracy: 0.6667 - val_loss: 1.3873 - val_accuracy: 0.2593 - 329ms/epoch - 82ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.38656\n",
      "4/4 - 0s - loss: 1.1080 - accuracy: 0.6349 - val_loss: 1.3870 - val_accuracy: 0.2593 - 326ms/epoch - 81ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.38656\n",
      "4/4 - 0s - loss: 1.0465 - accuracy: 0.6905 - val_loss: 1.3869 - val_accuracy: 0.2778 - 341ms/epoch - 85ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.38656\n",
      "4/4 - 0s - loss: 1.0369 - accuracy: 0.6984 - val_loss: 1.3872 - val_accuracy: 0.2593 - 323ms/epoch - 81ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 1.38656\n",
      "4/4 - 0s - loss: 1.0253 - accuracy: 0.7063 - val_loss: 1.3873 - val_accuracy: 0.2778 - 331ms/epoch - 83ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.38656\n",
      "4/4 - 0s - loss: 1.0393 - accuracy: 0.6984 - val_loss: 1.3870 - val_accuracy: 0.2778 - 324ms/epoch - 81ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 1.38656\n",
      "4/4 - 0s - loss: 0.9742 - accuracy: 0.7937 - val_loss: 1.3866 - val_accuracy: 0.2778 - 323ms/epoch - 81ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 1.38656\n",
      "4/4 - 0s - loss: 0.9608 - accuracy: 0.7222 - val_loss: 1.3874 - val_accuracy: 0.2778 - 334ms/epoch - 83ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 1.38656\n",
      "4/4 - 0s - loss: 0.9708 - accuracy: 0.7381 - val_loss: 1.3877 - val_accuracy: 0.2778 - 320ms/epoch - 80ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 1.38656\n",
      "4/4 - 0s - loss: 0.9378 - accuracy: 0.7698 - val_loss: 1.3877 - val_accuracy: 0.2778 - 325ms/epoch - 81ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss improved from 1.38656 to 1.38578, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.9115 - accuracy: 0.8254 - val_loss: 1.3858 - val_accuracy: 0.2778 - 393ms/epoch - 98ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 1.38578\n",
      "4/4 - 0s - loss: 0.9106 - accuracy: 0.8254 - val_loss: 1.3863 - val_accuracy: 0.2778 - 325ms/epoch - 81ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 1.38578\n",
      "4/4 - 0s - loss: 0.8761 - accuracy: 0.8571 - val_loss: 1.3868 - val_accuracy: 0.2778 - 327ms/epoch - 82ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss improved from 1.38578 to 1.38534, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.8732 - accuracy: 0.8016 - val_loss: 1.3853 - val_accuracy: 0.2778 - 387ms/epoch - 97ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss improved from 1.38534 to 1.38513, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.8583 - accuracy: 0.8730 - val_loss: 1.3851 - val_accuracy: 0.2778 - 382ms/epoch - 96ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.38513\n",
      "4/4 - 0s - loss: 0.7996 - accuracy: 0.8730 - val_loss: 1.3851 - val_accuracy: 0.2778 - 327ms/epoch - 82ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss improved from 1.38513 to 1.38476, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.8078 - accuracy: 0.8810 - val_loss: 1.3848 - val_accuracy: 0.2778 - 405ms/epoch - 101ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss improved from 1.38476 to 1.38319, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.8076 - accuracy: 0.8413 - val_loss: 1.3832 - val_accuracy: 0.2778 - 386ms/epoch - 97ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 1.38319\n",
      "4/4 - 0s - loss: 0.7754 - accuracy: 0.8810 - val_loss: 1.3837 - val_accuracy: 0.2778 - 324ms/epoch - 81ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 1.38319\n",
      "4/4 - 0s - loss: 0.7659 - accuracy: 0.8413 - val_loss: 1.3848 - val_accuracy: 0.2778 - 336ms/epoch - 84ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss improved from 1.38319 to 1.38212, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.7523 - accuracy: 0.8889 - val_loss: 1.3821 - val_accuracy: 0.2778 - 391ms/epoch - 98ms/step\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 1.38212\n",
      "4/4 - 0s - loss: 0.7189 - accuracy: 0.9206 - val_loss: 1.3823 - val_accuracy: 0.2593 - 325ms/epoch - 81ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 1.38212\n",
      "4/4 - 0s - loss: 0.7392 - accuracy: 0.9365 - val_loss: 1.3851 - val_accuracy: 0.2778 - 341ms/epoch - 85ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss improved from 1.38212 to 1.38060, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.7332 - accuracy: 0.9127 - val_loss: 1.3806 - val_accuracy: 0.2407 - 389ms/epoch - 97ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 1.38060\n",
      "4/4 - 0s - loss: 0.7379 - accuracy: 0.9286 - val_loss: 1.3828 - val_accuracy: 0.2778 - 331ms/epoch - 83ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 1.38060\n",
      "4/4 - 0s - loss: 0.6999 - accuracy: 0.9048 - val_loss: 1.3808 - val_accuracy: 0.3148 - 331ms/epoch - 83ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss improved from 1.38060 to 1.38040, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.6760 - accuracy: 0.9286 - val_loss: 1.3804 - val_accuracy: 0.2778 - 379ms/epoch - 95ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 1.38040\n",
      "4/4 - 0s - loss: 0.6440 - accuracy: 0.9365 - val_loss: 1.3816 - val_accuracy: 0.2778 - 331ms/epoch - 83ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss improved from 1.38040 to 1.37804, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.6292 - accuracy: 0.9444 - val_loss: 1.3780 - val_accuracy: 0.3148 - 380ms/epoch - 95ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 1.37804\n",
      "4/4 - 0s - loss: 0.6298 - accuracy: 0.9603 - val_loss: 1.3804 - val_accuracy: 0.2778 - 328ms/epoch - 82ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss improved from 1.37804 to 1.37672, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.6153 - accuracy: 0.9206 - val_loss: 1.3767 - val_accuracy: 0.2778 - 392ms/epoch - 98ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.6188 - accuracy: 0.9127 - val_loss: 1.3791 - val_accuracy: 0.2778 - 334ms/epoch - 84ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.5617 - accuracy: 0.9841 - val_loss: 1.3773 - val_accuracy: 0.2778 - 326ms/epoch - 81ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.5665 - accuracy: 0.9603 - val_loss: 1.3808 - val_accuracy: 0.2778 - 341ms/epoch - 85ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.5756 - accuracy: 0.9762 - val_loss: 1.3795 - val_accuracy: 0.3148 - 330ms/epoch - 82ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.5625 - accuracy: 0.9603 - val_loss: 1.3774 - val_accuracy: 0.2778 - 333ms/epoch - 83ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 1.37672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.5695 - accuracy: 0.9603 - val_loss: 1.3825 - val_accuracy: 0.3333 - 325ms/epoch - 81ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.5182 - accuracy: 0.9762 - val_loss: 1.3791 - val_accuracy: 0.2963 - 336ms/epoch - 84ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.5061 - accuracy: 0.9841 - val_loss: 1.3795 - val_accuracy: 0.2593 - 328ms/epoch - 82ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.5674 - accuracy: 0.9444 - val_loss: 1.3820 - val_accuracy: 0.2593 - 331ms/epoch - 83ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.5098 - accuracy: 0.9841 - val_loss: 1.3782 - val_accuracy: 0.3519 - 326ms/epoch - 82ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.5173 - accuracy: 0.9683 - val_loss: 1.3784 - val_accuracy: 0.3148 - 321ms/epoch - 80ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.4759 - accuracy: 0.9762 - val_loss: 1.3867 - val_accuracy: 0.3148 - 336ms/epoch - 84ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.5029 - accuracy: 0.9603 - val_loss: 1.3818 - val_accuracy: 0.2778 - 316ms/epoch - 79ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.4887 - accuracy: 0.9683 - val_loss: 1.3836 - val_accuracy: 0.2778 - 339ms/epoch - 85ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.4858 - accuracy: 0.9683 - val_loss: 1.3845 - val_accuracy: 0.3519 - 323ms/epoch - 81ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.4640 - accuracy: 0.9921 - val_loss: 1.3881 - val_accuracy: 0.2778 - 343ms/epoch - 86ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.4376 - accuracy: 1.0000 - val_loss: 1.3865 - val_accuracy: 0.3519 - 320ms/epoch - 80ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.4239 - accuracy: 0.9841 - val_loss: 1.3864 - val_accuracy: 0.2593 - 321ms/epoch - 80ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.4515 - accuracy: 0.9841 - val_loss: 1.3897 - val_accuracy: 0.3333 - 334ms/epoch - 84ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.4318 - accuracy: 0.9683 - val_loss: 1.3890 - val_accuracy: 0.3333 - 344ms/epoch - 86ms/step\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.4223 - accuracy: 0.9841 - val_loss: 1.3911 - val_accuracy: 0.3333 - 334ms/epoch - 84ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.4226 - accuracy: 1.0000 - val_loss: 1.3954 - val_accuracy: 0.2778 - 327ms/epoch - 82ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.4355 - accuracy: 0.9841 - val_loss: 1.3932 - val_accuracy: 0.3704 - 320ms/epoch - 80ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.3699 - accuracy: 0.9921 - val_loss: 1.3949 - val_accuracy: 0.3704 - 329ms/epoch - 82ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.4100 - accuracy: 0.9841 - val_loss: 1.4012 - val_accuracy: 0.2407 - 337ms/epoch - 84ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.3910 - accuracy: 0.9603 - val_loss: 1.3952 - val_accuracy: 0.3148 - 339ms/epoch - 85ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.4062 - accuracy: 0.9683 - val_loss: 1.3942 - val_accuracy: 0.3704 - 318ms/epoch - 80ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.3604 - accuracy: 0.9841 - val_loss: 1.3977 - val_accuracy: 0.3333 - 352ms/epoch - 88ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.3485 - accuracy: 1.0000 - val_loss: 1.4098 - val_accuracy: 0.2407 - 336ms/epoch - 84ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.3712 - accuracy: 0.9841 - val_loss: 1.4080 - val_accuracy: 0.3148 - 337ms/epoch - 84ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.3314 - accuracy: 0.9921 - val_loss: 1.4055 - val_accuracy: 0.2407 - 329ms/epoch - 82ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.3708 - accuracy: 0.9921 - val_loss: 1.4083 - val_accuracy: 0.2593 - 330ms/epoch - 83ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.3865 - accuracy: 0.9762 - val_loss: 1.4116 - val_accuracy: 0.3148 - 323ms/epoch - 81ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.3579 - accuracy: 1.0000 - val_loss: 1.4079 - val_accuracy: 0.2407 - 332ms/epoch - 83ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.3483 - accuracy: 0.9921 - val_loss: 1.4290 - val_accuracy: 0.2407 - 322ms/epoch - 80ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.3636 - accuracy: 1.0000 - val_loss: 1.4244 - val_accuracy: 0.3148 - 326ms/epoch - 81ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.3752 - accuracy: 0.9841 - val_loss: 1.4288 - val_accuracy: 0.2963 - 330ms/epoch - 83ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.3463 - accuracy: 0.9841 - val_loss: 1.4319 - val_accuracy: 0.2593 - 333ms/epoch - 83ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.3253 - accuracy: 0.9921 - val_loss: 1.4338 - val_accuracy: 0.2593 - 328ms/epoch - 82ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.3017 - accuracy: 1.0000 - val_loss: 1.4271 - val_accuracy: 0.2963 - 332ms/epoch - 83ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.3110 - accuracy: 0.9921 - val_loss: 1.4308 - val_accuracy: 0.2593 - 329ms/epoch - 82ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.3027 - accuracy: 1.0000 - val_loss: 1.4473 - val_accuracy: 0.3148 - 325ms/epoch - 81ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.3123 - accuracy: 1.0000 - val_loss: 1.4585 - val_accuracy: 0.2593 - 327ms/epoch - 82ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.3062 - accuracy: 1.0000 - val_loss: 1.4388 - val_accuracy: 0.3889 - 326ms/epoch - 81ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.2976 - accuracy: 0.9921 - val_loss: 1.4459 - val_accuracy: 0.2963 - 332ms/epoch - 83ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 1.37672\n",
      "4/4 - 1s - loss: 0.2928 - accuracy: 1.0000 - val_loss: 1.4739 - val_accuracy: 0.3889 - 657ms/epoch - 164ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.2939 - accuracy: 1.0000 - val_loss: 1.4739 - val_accuracy: 0.2593 - 336ms/epoch - 84ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.2763 - accuracy: 1.0000 - val_loss: 1.4582 - val_accuracy: 0.2222 - 335ms/epoch - 84ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.2662 - accuracy: 1.0000 - val_loss: 1.4714 - val_accuracy: 0.3333 - 338ms/epoch - 85ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.2676 - accuracy: 1.0000 - val_loss: 1.4850 - val_accuracy: 0.2963 - 334ms/epoch - 84ms/step\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.2974 - accuracy: 1.0000 - val_loss: 1.4786 - val_accuracy: 0.2037 - 350ms/epoch - 87ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.2668 - accuracy: 1.0000 - val_loss: 1.4524 - val_accuracy: 0.3704 - 339ms/epoch - 85ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.2709 - accuracy: 1.0000 - val_loss: 1.4842 - val_accuracy: 0.3148 - 350ms/epoch - 88ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.2624 - accuracy: 1.0000 - val_loss: 1.5114 - val_accuracy: 0.2222 - 335ms/epoch - 84ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.2498 - accuracy: 1.0000 - val_loss: 1.4853 - val_accuracy: 0.2778 - 344ms/epoch - 86ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.2343 - accuracy: 1.0000 - val_loss: 1.4886 - val_accuracy: 0.2963 - 331ms/epoch - 83ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.2304 - accuracy: 1.0000 - val_loss: 1.5204 - val_accuracy: 0.2222 - 331ms/epoch - 83ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.2680 - accuracy: 0.9921 - val_loss: 1.5128 - val_accuracy: 0.2407 - 342ms/epoch - 85ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.2438 - accuracy: 1.0000 - val_loss: 1.5143 - val_accuracy: 0.2593 - 342ms/epoch - 85ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.2320 - accuracy: 1.0000 - val_loss: 1.5684 - val_accuracy: 0.1852 - 335ms/epoch - 84ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.2398 - accuracy: 1.0000 - val_loss: 1.5309 - val_accuracy: 0.2222 - 331ms/epoch - 83ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.2462 - accuracy: 1.0000 - val_loss: 1.5269 - val_accuracy: 0.2407 - 339ms/epoch - 85ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.2597 - accuracy: 0.9921 - val_loss: 1.5960 - val_accuracy: 0.1667 - 335ms/epoch - 84ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.2655 - accuracy: 1.0000 - val_loss: 1.5594 - val_accuracy: 0.2593 - 338ms/epoch - 85ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.2668 - accuracy: 0.9841 - val_loss: 1.5837 - val_accuracy: 0.2037 - 328ms/epoch - 82ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.2760 - accuracy: 1.0000 - val_loss: 1.5114 - val_accuracy: 0.2963 - 337ms/epoch - 84ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.2493 - accuracy: 0.9921 - val_loss: 1.5833 - val_accuracy: 0.2222 - 337ms/epoch - 84ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.2421 - accuracy: 1.0000 - val_loss: 1.6107 - val_accuracy: 0.2037 - 342ms/epoch - 85ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.2219 - accuracy: 0.9921 - val_loss: 1.5648 - val_accuracy: 0.2037 - 334ms/epoch - 83ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.2191 - accuracy: 1.0000 - val_loss: 1.6663 - val_accuracy: 0.1667 - 333ms/epoch - 83ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.2321 - accuracy: 0.9921 - val_loss: 1.6116 - val_accuracy: 0.2037 - 345ms/epoch - 86ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.2699 - accuracy: 1.0000 - val_loss: 1.6428 - val_accuracy: 0.1852 - 343ms/epoch - 86ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.2384 - accuracy: 1.0000 - val_loss: 1.6200 - val_accuracy: 0.1667 - 340ms/epoch - 85ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.2275 - accuracy: 1.0000 - val_loss: 1.5822 - val_accuracy: 0.1481 - 331ms/epoch - 83ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.2071 - accuracy: 1.0000 - val_loss: 1.6429 - val_accuracy: 0.1481 - 325ms/epoch - 81ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.2054 - accuracy: 1.0000 - val_loss: 1.5812 - val_accuracy: 0.2222 - 337ms/epoch - 84ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1989 - accuracy: 1.0000 - val_loss: 1.6029 - val_accuracy: 0.2037 - 348ms/epoch - 87ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 1.6278 - val_accuracy: 0.1852 - 346ms/epoch - 86ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1991 - accuracy: 1.0000 - val_loss: 1.6358 - val_accuracy: 0.1667 - 351ms/epoch - 88ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1921 - accuracy: 1.0000 - val_loss: 1.6320 - val_accuracy: 0.2222 - 327ms/epoch - 82ms/step\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1996 - accuracy: 1.0000 - val_loss: 1.6216 - val_accuracy: 0.2407 - 354ms/epoch - 89ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1881 - accuracy: 1.0000 - val_loss: 1.6606 - val_accuracy: 0.1481 - 334ms/epoch - 83ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.2063 - accuracy: 1.0000 - val_loss: 1.6501 - val_accuracy: 0.1667 - 331ms/epoch - 83ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1931 - accuracy: 1.0000 - val_loss: 1.6890 - val_accuracy: 0.1667 - 355ms/epoch - 89ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 1.6642 - val_accuracy: 0.1852 - 330ms/epoch - 83ms/step\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1727 - accuracy: 1.0000 - val_loss: 1.7150 - val_accuracy: 0.1852 - 343ms/epoch - 86ms/step\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1779 - accuracy: 1.0000 - val_loss: 1.6261 - val_accuracy: 0.2222 - 324ms/epoch - 81ms/step\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1851 - accuracy: 1.0000 - val_loss: 1.6288 - val_accuracy: 0.2222 - 331ms/epoch - 83ms/step\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1708 - accuracy: 1.0000 - val_loss: 1.7135 - val_accuracy: 0.1111 - 331ms/epoch - 83ms/step\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1865 - accuracy: 1.0000 - val_loss: 1.6465 - val_accuracy: 0.1852 - 331ms/epoch - 83ms/step\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1798 - accuracy: 1.0000 - val_loss: 1.6163 - val_accuracy: 0.2593 - 333ms/epoch - 83ms/step\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1718 - accuracy: 1.0000 - val_loss: 1.6288 - val_accuracy: 0.2222 - 350ms/epoch - 87ms/step\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1646 - accuracy: 1.0000 - val_loss: 1.6779 - val_accuracy: 0.1296 - 338ms/epoch - 85ms/step\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1765 - accuracy: 1.0000 - val_loss: 1.7115 - val_accuracy: 0.1296 - 340ms/epoch - 85ms/step\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 135: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1805 - accuracy: 1.0000 - val_loss: 1.7114 - val_accuracy: 0.1481 - 344ms/epoch - 86ms/step\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 136: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1824 - accuracy: 1.0000 - val_loss: 1.7211 - val_accuracy: 0.1481 - 346ms/epoch - 86ms/step\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 137: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1715 - accuracy: 1.0000 - val_loss: 1.7198 - val_accuracy: 0.1667 - 336ms/epoch - 84ms/step\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 138: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1614 - accuracy: 1.0000 - val_loss: 1.6914 - val_accuracy: 0.1481 - 331ms/epoch - 83ms/step\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 139: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1809 - accuracy: 1.0000 - val_loss: 1.8430 - val_accuracy: 0.1667 - 328ms/epoch - 82ms/step\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 140: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1654 - accuracy: 1.0000 - val_loss: 1.7965 - val_accuracy: 0.1296 - 337ms/epoch - 84ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/300\n",
      "\n",
      "Epoch 141: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1607 - accuracy: 1.0000 - val_loss: 1.8008 - val_accuracy: 0.1481 - 330ms/epoch - 83ms/step\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 142: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1742 - accuracy: 1.0000 - val_loss: 1.7842 - val_accuracy: 0.1296 - 348ms/epoch - 87ms/step\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 143: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1719 - accuracy: 1.0000 - val_loss: 1.7144 - val_accuracy: 0.1481 - 333ms/epoch - 83ms/step\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 144: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1463 - accuracy: 1.0000 - val_loss: 1.7462 - val_accuracy: 0.1296 - 332ms/epoch - 83ms/step\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 145: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1547 - accuracy: 1.0000 - val_loss: 1.7275 - val_accuracy: 0.1852 - 332ms/epoch - 83ms/step\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 146: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1382 - accuracy: 1.0000 - val_loss: 1.7209 - val_accuracy: 0.1667 - 341ms/epoch - 85ms/step\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 147: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1563 - accuracy: 1.0000 - val_loss: 1.7477 - val_accuracy: 0.1852 - 339ms/epoch - 85ms/step\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 148: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1376 - accuracy: 1.0000 - val_loss: 1.7276 - val_accuracy: 0.2037 - 353ms/epoch - 88ms/step\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 149: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1514 - accuracy: 1.0000 - val_loss: 1.7167 - val_accuracy: 0.1667 - 333ms/epoch - 83ms/step\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 150: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1457 - accuracy: 1.0000 - val_loss: 1.7748 - val_accuracy: 0.2037 - 328ms/epoch - 82ms/step\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 151: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1264 - accuracy: 1.0000 - val_loss: 1.7891 - val_accuracy: 0.1667 - 327ms/epoch - 82ms/step\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 152: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1443 - accuracy: 1.0000 - val_loss: 1.7489 - val_accuracy: 0.1481 - 336ms/epoch - 84ms/step\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 153: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1236 - accuracy: 1.0000 - val_loss: 1.7417 - val_accuracy: 0.1111 - 327ms/epoch - 82ms/step\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 154: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1362 - accuracy: 1.0000 - val_loss: 1.7503 - val_accuracy: 0.1481 - 344ms/epoch - 86ms/step\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 155: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1406 - accuracy: 1.0000 - val_loss: 1.7597 - val_accuracy: 0.1481 - 328ms/epoch - 82ms/step\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 156: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1459 - accuracy: 1.0000 - val_loss: 1.7054 - val_accuracy: 0.1667 - 337ms/epoch - 84ms/step\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 157: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1423 - accuracy: 1.0000 - val_loss: 1.7644 - val_accuracy: 0.1481 - 341ms/epoch - 85ms/step\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 158: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1385 - accuracy: 1.0000 - val_loss: 1.7649 - val_accuracy: 0.1852 - 346ms/epoch - 86ms/step\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 159: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1374 - accuracy: 1.0000 - val_loss: 1.8167 - val_accuracy: 0.1481 - 324ms/epoch - 81ms/step\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 160: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1268 - accuracy: 1.0000 - val_loss: 1.7682 - val_accuracy: 0.1296 - 340ms/epoch - 85ms/step\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 161: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1341 - accuracy: 1.0000 - val_loss: 1.7672 - val_accuracy: 0.1481 - 335ms/epoch - 84ms/step\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 162: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1278 - accuracy: 1.0000 - val_loss: 1.7680 - val_accuracy: 0.2037 - 341ms/epoch - 85ms/step\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 163: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1255 - accuracy: 1.0000 - val_loss: 1.7321 - val_accuracy: 0.2037 - 340ms/epoch - 85ms/step\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 164: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1340 - accuracy: 1.0000 - val_loss: 1.7298 - val_accuracy: 0.1667 - 345ms/epoch - 86ms/step\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 165: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1319 - accuracy: 1.0000 - val_loss: 1.7638 - val_accuracy: 0.1667 - 333ms/epoch - 83ms/step\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 166: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1213 - accuracy: 1.0000 - val_loss: 1.7490 - val_accuracy: 0.1667 - 334ms/epoch - 83ms/step\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 167: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1171 - accuracy: 1.0000 - val_loss: 1.7574 - val_accuracy: 0.1481 - 329ms/epoch - 82ms/step\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 168: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1153 - accuracy: 1.0000 - val_loss: 1.8057 - val_accuracy: 0.1667 - 346ms/epoch - 87ms/step\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 169: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1102 - accuracy: 1.0000 - val_loss: 1.7991 - val_accuracy: 0.1296 - 331ms/epoch - 83ms/step\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 170: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1126 - accuracy: 1.0000 - val_loss: 1.8462 - val_accuracy: 0.1481 - 328ms/epoch - 82ms/step\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 171: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1357 - accuracy: 1.0000 - val_loss: 1.8334 - val_accuracy: 0.1667 - 328ms/epoch - 82ms/step\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 172: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0985 - accuracy: 1.0000 - val_loss: 1.7768 - val_accuracy: 0.1852 - 348ms/epoch - 87ms/step\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 173: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1205 - accuracy: 1.0000 - val_loss: 1.7942 - val_accuracy: 0.1296 - 345ms/epoch - 86ms/step\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 174: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1120 - accuracy: 1.0000 - val_loss: 1.8270 - val_accuracy: 0.2037 - 370ms/epoch - 92ms/step\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 175: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1166 - accuracy: 1.0000 - val_loss: 1.8350 - val_accuracy: 0.1852 - 354ms/epoch - 89ms/step\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 176: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1176 - accuracy: 1.0000 - val_loss: 1.8692 - val_accuracy: 0.1852 - 344ms/epoch - 86ms/step\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 177: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1058 - accuracy: 1.0000 - val_loss: 1.8681 - val_accuracy: 0.1296 - 336ms/epoch - 84ms/step\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 178: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1026 - accuracy: 1.0000 - val_loss: 1.8795 - val_accuracy: 0.1481 - 345ms/epoch - 86ms/step\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 179: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0995 - accuracy: 1.0000 - val_loss: 1.8654 - val_accuracy: 0.1667 - 330ms/epoch - 82ms/step\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 180: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1144 - accuracy: 1.0000 - val_loss: 1.8475 - val_accuracy: 0.2037 - 332ms/epoch - 83ms/step\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 181: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1078 - accuracy: 1.0000 - val_loss: 1.8609 - val_accuracy: 0.2037 - 331ms/epoch - 83ms/step\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 182: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1122 - accuracy: 1.0000 - val_loss: 1.9067 - val_accuracy: 0.1481 - 337ms/epoch - 84ms/step\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 183: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1342 - accuracy: 1.0000 - val_loss: 2.1299 - val_accuracy: 0.1852 - 334ms/epoch - 83ms/step\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 184: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1388 - accuracy: 1.0000 - val_loss: 1.9941 - val_accuracy: 0.1296 - 334ms/epoch - 84ms/step\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 185: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1504 - accuracy: 1.0000 - val_loss: 2.3195 - val_accuracy: 0.2037 - 338ms/epoch - 85ms/step\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 186: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1568 - accuracy: 1.0000 - val_loss: 1.9241 - val_accuracy: 0.1667 - 332ms/epoch - 83ms/step\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 187: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1334 - accuracy: 1.0000 - val_loss: 2.0641 - val_accuracy: 0.2222 - 349ms/epoch - 87ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188/300\n",
      "\n",
      "Epoch 188: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1204 - accuracy: 1.0000 - val_loss: 2.0762 - val_accuracy: 0.1852 - 331ms/epoch - 83ms/step\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 189: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1134 - accuracy: 1.0000 - val_loss: 2.7281 - val_accuracy: 0.1852 - 333ms/epoch - 83ms/step\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 190: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1163 - accuracy: 1.0000 - val_loss: 2.1139 - val_accuracy: 0.2222 - 344ms/epoch - 86ms/step\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 191: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1184 - accuracy: 1.0000 - val_loss: 1.8985 - val_accuracy: 0.1481 - 335ms/epoch - 84ms/step\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 192: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1059 - accuracy: 1.0000 - val_loss: 1.8380 - val_accuracy: 0.1852 - 329ms/epoch - 82ms/step\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 193: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1074 - accuracy: 1.0000 - val_loss: 1.9110 - val_accuracy: 0.1481 - 331ms/epoch - 83ms/step\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 194: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0965 - accuracy: 1.0000 - val_loss: 1.8599 - val_accuracy: 0.1667 - 336ms/epoch - 84ms/step\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 195: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.1100 - accuracy: 1.0000 - val_loss: 1.8479 - val_accuracy: 0.1852 - 343ms/epoch - 86ms/step\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 196: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0976 - accuracy: 1.0000 - val_loss: 1.8113 - val_accuracy: 0.2222 - 338ms/epoch - 84ms/step\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 197: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0980 - accuracy: 1.0000 - val_loss: 1.8358 - val_accuracy: 0.1852 - 333ms/epoch - 83ms/step\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 198: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0903 - accuracy: 1.0000 - val_loss: 1.8948 - val_accuracy: 0.1852 - 342ms/epoch - 85ms/step\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 199: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0968 - accuracy: 1.0000 - val_loss: 1.9180 - val_accuracy: 0.1852 - 346ms/epoch - 87ms/step\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 200: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0891 - accuracy: 1.0000 - val_loss: 1.9002 - val_accuracy: 0.2037 - 329ms/epoch - 82ms/step\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 201: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0967 - accuracy: 1.0000 - val_loss: 1.9259 - val_accuracy: 0.1481 - 330ms/epoch - 83ms/step\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 202: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0898 - accuracy: 1.0000 - val_loss: 1.9111 - val_accuracy: 0.1296 - 347ms/epoch - 87ms/step\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 203: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0847 - accuracy: 1.0000 - val_loss: 1.8576 - val_accuracy: 0.1481 - 336ms/epoch - 84ms/step\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 204: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0958 - accuracy: 1.0000 - val_loss: 1.8935 - val_accuracy: 0.1667 - 353ms/epoch - 88ms/step\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 205: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0950 - accuracy: 1.0000 - val_loss: 1.8814 - val_accuracy: 0.1481 - 338ms/epoch - 85ms/step\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 206: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0907 - accuracy: 1.0000 - val_loss: 1.8835 - val_accuracy: 0.1481 - 335ms/epoch - 84ms/step\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 207: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0879 - accuracy: 1.0000 - val_loss: 1.8080 - val_accuracy: 0.1481 - 330ms/epoch - 83ms/step\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 208: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0888 - accuracy: 1.0000 - val_loss: 1.8582 - val_accuracy: 0.1481 - 347ms/epoch - 87ms/step\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 209: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0855 - accuracy: 1.0000 - val_loss: 1.8718 - val_accuracy: 0.1481 - 328ms/epoch - 82ms/step\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 210: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0856 - accuracy: 1.0000 - val_loss: 1.8320 - val_accuracy: 0.2222 - 331ms/epoch - 83ms/step\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 211: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0817 - accuracy: 1.0000 - val_loss: 1.8409 - val_accuracy: 0.2222 - 340ms/epoch - 85ms/step\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 212: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0931 - accuracy: 1.0000 - val_loss: 1.8476 - val_accuracy: 0.1667 - 329ms/epoch - 82ms/step\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 213: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0997 - accuracy: 1.0000 - val_loss: 1.8516 - val_accuracy: 0.1852 - 339ms/epoch - 85ms/step\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 214: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0800 - accuracy: 1.0000 - val_loss: 1.8885 - val_accuracy: 0.1852 - 337ms/epoch - 84ms/step\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 215: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0802 - accuracy: 1.0000 - val_loss: 1.9539 - val_accuracy: 0.1667 - 341ms/epoch - 85ms/step\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 216: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0907 - accuracy: 1.0000 - val_loss: 1.9539 - val_accuracy: 0.1667 - 336ms/epoch - 84ms/step\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 217: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0758 - accuracy: 1.0000 - val_loss: 1.9281 - val_accuracy: 0.1111 - 337ms/epoch - 84ms/step\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 218: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0955 - accuracy: 1.0000 - val_loss: 1.9292 - val_accuracy: 0.1667 - 332ms/epoch - 83ms/step\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 219: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0772 - accuracy: 1.0000 - val_loss: 1.9348 - val_accuracy: 0.1667 - 337ms/epoch - 84ms/step\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 220: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0836 - accuracy: 1.0000 - val_loss: 1.8434 - val_accuracy: 0.2037 - 334ms/epoch - 83ms/step\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 221: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0866 - accuracy: 1.0000 - val_loss: 1.8457 - val_accuracy: 0.1852 - 341ms/epoch - 85ms/step\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 222: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0820 - accuracy: 1.0000 - val_loss: 1.8423 - val_accuracy: 0.2037 - 327ms/epoch - 82ms/step\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 223: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0791 - accuracy: 1.0000 - val_loss: 1.8754 - val_accuracy: 0.1667 - 350ms/epoch - 87ms/step\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 224: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0762 - accuracy: 1.0000 - val_loss: 1.8905 - val_accuracy: 0.1667 - 326ms/epoch - 82ms/step\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 225: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0867 - accuracy: 1.0000 - val_loss: 1.9054 - val_accuracy: 0.2222 - 325ms/epoch - 81ms/step\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 226: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0772 - accuracy: 1.0000 - val_loss: 1.8779 - val_accuracy: 0.2407 - 348ms/epoch - 87ms/step\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 227: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0746 - accuracy: 1.0000 - val_loss: 1.9113 - val_accuracy: 0.1667 - 342ms/epoch - 85ms/step\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 228: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0860 - accuracy: 1.0000 - val_loss: 1.8837 - val_accuracy: 0.2037 - 328ms/epoch - 82ms/step\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 229: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0767 - accuracy: 1.0000 - val_loss: 1.8977 - val_accuracy: 0.2037 - 344ms/epoch - 86ms/step\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 230: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0822 - accuracy: 1.0000 - val_loss: 1.8812 - val_accuracy: 0.1852 - 337ms/epoch - 84ms/step\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 231: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0874 - accuracy: 1.0000 - val_loss: 1.9399 - val_accuracy: 0.2037 - 325ms/epoch - 81ms/step\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 232: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0862 - accuracy: 1.0000 - val_loss: 1.9356 - val_accuracy: 0.2037 - 335ms/epoch - 84ms/step\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 233: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0802 - accuracy: 1.0000 - val_loss: 1.9658 - val_accuracy: 0.1667 - 339ms/epoch - 85ms/step\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 234: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0840 - accuracy: 1.0000 - val_loss: 1.9691 - val_accuracy: 0.1296 - 342ms/epoch - 86ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235/300\n",
      "\n",
      "Epoch 235: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0658 - accuracy: 1.0000 - val_loss: 1.9422 - val_accuracy: 0.1852 - 339ms/epoch - 85ms/step\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 236: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0662 - accuracy: 1.0000 - val_loss: 1.9245 - val_accuracy: 0.2037 - 325ms/epoch - 81ms/step\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 237: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0745 - accuracy: 1.0000 - val_loss: 2.0180 - val_accuracy: 0.1481 - 341ms/epoch - 85ms/step\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 238: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0686 - accuracy: 1.0000 - val_loss: 1.9935 - val_accuracy: 0.1481 - 324ms/epoch - 81ms/step\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 239: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0773 - accuracy: 1.0000 - val_loss: 1.9738 - val_accuracy: 0.1852 - 324ms/epoch - 81ms/step\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 240: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0810 - accuracy: 1.0000 - val_loss: 1.9380 - val_accuracy: 0.1852 - 333ms/epoch - 83ms/step\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 241: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0759 - accuracy: 1.0000 - val_loss: 1.9159 - val_accuracy: 0.1667 - 342ms/epoch - 85ms/step\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 242: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0712 - accuracy: 1.0000 - val_loss: 1.9001 - val_accuracy: 0.1852 - 328ms/epoch - 82ms/step\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 243: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0916 - accuracy: 1.0000 - val_loss: 1.9153 - val_accuracy: 0.1667 - 335ms/epoch - 84ms/step\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 244: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0761 - accuracy: 1.0000 - val_loss: 1.9225 - val_accuracy: 0.2037 - 348ms/epoch - 87ms/step\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 245: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0786 - accuracy: 1.0000 - val_loss: 1.9040 - val_accuracy: 0.2037 - 326ms/epoch - 82ms/step\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 246: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0719 - accuracy: 1.0000 - val_loss: 1.9906 - val_accuracy: 0.2037 - 334ms/epoch - 83ms/step\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 247: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0735 - accuracy: 1.0000 - val_loss: 2.0662 - val_accuracy: 0.1111 - 326ms/epoch - 82ms/step\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 248: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0723 - accuracy: 1.0000 - val_loss: 1.9764 - val_accuracy: 0.2037 - 327ms/epoch - 82ms/step\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 249: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0669 - accuracy: 1.0000 - val_loss: 1.9261 - val_accuracy: 0.1667 - 328ms/epoch - 82ms/step\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 250: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0613 - accuracy: 1.0000 - val_loss: 1.9586 - val_accuracy: 0.1481 - 343ms/epoch - 86ms/step\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 251: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0630 - accuracy: 1.0000 - val_loss: 1.9315 - val_accuracy: 0.1667 - 329ms/epoch - 82ms/step\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 252: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0624 - accuracy: 1.0000 - val_loss: 1.9219 - val_accuracy: 0.1852 - 337ms/epoch - 84ms/step\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 253: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0584 - accuracy: 1.0000 - val_loss: 1.8919 - val_accuracy: 0.1852 - 342ms/epoch - 86ms/step\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 254: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0596 - accuracy: 1.0000 - val_loss: 1.9019 - val_accuracy: 0.2037 - 326ms/epoch - 82ms/step\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 255: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0610 - accuracy: 1.0000 - val_loss: 1.9283 - val_accuracy: 0.1667 - 326ms/epoch - 81ms/step\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 256: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0686 - accuracy: 1.0000 - val_loss: 1.9042 - val_accuracy: 0.2407 - 334ms/epoch - 83ms/step\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 257: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0663 - accuracy: 1.0000 - val_loss: 1.8963 - val_accuracy: 0.1852 - 339ms/epoch - 85ms/step\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 258: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0626 - accuracy: 1.0000 - val_loss: 1.9180 - val_accuracy: 0.1667 - 329ms/epoch - 82ms/step\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 259: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0582 - accuracy: 1.0000 - val_loss: 1.9594 - val_accuracy: 0.1852 - 329ms/epoch - 82ms/step\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 260: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0662 - accuracy: 1.0000 - val_loss: 1.9130 - val_accuracy: 0.2037 - 338ms/epoch - 85ms/step\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 261: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0596 - accuracy: 1.0000 - val_loss: 1.9194 - val_accuracy: 0.1852 - 338ms/epoch - 84ms/step\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 262: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0754 - accuracy: 1.0000 - val_loss: 1.9481 - val_accuracy: 0.1111 - 331ms/epoch - 83ms/step\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 263: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0664 - accuracy: 1.0000 - val_loss: 1.9336 - val_accuracy: 0.1296 - 326ms/epoch - 81ms/step\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 264: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0664 - accuracy: 1.0000 - val_loss: 1.9397 - val_accuracy: 0.1667 - 350ms/epoch - 88ms/step\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 265: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0680 - accuracy: 1.0000 - val_loss: 1.9457 - val_accuracy: 0.1481 - 327ms/epoch - 82ms/step\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 266: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0637 - accuracy: 1.0000 - val_loss: 1.9230 - val_accuracy: 0.2037 - 338ms/epoch - 84ms/step\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 267: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0622 - accuracy: 1.0000 - val_loss: 1.9465 - val_accuracy: 0.2037 - 326ms/epoch - 81ms/step\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 268: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0651 - accuracy: 1.0000 - val_loss: 2.0119 - val_accuracy: 0.1667 - 334ms/epoch - 84ms/step\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 269: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0601 - accuracy: 1.0000 - val_loss: 1.9532 - val_accuracy: 0.1852 - 348ms/epoch - 87ms/step\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 270: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0703 - accuracy: 1.0000 - val_loss: 1.9260 - val_accuracy: 0.1852 - 335ms/epoch - 84ms/step\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 271: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0604 - accuracy: 1.0000 - val_loss: 1.9860 - val_accuracy: 0.2037 - 340ms/epoch - 85ms/step\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 272: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0618 - accuracy: 1.0000 - val_loss: 2.0511 - val_accuracy: 0.1111 - 355ms/epoch - 89ms/step\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 273: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0608 - accuracy: 1.0000 - val_loss: 1.9982 - val_accuracy: 0.2037 - 336ms/epoch - 84ms/step\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 274: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0573 - accuracy: 1.0000 - val_loss: 1.9798 - val_accuracy: 0.1667 - 352ms/epoch - 88ms/step\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 275: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0671 - accuracy: 1.0000 - val_loss: 2.0694 - val_accuracy: 0.1852 - 334ms/epoch - 83ms/step\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 276: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0698 - accuracy: 1.0000 - val_loss: 2.0588 - val_accuracy: 0.1296 - 349ms/epoch - 87ms/step\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 277: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0548 - accuracy: 1.0000 - val_loss: 1.9675 - val_accuracy: 0.1852 - 333ms/epoch - 83ms/step\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 278: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0587 - accuracy: 1.0000 - val_loss: 1.9849 - val_accuracy: 0.2037 - 328ms/epoch - 82ms/step\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 279: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0636 - accuracy: 1.0000 - val_loss: 2.1685 - val_accuracy: 0.1852 - 333ms/epoch - 83ms/step\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 280: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0586 - accuracy: 1.0000 - val_loss: 2.0429 - val_accuracy: 0.1852 - 349ms/epoch - 87ms/step\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 281: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0582 - accuracy: 1.0000 - val_loss: 2.0370 - val_accuracy: 0.1667 - 326ms/epoch - 82ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 282/300\n",
      "\n",
      "Epoch 282: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0580 - accuracy: 1.0000 - val_loss: 2.0287 - val_accuracy: 0.1667 - 334ms/epoch - 84ms/step\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 283: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0535 - accuracy: 1.0000 - val_loss: 2.0132 - val_accuracy: 0.2037 - 338ms/epoch - 84ms/step\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 284: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0531 - accuracy: 1.0000 - val_loss: 2.0301 - val_accuracy: 0.2593 - 342ms/epoch - 86ms/step\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 285: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0581 - accuracy: 1.0000 - val_loss: 1.9397 - val_accuracy: 0.2222 - 342ms/epoch - 85ms/step\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 286: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0598 - accuracy: 1.0000 - val_loss: 1.9578 - val_accuracy: 0.2222 - 329ms/epoch - 82ms/step\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 287: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0602 - accuracy: 1.0000 - val_loss: 1.9258 - val_accuracy: 0.1852 - 336ms/epoch - 84ms/step\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 288: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0678 - accuracy: 1.0000 - val_loss: 1.9802 - val_accuracy: 0.2037 - 326ms/epoch - 82ms/step\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 289: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0588 - accuracy: 1.0000 - val_loss: 1.9927 - val_accuracy: 0.2037 - 330ms/epoch - 82ms/step\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 290: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0540 - accuracy: 1.0000 - val_loss: 2.0398 - val_accuracy: 0.1852 - 339ms/epoch - 85ms/step\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 291: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0522 - accuracy: 1.0000 - val_loss: 2.0364 - val_accuracy: 0.1481 - 340ms/epoch - 85ms/step\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 292: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0522 - accuracy: 1.0000 - val_loss: 2.0000 - val_accuracy: 0.1667 - 341ms/epoch - 85ms/step\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 293: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0508 - accuracy: 1.0000 - val_loss: 1.9967 - val_accuracy: 0.2037 - 325ms/epoch - 81ms/step\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 294: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0565 - accuracy: 1.0000 - val_loss: 1.9605 - val_accuracy: 0.2407 - 336ms/epoch - 84ms/step\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 295: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0556 - accuracy: 1.0000 - val_loss: 1.9779 - val_accuracy: 0.2222 - 342ms/epoch - 86ms/step\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 296: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0563 - accuracy: 1.0000 - val_loss: 1.9772 - val_accuracy: 0.1852 - 339ms/epoch - 85ms/step\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 297: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0686 - accuracy: 1.0000 - val_loss: 1.9829 - val_accuracy: 0.2037 - 333ms/epoch - 83ms/step\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 298: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0716 - accuracy: 1.0000 - val_loss: 2.0338 - val_accuracy: 0.2037 - 334ms/epoch - 84ms/step\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 299: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0557 - accuracy: 1.0000 - val_loss: 2.0192 - val_accuracy: 0.2222 - 325ms/epoch - 81ms/step\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 300: val_loss did not improve from 1.37672\n",
      "4/4 - 0s - loss: 0.0702 - accuracy: 0.9921 - val_loss: 2.0649 - val_accuracy: 0.1852 - 328ms/epoch - 82ms/step\n",
      "2/2 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2022-11-11 09:17:46.674101: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_8679266\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:570040\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 09:17:50.673905: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_8682336\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:570082\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38643, saving model to checkpoint1.h5\n",
      "4/4 - 5s - loss: 1.4776 - accuracy: 0.1508 - val_loss: 1.3864 - val_accuracy: 0.2407 - 5s/epoch - 1s/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 1.3461 - accuracy: 0.3571 - val_loss: 1.3868 - val_accuracy: 0.2407 - 329ms/epoch - 82ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 1.3054 - accuracy: 0.3968 - val_loss: 1.3872 - val_accuracy: 0.2407 - 333ms/epoch - 83ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 1.2799 - accuracy: 0.3968 - val_loss: 1.3874 - val_accuracy: 0.2407 - 337ms/epoch - 84ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 1.2270 - accuracy: 0.4365 - val_loss: 1.3874 - val_accuracy: 0.2407 - 330ms/epoch - 82ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 1.2047 - accuracy: 0.5079 - val_loss: 1.3875 - val_accuracy: 0.2407 - 334ms/epoch - 84ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 1.1928 - accuracy: 0.5794 - val_loss: 1.3879 - val_accuracy: 0.2407 - 322ms/epoch - 80ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 1.1469 - accuracy: 0.6111 - val_loss: 1.3885 - val_accuracy: 0.2407 - 331ms/epoch - 83ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 1.1367 - accuracy: 0.6587 - val_loss: 1.3891 - val_accuracy: 0.2222 - 321ms/epoch - 80ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 1.0982 - accuracy: 0.6349 - val_loss: 1.3892 - val_accuracy: 0.2963 - 331ms/epoch - 83ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 1.0730 - accuracy: 0.6587 - val_loss: 1.3897 - val_accuracy: 0.1852 - 333ms/epoch - 83ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 1.0383 - accuracy: 0.7222 - val_loss: 1.3895 - val_accuracy: 0.2037 - 329ms/epoch - 82ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 1.0333 - accuracy: 0.6905 - val_loss: 1.3896 - val_accuracy: 0.2222 - 321ms/epoch - 80ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 1.0146 - accuracy: 0.7302 - val_loss: 1.3901 - val_accuracy: 0.2222 - 330ms/epoch - 83ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.9816 - accuracy: 0.7143 - val_loss: 1.3905 - val_accuracy: 0.2037 - 342ms/epoch - 86ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 1.0007 - accuracy: 0.7381 - val_loss: 1.3906 - val_accuracy: 0.2407 - 322ms/epoch - 81ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.9628 - accuracy: 0.7540 - val_loss: 1.3907 - val_accuracy: 0.2778 - 343ms/epoch - 86ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.9292 - accuracy: 0.7857 - val_loss: 1.3905 - val_accuracy: 0.2593 - 333ms/epoch - 83ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.9136 - accuracy: 0.7778 - val_loss: 1.3906 - val_accuracy: 0.2593 - 344ms/epoch - 86ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.9105 - accuracy: 0.7460 - val_loss: 1.3912 - val_accuracy: 0.2778 - 345ms/epoch - 86ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.9274 - accuracy: 0.7619 - val_loss: 1.3906 - val_accuracy: 0.2778 - 325ms/epoch - 81ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.8880 - accuracy: 0.8016 - val_loss: 1.3912 - val_accuracy: 0.2222 - 335ms/epoch - 84ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.8705 - accuracy: 0.8254 - val_loss: 1.3919 - val_accuracy: 0.3148 - 330ms/epoch - 82ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.8714 - accuracy: 0.8413 - val_loss: 1.3920 - val_accuracy: 0.3148 - 329ms/epoch - 82ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.8478 - accuracy: 0.8413 - val_loss: 1.3910 - val_accuracy: 0.3148 - 330ms/epoch - 82ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.8487 - accuracy: 0.8571 - val_loss: 1.3907 - val_accuracy: 0.2778 - 322ms/epoch - 80ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.8290 - accuracy: 0.8492 - val_loss: 1.3963 - val_accuracy: 0.2593 - 331ms/epoch - 83ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.8231 - accuracy: 0.8254 - val_loss: 1.3934 - val_accuracy: 0.3333 - 336ms/epoch - 84ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.7865 - accuracy: 0.8810 - val_loss: 1.3900 - val_accuracy: 0.2778 - 337ms/epoch - 84ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.8150 - accuracy: 0.8730 - val_loss: 1.3960 - val_accuracy: 0.2963 - 341ms/epoch - 85ms/step\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.7773 - accuracy: 0.8968 - val_loss: 1.3976 - val_accuracy: 0.2963 - 322ms/epoch - 80ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.7622 - accuracy: 0.8889 - val_loss: 1.3968 - val_accuracy: 0.2963 - 332ms/epoch - 83ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.7319 - accuracy: 0.9206 - val_loss: 1.3971 - val_accuracy: 0.3333 - 337ms/epoch - 84ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.7292 - accuracy: 0.9365 - val_loss: 1.3947 - val_accuracy: 0.2778 - 335ms/epoch - 84ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.7206 - accuracy: 0.8889 - val_loss: 1.3982 - val_accuracy: 0.2778 - 332ms/epoch - 83ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.6982 - accuracy: 0.9206 - val_loss: 1.3999 - val_accuracy: 0.2963 - 332ms/epoch - 83ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.7224 - accuracy: 0.8571 - val_loss: 1.3998 - val_accuracy: 0.2963 - 343ms/epoch - 86ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.6791 - accuracy: 0.9286 - val_loss: 1.3985 - val_accuracy: 0.2963 - 320ms/epoch - 80ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.6590 - accuracy: 0.9127 - val_loss: 1.3980 - val_accuracy: 0.3333 - 322ms/epoch - 81ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.6585 - accuracy: 0.9127 - val_loss: 1.4013 - val_accuracy: 0.2778 - 343ms/epoch - 86ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.6294 - accuracy: 0.9762 - val_loss: 1.4067 - val_accuracy: 0.2963 - 340ms/epoch - 85ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.6432 - accuracy: 0.9365 - val_loss: 1.4093 - val_accuracy: 0.2963 - 334ms/epoch - 83ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.6292 - accuracy: 0.9127 - val_loss: 1.4100 - val_accuracy: 0.2778 - 324ms/epoch - 81ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.6025 - accuracy: 0.9444 - val_loss: 1.4123 - val_accuracy: 0.2963 - 337ms/epoch - 84ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.5834 - accuracy: 0.9683 - val_loss: 1.4155 - val_accuracy: 0.2778 - 351ms/epoch - 88ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.5672 - accuracy: 0.9841 - val_loss: 1.4274 - val_accuracy: 0.2778 - 324ms/epoch - 81ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.5862 - accuracy: 0.9524 - val_loss: 1.4231 - val_accuracy: 0.3333 - 327ms/epoch - 82ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.5505 - accuracy: 0.9683 - val_loss: 1.4172 - val_accuracy: 0.2778 - 323ms/epoch - 81ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.5504 - accuracy: 0.9841 - val_loss: 1.4225 - val_accuracy: 0.3333 - 326ms/epoch - 81ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.5642 - accuracy: 0.9603 - val_loss: 1.4478 - val_accuracy: 0.3333 - 327ms/epoch - 82ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.5515 - accuracy: 0.9841 - val_loss: 1.4176 - val_accuracy: 0.2778 - 346ms/epoch - 87ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.5169 - accuracy: 0.9921 - val_loss: 1.4379 - val_accuracy: 0.3148 - 321ms/epoch - 80ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.5459 - accuracy: 0.9603 - val_loss: 1.4405 - val_accuracy: 0.2963 - 336ms/epoch - 84ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.5477 - accuracy: 0.9444 - val_loss: 1.4143 - val_accuracy: 0.2778 - 335ms/epoch - 84ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.5425 - accuracy: 0.9365 - val_loss: 1.4729 - val_accuracy: 0.2593 - 349ms/epoch - 87ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.5262 - accuracy: 0.9524 - val_loss: 1.4322 - val_accuracy: 0.2778 - 340ms/epoch - 85ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.4918 - accuracy: 0.9683 - val_loss: 1.4717 - val_accuracy: 0.2778 - 331ms/epoch - 83ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.5069 - accuracy: 0.9683 - val_loss: 1.4391 - val_accuracy: 0.2963 - 332ms/epoch - 83ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.4532 - accuracy: 0.9921 - val_loss: 1.4549 - val_accuracy: 0.2963 - 343ms/epoch - 86ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.4657 - accuracy: 0.9841 - val_loss: 1.4540 - val_accuracy: 0.3333 - 345ms/epoch - 86ms/step\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.4469 - accuracy: 0.9921 - val_loss: 1.4159 - val_accuracy: 0.2963 - 324ms/epoch - 81ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.4475 - accuracy: 0.9921 - val_loss: 1.4776 - val_accuracy: 0.3148 - 335ms/epoch - 84ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.4368 - accuracy: 0.9683 - val_loss: 1.4299 - val_accuracy: 0.2778 - 348ms/epoch - 87ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3996 - accuracy: 0.9921 - val_loss: 1.4730 - val_accuracy: 0.2593 - 340ms/epoch - 85ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.4210 - accuracy: 0.9841 - val_loss: 1.4706 - val_accuracy: 0.2963 - 332ms/epoch - 83ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3939 - accuracy: 0.9841 - val_loss: 1.4348 - val_accuracy: 0.3148 - 339ms/epoch - 85ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.4298 - accuracy: 0.9762 - val_loss: 1.4805 - val_accuracy: 0.2778 - 338ms/epoch - 84ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.4202 - accuracy: 1.0000 - val_loss: 1.4270 - val_accuracy: 0.3148 - 342ms/epoch - 86ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.4140 - accuracy: 0.9762 - val_loss: 1.4915 - val_accuracy: 0.2593 - 328ms/epoch - 82ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.4037 - accuracy: 0.9921 - val_loss: 1.4284 - val_accuracy: 0.3333 - 327ms/epoch - 82ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3986 - accuracy: 0.9683 - val_loss: 1.4970 - val_accuracy: 0.2778 - 338ms/epoch - 84ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3926 - accuracy: 1.0000 - val_loss: 1.4325 - val_accuracy: 0.3148 - 330ms/epoch - 82ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3787 - accuracy: 0.9841 - val_loss: 1.4694 - val_accuracy: 0.2778 - 340ms/epoch - 85ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3693 - accuracy: 0.9921 - val_loss: 1.4775 - val_accuracy: 0.3148 - 339ms/epoch - 85ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3559 - accuracy: 1.0000 - val_loss: 1.4736 - val_accuracy: 0.3148 - 319ms/epoch - 80ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3195 - accuracy: 0.9921 - val_loss: 1.5353 - val_accuracy: 0.2963 - 323ms/epoch - 81ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3652 - accuracy: 1.0000 - val_loss: 1.4985 - val_accuracy: 0.3333 - 331ms/epoch - 83ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3419 - accuracy: 0.9841 - val_loss: 1.4561 - val_accuracy: 0.3333 - 337ms/epoch - 84ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3303 - accuracy: 0.9921 - val_loss: 1.4951 - val_accuracy: 0.2963 - 323ms/epoch - 81ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3422 - accuracy: 1.0000 - val_loss: 1.4691 - val_accuracy: 0.3333 - 327ms/epoch - 82ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3349 - accuracy: 1.0000 - val_loss: 1.5850 - val_accuracy: 0.2593 - 328ms/epoch - 82ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3291 - accuracy: 1.0000 - val_loss: 1.4449 - val_accuracy: 0.3519 - 327ms/epoch - 82ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3123 - accuracy: 1.0000 - val_loss: 1.5236 - val_accuracy: 0.2778 - 357ms/epoch - 89ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3232 - accuracy: 1.0000 - val_loss: 1.4677 - val_accuracy: 0.3333 - 333ms/epoch - 83ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3252 - accuracy: 1.0000 - val_loss: 1.5354 - val_accuracy: 0.2593 - 323ms/epoch - 81ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3636 - accuracy: 1.0000 - val_loss: 1.4714 - val_accuracy: 0.2778 - 332ms/epoch - 83ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3098 - accuracy: 1.0000 - val_loss: 1.5638 - val_accuracy: 0.2407 - 333ms/epoch - 83ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3129 - accuracy: 1.0000 - val_loss: 1.5060 - val_accuracy: 0.2778 - 330ms/epoch - 82ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3180 - accuracy: 1.0000 - val_loss: 1.6258 - val_accuracy: 0.3148 - 329ms/epoch - 82ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3346 - accuracy: 0.9921 - val_loss: 1.4294 - val_accuracy: 0.3148 - 325ms/epoch - 81ms/step\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3317 - accuracy: 1.0000 - val_loss: 1.6529 - val_accuracy: 0.2222 - 322ms/epoch - 81ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3090 - accuracy: 1.0000 - val_loss: 1.4301 - val_accuracy: 0.3704 - 333ms/epoch - 83ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2986 - accuracy: 0.9841 - val_loss: 1.5469 - val_accuracy: 0.2593 - 342ms/epoch - 85ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2988 - accuracy: 0.9841 - val_loss: 1.5894 - val_accuracy: 0.2778 - 339ms/epoch - 85ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2743 - accuracy: 1.0000 - val_loss: 1.4363 - val_accuracy: 0.3889 - 353ms/epoch - 88ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 1.38643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.2624 - accuracy: 1.0000 - val_loss: 1.6210 - val_accuracy: 0.2222 - 326ms/epoch - 82ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2732 - accuracy: 0.9841 - val_loss: 1.5993 - val_accuracy: 0.2037 - 348ms/epoch - 87ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2462 - accuracy: 1.0000 - val_loss: 1.5772 - val_accuracy: 0.2407 - 325ms/epoch - 81ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2534 - accuracy: 1.0000 - val_loss: 1.5437 - val_accuracy: 0.2407 - 334ms/epoch - 83ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2489 - accuracy: 1.0000 - val_loss: 1.5411 - val_accuracy: 0.2593 - 329ms/epoch - 82ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2604 - accuracy: 1.0000 - val_loss: 1.5819 - val_accuracy: 0.2593 - 331ms/epoch - 83ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2511 - accuracy: 0.9921 - val_loss: 1.4939 - val_accuracy: 0.2963 - 329ms/epoch - 82ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2034 - accuracy: 1.0000 - val_loss: 1.6107 - val_accuracy: 0.2407 - 338ms/epoch - 85ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2551 - accuracy: 1.0000 - val_loss: 1.5004 - val_accuracy: 0.2407 - 341ms/epoch - 85ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2431 - accuracy: 0.9841 - val_loss: 1.5453 - val_accuracy: 0.3148 - 338ms/epoch - 84ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 1.5901 - val_accuracy: 0.2593 - 324ms/epoch - 81ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2280 - accuracy: 1.0000 - val_loss: 1.5953 - val_accuracy: 0.2593 - 332ms/epoch - 83ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 1.7183 - val_accuracy: 0.2037 - 321ms/epoch - 80ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2271 - accuracy: 1.0000 - val_loss: 1.5289 - val_accuracy: 0.2963 - 338ms/epoch - 85ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2281 - accuracy: 1.0000 - val_loss: 1.5817 - val_accuracy: 0.2778 - 328ms/epoch - 82ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2244 - accuracy: 1.0000 - val_loss: 1.6199 - val_accuracy: 0.2407 - 329ms/epoch - 82ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 1.5279 - val_accuracy: 0.2778 - 333ms/epoch - 83ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2200 - accuracy: 1.0000 - val_loss: 1.5585 - val_accuracy: 0.2593 - 336ms/epoch - 84ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 1.5419 - val_accuracy: 0.2407 - 326ms/epoch - 81ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 1.6185 - val_accuracy: 0.2407 - 319ms/epoch - 80ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2002 - accuracy: 1.0000 - val_loss: 1.5939 - val_accuracy: 0.3333 - 321ms/epoch - 80ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1984 - accuracy: 1.0000 - val_loss: 1.6300 - val_accuracy: 0.3148 - 334ms/epoch - 83ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1857 - accuracy: 1.0000 - val_loss: 1.5888 - val_accuracy: 0.2593 - 342ms/epoch - 86ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 1.5236 - val_accuracy: 0.3333 - 344ms/epoch - 86ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2004 - accuracy: 1.0000 - val_loss: 1.5217 - val_accuracy: 0.2778 - 333ms/epoch - 83ms/step\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1933 - accuracy: 1.0000 - val_loss: 1.4472 - val_accuracy: 0.2778 - 335ms/epoch - 84ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2025 - accuracy: 1.0000 - val_loss: 1.4776 - val_accuracy: 0.2963 - 339ms/epoch - 85ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1723 - accuracy: 1.0000 - val_loss: 1.5555 - val_accuracy: 0.2593 - 329ms/epoch - 82ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2068 - accuracy: 1.0000 - val_loss: 1.5561 - val_accuracy: 0.2222 - 332ms/epoch - 83ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1874 - accuracy: 1.0000 - val_loss: 1.4704 - val_accuracy: 0.2963 - 328ms/epoch - 82ms/step\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1814 - accuracy: 1.0000 - val_loss: 1.5334 - val_accuracy: 0.2778 - 326ms/epoch - 81ms/step\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2024 - accuracy: 1.0000 - val_loss: 1.5728 - val_accuracy: 0.2778 - 324ms/epoch - 81ms/step\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1804 - accuracy: 1.0000 - val_loss: 1.6067 - val_accuracy: 0.2963 - 333ms/epoch - 83ms/step\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1618 - accuracy: 1.0000 - val_loss: 1.4814 - val_accuracy: 0.2963 - 326ms/epoch - 81ms/step\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1923 - accuracy: 1.0000 - val_loss: 1.4878 - val_accuracy: 0.2963 - 327ms/epoch - 82ms/step\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1903 - accuracy: 1.0000 - val_loss: 1.5983 - val_accuracy: 0.2593 - 334ms/epoch - 84ms/step\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1843 - accuracy: 1.0000 - val_loss: 1.5682 - val_accuracy: 0.2963 - 322ms/epoch - 80ms/step\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1764 - accuracy: 1.0000 - val_loss: 1.6797 - val_accuracy: 0.2407 - 335ms/epoch - 84ms/step\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1704 - accuracy: 1.0000 - val_loss: 1.5684 - val_accuracy: 0.2778 - 330ms/epoch - 82ms/step\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 135: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1462 - accuracy: 1.0000 - val_loss: 1.6396 - val_accuracy: 0.2963 - 340ms/epoch - 85ms/step\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 136: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1501 - accuracy: 1.0000 - val_loss: 1.5647 - val_accuracy: 0.2593 - 328ms/epoch - 82ms/step\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 137: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1732 - accuracy: 1.0000 - val_loss: 1.5011 - val_accuracy: 0.3148 - 341ms/epoch - 85ms/step\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 138: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1524 - accuracy: 1.0000 - val_loss: 1.4593 - val_accuracy: 0.3148 - 335ms/epoch - 84ms/step\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 139: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1568 - accuracy: 1.0000 - val_loss: 1.5730 - val_accuracy: 0.2778 - 339ms/epoch - 85ms/step\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 140: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1754 - accuracy: 1.0000 - val_loss: 1.5254 - val_accuracy: 0.2778 - 346ms/epoch - 86ms/step\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 141: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1657 - accuracy: 1.0000 - val_loss: 1.5555 - val_accuracy: 0.2963 - 330ms/epoch - 83ms/step\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 142: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1643 - accuracy: 1.0000 - val_loss: 1.6894 - val_accuracy: 0.2593 - 332ms/epoch - 83ms/step\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 143: val_loss did not improve from 1.38643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.1625 - accuracy: 1.0000 - val_loss: 1.6975 - val_accuracy: 0.3148 - 346ms/epoch - 87ms/step\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 144: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1595 - accuracy: 1.0000 - val_loss: 1.7882 - val_accuracy: 0.2407 - 327ms/epoch - 82ms/step\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 145: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1503 - accuracy: 1.0000 - val_loss: 1.6536 - val_accuracy: 0.2593 - 336ms/epoch - 84ms/step\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 146: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1548 - accuracy: 1.0000 - val_loss: 1.7611 - val_accuracy: 0.2407 - 322ms/epoch - 81ms/step\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 147: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1470 - accuracy: 1.0000 - val_loss: 1.6095 - val_accuracy: 0.2778 - 331ms/epoch - 83ms/step\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 148: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1464 - accuracy: 1.0000 - val_loss: 1.7221 - val_accuracy: 0.2222 - 331ms/epoch - 83ms/step\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 149: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1597 - accuracy: 1.0000 - val_loss: 1.5833 - val_accuracy: 0.2778 - 330ms/epoch - 83ms/step\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 150: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1615 - accuracy: 1.0000 - val_loss: 1.6201 - val_accuracy: 0.2963 - 322ms/epoch - 80ms/step\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 151: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1550 - accuracy: 1.0000 - val_loss: 1.6646 - val_accuracy: 0.2963 - 339ms/epoch - 85ms/step\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 152: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1581 - accuracy: 1.0000 - val_loss: 1.6770 - val_accuracy: 0.2778 - 320ms/epoch - 80ms/step\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 153: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1456 - accuracy: 1.0000 - val_loss: 1.6706 - val_accuracy: 0.3148 - 331ms/epoch - 83ms/step\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 154: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1410 - accuracy: 1.0000 - val_loss: 1.6247 - val_accuracy: 0.2593 - 325ms/epoch - 81ms/step\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 155: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1392 - accuracy: 1.0000 - val_loss: 1.5321 - val_accuracy: 0.2593 - 336ms/epoch - 84ms/step\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 156: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1220 - accuracy: 1.0000 - val_loss: 1.5139 - val_accuracy: 0.2778 - 324ms/epoch - 81ms/step\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 157: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1376 - accuracy: 1.0000 - val_loss: 1.6170 - val_accuracy: 0.2778 - 332ms/epoch - 83ms/step\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 158: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1254 - accuracy: 1.0000 - val_loss: 1.6445 - val_accuracy: 0.2593 - 326ms/epoch - 82ms/step\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 159: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1410 - accuracy: 1.0000 - val_loss: 1.6126 - val_accuracy: 0.3333 - 324ms/epoch - 81ms/step\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 160: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1310 - accuracy: 1.0000 - val_loss: 1.5227 - val_accuracy: 0.3148 - 328ms/epoch - 82ms/step\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 161: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1534 - accuracy: 1.0000 - val_loss: 1.5999 - val_accuracy: 0.2407 - 330ms/epoch - 83ms/step\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 162: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1367 - accuracy: 1.0000 - val_loss: 1.6354 - val_accuracy: 0.2963 - 331ms/epoch - 83ms/step\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 163: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1454 - accuracy: 1.0000 - val_loss: 1.6373 - val_accuracy: 0.2222 - 342ms/epoch - 85ms/step\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 164: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1330 - accuracy: 1.0000 - val_loss: 1.6486 - val_accuracy: 0.2778 - 330ms/epoch - 83ms/step\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 165: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1305 - accuracy: 1.0000 - val_loss: 1.5678 - val_accuracy: 0.2778 - 338ms/epoch - 84ms/step\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 166: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1403 - accuracy: 1.0000 - val_loss: 1.6185 - val_accuracy: 0.2963 - 318ms/epoch - 80ms/step\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 167: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1344 - accuracy: 1.0000 - val_loss: 1.6566 - val_accuracy: 0.2593 - 338ms/epoch - 84ms/step\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 168: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1549 - accuracy: 0.9921 - val_loss: 1.7237 - val_accuracy: 0.2037 - 324ms/epoch - 81ms/step\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 169: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1150 - accuracy: 1.0000 - val_loss: 1.7117 - val_accuracy: 0.2407 - 334ms/epoch - 84ms/step\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 170: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1342 - accuracy: 1.0000 - val_loss: 1.7219 - val_accuracy: 0.2778 - 333ms/epoch - 83ms/step\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 171: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1140 - accuracy: 1.0000 - val_loss: 1.7284 - val_accuracy: 0.2593 - 337ms/epoch - 84ms/step\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 172: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1237 - accuracy: 1.0000 - val_loss: 1.6644 - val_accuracy: 0.2778 - 325ms/epoch - 81ms/step\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 173: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1298 - accuracy: 1.0000 - val_loss: 1.6447 - val_accuracy: 0.2778 - 335ms/epoch - 84ms/step\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 174: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1378 - accuracy: 1.0000 - val_loss: 1.6799 - val_accuracy: 0.2222 - 336ms/epoch - 84ms/step\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 175: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1212 - accuracy: 1.0000 - val_loss: 1.6313 - val_accuracy: 0.2407 - 325ms/epoch - 81ms/step\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 176: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1356 - accuracy: 0.9921 - val_loss: 1.7406 - val_accuracy: 0.2963 - 332ms/epoch - 83ms/step\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 177: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1257 - accuracy: 1.0000 - val_loss: 1.6730 - val_accuracy: 0.2407 - 330ms/epoch - 82ms/step\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 178: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1224 - accuracy: 1.0000 - val_loss: 1.6121 - val_accuracy: 0.2963 - 333ms/epoch - 83ms/step\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 179: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1307 - accuracy: 1.0000 - val_loss: 1.6409 - val_accuracy: 0.2222 - 332ms/epoch - 83ms/step\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 180: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1122 - accuracy: 1.0000 - val_loss: 1.5952 - val_accuracy: 0.2778 - 329ms/epoch - 82ms/step\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 181: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1117 - accuracy: 1.0000 - val_loss: 1.6382 - val_accuracy: 0.2037 - 325ms/epoch - 81ms/step\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 182: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1220 - accuracy: 1.0000 - val_loss: 1.6036 - val_accuracy: 0.2593 - 322ms/epoch - 80ms/step\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 183: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1053 - accuracy: 1.0000 - val_loss: 1.7059 - val_accuracy: 0.2407 - 322ms/epoch - 81ms/step\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 184: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1128 - accuracy: 1.0000 - val_loss: 1.6546 - val_accuracy: 0.2222 - 330ms/epoch - 83ms/step\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 185: val_loss did not improve from 1.38643\n",
      "4/4 - 1s - loss: 0.0943 - accuracy: 1.0000 - val_loss: 1.6473 - val_accuracy: 0.2593 - 674ms/epoch - 168ms/step\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 186: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1022 - accuracy: 1.0000 - val_loss: 1.6246 - val_accuracy: 0.2778 - 333ms/epoch - 83ms/step\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 187: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1044 - accuracy: 1.0000 - val_loss: 1.5992 - val_accuracy: 0.2778 - 334ms/epoch - 83ms/step\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 188: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1038 - accuracy: 1.0000 - val_loss: 1.6258 - val_accuracy: 0.2778 - 341ms/epoch - 85ms/step\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 189: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1132 - accuracy: 1.0000 - val_loss: 1.6313 - val_accuracy: 0.2593 - 352ms/epoch - 88ms/step\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 190: val_loss did not improve from 1.38643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.1038 - accuracy: 1.0000 - val_loss: 1.6451 - val_accuracy: 0.2407 - 337ms/epoch - 84ms/step\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 191: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1001 - accuracy: 1.0000 - val_loss: 1.5657 - val_accuracy: 0.2593 - 352ms/epoch - 88ms/step\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 192: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1018 - accuracy: 1.0000 - val_loss: 1.5219 - val_accuracy: 0.3519 - 344ms/epoch - 86ms/step\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 193: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1046 - accuracy: 1.0000 - val_loss: 1.6538 - val_accuracy: 0.2407 - 343ms/epoch - 86ms/step\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 194: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1017 - accuracy: 1.0000 - val_loss: 1.5986 - val_accuracy: 0.2407 - 339ms/epoch - 85ms/step\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 195: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1101 - accuracy: 1.0000 - val_loss: 1.6946 - val_accuracy: 0.2222 - 335ms/epoch - 84ms/step\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 196: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1155 - accuracy: 1.0000 - val_loss: 1.6556 - val_accuracy: 0.2593 - 342ms/epoch - 85ms/step\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 197: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1013 - accuracy: 1.0000 - val_loss: 1.9009 - val_accuracy: 0.2407 - 359ms/epoch - 90ms/step\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 198: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1048 - accuracy: 1.0000 - val_loss: 1.8016 - val_accuracy: 0.2593 - 335ms/epoch - 84ms/step\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 199: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1205 - accuracy: 1.0000 - val_loss: 1.6990 - val_accuracy: 0.2407 - 346ms/epoch - 87ms/step\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 200: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1059 - accuracy: 1.0000 - val_loss: 1.6768 - val_accuracy: 0.2778 - 338ms/epoch - 85ms/step\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 201: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1059 - accuracy: 1.0000 - val_loss: 1.6635 - val_accuracy: 0.2407 - 336ms/epoch - 84ms/step\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 202: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1103 - accuracy: 1.0000 - val_loss: 1.6140 - val_accuracy: 0.2593 - 335ms/epoch - 84ms/step\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 203: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1069 - accuracy: 1.0000 - val_loss: 1.5866 - val_accuracy: 0.2963 - 346ms/epoch - 86ms/step\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 204: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0970 - accuracy: 1.0000 - val_loss: 1.7932 - val_accuracy: 0.2037 - 363ms/epoch - 91ms/step\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 205: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0933 - accuracy: 1.0000 - val_loss: 1.6664 - val_accuracy: 0.2593 - 349ms/epoch - 87ms/step\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 206: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0992 - accuracy: 1.0000 - val_loss: 1.6354 - val_accuracy: 0.2963 - 336ms/epoch - 84ms/step\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 207: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1092 - accuracy: 1.0000 - val_loss: 1.6647 - val_accuracy: 0.2037 - 334ms/epoch - 84ms/step\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 208: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0978 - accuracy: 1.0000 - val_loss: 1.6123 - val_accuracy: 0.2593 - 355ms/epoch - 89ms/step\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 209: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1031 - accuracy: 1.0000 - val_loss: 1.6507 - val_accuracy: 0.2963 - 340ms/epoch - 85ms/step\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 210: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1003 - accuracy: 1.0000 - val_loss: 1.6968 - val_accuracy: 0.2963 - 345ms/epoch - 86ms/step\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 211: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0953 - accuracy: 1.0000 - val_loss: 1.6613 - val_accuracy: 0.2593 - 352ms/epoch - 88ms/step\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 212: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0978 - accuracy: 0.9921 - val_loss: 1.6672 - val_accuracy: 0.2407 - 335ms/epoch - 84ms/step\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 213: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0924 - accuracy: 1.0000 - val_loss: 1.7042 - val_accuracy: 0.2778 - 346ms/epoch - 86ms/step\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 214: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0987 - accuracy: 1.0000 - val_loss: 1.6844 - val_accuracy: 0.2778 - 333ms/epoch - 83ms/step\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 215: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0966 - accuracy: 1.0000 - val_loss: 1.5496 - val_accuracy: 0.2778 - 342ms/epoch - 85ms/step\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 216: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0993 - accuracy: 1.0000 - val_loss: 1.6197 - val_accuracy: 0.2037 - 345ms/epoch - 86ms/step\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 217: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0943 - accuracy: 1.0000 - val_loss: 1.7567 - val_accuracy: 0.2407 - 343ms/epoch - 86ms/step\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 218: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0874 - accuracy: 1.0000 - val_loss: 1.6714 - val_accuracy: 0.2593 - 337ms/epoch - 84ms/step\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 219: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0835 - accuracy: 1.0000 - val_loss: 1.9061 - val_accuracy: 0.2037 - 341ms/epoch - 85ms/step\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 220: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0958 - accuracy: 1.0000 - val_loss: 1.7821 - val_accuracy: 0.2407 - 347ms/epoch - 87ms/step\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 221: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0889 - accuracy: 1.0000 - val_loss: 1.8646 - val_accuracy: 0.2407 - 350ms/epoch - 87ms/step\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 222: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1055 - accuracy: 1.0000 - val_loss: 1.7346 - val_accuracy: 0.2407 - 336ms/epoch - 84ms/step\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 223: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0857 - accuracy: 1.0000 - val_loss: 1.7232 - val_accuracy: 0.2222 - 334ms/epoch - 83ms/step\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 224: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1089 - accuracy: 1.0000 - val_loss: 1.6494 - val_accuracy: 0.2222 - 350ms/epoch - 87ms/step\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 225: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0899 - accuracy: 1.0000 - val_loss: 1.6575 - val_accuracy: 0.2037 - 340ms/epoch - 85ms/step\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 226: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0878 - accuracy: 1.0000 - val_loss: 1.6161 - val_accuracy: 0.2778 - 350ms/epoch - 88ms/step\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 227: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0915 - accuracy: 1.0000 - val_loss: 1.6824 - val_accuracy: 0.2593 - 342ms/epoch - 86ms/step\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 228: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0865 - accuracy: 1.0000 - val_loss: 1.7220 - val_accuracy: 0.2407 - 349ms/epoch - 87ms/step\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 229: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0841 - accuracy: 1.0000 - val_loss: 1.5013 - val_accuracy: 0.3148 - 343ms/epoch - 86ms/step\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 230: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0887 - accuracy: 1.0000 - val_loss: 1.6218 - val_accuracy: 0.3148 - 346ms/epoch - 87ms/step\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 231: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0986 - accuracy: 1.0000 - val_loss: 1.5133 - val_accuracy: 0.3333 - 344ms/epoch - 86ms/step\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 232: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0876 - accuracy: 1.0000 - val_loss: 1.6771 - val_accuracy: 0.2778 - 340ms/epoch - 85ms/step\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 233: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0869 - accuracy: 1.0000 - val_loss: 1.6706 - val_accuracy: 0.2778 - 350ms/epoch - 88ms/step\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 234: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0920 - accuracy: 0.9921 - val_loss: 1.7792 - val_accuracy: 0.2778 - 335ms/epoch - 84ms/step\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 235: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0818 - accuracy: 1.0000 - val_loss: 1.8010 - val_accuracy: 0.2593 - 334ms/epoch - 84ms/step\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 236: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0888 - accuracy: 1.0000 - val_loss: 1.8775 - val_accuracy: 0.2222 - 334ms/epoch - 83ms/step\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 237: val_loss did not improve from 1.38643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.0780 - accuracy: 1.0000 - val_loss: 1.8693 - val_accuracy: 0.2407 - 345ms/epoch - 86ms/step\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 238: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0876 - accuracy: 1.0000 - val_loss: 1.8736 - val_accuracy: 0.2407 - 337ms/epoch - 84ms/step\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 239: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0844 - accuracy: 1.0000 - val_loss: 1.8394 - val_accuracy: 0.2778 - 356ms/epoch - 89ms/step\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 240: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0768 - accuracy: 1.0000 - val_loss: 1.7654 - val_accuracy: 0.2963 - 335ms/epoch - 84ms/step\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 241: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0811 - accuracy: 1.0000 - val_loss: 1.6963 - val_accuracy: 0.2778 - 336ms/epoch - 84ms/step\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 242: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0728 - accuracy: 1.0000 - val_loss: 1.5941 - val_accuracy: 0.2593 - 332ms/epoch - 83ms/step\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 243: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0710 - accuracy: 1.0000 - val_loss: 1.6743 - val_accuracy: 0.2778 - 345ms/epoch - 86ms/step\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 244: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0732 - accuracy: 1.0000 - val_loss: 1.6525 - val_accuracy: 0.2593 - 370ms/epoch - 93ms/step\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 245: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0766 - accuracy: 1.0000 - val_loss: 1.6857 - val_accuracy: 0.2407 - 329ms/epoch - 82ms/step\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 246: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0646 - accuracy: 1.0000 - val_loss: 1.6176 - val_accuracy: 0.2778 - 330ms/epoch - 82ms/step\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 247: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0746 - accuracy: 1.0000 - val_loss: 1.5640 - val_accuracy: 0.2778 - 332ms/epoch - 83ms/step\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 248: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0816 - accuracy: 1.0000 - val_loss: 1.6510 - val_accuracy: 0.2222 - 334ms/epoch - 84ms/step\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 249: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0638 - accuracy: 1.0000 - val_loss: 1.6459 - val_accuracy: 0.2778 - 332ms/epoch - 83ms/step\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 250: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0647 - accuracy: 1.0000 - val_loss: 1.6539 - val_accuracy: 0.2407 - 350ms/epoch - 87ms/step\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 251: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0679 - accuracy: 1.0000 - val_loss: 1.5567 - val_accuracy: 0.2593 - 351ms/epoch - 88ms/step\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 252: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0647 - accuracy: 1.0000 - val_loss: 1.6938 - val_accuracy: 0.2593 - 346ms/epoch - 86ms/step\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 253: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0698 - accuracy: 1.0000 - val_loss: 1.7360 - val_accuracy: 0.2037 - 340ms/epoch - 85ms/step\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 254: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0855 - accuracy: 1.0000 - val_loss: 1.6468 - val_accuracy: 0.3148 - 359ms/epoch - 90ms/step\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 255: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0722 - accuracy: 1.0000 - val_loss: 1.5986 - val_accuracy: 0.3148 - 340ms/epoch - 85ms/step\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 256: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0740 - accuracy: 1.0000 - val_loss: 1.6814 - val_accuracy: 0.2407 - 336ms/epoch - 84ms/step\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 257: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0774 - accuracy: 1.0000 - val_loss: 1.6733 - val_accuracy: 0.2407 - 344ms/epoch - 86ms/step\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 258: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0573 - accuracy: 1.0000 - val_loss: 1.6898 - val_accuracy: 0.2407 - 341ms/epoch - 85ms/step\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 259: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0629 - accuracy: 1.0000 - val_loss: 1.7723 - val_accuracy: 0.2407 - 333ms/epoch - 83ms/step\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 260: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0710 - accuracy: 1.0000 - val_loss: 1.7563 - val_accuracy: 0.1852 - 353ms/epoch - 88ms/step\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 261: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0709 - accuracy: 1.0000 - val_loss: 1.6979 - val_accuracy: 0.2593 - 328ms/epoch - 82ms/step\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 262: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0625 - accuracy: 1.0000 - val_loss: 1.7497 - val_accuracy: 0.2963 - 338ms/epoch - 85ms/step\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 263: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0651 - accuracy: 1.0000 - val_loss: 1.7838 - val_accuracy: 0.2778 - 361ms/epoch - 90ms/step\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 264: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0686 - accuracy: 1.0000 - val_loss: 1.6622 - val_accuracy: 0.2222 - 333ms/epoch - 83ms/step\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 265: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0574 - accuracy: 1.0000 - val_loss: 1.6922 - val_accuracy: 0.2593 - 354ms/epoch - 89ms/step\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 266: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0580 - accuracy: 1.0000 - val_loss: 1.7265 - val_accuracy: 0.2037 - 348ms/epoch - 87ms/step\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 267: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0611 - accuracy: 1.0000 - val_loss: 1.7584 - val_accuracy: 0.2222 - 345ms/epoch - 86ms/step\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 268: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0669 - accuracy: 1.0000 - val_loss: 1.7196 - val_accuracy: 0.2963 - 340ms/epoch - 85ms/step\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 269: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0701 - accuracy: 1.0000 - val_loss: 1.7869 - val_accuracy: 0.2593 - 344ms/epoch - 86ms/step\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 270: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0698 - accuracy: 1.0000 - val_loss: 1.7441 - val_accuracy: 0.2593 - 331ms/epoch - 83ms/step\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 271: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0604 - accuracy: 1.0000 - val_loss: 1.7798 - val_accuracy: 0.2407 - 342ms/epoch - 85ms/step\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 272: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0799 - accuracy: 1.0000 - val_loss: 1.7294 - val_accuracy: 0.2593 - 339ms/epoch - 85ms/step\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 273: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0621 - accuracy: 1.0000 - val_loss: 1.8244 - val_accuracy: 0.2037 - 351ms/epoch - 88ms/step\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 274: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0681 - accuracy: 1.0000 - val_loss: 1.6645 - val_accuracy: 0.3148 - 343ms/epoch - 86ms/step\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 275: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0743 - accuracy: 1.0000 - val_loss: 1.6850 - val_accuracy: 0.3148 - 330ms/epoch - 82ms/step\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 276: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0686 - accuracy: 1.0000 - val_loss: 1.6471 - val_accuracy: 0.3148 - 362ms/epoch - 90ms/step\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 277: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0630 - accuracy: 1.0000 - val_loss: 1.6417 - val_accuracy: 0.2407 - 335ms/epoch - 84ms/step\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 278: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0659 - accuracy: 1.0000 - val_loss: 1.7113 - val_accuracy: 0.2593 - 338ms/epoch - 85ms/step\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 279: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0678 - accuracy: 1.0000 - val_loss: 1.7438 - val_accuracy: 0.2037 - 338ms/epoch - 84ms/step\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 280: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0698 - accuracy: 1.0000 - val_loss: 1.8498 - val_accuracy: 0.1852 - 353ms/epoch - 88ms/step\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 281: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0642 - accuracy: 1.0000 - val_loss: 1.7133 - val_accuracy: 0.2593 - 332ms/epoch - 83ms/step\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 282: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0526 - accuracy: 1.0000 - val_loss: 1.7002 - val_accuracy: 0.2407 - 364ms/epoch - 91ms/step\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 283: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0651 - accuracy: 1.0000 - val_loss: 1.7636 - val_accuracy: 0.2222 - 345ms/epoch - 86ms/step\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 284: val_loss did not improve from 1.38643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.0567 - accuracy: 1.0000 - val_loss: 1.7156 - val_accuracy: 0.2407 - 363ms/epoch - 91ms/step\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 285: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0756 - accuracy: 1.0000 - val_loss: 1.6625 - val_accuracy: 0.2778 - 337ms/epoch - 84ms/step\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 286: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0538 - accuracy: 1.0000 - val_loss: 1.6865 - val_accuracy: 0.1852 - 346ms/epoch - 87ms/step\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 287: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0543 - accuracy: 1.0000 - val_loss: 1.7757 - val_accuracy: 0.2222 - 346ms/epoch - 86ms/step\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 288: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0529 - accuracy: 1.0000 - val_loss: 1.6908 - val_accuracy: 0.2778 - 335ms/epoch - 84ms/step\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 289: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0574 - accuracy: 1.0000 - val_loss: 1.6859 - val_accuracy: 0.2593 - 352ms/epoch - 88ms/step\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 290: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0520 - accuracy: 1.0000 - val_loss: 1.7149 - val_accuracy: 0.2778 - 335ms/epoch - 84ms/step\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 291: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0513 - accuracy: 1.0000 - val_loss: 1.6933 - val_accuracy: 0.2407 - 334ms/epoch - 83ms/step\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 292: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0482 - accuracy: 1.0000 - val_loss: 1.7221 - val_accuracy: 0.2407 - 351ms/epoch - 88ms/step\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 293: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0665 - accuracy: 1.0000 - val_loss: 1.6220 - val_accuracy: 0.2778 - 337ms/epoch - 84ms/step\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 294: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0605 - accuracy: 1.0000 - val_loss: 1.8001 - val_accuracy: 0.2037 - 330ms/epoch - 82ms/step\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 295: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0620 - accuracy: 1.0000 - val_loss: 1.9717 - val_accuracy: 0.1667 - 343ms/epoch - 86ms/step\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 296: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0546 - accuracy: 1.0000 - val_loss: 1.8381 - val_accuracy: 0.2407 - 338ms/epoch - 85ms/step\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 297: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0563 - accuracy: 1.0000 - val_loss: 1.7562 - val_accuracy: 0.2222 - 336ms/epoch - 84ms/step\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 298: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0590 - accuracy: 1.0000 - val_loss: 1.7561 - val_accuracy: 0.2037 - 364ms/epoch - 91ms/step\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 299: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0588 - accuracy: 1.0000 - val_loss: 1.7817 - val_accuracy: 0.2407 - 337ms/epoch - 84ms/step\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 300: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0586 - accuracy: 1.0000 - val_loss: 1.7009 - val_accuracy: 0.2778 - 335ms/epoch - 84ms/step\n",
      "2/2 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2022-11-11 09:19:36.261428: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_8743574\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:574294\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 09:19:40.289847: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_8746644\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:574336\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38670, saving model to checkpoint1.h5\n",
      "4/4 - 5s - loss: 1.4128 - accuracy: 0.2460 - val_loss: 1.3867 - val_accuracy: 0.2407 - 5s/epoch - 1s/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 1.3211 - accuracy: 0.4048 - val_loss: 1.3874 - val_accuracy: 0.2407 - 328ms/epoch - 82ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 1.2804 - accuracy: 0.4524 - val_loss: 1.3882 - val_accuracy: 0.2407 - 323ms/epoch - 81ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 1.2645 - accuracy: 0.5079 - val_loss: 1.3887 - val_accuracy: 0.2407 - 330ms/epoch - 83ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 1.2286 - accuracy: 0.4921 - val_loss: 1.3894 - val_accuracy: 0.2407 - 334ms/epoch - 83ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 1.2025 - accuracy: 0.5397 - val_loss: 1.3897 - val_accuracy: 0.2407 - 333ms/epoch - 83ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 1.1740 - accuracy: 0.6111 - val_loss: 1.3899 - val_accuracy: 0.2407 - 328ms/epoch - 82ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 1.1226 - accuracy: 0.6190 - val_loss: 1.3902 - val_accuracy: 0.2407 - 332ms/epoch - 83ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 1.0987 - accuracy: 0.6429 - val_loss: 1.3909 - val_accuracy: 0.2407 - 319ms/epoch - 80ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 1.0843 - accuracy: 0.6429 - val_loss: 1.3914 - val_accuracy: 0.2407 - 324ms/epoch - 81ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 1.0383 - accuracy: 0.7222 - val_loss: 1.3906 - val_accuracy: 0.2407 - 326ms/epoch - 81ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 1.0402 - accuracy: 0.6667 - val_loss: 1.3905 - val_accuracy: 0.2407 - 322ms/epoch - 81ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 1.0127 - accuracy: 0.7063 - val_loss: 1.3916 - val_accuracy: 0.2407 - 330ms/epoch - 83ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.9927 - accuracy: 0.7063 - val_loss: 1.3928 - val_accuracy: 0.2407 - 329ms/epoch - 82ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.9546 - accuracy: 0.7619 - val_loss: 1.3932 - val_accuracy: 0.2407 - 331ms/epoch - 83ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.9621 - accuracy: 0.7619 - val_loss: 1.3932 - val_accuracy: 0.2407 - 327ms/epoch - 82ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.9549 - accuracy: 0.7698 - val_loss: 1.3946 - val_accuracy: 0.2407 - 354ms/epoch - 88ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.9143 - accuracy: 0.7937 - val_loss: 1.3954 - val_accuracy: 0.2407 - 326ms/epoch - 81ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.9119 - accuracy: 0.7857 - val_loss: 1.3948 - val_accuracy: 0.2407 - 326ms/epoch - 82ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.8823 - accuracy: 0.8333 - val_loss: 1.3962 - val_accuracy: 0.2407 - 336ms/epoch - 84ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.8773 - accuracy: 0.8492 - val_loss: 1.3988 - val_accuracy: 0.2407 - 328ms/epoch - 82ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.8838 - accuracy: 0.8016 - val_loss: 1.3988 - val_accuracy: 0.2407 - 319ms/epoch - 80ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.8643 - accuracy: 0.7937 - val_loss: 1.3987 - val_accuracy: 0.2407 - 328ms/epoch - 82ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.8317 - accuracy: 0.8095 - val_loss: 1.4015 - val_accuracy: 0.2407 - 335ms/epoch - 84ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.8559 - accuracy: 0.8254 - val_loss: 1.4012 - val_accuracy: 0.2407 - 330ms/epoch - 82ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.8299 - accuracy: 0.8333 - val_loss: 1.4009 - val_accuracy: 0.2407 - 325ms/epoch - 81ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.8244 - accuracy: 0.8175 - val_loss: 1.4060 - val_accuracy: 0.2407 - 333ms/epoch - 83ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.7989 - accuracy: 0.8492 - val_loss: 1.4048 - val_accuracy: 0.2407 - 323ms/epoch - 81ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.8033 - accuracy: 0.8413 - val_loss: 1.4043 - val_accuracy: 0.2407 - 359ms/epoch - 90ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.7440 - accuracy: 0.8730 - val_loss: 1.4069 - val_accuracy: 0.2407 - 329ms/epoch - 82ms/step\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.7506 - accuracy: 0.8651 - val_loss: 1.4038 - val_accuracy: 0.2407 - 336ms/epoch - 84ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.7239 - accuracy: 0.8889 - val_loss: 1.4080 - val_accuracy: 0.2407 - 331ms/epoch - 83ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.7243 - accuracy: 0.8968 - val_loss: 1.4074 - val_accuracy: 0.2407 - 340ms/epoch - 85ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.6991 - accuracy: 0.9206 - val_loss: 1.4090 - val_accuracy: 0.2407 - 316ms/epoch - 79ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.7060 - accuracy: 0.9048 - val_loss: 1.4069 - val_accuracy: 0.2407 - 343ms/epoch - 86ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.7172 - accuracy: 0.9048 - val_loss: 1.4058 - val_accuracy: 0.2407 - 333ms/epoch - 83ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.6585 - accuracy: 0.9444 - val_loss: 1.4157 - val_accuracy: 0.2407 - 326ms/epoch - 81ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.6394 - accuracy: 0.9127 - val_loss: 1.4150 - val_accuracy: 0.2407 - 332ms/epoch - 83ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.6386 - accuracy: 0.9444 - val_loss: 1.4088 - val_accuracy: 0.2407 - 325ms/epoch - 81ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.6217 - accuracy: 0.9127 - val_loss: 1.4139 - val_accuracy: 0.2407 - 334ms/epoch - 83ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.6275 - accuracy: 0.9603 - val_loss: 1.4142 - val_accuracy: 0.2407 - 330ms/epoch - 82ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.5762 - accuracy: 0.9841 - val_loss: 1.4090 - val_accuracy: 0.2407 - 329ms/epoch - 82ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.6228 - accuracy: 0.9524 - val_loss: 1.4265 - val_accuracy: 0.2407 - 325ms/epoch - 81ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.5675 - accuracy: 0.9762 - val_loss: 1.4239 - val_accuracy: 0.2407 - 345ms/epoch - 86ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.5549 - accuracy: 0.9444 - val_loss: 1.4325 - val_accuracy: 0.2407 - 323ms/epoch - 81ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.5379 - accuracy: 0.9762 - val_loss: 1.4017 - val_accuracy: 0.2407 - 323ms/epoch - 81ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.5274 - accuracy: 0.9524 - val_loss: 1.4423 - val_accuracy: 0.2037 - 340ms/epoch - 85ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.5085 - accuracy: 0.9683 - val_loss: 1.4165 - val_accuracy: 0.2407 - 324ms/epoch - 81ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.5091 - accuracy: 0.9683 - val_loss: 1.4280 - val_accuracy: 0.2222 - 324ms/epoch - 81ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.4994 - accuracy: 0.9603 - val_loss: 1.4232 - val_accuracy: 0.2407 - 331ms/epoch - 83ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.5085 - accuracy: 0.9762 - val_loss: 1.4450 - val_accuracy: 0.2037 - 324ms/epoch - 81ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.4897 - accuracy: 0.9683 - val_loss: 1.4194 - val_accuracy: 0.2222 - 335ms/epoch - 84ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.4556 - accuracy: 0.9841 - val_loss: 1.4303 - val_accuracy: 0.2222 - 327ms/epoch - 82ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.4683 - accuracy: 0.9841 - val_loss: 1.4390 - val_accuracy: 0.2407 - 327ms/epoch - 82ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.4626 - accuracy: 0.9921 - val_loss: 1.4253 - val_accuracy: 0.2407 - 322ms/epoch - 80ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.4529 - accuracy: 0.9841 - val_loss: 1.4191 - val_accuracy: 0.1852 - 337ms/epoch - 84ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.4364 - accuracy: 0.9921 - val_loss: 1.4358 - val_accuracy: 0.2407 - 332ms/epoch - 83ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.4335 - accuracy: 0.9762 - val_loss: 1.4379 - val_accuracy: 0.2222 - 331ms/epoch - 83ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.4366 - accuracy: 0.9841 - val_loss: 1.4328 - val_accuracy: 0.2222 - 342ms/epoch - 85ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.4148 - accuracy: 0.9921 - val_loss: 1.4265 - val_accuracy: 0.2222 - 333ms/epoch - 83ms/step\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.4093 - accuracy: 0.9921 - val_loss: 1.4493 - val_accuracy: 0.2407 - 324ms/epoch - 81ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.3881 - accuracy: 1.0000 - val_loss: 1.4198 - val_accuracy: 0.2407 - 325ms/epoch - 81ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.3922 - accuracy: 0.9921 - val_loss: 1.4159 - val_accuracy: 0.2222 - 333ms/epoch - 83ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.3796 - accuracy: 0.9921 - val_loss: 1.4562 - val_accuracy: 0.2593 - 339ms/epoch - 85ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.3682 - accuracy: 0.9921 - val_loss: 1.4406 - val_accuracy: 0.2222 - 349ms/epoch - 87ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.3779 - accuracy: 0.9841 - val_loss: 1.4456 - val_accuracy: 0.2593 - 330ms/epoch - 83ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.3738 - accuracy: 0.9762 - val_loss: 1.4271 - val_accuracy: 0.2407 - 333ms/epoch - 83ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.3488 - accuracy: 0.9921 - val_loss: 1.4430 - val_accuracy: 0.2593 - 329ms/epoch - 82ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.3494 - accuracy: 0.9921 - val_loss: 1.4277 - val_accuracy: 0.2222 - 325ms/epoch - 81ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.3623 - accuracy: 1.0000 - val_loss: 1.4218 - val_accuracy: 0.2778 - 331ms/epoch - 83ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.3192 - accuracy: 1.0000 - val_loss: 1.4553 - val_accuracy: 0.2593 - 332ms/epoch - 83ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.3440 - accuracy: 0.9841 - val_loss: 1.4032 - val_accuracy: 0.2593 - 333ms/epoch - 83ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.3068 - accuracy: 1.0000 - val_loss: 1.4420 - val_accuracy: 0.2778 - 326ms/epoch - 82ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.2926 - accuracy: 1.0000 - val_loss: 1.4144 - val_accuracy: 0.2593 - 323ms/epoch - 81ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.3343 - accuracy: 0.9921 - val_loss: 1.4245 - val_accuracy: 0.2593 - 333ms/epoch - 83ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.3528 - accuracy: 1.0000 - val_loss: 1.4409 - val_accuracy: 0.2593 - 324ms/epoch - 81ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.3169 - accuracy: 0.9921 - val_loss: 1.4778 - val_accuracy: 0.2037 - 327ms/epoch - 82ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.3124 - accuracy: 1.0000 - val_loss: 1.3944 - val_accuracy: 0.3333 - 335ms/epoch - 84ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.2972 - accuracy: 1.0000 - val_loss: 1.4774 - val_accuracy: 0.2963 - 330ms/epoch - 82ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.3023 - accuracy: 0.9921 - val_loss: 1.4285 - val_accuracy: 0.2963 - 324ms/epoch - 81ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.2885 - accuracy: 1.0000 - val_loss: 1.4971 - val_accuracy: 0.2778 - 323ms/epoch - 81ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.2932 - accuracy: 0.9841 - val_loss: 1.4156 - val_accuracy: 0.2778 - 324ms/epoch - 81ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.2811 - accuracy: 1.0000 - val_loss: 1.4708 - val_accuracy: 0.2593 - 337ms/epoch - 84ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.2924 - accuracy: 1.0000 - val_loss: 1.4602 - val_accuracy: 0.2407 - 337ms/epoch - 84ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.2795 - accuracy: 1.0000 - val_loss: 1.4316 - val_accuracy: 0.2963 - 333ms/epoch - 83ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.2555 - accuracy: 1.0000 - val_loss: 1.4320 - val_accuracy: 0.2778 - 336ms/epoch - 84ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.2682 - accuracy: 1.0000 - val_loss: 1.4336 - val_accuracy: 0.2407 - 344ms/epoch - 86ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.2486 - accuracy: 1.0000 - val_loss: 1.4287 - val_accuracy: 0.2778 - 324ms/epoch - 81ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.2856 - accuracy: 0.9921 - val_loss: 1.4514 - val_accuracy: 0.2778 - 330ms/epoch - 82ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.2717 - accuracy: 0.9921 - val_loss: 1.4332 - val_accuracy: 0.2593 - 330ms/epoch - 83ms/step\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.2478 - accuracy: 0.9841 - val_loss: 1.4605 - val_accuracy: 0.2778 - 331ms/epoch - 83ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.2481 - accuracy: 1.0000 - val_loss: 1.4288 - val_accuracy: 0.2778 - 326ms/epoch - 81ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.2273 - accuracy: 1.0000 - val_loss: 1.4649 - val_accuracy: 0.2963 - 334ms/epoch - 83ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.2381 - accuracy: 1.0000 - val_loss: 1.4604 - val_accuracy: 0.2593 - 321ms/epoch - 80ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.2479 - accuracy: 0.9921 - val_loss: 1.4808 - val_accuracy: 0.2963 - 330ms/epoch - 83ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 1.38670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.2559 - accuracy: 1.0000 - val_loss: 1.4484 - val_accuracy: 0.2778 - 330ms/epoch - 83ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.2337 - accuracy: 0.9921 - val_loss: 1.4862 - val_accuracy: 0.2593 - 349ms/epoch - 87ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.2312 - accuracy: 1.0000 - val_loss: 1.4592 - val_accuracy: 0.3148 - 338ms/epoch - 84ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.2290 - accuracy: 1.0000 - val_loss: 1.4459 - val_accuracy: 0.2963 - 333ms/epoch - 83ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.2252 - accuracy: 1.0000 - val_loss: 1.4164 - val_accuracy: 0.2778 - 326ms/epoch - 82ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.2249 - accuracy: 1.0000 - val_loss: 1.4757 - val_accuracy: 0.3333 - 331ms/epoch - 83ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.2314 - accuracy: 1.0000 - val_loss: 1.4212 - val_accuracy: 0.3889 - 330ms/epoch - 82ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.2285 - accuracy: 1.0000 - val_loss: 1.5334 - val_accuracy: 0.3148 - 331ms/epoch - 83ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1961 - accuracy: 1.0000 - val_loss: 1.4421 - val_accuracy: 0.3333 - 342ms/epoch - 86ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.2340 - accuracy: 1.0000 - val_loss: 1.4565 - val_accuracy: 0.3333 - 340ms/epoch - 85ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.2021 - accuracy: 1.0000 - val_loss: 1.5441 - val_accuracy: 0.3148 - 331ms/epoch - 83ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 1.4524 - val_accuracy: 0.2963 - 337ms/epoch - 84ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.2041 - accuracy: 1.0000 - val_loss: 1.5625 - val_accuracy: 0.2593 - 363ms/epoch - 91ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.2019 - accuracy: 0.9921 - val_loss: 1.5082 - val_accuracy: 0.2963 - 343ms/epoch - 86ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.2054 - accuracy: 1.0000 - val_loss: 1.4410 - val_accuracy: 0.3148 - 340ms/epoch - 85ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1948 - accuracy: 1.0000 - val_loss: 1.5578 - val_accuracy: 0.2778 - 324ms/epoch - 81ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1963 - accuracy: 1.0000 - val_loss: 1.4308 - val_accuracy: 0.3333 - 339ms/epoch - 85ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.2035 - accuracy: 1.0000 - val_loss: 1.6157 - val_accuracy: 0.3148 - 329ms/epoch - 82ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1963 - accuracy: 1.0000 - val_loss: 1.4445 - val_accuracy: 0.3148 - 334ms/epoch - 84ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.2078 - accuracy: 1.0000 - val_loss: 1.6122 - val_accuracy: 0.3148 - 325ms/epoch - 81ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.2108 - accuracy: 0.9921 - val_loss: 1.5815 - val_accuracy: 0.2593 - 324ms/epoch - 81ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.2024 - accuracy: 1.0000 - val_loss: 1.5474 - val_accuracy: 0.3333 - 335ms/epoch - 84ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1836 - accuracy: 1.0000 - val_loss: 1.6077 - val_accuracy: 0.2963 - 335ms/epoch - 84ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1980 - accuracy: 1.0000 - val_loss: 1.5938 - val_accuracy: 0.3519 - 327ms/epoch - 82ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1768 - accuracy: 1.0000 - val_loss: 1.5544 - val_accuracy: 0.2963 - 357ms/epoch - 89ms/step\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1688 - accuracy: 1.0000 - val_loss: 1.5708 - val_accuracy: 0.3333 - 332ms/epoch - 83ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1636 - accuracy: 1.0000 - val_loss: 1.5305 - val_accuracy: 0.3333 - 338ms/epoch - 84ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1790 - accuracy: 1.0000 - val_loss: 1.5290 - val_accuracy: 0.3148 - 340ms/epoch - 85ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1590 - accuracy: 1.0000 - val_loss: 1.5512 - val_accuracy: 0.3148 - 336ms/epoch - 84ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1680 - accuracy: 1.0000 - val_loss: 1.5170 - val_accuracy: 0.3333 - 340ms/epoch - 85ms/step\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1593 - accuracy: 1.0000 - val_loss: 1.6785 - val_accuracy: 0.3333 - 325ms/epoch - 81ms/step\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1610 - accuracy: 1.0000 - val_loss: 1.5669 - val_accuracy: 0.3519 - 341ms/epoch - 85ms/step\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1558 - accuracy: 1.0000 - val_loss: 1.6928 - val_accuracy: 0.2963 - 331ms/epoch - 83ms/step\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1602 - accuracy: 1.0000 - val_loss: 1.6040 - val_accuracy: 0.3333 - 326ms/epoch - 82ms/step\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1601 - accuracy: 1.0000 - val_loss: 1.5767 - val_accuracy: 0.3333 - 323ms/epoch - 81ms/step\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1517 - accuracy: 1.0000 - val_loss: 1.5344 - val_accuracy: 0.3704 - 335ms/epoch - 84ms/step\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1575 - accuracy: 1.0000 - val_loss: 1.6910 - val_accuracy: 0.3333 - 333ms/epoch - 83ms/step\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1572 - accuracy: 1.0000 - val_loss: 1.5967 - val_accuracy: 0.3519 - 324ms/epoch - 81ms/step\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1641 - accuracy: 1.0000 - val_loss: 1.8023 - val_accuracy: 0.3148 - 333ms/epoch - 83ms/step\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 135: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1654 - accuracy: 1.0000 - val_loss: 1.6427 - val_accuracy: 0.3333 - 328ms/epoch - 82ms/step\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 136: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1409 - accuracy: 1.0000 - val_loss: 1.7970 - val_accuracy: 0.3333 - 332ms/epoch - 83ms/step\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 137: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1645 - accuracy: 1.0000 - val_loss: 1.5796 - val_accuracy: 0.3333 - 341ms/epoch - 85ms/step\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 138: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1601 - accuracy: 1.0000 - val_loss: 1.7473 - val_accuracy: 0.3519 - 334ms/epoch - 84ms/step\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 139: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1525 - accuracy: 1.0000 - val_loss: 1.5723 - val_accuracy: 0.2963 - 325ms/epoch - 81ms/step\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 140: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1462 - accuracy: 1.0000 - val_loss: 1.6004 - val_accuracy: 0.3148 - 334ms/epoch - 83ms/step\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 141: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1479 - accuracy: 1.0000 - val_loss: 1.6365 - val_accuracy: 0.3704 - 326ms/epoch - 82ms/step\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 142: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1271 - accuracy: 1.0000 - val_loss: 1.6270 - val_accuracy: 0.3519 - 329ms/epoch - 82ms/step\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 143: val_loss did not improve from 1.38670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.1503 - accuracy: 1.0000 - val_loss: 1.6089 - val_accuracy: 0.2963 - 340ms/epoch - 85ms/step\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 144: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1386 - accuracy: 1.0000 - val_loss: 1.5379 - val_accuracy: 0.3704 - 324ms/epoch - 81ms/step\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 145: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1268 - accuracy: 1.0000 - val_loss: 1.5900 - val_accuracy: 0.3519 - 339ms/epoch - 85ms/step\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 146: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1318 - accuracy: 1.0000 - val_loss: 1.6352 - val_accuracy: 0.3519 - 332ms/epoch - 83ms/step\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 147: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1275 - accuracy: 1.0000 - val_loss: 1.5712 - val_accuracy: 0.3704 - 334ms/epoch - 83ms/step\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 148: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1234 - accuracy: 1.0000 - val_loss: 1.5834 - val_accuracy: 0.3704 - 323ms/epoch - 81ms/step\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 149: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1293 - accuracy: 1.0000 - val_loss: 1.6310 - val_accuracy: 0.3148 - 335ms/epoch - 84ms/step\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 150: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1190 - accuracy: 1.0000 - val_loss: 1.5407 - val_accuracy: 0.3519 - 330ms/epoch - 83ms/step\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 151: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1254 - accuracy: 1.0000 - val_loss: 1.5435 - val_accuracy: 0.3333 - 331ms/epoch - 83ms/step\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 152: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1200 - accuracy: 1.0000 - val_loss: 1.5804 - val_accuracy: 0.2778 - 325ms/epoch - 81ms/step\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 153: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1265 - accuracy: 1.0000 - val_loss: 1.6117 - val_accuracy: 0.3148 - 321ms/epoch - 80ms/step\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 154: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1259 - accuracy: 1.0000 - val_loss: 1.6258 - val_accuracy: 0.3889 - 326ms/epoch - 82ms/step\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 155: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1271 - accuracy: 1.0000 - val_loss: 1.5821 - val_accuracy: 0.3148 - 327ms/epoch - 82ms/step\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 156: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1251 - accuracy: 1.0000 - val_loss: 1.4817 - val_accuracy: 0.4074 - 327ms/epoch - 82ms/step\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 157: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1170 - accuracy: 1.0000 - val_loss: 1.5235 - val_accuracy: 0.3704 - 329ms/epoch - 82ms/step\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 158: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1297 - accuracy: 1.0000 - val_loss: 1.6119 - val_accuracy: 0.3519 - 323ms/epoch - 81ms/step\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 159: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1197 - accuracy: 1.0000 - val_loss: 1.6914 - val_accuracy: 0.3148 - 319ms/epoch - 80ms/step\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 160: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1166 - accuracy: 1.0000 - val_loss: 1.7039 - val_accuracy: 0.3519 - 332ms/epoch - 83ms/step\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 161: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1113 - accuracy: 1.0000 - val_loss: 1.5572 - val_accuracy: 0.3704 - 339ms/epoch - 85ms/step\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 162: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1329 - accuracy: 1.0000 - val_loss: 1.6319 - val_accuracy: 0.3519 - 327ms/epoch - 82ms/step\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 163: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1131 - accuracy: 1.0000 - val_loss: 1.6078 - val_accuracy: 0.3333 - 340ms/epoch - 85ms/step\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 164: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1221 - accuracy: 1.0000 - val_loss: 1.6552 - val_accuracy: 0.3148 - 321ms/epoch - 80ms/step\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 165: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1095 - accuracy: 1.0000 - val_loss: 1.6608 - val_accuracy: 0.3519 - 333ms/epoch - 83ms/step\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 166: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0995 - accuracy: 1.0000 - val_loss: 1.5246 - val_accuracy: 0.3333 - 318ms/epoch - 80ms/step\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 167: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1079 - accuracy: 1.0000 - val_loss: 1.5179 - val_accuracy: 0.3519 - 329ms/epoch - 82ms/step\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 168: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1256 - accuracy: 1.0000 - val_loss: 1.5839 - val_accuracy: 0.3704 - 325ms/epoch - 81ms/step\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 169: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1102 - accuracy: 1.0000 - val_loss: 1.5101 - val_accuracy: 0.3889 - 333ms/epoch - 83ms/step\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 170: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1109 - accuracy: 1.0000 - val_loss: 1.5220 - val_accuracy: 0.3519 - 336ms/epoch - 84ms/step\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 171: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1150 - accuracy: 1.0000 - val_loss: 1.6175 - val_accuracy: 0.3889 - 334ms/epoch - 84ms/step\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 172: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1022 - accuracy: 1.0000 - val_loss: 1.6338 - val_accuracy: 0.3148 - 327ms/epoch - 82ms/step\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 173: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1148 - accuracy: 1.0000 - val_loss: 1.5666 - val_accuracy: 0.3519 - 332ms/epoch - 83ms/step\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 174: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1112 - accuracy: 1.0000 - val_loss: 1.5866 - val_accuracy: 0.3519 - 335ms/epoch - 84ms/step\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 175: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1022 - accuracy: 1.0000 - val_loss: 1.4970 - val_accuracy: 0.4444 - 339ms/epoch - 85ms/step\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 176: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0996 - accuracy: 1.0000 - val_loss: 1.5215 - val_accuracy: 0.4444 - 324ms/epoch - 81ms/step\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 177: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0964 - accuracy: 1.0000 - val_loss: 1.6020 - val_accuracy: 0.3889 - 334ms/epoch - 83ms/step\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 178: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1259 - accuracy: 1.0000 - val_loss: 1.5321 - val_accuracy: 0.3519 - 327ms/epoch - 82ms/step\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 179: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1117 - accuracy: 1.0000 - val_loss: 1.6048 - val_accuracy: 0.2963 - 353ms/epoch - 88ms/step\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 180: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0904 - accuracy: 1.0000 - val_loss: 1.6153 - val_accuracy: 0.3889 - 317ms/epoch - 79ms/step\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 181: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1077 - accuracy: 1.0000 - val_loss: 1.6280 - val_accuracy: 0.3333 - 333ms/epoch - 83ms/step\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 182: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0886 - accuracy: 1.0000 - val_loss: 1.5761 - val_accuracy: 0.3519 - 342ms/epoch - 86ms/step\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 183: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0849 - accuracy: 1.0000 - val_loss: 1.5941 - val_accuracy: 0.3889 - 334ms/epoch - 83ms/step\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 184: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1127 - accuracy: 1.0000 - val_loss: 1.5618 - val_accuracy: 0.4259 - 334ms/epoch - 83ms/step\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 185: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0929 - accuracy: 1.0000 - val_loss: 1.5327 - val_accuracy: 0.4074 - 327ms/epoch - 82ms/step\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 186: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0916 - accuracy: 1.0000 - val_loss: 1.6309 - val_accuracy: 0.2963 - 346ms/epoch - 86ms/step\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 187: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1078 - accuracy: 1.0000 - val_loss: 1.6079 - val_accuracy: 0.3333 - 322ms/epoch - 81ms/step\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 188: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1045 - accuracy: 1.0000 - val_loss: 1.6711 - val_accuracy: 0.3519 - 341ms/epoch - 85ms/step\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 189: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1013 - accuracy: 1.0000 - val_loss: 1.5660 - val_accuracy: 0.4074 - 322ms/epoch - 80ms/step\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 190: val_loss did not improve from 1.38670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.1095 - accuracy: 1.0000 - val_loss: 1.6052 - val_accuracy: 0.3333 - 331ms/epoch - 83ms/step\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 191: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.1126 - accuracy: 1.0000 - val_loss: 1.8261 - val_accuracy: 0.3148 - 326ms/epoch - 81ms/step\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 192: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0844 - accuracy: 1.0000 - val_loss: 1.7303 - val_accuracy: 0.2963 - 340ms/epoch - 85ms/step\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 193: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0940 - accuracy: 1.0000 - val_loss: 1.7047 - val_accuracy: 0.3519 - 324ms/epoch - 81ms/step\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 194: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0952 - accuracy: 1.0000 - val_loss: 1.6046 - val_accuracy: 0.2963 - 323ms/epoch - 81ms/step\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 195: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0920 - accuracy: 1.0000 - val_loss: 1.5364 - val_accuracy: 0.3889 - 341ms/epoch - 85ms/step\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 196: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0933 - accuracy: 1.0000 - val_loss: 1.6326 - val_accuracy: 0.3333 - 313ms/epoch - 78ms/step\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 197: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0936 - accuracy: 1.0000 - val_loss: 1.5916 - val_accuracy: 0.4074 - 336ms/epoch - 84ms/step\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 198: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0927 - accuracy: 1.0000 - val_loss: 1.6777 - val_accuracy: 0.3519 - 323ms/epoch - 81ms/step\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 199: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0973 - accuracy: 1.0000 - val_loss: 1.6364 - val_accuracy: 0.3704 - 324ms/epoch - 81ms/step\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 200: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0990 - accuracy: 1.0000 - val_loss: 1.6528 - val_accuracy: 0.3519 - 338ms/epoch - 85ms/step\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 201: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0930 - accuracy: 1.0000 - val_loss: 1.5601 - val_accuracy: 0.3704 - 324ms/epoch - 81ms/step\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 202: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0964 - accuracy: 1.0000 - val_loss: 1.6666 - val_accuracy: 0.2778 - 335ms/epoch - 84ms/step\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 203: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0882 - accuracy: 1.0000 - val_loss: 1.5618 - val_accuracy: 0.4074 - 333ms/epoch - 83ms/step\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 204: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0853 - accuracy: 1.0000 - val_loss: 1.5561 - val_accuracy: 0.3704 - 329ms/epoch - 82ms/step\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 205: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0799 - accuracy: 1.0000 - val_loss: 1.5914 - val_accuracy: 0.3519 - 353ms/epoch - 88ms/step\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 206: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0745 - accuracy: 1.0000 - val_loss: 1.4947 - val_accuracy: 0.4444 - 343ms/epoch - 86ms/step\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 207: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0811 - accuracy: 1.0000 - val_loss: 1.4705 - val_accuracy: 0.4815 - 322ms/epoch - 81ms/step\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 208: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0830 - accuracy: 1.0000 - val_loss: 1.5314 - val_accuracy: 0.4074 - 325ms/epoch - 81ms/step\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 209: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0778 - accuracy: 1.0000 - val_loss: 1.5635 - val_accuracy: 0.3889 - 331ms/epoch - 83ms/step\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 210: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0825 - accuracy: 1.0000 - val_loss: 1.6597 - val_accuracy: 0.3519 - 329ms/epoch - 82ms/step\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 211: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0769 - accuracy: 1.0000 - val_loss: 1.5501 - val_accuracy: 0.3889 - 332ms/epoch - 83ms/step\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 212: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0769 - accuracy: 1.0000 - val_loss: 1.5786 - val_accuracy: 0.4074 - 322ms/epoch - 80ms/step\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 213: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0762 - accuracy: 1.0000 - val_loss: 1.5780 - val_accuracy: 0.3889 - 323ms/epoch - 81ms/step\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 214: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0842 - accuracy: 1.0000 - val_loss: 1.5459 - val_accuracy: 0.4259 - 323ms/epoch - 81ms/step\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 215: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0768 - accuracy: 1.0000 - val_loss: 1.5761 - val_accuracy: 0.3704 - 331ms/epoch - 83ms/step\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 216: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0794 - accuracy: 1.0000 - val_loss: 1.5091 - val_accuracy: 0.3889 - 338ms/epoch - 84ms/step\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 217: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0747 - accuracy: 1.0000 - val_loss: 1.5487 - val_accuracy: 0.3704 - 331ms/epoch - 83ms/step\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 218: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0704 - accuracy: 1.0000 - val_loss: 1.5884 - val_accuracy: 0.2963 - 322ms/epoch - 80ms/step\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 219: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0754 - accuracy: 1.0000 - val_loss: 1.6361 - val_accuracy: 0.3333 - 336ms/epoch - 84ms/step\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 220: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0803 - accuracy: 1.0000 - val_loss: 1.5989 - val_accuracy: 0.3519 - 323ms/epoch - 81ms/step\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 221: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0725 - accuracy: 1.0000 - val_loss: 1.7327 - val_accuracy: 0.3519 - 340ms/epoch - 85ms/step\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 222: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0740 - accuracy: 1.0000 - val_loss: 1.5800 - val_accuracy: 0.3889 - 319ms/epoch - 80ms/step\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 223: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0686 - accuracy: 1.0000 - val_loss: 1.5744 - val_accuracy: 0.3704 - 329ms/epoch - 82ms/step\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 224: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0732 - accuracy: 1.0000 - val_loss: 1.6360 - val_accuracy: 0.3333 - 334ms/epoch - 84ms/step\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 225: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0657 - accuracy: 1.0000 - val_loss: 1.5891 - val_accuracy: 0.3519 - 344ms/epoch - 86ms/step\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 226: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0764 - accuracy: 1.0000 - val_loss: 1.5969 - val_accuracy: 0.3519 - 332ms/epoch - 83ms/step\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 227: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0886 - accuracy: 1.0000 - val_loss: 1.6718 - val_accuracy: 0.3148 - 344ms/epoch - 86ms/step\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 228: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0688 - accuracy: 1.0000 - val_loss: 1.6527 - val_accuracy: 0.3889 - 321ms/epoch - 80ms/step\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 229: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0911 - accuracy: 1.0000 - val_loss: 1.6753 - val_accuracy: 0.3519 - 344ms/epoch - 86ms/step\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 230: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0650 - accuracy: 1.0000 - val_loss: 1.7098 - val_accuracy: 0.3704 - 331ms/epoch - 83ms/step\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 231: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0768 - accuracy: 1.0000 - val_loss: 1.6975 - val_accuracy: 0.3148 - 328ms/epoch - 82ms/step\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 232: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0670 - accuracy: 1.0000 - val_loss: 1.7162 - val_accuracy: 0.3704 - 348ms/epoch - 87ms/step\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 233: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0752 - accuracy: 1.0000 - val_loss: 1.7862 - val_accuracy: 0.3519 - 328ms/epoch - 82ms/step\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 234: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0793 - accuracy: 1.0000 - val_loss: 1.7041 - val_accuracy: 0.2963 - 348ms/epoch - 87ms/step\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 235: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0788 - accuracy: 1.0000 - val_loss: 1.6050 - val_accuracy: 0.3519 - 342ms/epoch - 85ms/step\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 236: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0733 - accuracy: 1.0000 - val_loss: 1.6953 - val_accuracy: 0.3519 - 321ms/epoch - 80ms/step\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 237: val_loss did not improve from 1.38670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.0662 - accuracy: 1.0000 - val_loss: 1.7208 - val_accuracy: 0.3519 - 343ms/epoch - 86ms/step\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 238: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0593 - accuracy: 1.0000 - val_loss: 1.6283 - val_accuracy: 0.3519 - 328ms/epoch - 82ms/step\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 239: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0724 - accuracy: 1.0000 - val_loss: 1.6139 - val_accuracy: 0.3889 - 341ms/epoch - 85ms/step\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 240: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0709 - accuracy: 1.0000 - val_loss: 1.6181 - val_accuracy: 0.3704 - 331ms/epoch - 83ms/step\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 241: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0743 - accuracy: 1.0000 - val_loss: 1.5269 - val_accuracy: 0.4444 - 323ms/epoch - 81ms/step\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 242: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0658 - accuracy: 1.0000 - val_loss: 1.5247 - val_accuracy: 0.4259 - 322ms/epoch - 81ms/step\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 243: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0735 - accuracy: 1.0000 - val_loss: 1.5844 - val_accuracy: 0.3889 - 330ms/epoch - 82ms/step\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 244: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0659 - accuracy: 1.0000 - val_loss: 1.6128 - val_accuracy: 0.3704 - 322ms/epoch - 80ms/step\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 245: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0688 - accuracy: 1.0000 - val_loss: 1.6297 - val_accuracy: 0.3519 - 338ms/epoch - 84ms/step\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 246: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0681 - accuracy: 1.0000 - val_loss: 1.5929 - val_accuracy: 0.3519 - 325ms/epoch - 81ms/step\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 247: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0653 - accuracy: 1.0000 - val_loss: 1.6081 - val_accuracy: 0.3704 - 344ms/epoch - 86ms/step\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 248: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0744 - accuracy: 1.0000 - val_loss: 1.6532 - val_accuracy: 0.3148 - 321ms/epoch - 80ms/step\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 249: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0706 - accuracy: 1.0000 - val_loss: 1.5658 - val_accuracy: 0.4259 - 323ms/epoch - 81ms/step\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 250: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0665 - accuracy: 1.0000 - val_loss: 1.7082 - val_accuracy: 0.2778 - 327ms/epoch - 82ms/step\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 251: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0603 - accuracy: 1.0000 - val_loss: 1.6047 - val_accuracy: 0.3333 - 329ms/epoch - 82ms/step\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 252: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0632 - accuracy: 1.0000 - val_loss: 1.7421 - val_accuracy: 0.3333 - 352ms/epoch - 88ms/step\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 253: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0699 - accuracy: 1.0000 - val_loss: 1.6376 - val_accuracy: 0.3333 - 326ms/epoch - 81ms/step\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 254: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0642 - accuracy: 1.0000 - val_loss: 1.5636 - val_accuracy: 0.3519 - 324ms/epoch - 81ms/step\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 255: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0682 - accuracy: 1.0000 - val_loss: 1.6698 - val_accuracy: 0.3519 - 324ms/epoch - 81ms/step\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 256: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0683 - accuracy: 1.0000 - val_loss: 1.6455 - val_accuracy: 0.3519 - 340ms/epoch - 85ms/step\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 257: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0631 - accuracy: 1.0000 - val_loss: 1.6606 - val_accuracy: 0.3704 - 351ms/epoch - 88ms/step\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 258: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0752 - accuracy: 1.0000 - val_loss: 1.7092 - val_accuracy: 0.3704 - 332ms/epoch - 83ms/step\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 259: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0833 - accuracy: 1.0000 - val_loss: 1.6275 - val_accuracy: 0.3333 - 332ms/epoch - 83ms/step\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 260: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0745 - accuracy: 1.0000 - val_loss: 1.6051 - val_accuracy: 0.3889 - 328ms/epoch - 82ms/step\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 261: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0622 - accuracy: 1.0000 - val_loss: 1.6743 - val_accuracy: 0.3148 - 345ms/epoch - 86ms/step\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 262: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0642 - accuracy: 1.0000 - val_loss: 1.6580 - val_accuracy: 0.3333 - 331ms/epoch - 83ms/step\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 263: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0616 - accuracy: 1.0000 - val_loss: 2.0146 - val_accuracy: 0.2963 - 337ms/epoch - 84ms/step\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 264: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0604 - accuracy: 1.0000 - val_loss: 1.8271 - val_accuracy: 0.4074 - 330ms/epoch - 82ms/step\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 265: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0589 - accuracy: 1.0000 - val_loss: 1.7362 - val_accuracy: 0.3333 - 334ms/epoch - 84ms/step\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 266: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0499 - accuracy: 1.0000 - val_loss: 1.6458 - val_accuracy: 0.3519 - 328ms/epoch - 82ms/step\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 267: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0703 - accuracy: 1.0000 - val_loss: 1.6777 - val_accuracy: 0.3519 - 328ms/epoch - 82ms/step\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 268: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0606 - accuracy: 1.0000 - val_loss: 1.6924 - val_accuracy: 0.3148 - 329ms/epoch - 82ms/step\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 269: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0640 - accuracy: 1.0000 - val_loss: 1.6526 - val_accuracy: 0.3519 - 341ms/epoch - 85ms/step\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 270: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0615 - accuracy: 1.0000 - val_loss: 1.6612 - val_accuracy: 0.3333 - 325ms/epoch - 81ms/step\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 271: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0582 - accuracy: 1.0000 - val_loss: 1.6489 - val_accuracy: 0.2963 - 333ms/epoch - 83ms/step\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 272: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0644 - accuracy: 1.0000 - val_loss: 1.6633 - val_accuracy: 0.3519 - 320ms/epoch - 80ms/step\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 273: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0548 - accuracy: 1.0000 - val_loss: 1.8066 - val_accuracy: 0.3519 - 319ms/epoch - 80ms/step\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 274: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0583 - accuracy: 1.0000 - val_loss: 1.6726 - val_accuracy: 0.3519 - 340ms/epoch - 85ms/step\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 275: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0528 - accuracy: 1.0000 - val_loss: 1.5788 - val_accuracy: 0.4074 - 332ms/epoch - 83ms/step\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 276: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0473 - accuracy: 1.0000 - val_loss: 1.5718 - val_accuracy: 0.4074 - 320ms/epoch - 80ms/step\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 277: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0589 - accuracy: 1.0000 - val_loss: 1.6962 - val_accuracy: 0.3333 - 328ms/epoch - 82ms/step\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 278: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0551 - accuracy: 1.0000 - val_loss: 1.7908 - val_accuracy: 0.2963 - 332ms/epoch - 83ms/step\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 279: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0505 - accuracy: 1.0000 - val_loss: 1.6938 - val_accuracy: 0.2963 - 321ms/epoch - 80ms/step\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 280: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0514 - accuracy: 1.0000 - val_loss: 1.7154 - val_accuracy: 0.3333 - 323ms/epoch - 81ms/step\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 281: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0529 - accuracy: 1.0000 - val_loss: 1.5801 - val_accuracy: 0.3889 - 351ms/epoch - 88ms/step\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 282: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0494 - accuracy: 1.0000 - val_loss: 1.5444 - val_accuracy: 0.3704 - 331ms/epoch - 83ms/step\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 283: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0515 - accuracy: 1.0000 - val_loss: 1.6522 - val_accuracy: 0.3148 - 324ms/epoch - 81ms/step\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 284: val_loss did not improve from 1.38670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.0525 - accuracy: 1.0000 - val_loss: 1.5946 - val_accuracy: 0.3519 - 322ms/epoch - 81ms/step\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 285: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0531 - accuracy: 1.0000 - val_loss: 1.6460 - val_accuracy: 0.3333 - 336ms/epoch - 84ms/step\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 286: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0584 - accuracy: 1.0000 - val_loss: 1.6286 - val_accuracy: 0.3704 - 321ms/epoch - 80ms/step\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 287: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0609 - accuracy: 1.0000 - val_loss: 1.6284 - val_accuracy: 0.3148 - 332ms/epoch - 83ms/step\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 288: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0624 - accuracy: 1.0000 - val_loss: 1.6750 - val_accuracy: 0.3704 - 328ms/epoch - 82ms/step\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 289: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0619 - accuracy: 1.0000 - val_loss: 1.6569 - val_accuracy: 0.3889 - 340ms/epoch - 85ms/step\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 290: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0583 - accuracy: 1.0000 - val_loss: 1.8473 - val_accuracy: 0.3148 - 325ms/epoch - 81ms/step\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 291: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0645 - accuracy: 1.0000 - val_loss: 1.7507 - val_accuracy: 0.3519 - 321ms/epoch - 80ms/step\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 292: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0667 - accuracy: 1.0000 - val_loss: 1.6318 - val_accuracy: 0.3519 - 324ms/epoch - 81ms/step\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 293: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0684 - accuracy: 1.0000 - val_loss: 1.7412 - val_accuracy: 0.3148 - 332ms/epoch - 83ms/step\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 294: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0563 - accuracy: 1.0000 - val_loss: 1.5289 - val_accuracy: 0.3889 - 334ms/epoch - 84ms/step\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 295: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0573 - accuracy: 1.0000 - val_loss: 1.6446 - val_accuracy: 0.3148 - 331ms/epoch - 83ms/step\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 296: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0485 - accuracy: 1.0000 - val_loss: 1.6224 - val_accuracy: 0.3519 - 339ms/epoch - 85ms/step\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 297: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0513 - accuracy: 1.0000 - val_loss: 1.7046 - val_accuracy: 0.2963 - 326ms/epoch - 82ms/step\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 298: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0522 - accuracy: 1.0000 - val_loss: 1.8562 - val_accuracy: 0.2778 - 334ms/epoch - 83ms/step\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 299: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0498 - accuracy: 1.0000 - val_loss: 1.5458 - val_accuracy: 0.3704 - 327ms/epoch - 82ms/step\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 300: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.0559 - accuracy: 1.0000 - val_loss: 1.6035 - val_accuracy: 0.3704 - 337ms/epoch - 84ms/step\n",
      "2/2 [==============================] - 0s 22ms/step\n",
      "Lists\n",
      "[0.26666666666666666, 0.21666666666666667, 0.16666666666666666, 0.15]\n",
      "[0.13194444444444445, 0.05508474576271186, 0.041666666666666664, 0.0375]\n",
      "[0.2326388888888889, 0.25, 0.25, 0.25]\n",
      "[0.1675925925925926, 0.09027777777777778, 0.07142857142857142, 0.06521739130434782]\n",
      "dicts\n",
      "{1: 0.28, 2: 0.2, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0}\n",
      "{1: 0.179879077643203, 2: 0.06654896421845574, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0}\n",
      "{1: 0.285120781995782, 2: 0.2456597222222222, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0}\n",
      "{1: 0.19991143316006618, 2: 0.09862908327582241, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Number of devices: 2\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 09:21:25.643037: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_8807888\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:578548\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
      "2022-11-11 09:21:30.054376: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_8810953\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:578596\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38653, saving model to checkpoint1.h5\n",
      "3/3 - 6s - loss: 1.4438 - accuracy: 0.2553 - val_loss: 1.3865 - val_accuracy: 0.2195 - 6s/epoch - 2s/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 1.3247 - accuracy: 0.3617 - val_loss: 1.3866 - val_accuracy: 0.2195 - 308ms/epoch - 103ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 1.2883 - accuracy: 0.4468 - val_loss: 1.3868 - val_accuracy: 0.2195 - 291ms/epoch - 97ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 1.2484 - accuracy: 0.4574 - val_loss: 1.3868 - val_accuracy: 0.2195 - 278ms/epoch - 93ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 1.1963 - accuracy: 0.5106 - val_loss: 1.3869 - val_accuracy: 0.3171 - 271ms/epoch - 90ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 1.2062 - accuracy: 0.5426 - val_loss: 1.3869 - val_accuracy: 0.3171 - 269ms/epoch - 90ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 1.1553 - accuracy: 0.5638 - val_loss: 1.3870 - val_accuracy: 0.2195 - 278ms/epoch - 93ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 1.1561 - accuracy: 0.6170 - val_loss: 1.3871 - val_accuracy: 0.2195 - 274ms/epoch - 91ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 1.0857 - accuracy: 0.6915 - val_loss: 1.3873 - val_accuracy: 0.2195 - 279ms/epoch - 93ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 1.0758 - accuracy: 0.6809 - val_loss: 1.3872 - val_accuracy: 0.2195 - 282ms/epoch - 94ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 1.0661 - accuracy: 0.6170 - val_loss: 1.3871 - val_accuracy: 0.3171 - 279ms/epoch - 93ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 1.0364 - accuracy: 0.7447 - val_loss: 1.3871 - val_accuracy: 0.2683 - 267ms/epoch - 89ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 1.0137 - accuracy: 0.7340 - val_loss: 1.3873 - val_accuracy: 0.2927 - 269ms/epoch - 90ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.9505 - accuracy: 0.8298 - val_loss: 1.3874 - val_accuracy: 0.2439 - 280ms/epoch - 93ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.9481 - accuracy: 0.8298 - val_loss: 1.3874 - val_accuracy: 0.3171 - 269ms/epoch - 90ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.9419 - accuracy: 0.8085 - val_loss: 1.3875 - val_accuracy: 0.2439 - 271ms/epoch - 90ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.9119 - accuracy: 0.8298 - val_loss: 1.3876 - val_accuracy: 0.2683 - 281ms/epoch - 94ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.8954 - accuracy: 0.9043 - val_loss: 1.3874 - val_accuracy: 0.2927 - 273ms/epoch - 91ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.9054 - accuracy: 0.8085 - val_loss: 1.3877 - val_accuracy: 0.2927 - 273ms/epoch - 91ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.8656 - accuracy: 0.8617 - val_loss: 1.3880 - val_accuracy: 0.2683 - 274ms/epoch - 91ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.8945 - accuracy: 0.8191 - val_loss: 1.3881 - val_accuracy: 0.2683 - 274ms/epoch - 91ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.8446 - accuracy: 0.8936 - val_loss: 1.3883 - val_accuracy: 0.2927 - 279ms/epoch - 93ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.8502 - accuracy: 0.8298 - val_loss: 1.3886 - val_accuracy: 0.2683 - 286ms/epoch - 95ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.7892 - accuracy: 0.9468 - val_loss: 1.3894 - val_accuracy: 0.2683 - 272ms/epoch - 91ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.8149 - accuracy: 0.8936 - val_loss: 1.3897 - val_accuracy: 0.2683 - 271ms/epoch - 90ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.8018 - accuracy: 0.9149 - val_loss: 1.3897 - val_accuracy: 0.2683 - 281ms/epoch - 94ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.7550 - accuracy: 0.9149 - val_loss: 1.3905 - val_accuracy: 0.2683 - 290ms/epoch - 97ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.7747 - accuracy: 0.9255 - val_loss: 1.3913 - val_accuracy: 0.2683 - 273ms/epoch - 91ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.7560 - accuracy: 0.9043 - val_loss: 1.3905 - val_accuracy: 0.2683 - 279ms/epoch - 93ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.8023 - accuracy: 0.8191 - val_loss: 1.3916 - val_accuracy: 0.2683 - 279ms/epoch - 93ms/step\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.7613 - accuracy: 0.8936 - val_loss: 1.3933 - val_accuracy: 0.2683 - 278ms/epoch - 93ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.7215 - accuracy: 0.9043 - val_loss: 1.3909 - val_accuracy: 0.2683 - 269ms/epoch - 90ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.7321 - accuracy: 0.9255 - val_loss: 1.3923 - val_accuracy: 0.2683 - 270ms/epoch - 90ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.7039 - accuracy: 0.9255 - val_loss: 1.3951 - val_accuracy: 0.2683 - 282ms/epoch - 94ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.7006 - accuracy: 0.9362 - val_loss: 1.3941 - val_accuracy: 0.2683 - 271ms/epoch - 90ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.6710 - accuracy: 0.9574 - val_loss: 1.3948 - val_accuracy: 0.2683 - 287ms/epoch - 96ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.6592 - accuracy: 0.9362 - val_loss: 1.3978 - val_accuracy: 0.2683 - 266ms/epoch - 89ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.6426 - accuracy: 0.9468 - val_loss: 1.3962 - val_accuracy: 0.2683 - 274ms/epoch - 91ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.6467 - accuracy: 0.9681 - val_loss: 1.3991 - val_accuracy: 0.2683 - 277ms/epoch - 92ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.6435 - accuracy: 0.9362 - val_loss: 1.4001 - val_accuracy: 0.2683 - 281ms/epoch - 94ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.6245 - accuracy: 0.9574 - val_loss: 1.4016 - val_accuracy: 0.2683 - 279ms/epoch - 93ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.6237 - accuracy: 0.9574 - val_loss: 1.4017 - val_accuracy: 0.2683 - 273ms/epoch - 91ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.6262 - accuracy: 0.9468 - val_loss: 1.4050 - val_accuracy: 0.2683 - 274ms/epoch - 91ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.5842 - accuracy: 0.9681 - val_loss: 1.4070 - val_accuracy: 0.2683 - 273ms/epoch - 91ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.6382 - accuracy: 0.9149 - val_loss: 1.4085 - val_accuracy: 0.2683 - 271ms/epoch - 90ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.5809 - accuracy: 0.9681 - val_loss: 1.4144 - val_accuracy: 0.2683 - 289ms/epoch - 96ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.6126 - accuracy: 0.9574 - val_loss: 1.4129 - val_accuracy: 0.2683 - 272ms/epoch - 91ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.5553 - accuracy: 0.9787 - val_loss: 1.4167 - val_accuracy: 0.2683 - 272ms/epoch - 91ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.5580 - accuracy: 0.9787 - val_loss: 1.4207 - val_accuracy: 0.2683 - 271ms/epoch - 90ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.5722 - accuracy: 0.9574 - val_loss: 1.4212 - val_accuracy: 0.2683 - 272ms/epoch - 91ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.5329 - accuracy: 0.9787 - val_loss: 1.4318 - val_accuracy: 0.2683 - 279ms/epoch - 93ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.5273 - accuracy: 0.9681 - val_loss: 1.4314 - val_accuracy: 0.2683 - 272ms/epoch - 91ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.5078 - accuracy: 0.9681 - val_loss: 1.4275 - val_accuracy: 0.2683 - 281ms/epoch - 94ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.5212 - accuracy: 0.9894 - val_loss: 1.4455 - val_accuracy: 0.2683 - 276ms/epoch - 92ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.4846 - accuracy: 0.9787 - val_loss: 1.4403 - val_accuracy: 0.2683 - 274ms/epoch - 91ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.4838 - accuracy: 0.9894 - val_loss: 1.4562 - val_accuracy: 0.2683 - 272ms/epoch - 91ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.5035 - accuracy: 0.9681 - val_loss: 1.4595 - val_accuracy: 0.2683 - 274ms/epoch - 91ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.5272 - accuracy: 0.9468 - val_loss: 1.4484 - val_accuracy: 0.2683 - 278ms/epoch - 93ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.5015 - accuracy: 0.9681 - val_loss: 1.4688 - val_accuracy: 0.2683 - 292ms/epoch - 97ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.4698 - accuracy: 0.9894 - val_loss: 1.4659 - val_accuracy: 0.2683 - 273ms/epoch - 91ms/step\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.4776 - accuracy: 1.0000 - val_loss: 1.4738 - val_accuracy: 0.2683 - 278ms/epoch - 93ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.4985 - accuracy: 0.9787 - val_loss: 1.4873 - val_accuracy: 0.2683 - 284ms/epoch - 95ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.4645 - accuracy: 0.9787 - val_loss: 1.4743 - val_accuracy: 0.2683 - 273ms/epoch - 91ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.4508 - accuracy: 0.9787 - val_loss: 1.5072 - val_accuracy: 0.2683 - 272ms/epoch - 91ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.4642 - accuracy: 0.9681 - val_loss: 1.5140 - val_accuracy: 0.2683 - 268ms/epoch - 89ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.4431 - accuracy: 0.9894 - val_loss: 1.5088 - val_accuracy: 0.2683 - 281ms/epoch - 94ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.4322 - accuracy: 0.9787 - val_loss: 1.5195 - val_accuracy: 0.2683 - 271ms/epoch - 90ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.4408 - accuracy: 0.9574 - val_loss: 1.5454 - val_accuracy: 0.2683 - 275ms/epoch - 92ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.4275 - accuracy: 0.9681 - val_loss: 1.4985 - val_accuracy: 0.2683 - 267ms/epoch - 89ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.4022 - accuracy: 0.9894 - val_loss: 1.5566 - val_accuracy: 0.2683 - 269ms/epoch - 90ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.3856 - accuracy: 1.0000 - val_loss: 1.5323 - val_accuracy: 0.2683 - 276ms/epoch - 92ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.4080 - accuracy: 0.9894 - val_loss: 1.5568 - val_accuracy: 0.2683 - 295ms/epoch - 98ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.4268 - accuracy: 1.0000 - val_loss: 1.5762 - val_accuracy: 0.2683 - 281ms/epoch - 94ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.3882 - accuracy: 1.0000 - val_loss: 1.5553 - val_accuracy: 0.2683 - 271ms/epoch - 90ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.3695 - accuracy: 1.0000 - val_loss: 1.6052 - val_accuracy: 0.2683 - 270ms/epoch - 90ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.4003 - accuracy: 1.0000 - val_loss: 1.5658 - val_accuracy: 0.2683 - 283ms/epoch - 94ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.4070 - accuracy: 1.0000 - val_loss: 1.6066 - val_accuracy: 0.2683 - 270ms/epoch - 90ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.3919 - accuracy: 0.9894 - val_loss: 1.6139 - val_accuracy: 0.2683 - 298ms/epoch - 99ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.3575 - accuracy: 1.0000 - val_loss: 1.6195 - val_accuracy: 0.2683 - 276ms/epoch - 92ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.3903 - accuracy: 0.9894 - val_loss: 1.7043 - val_accuracy: 0.2683 - 283ms/epoch - 94ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.3847 - accuracy: 0.9681 - val_loss: 1.6114 - val_accuracy: 0.2683 - 272ms/epoch - 91ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.3751 - accuracy: 0.9894 - val_loss: 1.6639 - val_accuracy: 0.2683 - 283ms/epoch - 94ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.3850 - accuracy: 0.9787 - val_loss: 1.6474 - val_accuracy: 0.2683 - 286ms/epoch - 95ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.3549 - accuracy: 1.0000 - val_loss: 1.6590 - val_accuracy: 0.2683 - 277ms/epoch - 92ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.3535 - accuracy: 0.9894 - val_loss: 1.6728 - val_accuracy: 0.2683 - 275ms/epoch - 92ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.2893 - accuracy: 1.0000 - val_loss: 1.6609 - val_accuracy: 0.2683 - 273ms/epoch - 91ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.3349 - accuracy: 0.9894 - val_loss: 1.7344 - val_accuracy: 0.2683 - 284ms/epoch - 95ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.3234 - accuracy: 1.0000 - val_loss: 1.7052 - val_accuracy: 0.2683 - 268ms/epoch - 89ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.3174 - accuracy: 1.0000 - val_loss: 1.7299 - val_accuracy: 0.2683 - 280ms/epoch - 93ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.3441 - accuracy: 0.9894 - val_loss: 1.7813 - val_accuracy: 0.2683 - 280ms/epoch - 93ms/step\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.3159 - accuracy: 1.0000 - val_loss: 1.7484 - val_accuracy: 0.2683 - 284ms/epoch - 95ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.3212 - accuracy: 1.0000 - val_loss: 1.8148 - val_accuracy: 0.2683 - 273ms/epoch - 91ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.3187 - accuracy: 0.9894 - val_loss: 1.8289 - val_accuracy: 0.2683 - 279ms/epoch - 93ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.3088 - accuracy: 1.0000 - val_loss: 1.7774 - val_accuracy: 0.2683 - 276ms/epoch - 92ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.3133 - accuracy: 0.9894 - val_loss: 1.8931 - val_accuracy: 0.2683 - 272ms/epoch - 91ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 1.38653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 0.2789 - accuracy: 1.0000 - val_loss: 1.7525 - val_accuracy: 0.2683 - 288ms/epoch - 96ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.2942 - accuracy: 1.0000 - val_loss: 1.9194 - val_accuracy: 0.2683 - 284ms/epoch - 95ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.3033 - accuracy: 1.0000 - val_loss: 1.8480 - val_accuracy: 0.2683 - 280ms/epoch - 93ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.3149 - accuracy: 0.9894 - val_loss: 1.9671 - val_accuracy: 0.2683 - 276ms/epoch - 92ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.3083 - accuracy: 0.9894 - val_loss: 1.9212 - val_accuracy: 0.2683 - 266ms/epoch - 89ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.3211 - accuracy: 1.0000 - val_loss: 1.9527 - val_accuracy: 0.2683 - 279ms/epoch - 93ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.2708 - accuracy: 1.0000 - val_loss: 1.8861 - val_accuracy: 0.2683 - 282ms/epoch - 94ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.2814 - accuracy: 0.9894 - val_loss: 1.9467 - val_accuracy: 0.2683 - 281ms/epoch - 94ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.2561 - accuracy: 1.0000 - val_loss: 1.8995 - val_accuracy: 0.2683 - 275ms/epoch - 92ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.2891 - accuracy: 1.0000 - val_loss: 1.9721 - val_accuracy: 0.2683 - 271ms/epoch - 90ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.2695 - accuracy: 0.9787 - val_loss: 1.9489 - val_accuracy: 0.2683 - 275ms/epoch - 92ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.2734 - accuracy: 1.0000 - val_loss: 1.9344 - val_accuracy: 0.2683 - 288ms/epoch - 96ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.2664 - accuracy: 1.0000 - val_loss: 2.0519 - val_accuracy: 0.2683 - 283ms/epoch - 94ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.2615 - accuracy: 1.0000 - val_loss: 1.9482 - val_accuracy: 0.2683 - 269ms/epoch - 90ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.2578 - accuracy: 1.0000 - val_loss: 2.0109 - val_accuracy: 0.2683 - 271ms/epoch - 90ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.2506 - accuracy: 1.0000 - val_loss: 2.0299 - val_accuracy: 0.2683 - 272ms/epoch - 91ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.2548 - accuracy: 1.0000 - val_loss: 1.9858 - val_accuracy: 0.2683 - 277ms/epoch - 92ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.2363 - accuracy: 1.0000 - val_loss: 1.9808 - val_accuracy: 0.2683 - 269ms/epoch - 90ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.2050 - accuracy: 1.0000 - val_loss: 2.0812 - val_accuracy: 0.2683 - 279ms/epoch - 93ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.2428 - accuracy: 1.0000 - val_loss: 2.0617 - val_accuracy: 0.2683 - 273ms/epoch - 91ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.2512 - accuracy: 1.0000 - val_loss: 2.0677 - val_accuracy: 0.2683 - 286ms/epoch - 95ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.2591 - accuracy: 1.0000 - val_loss: 2.0281 - val_accuracy: 0.2683 - 281ms/epoch - 94ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 2.0794 - val_accuracy: 0.2683 - 281ms/epoch - 94ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.2380 - accuracy: 1.0000 - val_loss: 2.0504 - val_accuracy: 0.2683 - 273ms/epoch - 91ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.2268 - accuracy: 1.0000 - val_loss: 2.1911 - val_accuracy: 0.2683 - 292ms/epoch - 97ms/step\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.2233 - accuracy: 1.0000 - val_loss: 1.9458 - val_accuracy: 0.2683 - 270ms/epoch - 90ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.2334 - accuracy: 1.0000 - val_loss: 2.1052 - val_accuracy: 0.2683 - 274ms/epoch - 91ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.2045 - accuracy: 0.9894 - val_loss: 2.0401 - val_accuracy: 0.2683 - 280ms/epoch - 93ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.2346 - accuracy: 1.0000 - val_loss: 2.0436 - val_accuracy: 0.2683 - 283ms/epoch - 94ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.2255 - accuracy: 1.0000 - val_loss: 1.9987 - val_accuracy: 0.2683 - 286ms/epoch - 95ms/step\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 2.0356 - val_accuracy: 0.2683 - 272ms/epoch - 91ms/step\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 2.1138 - val_accuracy: 0.2683 - 281ms/epoch - 94ms/step\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1703 - accuracy: 1.0000 - val_loss: 2.1134 - val_accuracy: 0.2683 - 273ms/epoch - 91ms/step\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.2007 - accuracy: 1.0000 - val_loss: 2.1501 - val_accuracy: 0.2683 - 273ms/epoch - 91ms/step\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.2051 - accuracy: 1.0000 - val_loss: 2.0741 - val_accuracy: 0.2683 - 269ms/epoch - 90ms/step\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1962 - accuracy: 1.0000 - val_loss: 2.0647 - val_accuracy: 0.2683 - 270ms/epoch - 90ms/step\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.2096 - accuracy: 0.9894 - val_loss: 2.2086 - val_accuracy: 0.2683 - 285ms/epoch - 95ms/step\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1827 - accuracy: 1.0000 - val_loss: 2.2413 - val_accuracy: 0.2683 - 273ms/epoch - 91ms/step\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.2316 - accuracy: 1.0000 - val_loss: 2.0826 - val_accuracy: 0.2683 - 272ms/epoch - 91ms/step\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 135: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1815 - accuracy: 1.0000 - val_loss: 2.2337 - val_accuracy: 0.2683 - 287ms/epoch - 96ms/step\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 136: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1852 - accuracy: 1.0000 - val_loss: 2.0905 - val_accuracy: 0.2683 - 267ms/epoch - 89ms/step\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 137: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1607 - accuracy: 1.0000 - val_loss: 2.0927 - val_accuracy: 0.2683 - 270ms/epoch - 90ms/step\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 138: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1847 - accuracy: 1.0000 - val_loss: 2.1530 - val_accuracy: 0.2683 - 269ms/epoch - 90ms/step\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 139: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1928 - accuracy: 1.0000 - val_loss: 2.1643 - val_accuracy: 0.2683 - 272ms/epoch - 91ms/step\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 140: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 2.1458 - val_accuracy: 0.2683 - 271ms/epoch - 90ms/step\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 141: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1861 - accuracy: 1.0000 - val_loss: 2.1857 - val_accuracy: 0.2683 - 274ms/epoch - 91ms/step\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 142: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.2213 - accuracy: 1.0000 - val_loss: 2.0559 - val_accuracy: 0.2683 - 272ms/epoch - 91ms/step\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 143: val_loss did not improve from 1.38653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 2.3466 - val_accuracy: 0.2683 - 271ms/epoch - 90ms/step\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 144: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.2260 - accuracy: 0.9894 - val_loss: 2.0948 - val_accuracy: 0.2683 - 289ms/epoch - 96ms/step\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 145: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.2191 - accuracy: 0.9894 - val_loss: 2.2935 - val_accuracy: 0.2683 - 279ms/epoch - 93ms/step\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 146: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1958 - accuracy: 1.0000 - val_loss: 1.7097 - val_accuracy: 0.1951 - 275ms/epoch - 92ms/step\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 147: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1810 - accuracy: 1.0000 - val_loss: 1.9429 - val_accuracy: 0.2439 - 273ms/epoch - 91ms/step\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 148: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1625 - accuracy: 1.0000 - val_loss: 1.8513 - val_accuracy: 0.2195 - 267ms/epoch - 89ms/step\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 149: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1757 - accuracy: 1.0000 - val_loss: 2.0208 - val_accuracy: 0.2683 - 271ms/epoch - 90ms/step\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 150: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1729 - accuracy: 0.9894 - val_loss: 2.0089 - val_accuracy: 0.2683 - 288ms/epoch - 96ms/step\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 151: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1718 - accuracy: 1.0000 - val_loss: 2.0823 - val_accuracy: 0.2683 - 273ms/epoch - 91ms/step\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 152: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1588 - accuracy: 1.0000 - val_loss: 2.1337 - val_accuracy: 0.2683 - 271ms/epoch - 90ms/step\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 153: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1661 - accuracy: 1.0000 - val_loss: 1.9515 - val_accuracy: 0.2439 - 272ms/epoch - 91ms/step\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 154: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1755 - accuracy: 1.0000 - val_loss: 2.1590 - val_accuracy: 0.2683 - 274ms/epoch - 91ms/step\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 155: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1477 - accuracy: 1.0000 - val_loss: 2.0469 - val_accuracy: 0.2683 - 274ms/epoch - 91ms/step\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 156: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1689 - accuracy: 1.0000 - val_loss: 2.1832 - val_accuracy: 0.2683 - 274ms/epoch - 91ms/step\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 157: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1852 - accuracy: 1.0000 - val_loss: 2.1223 - val_accuracy: 0.2439 - 281ms/epoch - 94ms/step\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 158: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1499 - accuracy: 1.0000 - val_loss: 2.1495 - val_accuracy: 0.2439 - 269ms/epoch - 90ms/step\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 159: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1589 - accuracy: 1.0000 - val_loss: 2.1442 - val_accuracy: 0.2683 - 281ms/epoch - 94ms/step\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 160: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1599 - accuracy: 1.0000 - val_loss: 2.0280 - val_accuracy: 0.2439 - 276ms/epoch - 92ms/step\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 161: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1576 - accuracy: 1.0000 - val_loss: 2.0707 - val_accuracy: 0.2439 - 275ms/epoch - 92ms/step\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 162: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1565 - accuracy: 1.0000 - val_loss: 2.0186 - val_accuracy: 0.1707 - 286ms/epoch - 95ms/step\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 163: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1510 - accuracy: 1.0000 - val_loss: 1.9958 - val_accuracy: 0.1707 - 272ms/epoch - 91ms/step\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 164: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1537 - accuracy: 1.0000 - val_loss: 2.0825 - val_accuracy: 0.2195 - 284ms/epoch - 95ms/step\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 165: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1486 - accuracy: 1.0000 - val_loss: 2.0233 - val_accuracy: 0.2195 - 271ms/epoch - 90ms/step\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 166: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1559 - accuracy: 1.0000 - val_loss: 2.1032 - val_accuracy: 0.2439 - 269ms/epoch - 90ms/step\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 167: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1475 - accuracy: 1.0000 - val_loss: 2.1456 - val_accuracy: 0.2195 - 272ms/epoch - 91ms/step\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 168: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1527 - accuracy: 1.0000 - val_loss: 2.0609 - val_accuracy: 0.1951 - 275ms/epoch - 92ms/step\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 169: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1470 - accuracy: 1.0000 - val_loss: 1.9615 - val_accuracy: 0.1707 - 270ms/epoch - 90ms/step\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 170: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1384 - accuracy: 1.0000 - val_loss: 2.0802 - val_accuracy: 0.2195 - 272ms/epoch - 91ms/step\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 171: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1651 - accuracy: 1.0000 - val_loss: 1.9981 - val_accuracy: 0.1463 - 274ms/epoch - 91ms/step\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 172: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1499 - accuracy: 1.0000 - val_loss: 1.9278 - val_accuracy: 0.2439 - 274ms/epoch - 91ms/step\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 173: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1496 - accuracy: 1.0000 - val_loss: 1.9191 - val_accuracy: 0.1951 - 267ms/epoch - 89ms/step\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 174: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1595 - accuracy: 1.0000 - val_loss: 1.9415 - val_accuracy: 0.1951 - 285ms/epoch - 95ms/step\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 175: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1677 - accuracy: 1.0000 - val_loss: 1.9807 - val_accuracy: 0.1951 - 264ms/epoch - 88ms/step\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 176: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1455 - accuracy: 1.0000 - val_loss: 2.0312 - val_accuracy: 0.2195 - 297ms/epoch - 99ms/step\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 177: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1561 - accuracy: 1.0000 - val_loss: 1.8734 - val_accuracy: 0.1951 - 282ms/epoch - 94ms/step\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 178: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1230 - accuracy: 1.0000 - val_loss: 1.7551 - val_accuracy: 0.2195 - 282ms/epoch - 94ms/step\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 179: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1320 - accuracy: 1.0000 - val_loss: 1.9137 - val_accuracy: 0.1707 - 279ms/epoch - 93ms/step\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 180: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1279 - accuracy: 1.0000 - val_loss: 1.9046 - val_accuracy: 0.2195 - 278ms/epoch - 93ms/step\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 181: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1369 - accuracy: 1.0000 - val_loss: 2.0024 - val_accuracy: 0.1951 - 286ms/epoch - 95ms/step\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 182: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1420 - accuracy: 1.0000 - val_loss: 1.9021 - val_accuracy: 0.1951 - 271ms/epoch - 90ms/step\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 183: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1427 - accuracy: 1.0000 - val_loss: 1.9434 - val_accuracy: 0.1707 - 267ms/epoch - 89ms/step\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 184: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1248 - accuracy: 1.0000 - val_loss: 1.9922 - val_accuracy: 0.1951 - 269ms/epoch - 90ms/step\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 185: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1385 - accuracy: 1.0000 - val_loss: 2.0230 - val_accuracy: 0.1951 - 292ms/epoch - 97ms/step\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 186: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1327 - accuracy: 1.0000 - val_loss: 2.0057 - val_accuracy: 0.1707 - 294ms/epoch - 98ms/step\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 187: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1287 - accuracy: 1.0000 - val_loss: 1.9741 - val_accuracy: 0.2195 - 281ms/epoch - 94ms/step\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 188: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1163 - accuracy: 1.0000 - val_loss: 2.1162 - val_accuracy: 0.1707 - 270ms/epoch - 90ms/step\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 189: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1144 - accuracy: 1.0000 - val_loss: 1.9634 - val_accuracy: 0.1951 - 277ms/epoch - 92ms/step\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 190: val_loss did not improve from 1.38653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 0.1188 - accuracy: 1.0000 - val_loss: 2.0036 - val_accuracy: 0.1707 - 278ms/epoch - 93ms/step\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 191: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1038 - accuracy: 1.0000 - val_loss: 1.8995 - val_accuracy: 0.2195 - 281ms/epoch - 94ms/step\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 192: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1223 - accuracy: 1.0000 - val_loss: 1.9619 - val_accuracy: 0.1707 - 275ms/epoch - 92ms/step\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 193: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1269 - accuracy: 1.0000 - val_loss: 1.8822 - val_accuracy: 0.1951 - 273ms/epoch - 91ms/step\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 194: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1151 - accuracy: 1.0000 - val_loss: 1.9108 - val_accuracy: 0.2195 - 265ms/epoch - 88ms/step\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 195: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1400 - accuracy: 1.0000 - val_loss: 1.8032 - val_accuracy: 0.2683 - 283ms/epoch - 94ms/step\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 196: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1269 - accuracy: 1.0000 - val_loss: 1.9204 - val_accuracy: 0.1707 - 267ms/epoch - 89ms/step\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 197: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1275 - accuracy: 0.9894 - val_loss: 1.9052 - val_accuracy: 0.1707 - 281ms/epoch - 94ms/step\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 198: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1105 - accuracy: 1.0000 - val_loss: 1.8713 - val_accuracy: 0.1707 - 295ms/epoch - 98ms/step\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 199: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1167 - accuracy: 1.0000 - val_loss: 2.0339 - val_accuracy: 0.1707 - 275ms/epoch - 92ms/step\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 200: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1174 - accuracy: 1.0000 - val_loss: 1.8622 - val_accuracy: 0.2927 - 273ms/epoch - 91ms/step\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 201: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1159 - accuracy: 1.0000 - val_loss: 1.9337 - val_accuracy: 0.2195 - 270ms/epoch - 90ms/step\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 202: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1293 - accuracy: 1.0000 - val_loss: 1.9543 - val_accuracy: 0.2195 - 272ms/epoch - 91ms/step\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 203: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1001 - accuracy: 1.0000 - val_loss: 2.0502 - val_accuracy: 0.1220 - 270ms/epoch - 90ms/step\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 204: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1252 - accuracy: 1.0000 - val_loss: 2.0047 - val_accuracy: 0.2195 - 279ms/epoch - 93ms/step\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 205: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1114 - accuracy: 1.0000 - val_loss: 2.0008 - val_accuracy: 0.2439 - 271ms/epoch - 90ms/step\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 206: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1208 - accuracy: 1.0000 - val_loss: 1.9006 - val_accuracy: 0.2683 - 278ms/epoch - 93ms/step\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 207: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1191 - accuracy: 1.0000 - val_loss: 1.8485 - val_accuracy: 0.2927 - 282ms/epoch - 94ms/step\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 208: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1167 - accuracy: 1.0000 - val_loss: 1.9570 - val_accuracy: 0.2927 - 281ms/epoch - 94ms/step\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 209: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1049 - accuracy: 1.0000 - val_loss: 1.9130 - val_accuracy: 0.2439 - 267ms/epoch - 89ms/step\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 210: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1207 - accuracy: 1.0000 - val_loss: 1.9886 - val_accuracy: 0.2927 - 289ms/epoch - 96ms/step\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 211: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1041 - accuracy: 1.0000 - val_loss: 1.9266 - val_accuracy: 0.2683 - 275ms/epoch - 92ms/step\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 212: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1216 - accuracy: 1.0000 - val_loss: 1.9075 - val_accuracy: 0.2927 - 280ms/epoch - 93ms/step\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 213: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1169 - accuracy: 1.0000 - val_loss: 1.9458 - val_accuracy: 0.2683 - 286ms/epoch - 95ms/step\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 214: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1075 - accuracy: 1.0000 - val_loss: 1.9393 - val_accuracy: 0.3171 - 275ms/epoch - 92ms/step\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 215: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0987 - accuracy: 1.0000 - val_loss: 1.8661 - val_accuracy: 0.3171 - 282ms/epoch - 94ms/step\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 216: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0930 - accuracy: 1.0000 - val_loss: 1.9360 - val_accuracy: 0.3415 - 301ms/epoch - 100ms/step\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 217: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1016 - accuracy: 1.0000 - val_loss: 1.8849 - val_accuracy: 0.2927 - 280ms/epoch - 93ms/step\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 218: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1016 - accuracy: 1.0000 - val_loss: 1.8571 - val_accuracy: 0.2683 - 269ms/epoch - 90ms/step\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 219: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1164 - accuracy: 1.0000 - val_loss: 1.9544 - val_accuracy: 0.2683 - 272ms/epoch - 91ms/step\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 220: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1027 - accuracy: 1.0000 - val_loss: 1.9426 - val_accuracy: 0.2195 - 268ms/epoch - 89ms/step\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 221: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0979 - accuracy: 1.0000 - val_loss: 1.8953 - val_accuracy: 0.3171 - 280ms/epoch - 93ms/step\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 222: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1030 - accuracy: 1.0000 - val_loss: 1.9229 - val_accuracy: 0.2683 - 269ms/epoch - 90ms/step\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 223: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1026 - accuracy: 1.0000 - val_loss: 1.9090 - val_accuracy: 0.3171 - 273ms/epoch - 91ms/step\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 224: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1011 - accuracy: 1.0000 - val_loss: 1.9177 - val_accuracy: 0.3415 - 289ms/epoch - 96ms/step\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 225: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0989 - accuracy: 1.0000 - val_loss: 1.9566 - val_accuracy: 0.3171 - 269ms/epoch - 90ms/step\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 226: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0945 - accuracy: 1.0000 - val_loss: 1.9555 - val_accuracy: 0.3171 - 269ms/epoch - 90ms/step\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 227: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0986 - accuracy: 1.0000 - val_loss: 1.9368 - val_accuracy: 0.3171 - 270ms/epoch - 90ms/step\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 228: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0852 - accuracy: 1.0000 - val_loss: 1.9313 - val_accuracy: 0.2683 - 274ms/epoch - 91ms/step\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 229: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0926 - accuracy: 1.0000 - val_loss: 1.9419 - val_accuracy: 0.3171 - 274ms/epoch - 91ms/step\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 230: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0986 - accuracy: 1.0000 - val_loss: 1.9018 - val_accuracy: 0.2683 - 272ms/epoch - 91ms/step\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 231: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0837 - accuracy: 1.0000 - val_loss: 1.8925 - val_accuracy: 0.3171 - 277ms/epoch - 92ms/step\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 232: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0927 - accuracy: 1.0000 - val_loss: 1.8808 - val_accuracy: 0.3171 - 281ms/epoch - 94ms/step\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 233: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0883 - accuracy: 1.0000 - val_loss: 1.8865 - val_accuracy: 0.3415 - 271ms/epoch - 90ms/step\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 234: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0893 - accuracy: 1.0000 - val_loss: 1.9056 - val_accuracy: 0.3415 - 290ms/epoch - 97ms/step\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 235: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0874 - accuracy: 1.0000 - val_loss: 1.9343 - val_accuracy: 0.3171 - 290ms/epoch - 97ms/step\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 236: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0927 - accuracy: 1.0000 - val_loss: 1.9103 - val_accuracy: 0.3171 - 286ms/epoch - 95ms/step\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 237: val_loss did not improve from 1.38653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 0.0921 - accuracy: 1.0000 - val_loss: 1.9637 - val_accuracy: 0.3171 - 283ms/epoch - 94ms/step\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 238: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1128 - accuracy: 1.0000 - val_loss: 2.0426 - val_accuracy: 0.2439 - 269ms/epoch - 90ms/step\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 239: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0893 - accuracy: 1.0000 - val_loss: 2.0305 - val_accuracy: 0.2927 - 266ms/epoch - 89ms/step\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 240: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0916 - accuracy: 1.0000 - val_loss: 1.9456 - val_accuracy: 0.2927 - 279ms/epoch - 93ms/step\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 241: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0860 - accuracy: 1.0000 - val_loss: 1.9642 - val_accuracy: 0.3415 - 281ms/epoch - 94ms/step\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 242: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0869 - accuracy: 1.0000 - val_loss: 2.0066 - val_accuracy: 0.3659 - 282ms/epoch - 94ms/step\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 243: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0930 - accuracy: 1.0000 - val_loss: 1.9748 - val_accuracy: 0.2927 - 271ms/epoch - 90ms/step\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 244: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0877 - accuracy: 1.0000 - val_loss: 1.9720 - val_accuracy: 0.3659 - 273ms/epoch - 91ms/step\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 245: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0866 - accuracy: 1.0000 - val_loss: 1.9527 - val_accuracy: 0.3659 - 272ms/epoch - 91ms/step\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 246: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0810 - accuracy: 1.0000 - val_loss: 1.9544 - val_accuracy: 0.2683 - 275ms/epoch - 92ms/step\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 247: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0786 - accuracy: 1.0000 - val_loss: 1.9680 - val_accuracy: 0.3415 - 273ms/epoch - 91ms/step\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 248: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0907 - accuracy: 1.0000 - val_loss: 1.9695 - val_accuracy: 0.2683 - 281ms/epoch - 94ms/step\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 249: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0844 - accuracy: 1.0000 - val_loss: 1.9707 - val_accuracy: 0.3171 - 276ms/epoch - 92ms/step\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 250: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0811 - accuracy: 1.0000 - val_loss: 1.9500 - val_accuracy: 0.2927 - 276ms/epoch - 92ms/step\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 251: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0831 - accuracy: 1.0000 - val_loss: 1.9930 - val_accuracy: 0.3171 - 275ms/epoch - 92ms/step\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 252: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0777 - accuracy: 1.0000 - val_loss: 1.9918 - val_accuracy: 0.3659 - 290ms/epoch - 97ms/step\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 253: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0849 - accuracy: 1.0000 - val_loss: 1.9628 - val_accuracy: 0.3171 - 286ms/epoch - 95ms/step\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 254: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0851 - accuracy: 1.0000 - val_loss: 2.0589 - val_accuracy: 0.2439 - 284ms/epoch - 95ms/step\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 255: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0782 - accuracy: 1.0000 - val_loss: 2.1060 - val_accuracy: 0.3659 - 275ms/epoch - 92ms/step\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 256: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.1003 - accuracy: 1.0000 - val_loss: 2.0305 - val_accuracy: 0.2439 - 280ms/epoch - 93ms/step\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 257: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0933 - accuracy: 1.0000 - val_loss: 2.0266 - val_accuracy: 0.3659 - 279ms/epoch - 93ms/step\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 258: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0931 - accuracy: 1.0000 - val_loss: 2.0346 - val_accuracy: 0.2927 - 277ms/epoch - 92ms/step\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 259: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0866 - accuracy: 1.0000 - val_loss: 1.9625 - val_accuracy: 0.2927 - 291ms/epoch - 97ms/step\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 260: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0936 - accuracy: 1.0000 - val_loss: 1.9858 - val_accuracy: 0.2683 - 268ms/epoch - 89ms/step\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 261: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0877 - accuracy: 1.0000 - val_loss: 2.0206 - val_accuracy: 0.2927 - 280ms/epoch - 93ms/step\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 262: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0893 - accuracy: 1.0000 - val_loss: 1.9786 - val_accuracy: 0.2683 - 268ms/epoch - 89ms/step\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 263: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0984 - accuracy: 1.0000 - val_loss: 1.9739 - val_accuracy: 0.3171 - 279ms/epoch - 93ms/step\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 264: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0996 - accuracy: 1.0000 - val_loss: 2.0055 - val_accuracy: 0.3171 - 275ms/epoch - 92ms/step\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 265: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0803 - accuracy: 1.0000 - val_loss: 2.0086 - val_accuracy: 0.3659 - 275ms/epoch - 92ms/step\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 266: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0816 - accuracy: 1.0000 - val_loss: 2.0515 - val_accuracy: 0.3415 - 274ms/epoch - 91ms/step\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 267: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0807 - accuracy: 1.0000 - val_loss: 2.0407 - val_accuracy: 0.3171 - 269ms/epoch - 90ms/step\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 268: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0699 - accuracy: 1.0000 - val_loss: 1.9995 - val_accuracy: 0.3171 - 283ms/epoch - 94ms/step\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 269: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0734 - accuracy: 1.0000 - val_loss: 2.0284 - val_accuracy: 0.2927 - 279ms/epoch - 93ms/step\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 270: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0757 - accuracy: 1.0000 - val_loss: 2.0408 - val_accuracy: 0.2927 - 291ms/epoch - 97ms/step\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 271: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0715 - accuracy: 1.0000 - val_loss: 2.0990 - val_accuracy: 0.3415 - 270ms/epoch - 90ms/step\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 272: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0829 - accuracy: 1.0000 - val_loss: 2.0873 - val_accuracy: 0.2927 - 272ms/epoch - 91ms/step\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 273: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0842 - accuracy: 1.0000 - val_loss: 2.0023 - val_accuracy: 0.3171 - 267ms/epoch - 89ms/step\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 274: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0690 - accuracy: 1.0000 - val_loss: 1.9955 - val_accuracy: 0.3171 - 270ms/epoch - 90ms/step\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 275: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0762 - accuracy: 1.0000 - val_loss: 2.0057 - val_accuracy: 0.3415 - 267ms/epoch - 89ms/step\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 276: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0703 - accuracy: 1.0000 - val_loss: 2.0585 - val_accuracy: 0.3171 - 283ms/epoch - 94ms/step\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 277: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0675 - accuracy: 1.0000 - val_loss: 2.0120 - val_accuracy: 0.2927 - 264ms/epoch - 88ms/step\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 278: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0764 - accuracy: 1.0000 - val_loss: 2.0264 - val_accuracy: 0.2683 - 271ms/epoch - 90ms/step\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 279: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0851 - accuracy: 1.0000 - val_loss: 2.0593 - val_accuracy: 0.3171 - 268ms/epoch - 89ms/step\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 280: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0711 - accuracy: 1.0000 - val_loss: 1.9734 - val_accuracy: 0.3415 - 266ms/epoch - 89ms/step\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 281: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0700 - accuracy: 1.0000 - val_loss: 1.9288 - val_accuracy: 0.3659 - 282ms/epoch - 94ms/step\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 282: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0684 - accuracy: 1.0000 - val_loss: 2.0068 - val_accuracy: 0.3171 - 293ms/epoch - 98ms/step\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 283: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0760 - accuracy: 1.0000 - val_loss: 2.0249 - val_accuracy: 0.3171 - 290ms/epoch - 97ms/step\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 284: val_loss did not improve from 1.38653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 0.0722 - accuracy: 1.0000 - val_loss: 2.0254 - val_accuracy: 0.2683 - 271ms/epoch - 90ms/step\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 285: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0643 - accuracy: 1.0000 - val_loss: 2.0506 - val_accuracy: 0.3171 - 275ms/epoch - 92ms/step\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 286: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0784 - accuracy: 1.0000 - val_loss: 2.0132 - val_accuracy: 0.2927 - 271ms/epoch - 90ms/step\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 287: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0701 - accuracy: 1.0000 - val_loss: 1.9316 - val_accuracy: 0.3171 - 289ms/epoch - 96ms/step\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 288: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0546 - accuracy: 1.0000 - val_loss: 1.9360 - val_accuracy: 0.3171 - 283ms/epoch - 94ms/step\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 289: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0618 - accuracy: 1.0000 - val_loss: 1.9890 - val_accuracy: 0.3171 - 271ms/epoch - 90ms/step\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 290: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0704 - accuracy: 1.0000 - val_loss: 2.0160 - val_accuracy: 0.3171 - 267ms/epoch - 89ms/step\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 291: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0727 - accuracy: 1.0000 - val_loss: 1.9879 - val_accuracy: 0.2683 - 279ms/epoch - 93ms/step\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 292: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0686 - accuracy: 1.0000 - val_loss: 1.9828 - val_accuracy: 0.2927 - 273ms/epoch - 91ms/step\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 293: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0696 - accuracy: 1.0000 - val_loss: 1.9866 - val_accuracy: 0.2927 - 296ms/epoch - 99ms/step\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 294: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0728 - accuracy: 1.0000 - val_loss: 2.0072 - val_accuracy: 0.2683 - 283ms/epoch - 94ms/step\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 295: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0646 - accuracy: 1.0000 - val_loss: 2.0660 - val_accuracy: 0.3171 - 276ms/epoch - 92ms/step\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 296: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0675 - accuracy: 1.0000 - val_loss: 2.0740 - val_accuracy: 0.3171 - 272ms/epoch - 91ms/step\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 297: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0661 - accuracy: 1.0000 - val_loss: 2.0873 - val_accuracy: 0.2927 - 285ms/epoch - 95ms/step\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 298: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0830 - accuracy: 1.0000 - val_loss: 2.0511 - val_accuracy: 0.3171 - 264ms/epoch - 88ms/step\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 299: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0657 - accuracy: 1.0000 - val_loss: 2.0274 - val_accuracy: 0.2683 - 274ms/epoch - 91ms/step\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 300: val_loss did not improve from 1.38653\n",
      "3/3 - 0s - loss: 0.0799 - accuracy: 1.0000 - val_loss: 1.9868 - val_accuracy: 0.3171 - 278ms/epoch - 93ms/step\n",
      "2/2 [==============================] - 0s 56ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2022-11-11 09:22:57.550166: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_8870696\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:582802\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 09:23:01.823230: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_8873761\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:582850\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38632, saving model to checkpoint1.h5\n",
      "3/3 - 6s - loss: 1.3948 - accuracy: 0.2553 - val_loss: 1.3863 - val_accuracy: 0.2683 - 6s/epoch - 2s/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 1.3433 - accuracy: 0.3723 - val_loss: 1.3865 - val_accuracy: 0.2195 - 276ms/epoch - 92ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 1.2804 - accuracy: 0.5426 - val_loss: 1.3867 - val_accuracy: 0.1951 - 270ms/epoch - 90ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 1.2469 - accuracy: 0.5000 - val_loss: 1.3868 - val_accuracy: 0.1951 - 272ms/epoch - 91ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 1.2216 - accuracy: 0.5638 - val_loss: 1.3868 - val_accuracy: 0.2439 - 278ms/epoch - 93ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 1.2214 - accuracy: 0.5745 - val_loss: 1.3869 - val_accuracy: 0.2195 - 285ms/epoch - 95ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 1.1780 - accuracy: 0.5957 - val_loss: 1.3871 - val_accuracy: 0.1707 - 270ms/epoch - 90ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 1.1724 - accuracy: 0.6383 - val_loss: 1.3871 - val_accuracy: 0.2439 - 281ms/epoch - 94ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 1.1159 - accuracy: 0.6915 - val_loss: 1.3870 - val_accuracy: 0.2439 - 279ms/epoch - 93ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 1.1173 - accuracy: 0.7128 - val_loss: 1.3869 - val_accuracy: 0.2439 - 275ms/epoch - 92ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 1.0727 - accuracy: 0.6915 - val_loss: 1.3873 - val_accuracy: 0.1951 - 287ms/epoch - 96ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 1.0798 - accuracy: 0.7234 - val_loss: 1.3878 - val_accuracy: 0.1951 - 287ms/epoch - 96ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 1.0377 - accuracy: 0.7660 - val_loss: 1.3879 - val_accuracy: 0.1951 - 280ms/epoch - 93ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 1.0701 - accuracy: 0.6277 - val_loss: 1.3876 - val_accuracy: 0.2683 - 277ms/epoch - 92ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 1.0225 - accuracy: 0.7872 - val_loss: 1.3871 - val_accuracy: 0.2683 - 272ms/epoch - 91ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.9605 - accuracy: 0.8404 - val_loss: 1.3873 - val_accuracy: 0.2195 - 284ms/epoch - 95ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 1.0088 - accuracy: 0.7766 - val_loss: 1.3877 - val_accuracy: 0.2439 - 276ms/epoch - 92ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.9345 - accuracy: 0.8085 - val_loss: 1.3882 - val_accuracy: 0.1951 - 275ms/epoch - 92ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.9686 - accuracy: 0.7660 - val_loss: 1.3881 - val_accuracy: 0.1951 - 273ms/epoch - 91ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.9470 - accuracy: 0.8404 - val_loss: 1.3878 - val_accuracy: 0.2683 - 278ms/epoch - 93ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.8823 - accuracy: 0.8298 - val_loss: 1.3879 - val_accuracy: 0.1951 - 271ms/epoch - 90ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.9277 - accuracy: 0.8404 - val_loss: 1.3887 - val_accuracy: 0.2439 - 284ms/epoch - 95ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.8720 - accuracy: 0.8511 - val_loss: 1.3892 - val_accuracy: 0.1463 - 272ms/epoch - 91ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.8927 - accuracy: 0.8191 - val_loss: 1.3890 - val_accuracy: 0.1951 - 280ms/epoch - 93ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.8737 - accuracy: 0.9149 - val_loss: 1.3892 - val_accuracy: 0.1951 - 274ms/epoch - 91ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.8472 - accuracy: 0.8404 - val_loss: 1.3893 - val_accuracy: 0.1951 - 264ms/epoch - 88ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.8568 - accuracy: 0.8723 - val_loss: 1.3894 - val_accuracy: 0.1951 - 275ms/epoch - 92ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.8053 - accuracy: 0.8617 - val_loss: 1.3896 - val_accuracy: 0.2195 - 283ms/epoch - 94ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.8162 - accuracy: 0.8830 - val_loss: 1.3898 - val_accuracy: 0.2195 - 270ms/epoch - 90ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.8129 - accuracy: 0.8723 - val_loss: 1.3899 - val_accuracy: 0.2195 - 279ms/epoch - 93ms/step\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.7909 - accuracy: 0.8617 - val_loss: 1.3905 - val_accuracy: 0.2683 - 278ms/epoch - 93ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.7893 - accuracy: 0.9149 - val_loss: 1.3917 - val_accuracy: 0.2195 - 275ms/epoch - 92ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.8002 - accuracy: 0.9043 - val_loss: 1.3909 - val_accuracy: 0.1951 - 275ms/epoch - 92ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.7832 - accuracy: 0.9149 - val_loss: 1.3914 - val_accuracy: 0.1951 - 279ms/epoch - 93ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.7579 - accuracy: 0.9362 - val_loss: 1.3951 - val_accuracy: 0.1951 - 280ms/epoch - 93ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.7646 - accuracy: 0.9043 - val_loss: 1.3951 - val_accuracy: 0.1463 - 272ms/epoch - 91ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.7406 - accuracy: 0.9255 - val_loss: 1.3923 - val_accuracy: 0.1707 - 269ms/epoch - 90ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.7517 - accuracy: 0.9255 - val_loss: 1.3930 - val_accuracy: 0.1707 - 272ms/epoch - 91ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.7243 - accuracy: 0.9043 - val_loss: 1.3954 - val_accuracy: 0.1951 - 270ms/epoch - 90ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.6672 - accuracy: 0.9787 - val_loss: 1.3956 - val_accuracy: 0.2439 - 275ms/epoch - 92ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.6797 - accuracy: 0.9574 - val_loss: 1.3926 - val_accuracy: 0.1951 - 275ms/epoch - 92ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.6751 - accuracy: 0.9468 - val_loss: 1.3945 - val_accuracy: 0.2439 - 279ms/epoch - 93ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.6355 - accuracy: 0.9681 - val_loss: 1.3968 - val_accuracy: 0.1951 - 280ms/epoch - 93ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.6613 - accuracy: 0.9362 - val_loss: 1.3983 - val_accuracy: 0.1707 - 274ms/epoch - 91ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.6775 - accuracy: 0.9362 - val_loss: 1.3959 - val_accuracy: 0.2683 - 272ms/epoch - 91ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.6274 - accuracy: 0.9574 - val_loss: 1.3979 - val_accuracy: 0.1951 - 272ms/epoch - 91ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.6563 - accuracy: 0.9681 - val_loss: 1.4020 - val_accuracy: 0.1463 - 284ms/epoch - 95ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.6395 - accuracy: 0.9574 - val_loss: 1.3989 - val_accuracy: 0.2195 - 287ms/epoch - 96ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.6557 - accuracy: 0.9468 - val_loss: 1.4042 - val_accuracy: 0.1951 - 276ms/epoch - 92ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.6085 - accuracy: 0.9787 - val_loss: 1.4054 - val_accuracy: 0.2195 - 270ms/epoch - 90ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.5731 - accuracy: 0.9787 - val_loss: 1.4011 - val_accuracy: 0.2195 - 271ms/epoch - 90ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.5947 - accuracy: 0.9681 - val_loss: 1.4082 - val_accuracy: 0.1951 - 279ms/epoch - 93ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.5852 - accuracy: 0.9681 - val_loss: 1.4047 - val_accuracy: 0.1951 - 273ms/epoch - 91ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.5778 - accuracy: 0.9681 - val_loss: 1.4081 - val_accuracy: 0.1463 - 278ms/epoch - 93ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.5973 - accuracy: 0.9681 - val_loss: 1.4117 - val_accuracy: 0.1951 - 290ms/epoch - 97ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.5758 - accuracy: 0.9894 - val_loss: 1.4129 - val_accuracy: 0.1463 - 270ms/epoch - 90ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.5559 - accuracy: 1.0000 - val_loss: 1.4159 - val_accuracy: 0.2195 - 268ms/epoch - 89ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.5484 - accuracy: 0.9894 - val_loss: 1.4200 - val_accuracy: 0.1951 - 271ms/epoch - 90ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.5085 - accuracy: 1.0000 - val_loss: 1.4161 - val_accuracy: 0.1951 - 271ms/epoch - 90ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.5322 - accuracy: 0.9787 - val_loss: 1.4195 - val_accuracy: 0.1951 - 270ms/epoch - 90ms/step\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.5129 - accuracy: 1.0000 - val_loss: 1.4244 - val_accuracy: 0.1951 - 283ms/epoch - 94ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.5022 - accuracy: 1.0000 - val_loss: 1.4196 - val_accuracy: 0.1951 - 274ms/epoch - 91ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.4876 - accuracy: 1.0000 - val_loss: 1.4287 - val_accuracy: 0.1951 - 267ms/epoch - 89ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.4975 - accuracy: 0.9894 - val_loss: 1.4297 - val_accuracy: 0.1951 - 280ms/epoch - 93ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.4695 - accuracy: 1.0000 - val_loss: 1.4302 - val_accuracy: 0.1707 - 275ms/epoch - 92ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.4893 - accuracy: 1.0000 - val_loss: 1.4338 - val_accuracy: 0.1951 - 288ms/epoch - 96ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.5078 - accuracy: 0.9574 - val_loss: 1.4349 - val_accuracy: 0.1951 - 277ms/epoch - 92ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.4720 - accuracy: 0.9894 - val_loss: 1.4434 - val_accuracy: 0.1707 - 279ms/epoch - 93ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.4727 - accuracy: 0.9787 - val_loss: 1.4314 - val_accuracy: 0.1951 - 283ms/epoch - 94ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.4402 - accuracy: 0.9894 - val_loss: 1.4452 - val_accuracy: 0.1951 - 289ms/epoch - 96ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.4820 - accuracy: 0.9787 - val_loss: 1.4347 - val_accuracy: 0.1951 - 288ms/epoch - 96ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.4658 - accuracy: 0.9894 - val_loss: 1.4486 - val_accuracy: 0.1951 - 276ms/epoch - 92ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.4669 - accuracy: 1.0000 - val_loss: 1.4642 - val_accuracy: 0.1951 - 274ms/epoch - 91ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.4298 - accuracy: 0.9894 - val_loss: 1.4614 - val_accuracy: 0.1951 - 283ms/epoch - 94ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.4063 - accuracy: 0.9894 - val_loss: 1.4564 - val_accuracy: 0.1951 - 261ms/epoch - 87ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.4036 - accuracy: 1.0000 - val_loss: 1.4766 - val_accuracy: 0.1951 - 283ms/epoch - 94ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.3947 - accuracy: 1.0000 - val_loss: 1.4690 - val_accuracy: 0.1951 - 282ms/epoch - 94ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.3742 - accuracy: 1.0000 - val_loss: 1.4631 - val_accuracy: 0.1951 - 279ms/epoch - 93ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.3844 - accuracy: 0.9894 - val_loss: 1.4675 - val_accuracy: 0.1951 - 280ms/epoch - 93ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.3635 - accuracy: 1.0000 - val_loss: 1.4634 - val_accuracy: 0.1951 - 273ms/epoch - 91ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.3774 - accuracy: 0.9787 - val_loss: 1.4907 - val_accuracy: 0.1951 - 273ms/epoch - 91ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.3534 - accuracy: 1.0000 - val_loss: 1.4719 - val_accuracy: 0.1951 - 283ms/epoch - 94ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.3864 - accuracy: 1.0000 - val_loss: 1.4788 - val_accuracy: 0.1951 - 276ms/epoch - 92ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.3924 - accuracy: 0.9894 - val_loss: 1.5101 - val_accuracy: 0.1951 - 272ms/epoch - 91ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.4013 - accuracy: 1.0000 - val_loss: 1.4661 - val_accuracy: 0.1951 - 270ms/epoch - 90ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.3777 - accuracy: 1.0000 - val_loss: 1.5595 - val_accuracy: 0.1951 - 280ms/epoch - 93ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.3569 - accuracy: 0.9894 - val_loss: 1.4952 - val_accuracy: 0.1951 - 278ms/epoch - 93ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.3723 - accuracy: 0.9894 - val_loss: 1.5035 - val_accuracy: 0.1951 - 277ms/epoch - 92ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.3634 - accuracy: 0.9894 - val_loss: 1.5049 - val_accuracy: 0.1951 - 273ms/epoch - 91ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.3451 - accuracy: 0.9894 - val_loss: 1.5217 - val_accuracy: 0.1463 - 280ms/epoch - 93ms/step\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.3205 - accuracy: 1.0000 - val_loss: 1.5716 - val_accuracy: 0.1951 - 270ms/epoch - 90ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.3531 - accuracy: 0.9894 - val_loss: 1.5272 - val_accuracy: 0.1463 - 277ms/epoch - 92ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.3498 - accuracy: 0.9894 - val_loss: 1.5582 - val_accuracy: 0.1707 - 276ms/epoch - 92ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.3365 - accuracy: 0.9894 - val_loss: 1.5879 - val_accuracy: 0.1951 - 275ms/epoch - 92ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.3319 - accuracy: 1.0000 - val_loss: 1.5604 - val_accuracy: 0.1707 - 283ms/epoch - 94ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 1.38632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 0.3318 - accuracy: 1.0000 - val_loss: 1.5350 - val_accuracy: 0.1951 - 277ms/epoch - 92ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.3453 - accuracy: 0.9894 - val_loss: 1.6032 - val_accuracy: 0.1951 - 279ms/epoch - 93ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.3667 - accuracy: 0.9894 - val_loss: 1.5851 - val_accuracy: 0.1220 - 283ms/epoch - 94ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.3331 - accuracy: 0.9894 - val_loss: 1.6094 - val_accuracy: 0.1951 - 284ms/epoch - 95ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.3006 - accuracy: 0.9894 - val_loss: 1.5331 - val_accuracy: 0.1951 - 281ms/epoch - 94ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.3200 - accuracy: 1.0000 - val_loss: 1.5859 - val_accuracy: 0.1951 - 270ms/epoch - 90ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.3172 - accuracy: 1.0000 - val_loss: 1.5986 - val_accuracy: 0.1951 - 275ms/epoch - 92ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.2770 - accuracy: 1.0000 - val_loss: 1.5962 - val_accuracy: 0.1707 - 272ms/epoch - 91ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.2816 - accuracy: 1.0000 - val_loss: 1.6259 - val_accuracy: 0.1951 - 285ms/epoch - 95ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.2973 - accuracy: 1.0000 - val_loss: 1.5870 - val_accuracy: 0.1951 - 284ms/epoch - 95ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.2872 - accuracy: 1.0000 - val_loss: 1.6458 - val_accuracy: 0.1951 - 279ms/epoch - 93ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.2884 - accuracy: 1.0000 - val_loss: 1.6253 - val_accuracy: 0.2195 - 289ms/epoch - 96ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.2719 - accuracy: 1.0000 - val_loss: 1.6014 - val_accuracy: 0.1951 - 267ms/epoch - 89ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.2585 - accuracy: 1.0000 - val_loss: 1.6217 - val_accuracy: 0.1951 - 273ms/epoch - 91ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.2732 - accuracy: 1.0000 - val_loss: 1.5909 - val_accuracy: 0.2195 - 279ms/epoch - 93ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.2630 - accuracy: 1.0000 - val_loss: 1.6107 - val_accuracy: 0.1951 - 271ms/epoch - 90ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.2568 - accuracy: 1.0000 - val_loss: 1.6037 - val_accuracy: 0.1951 - 282ms/epoch - 94ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.2618 - accuracy: 1.0000 - val_loss: 1.5934 - val_accuracy: 0.1951 - 284ms/epoch - 95ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.2358 - accuracy: 1.0000 - val_loss: 1.6573 - val_accuracy: 0.1951 - 272ms/epoch - 91ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.2443 - accuracy: 1.0000 - val_loss: 1.6498 - val_accuracy: 0.2195 - 283ms/epoch - 94ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.2586 - accuracy: 0.9894 - val_loss: 1.6411 - val_accuracy: 0.1951 - 287ms/epoch - 96ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.2662 - accuracy: 1.0000 - val_loss: 1.6439 - val_accuracy: 0.1707 - 273ms/epoch - 91ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.2681 - accuracy: 1.0000 - val_loss: 1.6851 - val_accuracy: 0.2195 - 280ms/epoch - 93ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.2649 - accuracy: 0.9894 - val_loss: 1.5820 - val_accuracy: 0.1707 - 281ms/epoch - 94ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.2314 - accuracy: 1.0000 - val_loss: 1.6354 - val_accuracy: 0.1463 - 275ms/epoch - 92ms/step\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.2332 - accuracy: 1.0000 - val_loss: 1.6700 - val_accuracy: 0.1951 - 272ms/epoch - 91ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.2551 - accuracy: 1.0000 - val_loss: 1.6035 - val_accuracy: 0.1951 - 280ms/epoch - 93ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 1.6810 - val_accuracy: 0.1707 - 273ms/epoch - 91ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.2266 - accuracy: 1.0000 - val_loss: 1.5801 - val_accuracy: 0.2195 - 289ms/epoch - 96ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.2194 - accuracy: 1.0000 - val_loss: 1.5961 - val_accuracy: 0.1951 - 275ms/epoch - 92ms/step\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 1.6585 - val_accuracy: 0.1463 - 268ms/epoch - 89ms/step\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.2177 - accuracy: 1.0000 - val_loss: 1.6197 - val_accuracy: 0.1707 - 281ms/epoch - 94ms/step\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.2378 - accuracy: 1.0000 - val_loss: 1.6823 - val_accuracy: 0.2195 - 281ms/epoch - 94ms/step\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1993 - accuracy: 1.0000 - val_loss: 1.6371 - val_accuracy: 0.1707 - 291ms/epoch - 97ms/step\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1979 - accuracy: 0.9894 - val_loss: 1.6450 - val_accuracy: 0.1951 - 277ms/epoch - 92ms/step\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 1.6204 - val_accuracy: 0.1951 - 273ms/epoch - 91ms/step\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1866 - accuracy: 1.0000 - val_loss: 1.6690 - val_accuracy: 0.1951 - 270ms/epoch - 90ms/step\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 1.6001 - val_accuracy: 0.1707 - 283ms/epoch - 94ms/step\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1857 - accuracy: 1.0000 - val_loss: 1.5970 - val_accuracy: 0.1707 - 275ms/epoch - 92ms/step\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 135: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1962 - accuracy: 1.0000 - val_loss: 1.6467 - val_accuracy: 0.1951 - 271ms/epoch - 90ms/step\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 136: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1700 - accuracy: 1.0000 - val_loss: 1.6616 - val_accuracy: 0.2195 - 270ms/epoch - 90ms/step\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 137: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1831 - accuracy: 1.0000 - val_loss: 1.7087 - val_accuracy: 0.2439 - 289ms/epoch - 96ms/step\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 138: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1999 - accuracy: 1.0000 - val_loss: 1.6183 - val_accuracy: 0.1707 - 276ms/epoch - 92ms/step\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 139: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1970 - accuracy: 1.0000 - val_loss: 1.7004 - val_accuracy: 0.2195 - 278ms/epoch - 93ms/step\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 140: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1665 - accuracy: 1.0000 - val_loss: 1.6945 - val_accuracy: 0.2195 - 270ms/epoch - 90ms/step\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 141: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1841 - accuracy: 1.0000 - val_loss: 1.6255 - val_accuracy: 0.2195 - 266ms/epoch - 89ms/step\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 142: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1991 - accuracy: 1.0000 - val_loss: 1.7633 - val_accuracy: 0.2683 - 286ms/epoch - 95ms/step\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 143: val_loss did not improve from 1.38632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 0.2012 - accuracy: 1.0000 - val_loss: 1.6292 - val_accuracy: 0.2195 - 282ms/epoch - 94ms/step\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 144: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 1.7875 - val_accuracy: 0.2195 - 277ms/epoch - 92ms/step\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 145: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1995 - accuracy: 1.0000 - val_loss: 1.7339 - val_accuracy: 0.2683 - 267ms/epoch - 89ms/step\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 146: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1967 - accuracy: 1.0000 - val_loss: 1.6409 - val_accuracy: 0.2195 - 269ms/epoch - 90ms/step\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 147: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1929 - accuracy: 1.0000 - val_loss: 1.6746 - val_accuracy: 0.1951 - 274ms/epoch - 91ms/step\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 148: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1792 - accuracy: 1.0000 - val_loss: 1.7295 - val_accuracy: 0.1707 - 276ms/epoch - 92ms/step\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 149: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1852 - accuracy: 1.0000 - val_loss: 1.7566 - val_accuracy: 0.1951 - 282ms/epoch - 94ms/step\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 150: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1929 - accuracy: 1.0000 - val_loss: 1.6567 - val_accuracy: 0.2683 - 271ms/epoch - 90ms/step\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 151: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.2032 - accuracy: 1.0000 - val_loss: 1.6970 - val_accuracy: 0.2439 - 273ms/epoch - 91ms/step\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 152: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1844 - accuracy: 1.0000 - val_loss: 1.8254 - val_accuracy: 0.2683 - 292ms/epoch - 97ms/step\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 153: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1922 - accuracy: 1.0000 - val_loss: 1.7273 - val_accuracy: 0.1951 - 274ms/epoch - 91ms/step\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 154: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1673 - accuracy: 1.0000 - val_loss: 1.6977 - val_accuracy: 0.2439 - 286ms/epoch - 95ms/step\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 155: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1619 - accuracy: 1.0000 - val_loss: 1.8434 - val_accuracy: 0.2439 - 278ms/epoch - 93ms/step\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 156: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1761 - accuracy: 1.0000 - val_loss: 1.7619 - val_accuracy: 0.1951 - 270ms/epoch - 90ms/step\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 157: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.2080 - accuracy: 1.0000 - val_loss: 1.7621 - val_accuracy: 0.2439 - 269ms/epoch - 90ms/step\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 158: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1714 - accuracy: 1.0000 - val_loss: 1.7182 - val_accuracy: 0.2683 - 279ms/epoch - 93ms/step\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 159: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1529 - accuracy: 1.0000 - val_loss: 1.6553 - val_accuracy: 0.2195 - 277ms/epoch - 92ms/step\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 160: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1608 - accuracy: 1.0000 - val_loss: 1.8433 - val_accuracy: 0.1707 - 286ms/epoch - 95ms/step\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 161: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1637 - accuracy: 1.0000 - val_loss: 1.7706 - val_accuracy: 0.2683 - 276ms/epoch - 92ms/step\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 162: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1517 - accuracy: 1.0000 - val_loss: 1.6960 - val_accuracy: 0.2439 - 280ms/epoch - 93ms/step\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 163: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1633 - accuracy: 1.0000 - val_loss: 1.6849 - val_accuracy: 0.1951 - 266ms/epoch - 89ms/step\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 164: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1487 - accuracy: 1.0000 - val_loss: 1.6977 - val_accuracy: 0.2927 - 269ms/epoch - 90ms/step\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 165: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1661 - accuracy: 1.0000 - val_loss: 1.7333 - val_accuracy: 0.2195 - 281ms/epoch - 94ms/step\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 166: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1493 - accuracy: 1.0000 - val_loss: 1.7367 - val_accuracy: 0.2683 - 275ms/epoch - 92ms/step\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 167: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1606 - accuracy: 1.0000 - val_loss: 1.7110 - val_accuracy: 0.2195 - 274ms/epoch - 91ms/step\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 168: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1367 - accuracy: 1.0000 - val_loss: 1.7280 - val_accuracy: 0.2439 - 269ms/epoch - 90ms/step\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 169: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1436 - accuracy: 1.0000 - val_loss: 1.7189 - val_accuracy: 0.2439 - 280ms/epoch - 93ms/step\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 170: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1285 - accuracy: 1.0000 - val_loss: 1.7868 - val_accuracy: 0.2927 - 283ms/epoch - 94ms/step\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 171: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1395 - accuracy: 1.0000 - val_loss: 1.7169 - val_accuracy: 0.2683 - 272ms/epoch - 91ms/step\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 172: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1471 - accuracy: 1.0000 - val_loss: 1.7352 - val_accuracy: 0.2683 - 280ms/epoch - 93ms/step\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 173: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1469 - accuracy: 1.0000 - val_loss: 1.8002 - val_accuracy: 0.2439 - 289ms/epoch - 96ms/step\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 174: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1308 - accuracy: 1.0000 - val_loss: 1.6993 - val_accuracy: 0.2439 - 270ms/epoch - 90ms/step\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 175: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1433 - accuracy: 1.0000 - val_loss: 1.7604 - val_accuracy: 0.2927 - 273ms/epoch - 91ms/step\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 176: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1253 - accuracy: 1.0000 - val_loss: 1.7114 - val_accuracy: 0.2195 - 269ms/epoch - 90ms/step\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 177: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1413 - accuracy: 1.0000 - val_loss: 1.7440 - val_accuracy: 0.2683 - 277ms/epoch - 92ms/step\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 178: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1591 - accuracy: 1.0000 - val_loss: 1.7084 - val_accuracy: 0.2683 - 300ms/epoch - 100ms/step\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 179: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1289 - accuracy: 1.0000 - val_loss: 1.8788 - val_accuracy: 0.1951 - 274ms/epoch - 91ms/step\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 180: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1235 - accuracy: 1.0000 - val_loss: 1.7796 - val_accuracy: 0.2439 - 267ms/epoch - 89ms/step\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 181: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1322 - accuracy: 1.0000 - val_loss: 1.7158 - val_accuracy: 0.1951 - 269ms/epoch - 90ms/step\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 182: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1437 - accuracy: 1.0000 - val_loss: 1.8251 - val_accuracy: 0.2439 - 275ms/epoch - 92ms/step\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 183: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1275 - accuracy: 1.0000 - val_loss: 1.7603 - val_accuracy: 0.2195 - 273ms/epoch - 91ms/step\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 184: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1337 - accuracy: 1.0000 - val_loss: 1.8273 - val_accuracy: 0.2439 - 278ms/epoch - 93ms/step\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 185: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1513 - accuracy: 1.0000 - val_loss: 1.8022 - val_accuracy: 0.2195 - 278ms/epoch - 93ms/step\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 186: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1336 - accuracy: 1.0000 - val_loss: 1.9378 - val_accuracy: 0.2195 - 272ms/epoch - 91ms/step\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 187: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1343 - accuracy: 1.0000 - val_loss: 1.8134 - val_accuracy: 0.2195 - 269ms/epoch - 90ms/step\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 188: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1393 - accuracy: 1.0000 - val_loss: 1.8288 - val_accuracy: 0.2195 - 272ms/epoch - 91ms/step\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 189: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1129 - accuracy: 1.0000 - val_loss: 1.7742 - val_accuracy: 0.1951 - 269ms/epoch - 90ms/step\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 190: val_loss did not improve from 1.38632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 0.1330 - accuracy: 1.0000 - val_loss: 1.7604 - val_accuracy: 0.2439 - 279ms/epoch - 93ms/step\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 191: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1194 - accuracy: 1.0000 - val_loss: 1.8634 - val_accuracy: 0.2439 - 271ms/epoch - 90ms/step\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 192: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1258 - accuracy: 1.0000 - val_loss: 1.8095 - val_accuracy: 0.2683 - 283ms/epoch - 94ms/step\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 193: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1206 - accuracy: 1.0000 - val_loss: 1.8250 - val_accuracy: 0.2195 - 271ms/epoch - 90ms/step\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 194: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1287 - accuracy: 1.0000 - val_loss: 1.7953 - val_accuracy: 0.1951 - 277ms/epoch - 92ms/step\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 195: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1194 - accuracy: 1.0000 - val_loss: 1.7797 - val_accuracy: 0.1951 - 273ms/epoch - 91ms/step\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 196: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1173 - accuracy: 1.0000 - val_loss: 2.0603 - val_accuracy: 0.1951 - 286ms/epoch - 95ms/step\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 197: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1329 - accuracy: 1.0000 - val_loss: 1.7758 - val_accuracy: 0.2927 - 271ms/epoch - 90ms/step\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 198: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1105 - accuracy: 1.0000 - val_loss: 1.8293 - val_accuracy: 0.2683 - 289ms/epoch - 96ms/step\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 199: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1013 - accuracy: 1.0000 - val_loss: 1.7824 - val_accuracy: 0.2683 - 267ms/epoch - 89ms/step\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 200: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1202 - accuracy: 1.0000 - val_loss: 1.8794 - val_accuracy: 0.2683 - 270ms/epoch - 90ms/step\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 201: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1107 - accuracy: 1.0000 - val_loss: 1.7542 - val_accuracy: 0.2927 - 274ms/epoch - 91ms/step\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 202: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1117 - accuracy: 1.0000 - val_loss: 1.8853 - val_accuracy: 0.2683 - 290ms/epoch - 97ms/step\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 203: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1134 - accuracy: 1.0000 - val_loss: 1.8875 - val_accuracy: 0.2195 - 274ms/epoch - 91ms/step\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 204: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1039 - accuracy: 1.0000 - val_loss: 1.9970 - val_accuracy: 0.1951 - 287ms/epoch - 96ms/step\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 205: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1188 - accuracy: 1.0000 - val_loss: 1.8287 - val_accuracy: 0.1707 - 274ms/epoch - 91ms/step\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 206: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1060 - accuracy: 1.0000 - val_loss: 2.0365 - val_accuracy: 0.1951 - 293ms/epoch - 98ms/step\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 207: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1139 - accuracy: 1.0000 - val_loss: 1.9713 - val_accuracy: 0.1951 - 273ms/epoch - 91ms/step\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 208: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1142 - accuracy: 1.0000 - val_loss: 1.8998 - val_accuracy: 0.2683 - 286ms/epoch - 95ms/step\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 209: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1198 - accuracy: 1.0000 - val_loss: 1.9131 - val_accuracy: 0.2195 - 274ms/epoch - 91ms/step\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 210: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1133 - accuracy: 1.0000 - val_loss: 1.9574 - val_accuracy: 0.2195 - 272ms/epoch - 91ms/step\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 211: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1145 - accuracy: 1.0000 - val_loss: 2.0345 - val_accuracy: 0.2439 - 272ms/epoch - 91ms/step\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 212: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1098 - accuracy: 1.0000 - val_loss: 1.8304 - val_accuracy: 0.2927 - 276ms/epoch - 92ms/step\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 213: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1148 - accuracy: 1.0000 - val_loss: 1.7605 - val_accuracy: 0.2927 - 267ms/epoch - 89ms/step\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 214: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1306 - accuracy: 1.0000 - val_loss: 1.8195 - val_accuracy: 0.1951 - 276ms/epoch - 92ms/step\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 215: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1283 - accuracy: 0.9894 - val_loss: 1.8018 - val_accuracy: 0.2439 - 275ms/epoch - 92ms/step\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 216: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1040 - accuracy: 1.0000 - val_loss: 1.9035 - val_accuracy: 0.2195 - 279ms/epoch - 93ms/step\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 217: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1254 - accuracy: 1.0000 - val_loss: 2.0485 - val_accuracy: 0.1951 - 277ms/epoch - 92ms/step\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 218: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1117 - accuracy: 1.0000 - val_loss: 1.8439 - val_accuracy: 0.2195 - 273ms/epoch - 91ms/step\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 219: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1179 - accuracy: 1.0000 - val_loss: 1.7943 - val_accuracy: 0.2195 - 280ms/epoch - 93ms/step\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 220: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1061 - accuracy: 1.0000 - val_loss: 1.7449 - val_accuracy: 0.2683 - 275ms/epoch - 92ms/step\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 221: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1214 - accuracy: 1.0000 - val_loss: 1.8428 - val_accuracy: 0.1463 - 273ms/epoch - 91ms/step\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 222: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0860 - accuracy: 1.0000 - val_loss: 1.8454 - val_accuracy: 0.1463 - 274ms/epoch - 91ms/step\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 223: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1082 - accuracy: 1.0000 - val_loss: 1.8452 - val_accuracy: 0.1951 - 286ms/epoch - 95ms/step\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 224: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1092 - accuracy: 1.0000 - val_loss: 1.8609 - val_accuracy: 0.1220 - 271ms/epoch - 90ms/step\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 225: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1108 - accuracy: 1.0000 - val_loss: 1.8567 - val_accuracy: 0.2195 - 282ms/epoch - 94ms/step\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 226: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0960 - accuracy: 1.0000 - val_loss: 1.8262 - val_accuracy: 0.2439 - 288ms/epoch - 96ms/step\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 227: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1324 - accuracy: 1.0000 - val_loss: 1.8144 - val_accuracy: 0.2439 - 283ms/epoch - 94ms/step\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 228: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1118 - accuracy: 1.0000 - val_loss: 1.8287 - val_accuracy: 0.2195 - 275ms/epoch - 92ms/step\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 229: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1047 - accuracy: 1.0000 - val_loss: 1.9005 - val_accuracy: 0.2195 - 276ms/epoch - 92ms/step\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 230: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0967 - accuracy: 1.0000 - val_loss: 1.9385 - val_accuracy: 0.2195 - 271ms/epoch - 90ms/step\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 231: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1070 - accuracy: 1.0000 - val_loss: 1.8099 - val_accuracy: 0.1951 - 273ms/epoch - 91ms/step\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 232: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1194 - accuracy: 1.0000 - val_loss: 1.9497 - val_accuracy: 0.1707 - 285ms/epoch - 95ms/step\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 233: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1037 - accuracy: 1.0000 - val_loss: 1.7104 - val_accuracy: 0.2927 - 273ms/epoch - 91ms/step\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 234: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1060 - accuracy: 1.0000 - val_loss: 1.7953 - val_accuracy: 0.2195 - 280ms/epoch - 93ms/step\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 235: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1006 - accuracy: 1.0000 - val_loss: 1.7884 - val_accuracy: 0.3171 - 269ms/epoch - 90ms/step\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 236: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1066 - accuracy: 1.0000 - val_loss: 1.9643 - val_accuracy: 0.2439 - 271ms/epoch - 90ms/step\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 237: val_loss did not improve from 1.38632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 0.0905 - accuracy: 1.0000 - val_loss: 1.7760 - val_accuracy: 0.2439 - 272ms/epoch - 91ms/step\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 238: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0939 - accuracy: 1.0000 - val_loss: 1.7982 - val_accuracy: 0.2439 - 284ms/epoch - 95ms/step\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 239: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0910 - accuracy: 1.0000 - val_loss: 1.8844 - val_accuracy: 0.1951 - 282ms/epoch - 94ms/step\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 240: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0976 - accuracy: 1.0000 - val_loss: 1.7839 - val_accuracy: 0.1951 - 269ms/epoch - 90ms/step\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 241: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1053 - accuracy: 1.0000 - val_loss: 1.7337 - val_accuracy: 0.2683 - 278ms/epoch - 93ms/step\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 242: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0945 - accuracy: 1.0000 - val_loss: 1.7477 - val_accuracy: 0.2683 - 273ms/epoch - 91ms/step\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 243: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1004 - accuracy: 1.0000 - val_loss: 1.8664 - val_accuracy: 0.2439 - 270ms/epoch - 90ms/step\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 244: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0923 - accuracy: 1.0000 - val_loss: 1.7522 - val_accuracy: 0.2683 - 278ms/epoch - 93ms/step\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 245: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0883 - accuracy: 1.0000 - val_loss: 1.8494 - val_accuracy: 0.2195 - 286ms/epoch - 95ms/step\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 246: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1068 - accuracy: 1.0000 - val_loss: 1.8133 - val_accuracy: 0.2927 - 270ms/epoch - 90ms/step\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 247: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1037 - accuracy: 1.0000 - val_loss: 1.7642 - val_accuracy: 0.2439 - 281ms/epoch - 94ms/step\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 248: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1000 - accuracy: 1.0000 - val_loss: 1.8116 - val_accuracy: 0.3659 - 278ms/epoch - 93ms/step\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 249: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1029 - accuracy: 1.0000 - val_loss: 1.8911 - val_accuracy: 0.2439 - 281ms/epoch - 94ms/step\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 250: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0948 - accuracy: 1.0000 - val_loss: 1.8108 - val_accuracy: 0.2927 - 278ms/epoch - 93ms/step\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 251: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0974 - accuracy: 1.0000 - val_loss: 1.8323 - val_accuracy: 0.2683 - 269ms/epoch - 90ms/step\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 252: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1034 - accuracy: 1.0000 - val_loss: 1.8396 - val_accuracy: 0.2683 - 286ms/epoch - 95ms/step\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 253: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1017 - accuracy: 1.0000 - val_loss: 1.9038 - val_accuracy: 0.2927 - 284ms/epoch - 95ms/step\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 254: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1035 - accuracy: 1.0000 - val_loss: 1.9046 - val_accuracy: 0.1463 - 289ms/epoch - 96ms/step\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 255: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0973 - accuracy: 1.0000 - val_loss: 1.8453 - val_accuracy: 0.2683 - 266ms/epoch - 89ms/step\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 256: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0927 - accuracy: 1.0000 - val_loss: 1.9904 - val_accuracy: 0.1951 - 277ms/epoch - 92ms/step\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 257: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1011 - accuracy: 1.0000 - val_loss: 2.0850 - val_accuracy: 0.1951 - 267ms/epoch - 89ms/step\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 258: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1018 - accuracy: 1.0000 - val_loss: 2.0100 - val_accuracy: 0.2195 - 272ms/epoch - 91ms/step\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 259: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0902 - accuracy: 1.0000 - val_loss: 1.8989 - val_accuracy: 0.2439 - 272ms/epoch - 91ms/step\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 260: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0917 - accuracy: 1.0000 - val_loss: 1.9774 - val_accuracy: 0.2683 - 275ms/epoch - 92ms/step\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 261: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0922 - accuracy: 1.0000 - val_loss: 1.7641 - val_accuracy: 0.2927 - 272ms/epoch - 91ms/step\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 262: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0987 - accuracy: 1.0000 - val_loss: 1.8627 - val_accuracy: 0.2927 - 287ms/epoch - 96ms/step\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 263: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1135 - accuracy: 1.0000 - val_loss: 1.7904 - val_accuracy: 0.2927 - 273ms/epoch - 91ms/step\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 264: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0936 - accuracy: 1.0000 - val_loss: 1.9044 - val_accuracy: 0.2683 - 271ms/epoch - 90ms/step\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 265: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.1053 - accuracy: 1.0000 - val_loss: 1.7806 - val_accuracy: 0.2927 - 280ms/epoch - 93ms/step\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 266: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0849 - accuracy: 1.0000 - val_loss: 1.9243 - val_accuracy: 0.2439 - 270ms/epoch - 90ms/step\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 267: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0816 - accuracy: 1.0000 - val_loss: 1.8301 - val_accuracy: 0.2683 - 270ms/epoch - 90ms/step\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 268: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0916 - accuracy: 1.0000 - val_loss: 1.7901 - val_accuracy: 0.2683 - 284ms/epoch - 95ms/step\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 269: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0984 - accuracy: 1.0000 - val_loss: 1.9879 - val_accuracy: 0.2439 - 287ms/epoch - 96ms/step\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 270: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0882 - accuracy: 1.0000 - val_loss: 1.8149 - val_accuracy: 0.2439 - 275ms/epoch - 92ms/step\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 271: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0812 - accuracy: 1.0000 - val_loss: 1.8126 - val_accuracy: 0.2439 - 269ms/epoch - 90ms/step\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 272: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0683 - accuracy: 1.0000 - val_loss: 1.8002 - val_accuracy: 0.2683 - 289ms/epoch - 96ms/step\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 273: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0900 - accuracy: 1.0000 - val_loss: 1.8725 - val_accuracy: 0.2927 - 269ms/epoch - 90ms/step\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 274: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0830 - accuracy: 1.0000 - val_loss: 1.9047 - val_accuracy: 0.2927 - 277ms/epoch - 92ms/step\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 275: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0939 - accuracy: 1.0000 - val_loss: 1.9089 - val_accuracy: 0.2439 - 276ms/epoch - 92ms/step\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 276: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0821 - accuracy: 1.0000 - val_loss: 1.8665 - val_accuracy: 0.2683 - 270ms/epoch - 90ms/step\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 277: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0871 - accuracy: 1.0000 - val_loss: 1.9277 - val_accuracy: 0.2683 - 281ms/epoch - 94ms/step\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 278: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0813 - accuracy: 1.0000 - val_loss: 2.0358 - val_accuracy: 0.2439 - 267ms/epoch - 89ms/step\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 279: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0831 - accuracy: 1.0000 - val_loss: 1.9584 - val_accuracy: 0.2683 - 270ms/epoch - 90ms/step\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 280: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0799 - accuracy: 1.0000 - val_loss: 1.9679 - val_accuracy: 0.1707 - 287ms/epoch - 96ms/step\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 281: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0897 - accuracy: 1.0000 - val_loss: 1.8805 - val_accuracy: 0.3171 - 283ms/epoch - 94ms/step\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 282: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0936 - accuracy: 1.0000 - val_loss: 1.8448 - val_accuracy: 0.1951 - 286ms/epoch - 95ms/step\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 283: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0744 - accuracy: 1.0000 - val_loss: 1.9079 - val_accuracy: 0.2439 - 270ms/epoch - 90ms/step\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 284: val_loss did not improve from 1.38632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 0.0841 - accuracy: 1.0000 - val_loss: 1.8024 - val_accuracy: 0.2439 - 288ms/epoch - 96ms/step\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 285: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0876 - accuracy: 1.0000 - val_loss: 1.7860 - val_accuracy: 0.2195 - 267ms/epoch - 89ms/step\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 286: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0841 - accuracy: 1.0000 - val_loss: 1.9847 - val_accuracy: 0.2439 - 276ms/epoch - 92ms/step\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 287: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0747 - accuracy: 1.0000 - val_loss: 2.0925 - val_accuracy: 0.1951 - 282ms/epoch - 94ms/step\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 288: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0758 - accuracy: 1.0000 - val_loss: 2.0308 - val_accuracy: 0.2439 - 269ms/epoch - 90ms/step\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 289: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0845 - accuracy: 1.0000 - val_loss: 1.9515 - val_accuracy: 0.2439 - 280ms/epoch - 93ms/step\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 290: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0732 - accuracy: 1.0000 - val_loss: 1.9470 - val_accuracy: 0.2195 - 273ms/epoch - 91ms/step\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 291: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0827 - accuracy: 1.0000 - val_loss: 1.9109 - val_accuracy: 0.2195 - 274ms/epoch - 91ms/step\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 292: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0755 - accuracy: 1.0000 - val_loss: 1.9140 - val_accuracy: 0.2683 - 280ms/epoch - 93ms/step\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 293: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0758 - accuracy: 1.0000 - val_loss: 1.9488 - val_accuracy: 0.2195 - 274ms/epoch - 91ms/step\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 294: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0676 - accuracy: 1.0000 - val_loss: 1.8201 - val_accuracy: 0.3415 - 276ms/epoch - 92ms/step\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 295: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0803 - accuracy: 1.0000 - val_loss: 1.8239 - val_accuracy: 0.2195 - 264ms/epoch - 88ms/step\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 296: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0681 - accuracy: 1.0000 - val_loss: 1.7777 - val_accuracy: 0.2927 - 269ms/epoch - 90ms/step\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 297: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0746 - accuracy: 1.0000 - val_loss: 1.6849 - val_accuracy: 0.2927 - 278ms/epoch - 93ms/step\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 298: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0750 - accuracy: 1.0000 - val_loss: 1.8481 - val_accuracy: 0.2439 - 287ms/epoch - 96ms/step\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 299: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0662 - accuracy: 1.0000 - val_loss: 1.8922 - val_accuracy: 0.2683 - 284ms/epoch - 95ms/step\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 300: val_loss did not improve from 1.38632\n",
      "3/3 - 0s - loss: 0.0717 - accuracy: 1.0000 - val_loss: 1.8448 - val_accuracy: 0.2195 - 276ms/epoch - 92ms/step\n",
      "2/2 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2022-11-11 09:24:29.263396: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_8933504\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:587056\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 09:24:33.533753: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_8936569\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:587104\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38659, saving model to checkpoint1.h5\n",
      "3/3 - 6s - loss: 1.4366 - accuracy: 0.2447 - val_loss: 1.3866 - val_accuracy: 0.1951 - 6s/epoch - 2s/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss did not improve from 1.38659\n",
      "3/3 - 0s - loss: 1.3370 - accuracy: 0.3191 - val_loss: 1.3867 - val_accuracy: 0.1951 - 294ms/epoch - 98ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss did not improve from 1.38659\n",
      "3/3 - 0s - loss: 1.3006 - accuracy: 0.4468 - val_loss: 1.3869 - val_accuracy: 0.1951 - 283ms/epoch - 94ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss did not improve from 1.38659\n",
      "3/3 - 0s - loss: 1.2549 - accuracy: 0.5213 - val_loss: 1.3869 - val_accuracy: 0.1951 - 271ms/epoch - 90ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss did not improve from 1.38659\n",
      "3/3 - 0s - loss: 1.2291 - accuracy: 0.5532 - val_loss: 1.3868 - val_accuracy: 0.1951 - 271ms/epoch - 90ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.38659\n",
      "3/3 - 0s - loss: 1.1626 - accuracy: 0.5957 - val_loss: 1.3869 - val_accuracy: 0.1951 - 272ms/epoch - 91ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 1.38659\n",
      "3/3 - 0s - loss: 1.1583 - accuracy: 0.5851 - val_loss: 1.3868 - val_accuracy: 0.1951 - 266ms/epoch - 89ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 1.38659\n",
      "3/3 - 0s - loss: 1.1593 - accuracy: 0.6170 - val_loss: 1.3867 - val_accuracy: 0.1951 - 279ms/epoch - 93ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 1.38659\n",
      "3/3 - 0s - loss: 1.1041 - accuracy: 0.6383 - val_loss: 1.3867 - val_accuracy: 0.1951 - 281ms/epoch - 94ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.38659\n",
      "3/3 - 0s - loss: 1.0784 - accuracy: 0.6702 - val_loss: 1.3868 - val_accuracy: 0.1951 - 276ms/epoch - 92ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.38659\n",
      "3/3 - 0s - loss: 1.0755 - accuracy: 0.6489 - val_loss: 1.3869 - val_accuracy: 0.1951 - 280ms/epoch - 93ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.38659\n",
      "3/3 - 0s - loss: 1.0374 - accuracy: 0.7021 - val_loss: 1.3868 - val_accuracy: 0.1951 - 272ms/epoch - 91ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.38659\n",
      "3/3 - 0s - loss: 1.0353 - accuracy: 0.6809 - val_loss: 1.3867 - val_accuracy: 0.2195 - 268ms/epoch - 89ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 1.38659\n",
      "3/3 - 0s - loss: 1.0270 - accuracy: 0.6809 - val_loss: 1.3867 - val_accuracy: 0.3171 - 283ms/epoch - 94ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.38659\n",
      "3/3 - 0s - loss: 1.0158 - accuracy: 0.7128 - val_loss: 1.3868 - val_accuracy: 0.2195 - 274ms/epoch - 91ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 1.38659\n",
      "3/3 - 0s - loss: 0.9806 - accuracy: 0.6702 - val_loss: 1.3870 - val_accuracy: 0.2195 - 270ms/epoch - 90ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 1.38659\n",
      "3/3 - 0s - loss: 0.9359 - accuracy: 0.7872 - val_loss: 1.3871 - val_accuracy: 0.2195 - 284ms/epoch - 95ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 1.38659\n",
      "3/3 - 0s - loss: 0.9460 - accuracy: 0.7553 - val_loss: 1.3869 - val_accuracy: 0.2439 - 271ms/epoch - 90ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 1.38659\n",
      "3/3 - 0s - loss: 0.9245 - accuracy: 0.7766 - val_loss: 1.3867 - val_accuracy: 0.2927 - 284ms/epoch - 95ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss improved from 1.38659 to 1.38650, saving model to checkpoint1.h5\n",
      "3/3 - 0s - loss: 0.9080 - accuracy: 0.7766 - val_loss: 1.3865 - val_accuracy: 0.2927 - 324ms/epoch - 108ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 1.38650\n",
      "3/3 - 0s - loss: 0.9114 - accuracy: 0.7660 - val_loss: 1.3867 - val_accuracy: 0.2683 - 285ms/epoch - 95ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 1.38650\n",
      "3/3 - 0s - loss: 0.9013 - accuracy: 0.8085 - val_loss: 1.3873 - val_accuracy: 0.2439 - 282ms/epoch - 94ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 1.38650\n",
      "3/3 - 0s - loss: 0.8849 - accuracy: 0.7447 - val_loss: 1.3872 - val_accuracy: 0.2927 - 289ms/epoch - 96ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 1.38650\n",
      "3/3 - 0s - loss: 0.8344 - accuracy: 0.7766 - val_loss: 1.3868 - val_accuracy: 0.2927 - 272ms/epoch - 91ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.38650\n",
      "3/3 - 0s - loss: 0.8331 - accuracy: 0.8723 - val_loss: 1.3867 - val_accuracy: 0.2927 - 270ms/epoch - 90ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 1.38650\n",
      "3/3 - 0s - loss: 0.8265 - accuracy: 0.8191 - val_loss: 1.3868 - val_accuracy: 0.2927 - 270ms/epoch - 90ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 1.38650\n",
      "3/3 - 0s - loss: 0.8272 - accuracy: 0.8298 - val_loss: 1.3869 - val_accuracy: 0.2683 - 272ms/epoch - 91ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 1.38650\n",
      "3/3 - 0s - loss: 0.7510 - accuracy: 0.9043 - val_loss: 1.3868 - val_accuracy: 0.2683 - 292ms/epoch - 97ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 1.38650\n",
      "3/3 - 0s - loss: 0.7799 - accuracy: 0.8617 - val_loss: 1.3870 - val_accuracy: 0.2927 - 290ms/epoch - 97ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 1.38650\n",
      "3/3 - 0s - loss: 0.7734 - accuracy: 0.8617 - val_loss: 1.3866 - val_accuracy: 0.2927 - 275ms/epoch - 92ms/step\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 1.38650\n",
      "3/3 - 0s - loss: 0.7311 - accuracy: 0.9255 - val_loss: 1.3873 - val_accuracy: 0.2439 - 269ms/epoch - 90ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 1.38650\n",
      "3/3 - 0s - loss: 0.7567 - accuracy: 0.8617 - val_loss: 1.3877 - val_accuracy: 0.2683 - 271ms/epoch - 90ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 1.38650\n",
      "3/3 - 0s - loss: 0.7311 - accuracy: 0.8830 - val_loss: 1.3872 - val_accuracy: 0.2927 - 276ms/epoch - 92ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 1.38650\n",
      "3/3 - 0s - loss: 0.6898 - accuracy: 0.9255 - val_loss: 1.3887 - val_accuracy: 0.3171 - 279ms/epoch - 93ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 1.38650\n",
      "3/3 - 0s - loss: 0.7032 - accuracy: 0.9043 - val_loss: 1.3893 - val_accuracy: 0.2439 - 275ms/epoch - 92ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 1.38650\n",
      "3/3 - 0s - loss: 0.6931 - accuracy: 0.9468 - val_loss: 1.3870 - val_accuracy: 0.2927 - 289ms/epoch - 96ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 1.38650\n",
      "3/3 - 0s - loss: 0.6711 - accuracy: 0.9255 - val_loss: 1.3895 - val_accuracy: 0.2439 - 270ms/epoch - 90ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss improved from 1.38650 to 1.38607, saving model to checkpoint1.h5\n",
      "3/3 - 0s - loss: 0.6714 - accuracy: 0.9362 - val_loss: 1.3861 - val_accuracy: 0.2927 - 326ms/epoch - 109ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.6890 - accuracy: 0.8723 - val_loss: 1.3877 - val_accuracy: 0.2927 - 273ms/epoch - 91ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.6718 - accuracy: 0.9468 - val_loss: 1.3922 - val_accuracy: 0.2195 - 272ms/epoch - 91ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.6312 - accuracy: 0.9468 - val_loss: 1.3882 - val_accuracy: 0.2683 - 279ms/epoch - 93ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.6654 - accuracy: 0.9149 - val_loss: 1.3898 - val_accuracy: 0.2683 - 274ms/epoch - 91ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.6476 - accuracy: 0.9043 - val_loss: 1.3917 - val_accuracy: 0.2683 - 276ms/epoch - 92ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.6100 - accuracy: 0.9574 - val_loss: 1.3884 - val_accuracy: 0.3171 - 287ms/epoch - 96ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.5933 - accuracy: 0.9362 - val_loss: 1.3917 - val_accuracy: 0.2927 - 277ms/epoch - 92ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.5889 - accuracy: 0.9681 - val_loss: 1.3912 - val_accuracy: 0.3171 - 275ms/epoch - 92ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.5891 - accuracy: 0.9574 - val_loss: 1.3883 - val_accuracy: 0.2683 - 279ms/epoch - 93ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.5949 - accuracy: 0.9149 - val_loss: 1.3923 - val_accuracy: 0.2683 - 274ms/epoch - 91ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.5847 - accuracy: 0.9787 - val_loss: 1.3891 - val_accuracy: 0.2683 - 290ms/epoch - 97ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.5504 - accuracy: 0.9894 - val_loss: 1.3917 - val_accuracy: 0.2683 - 276ms/epoch - 92ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.5526 - accuracy: 0.9894 - val_loss: 1.3911 - val_accuracy: 0.2683 - 280ms/epoch - 93ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.5285 - accuracy: 0.9894 - val_loss: 1.3906 - val_accuracy: 0.2439 - 286ms/epoch - 95ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.5598 - accuracy: 0.9894 - val_loss: 1.3938 - val_accuracy: 0.3659 - 294ms/epoch - 98ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.5137 - accuracy: 0.9787 - val_loss: 1.3901 - val_accuracy: 0.2683 - 286ms/epoch - 95ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.4575 - accuracy: 0.9787 - val_loss: 1.3942 - val_accuracy: 0.2439 - 274ms/epoch - 91ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.5346 - accuracy: 0.9574 - val_loss: 1.3881 - val_accuracy: 0.2927 - 273ms/epoch - 91ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.4894 - accuracy: 0.9894 - val_loss: 1.3902 - val_accuracy: 0.2683 - 284ms/epoch - 95ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.4728 - accuracy: 1.0000 - val_loss: 1.3938 - val_accuracy: 0.2927 - 266ms/epoch - 89ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.4674 - accuracy: 0.9894 - val_loss: 1.3870 - val_accuracy: 0.2927 - 290ms/epoch - 97ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.4788 - accuracy: 0.9894 - val_loss: 1.3902 - val_accuracy: 0.2683 - 286ms/epoch - 95ms/step\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.4926 - accuracy: 0.9681 - val_loss: 1.3933 - val_accuracy: 0.2195 - 277ms/epoch - 92ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.4834 - accuracy: 0.9894 - val_loss: 1.3879 - val_accuracy: 0.2927 - 268ms/epoch - 89ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.4545 - accuracy: 0.9787 - val_loss: 1.3925 - val_accuracy: 0.2195 - 273ms/epoch - 91ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.4469 - accuracy: 0.9894 - val_loss: 1.3946 - val_accuracy: 0.2683 - 281ms/epoch - 94ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.4372 - accuracy: 0.9894 - val_loss: 1.3893 - val_accuracy: 0.2195 - 275ms/epoch - 92ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.4216 - accuracy: 1.0000 - val_loss: 1.3987 - val_accuracy: 0.2439 - 270ms/epoch - 90ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.4237 - accuracy: 0.9574 - val_loss: 1.3934 - val_accuracy: 0.2439 - 288ms/epoch - 96ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.3988 - accuracy: 0.9894 - val_loss: 1.3935 - val_accuracy: 0.2195 - 275ms/epoch - 92ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.4429 - accuracy: 0.9681 - val_loss: 1.3921 - val_accuracy: 0.2439 - 273ms/epoch - 91ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.3894 - accuracy: 0.9787 - val_loss: 1.3947 - val_accuracy: 0.1707 - 270ms/epoch - 90ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.4399 - accuracy: 0.9787 - val_loss: 1.3951 - val_accuracy: 0.2927 - 274ms/epoch - 91ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.4158 - accuracy: 1.0000 - val_loss: 1.3896 - val_accuracy: 0.2683 - 271ms/epoch - 90ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.3764 - accuracy: 1.0000 - val_loss: 1.4009 - val_accuracy: 0.2439 - 279ms/epoch - 93ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.4690 - accuracy: 0.9681 - val_loss: 1.3918 - val_accuracy: 0.3171 - 275ms/epoch - 92ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.3715 - accuracy: 0.9894 - val_loss: 1.3897 - val_accuracy: 0.2683 - 273ms/epoch - 91ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.3714 - accuracy: 1.0000 - val_loss: 1.4000 - val_accuracy: 0.2683 - 285ms/epoch - 95ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.3614 - accuracy: 0.9894 - val_loss: 1.3910 - val_accuracy: 0.2683 - 277ms/epoch - 92ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.3326 - accuracy: 1.0000 - val_loss: 1.3997 - val_accuracy: 0.2683 - 275ms/epoch - 92ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.3139 - accuracy: 1.0000 - val_loss: 1.3996 - val_accuracy: 0.3415 - 277ms/epoch - 92ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.3348 - accuracy: 1.0000 - val_loss: 1.4040 - val_accuracy: 0.1951 - 281ms/epoch - 94ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.3296 - accuracy: 0.9894 - val_loss: 1.3968 - val_accuracy: 0.3171 - 270ms/epoch - 90ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.3357 - accuracy: 1.0000 - val_loss: 1.3965 - val_accuracy: 0.2439 - 278ms/epoch - 93ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.3265 - accuracy: 1.0000 - val_loss: 1.4004 - val_accuracy: 0.3171 - 277ms/epoch - 92ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.3362 - accuracy: 1.0000 - val_loss: 1.3991 - val_accuracy: 0.2927 - 271ms/epoch - 90ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.3244 - accuracy: 1.0000 - val_loss: 1.4009 - val_accuracy: 0.3415 - 272ms/epoch - 91ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.3108 - accuracy: 1.0000 - val_loss: 1.3978 - val_accuracy: 0.2683 - 284ms/epoch - 95ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.2682 - accuracy: 1.0000 - val_loss: 1.3930 - val_accuracy: 0.2683 - 269ms/epoch - 90ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.3349 - accuracy: 0.9894 - val_loss: 1.4128 - val_accuracy: 0.3171 - 298ms/epoch - 99ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.3030 - accuracy: 1.0000 - val_loss: 1.3949 - val_accuracy: 0.2195 - 267ms/epoch - 89ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.3106 - accuracy: 1.0000 - val_loss: 1.4180 - val_accuracy: 0.3415 - 273ms/epoch - 91ms/step\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.3136 - accuracy: 1.0000 - val_loss: 1.4033 - val_accuracy: 0.2439 - 281ms/epoch - 94ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.2902 - accuracy: 1.0000 - val_loss: 1.4077 - val_accuracy: 0.3415 - 285ms/epoch - 95ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.3125 - accuracy: 1.0000 - val_loss: 1.4059 - val_accuracy: 0.3171 - 267ms/epoch - 89ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.2680 - accuracy: 1.0000 - val_loss: 1.4169 - val_accuracy: 0.2439 - 269ms/epoch - 90ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 1.38607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 0.2794 - accuracy: 1.0000 - val_loss: 1.4149 - val_accuracy: 0.3659 - 282ms/epoch - 94ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.2724 - accuracy: 1.0000 - val_loss: 1.4024 - val_accuracy: 0.2683 - 276ms/epoch - 92ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.2723 - accuracy: 0.9894 - val_loss: 1.4250 - val_accuracy: 0.3659 - 283ms/epoch - 94ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.2742 - accuracy: 1.0000 - val_loss: 1.4149 - val_accuracy: 0.2927 - 288ms/epoch - 96ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.2849 - accuracy: 1.0000 - val_loss: 1.4253 - val_accuracy: 0.2683 - 275ms/epoch - 92ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.2642 - accuracy: 1.0000 - val_loss: 1.4175 - val_accuracy: 0.3171 - 271ms/epoch - 90ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.2546 - accuracy: 1.0000 - val_loss: 1.4264 - val_accuracy: 0.3171 - 277ms/epoch - 92ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.2814 - accuracy: 1.0000 - val_loss: 1.4287 - val_accuracy: 0.2439 - 271ms/epoch - 90ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.2371 - accuracy: 1.0000 - val_loss: 1.4366 - val_accuracy: 0.2927 - 287ms/epoch - 96ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.2688 - accuracy: 1.0000 - val_loss: 1.4248 - val_accuracy: 0.1951 - 269ms/epoch - 90ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.2530 - accuracy: 1.0000 - val_loss: 1.4469 - val_accuracy: 0.2439 - 270ms/epoch - 90ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.2460 - accuracy: 1.0000 - val_loss: 1.4404 - val_accuracy: 0.2195 - 271ms/epoch - 90ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.2632 - accuracy: 1.0000 - val_loss: 1.4678 - val_accuracy: 0.3171 - 291ms/epoch - 97ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.2550 - accuracy: 0.9894 - val_loss: 1.4370 - val_accuracy: 0.2439 - 273ms/epoch - 91ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.2255 - accuracy: 1.0000 - val_loss: 1.4654 - val_accuracy: 0.2439 - 274ms/epoch - 91ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.2442 - accuracy: 1.0000 - val_loss: 1.4502 - val_accuracy: 0.2927 - 271ms/epoch - 90ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.2404 - accuracy: 1.0000 - val_loss: 1.4295 - val_accuracy: 0.2683 - 274ms/epoch - 91ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.2381 - accuracy: 1.0000 - val_loss: 1.4794 - val_accuracy: 0.3171 - 272ms/epoch - 91ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.2698 - accuracy: 1.0000 - val_loss: 1.4369 - val_accuracy: 0.1951 - 281ms/epoch - 94ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.2366 - accuracy: 1.0000 - val_loss: 1.4911 - val_accuracy: 0.2439 - 270ms/epoch - 90ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.2221 - accuracy: 1.0000 - val_loss: 1.4503 - val_accuracy: 0.2439 - 280ms/epoch - 93ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.2311 - accuracy: 1.0000 - val_loss: 1.4846 - val_accuracy: 0.2195 - 286ms/epoch - 95ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.2394 - accuracy: 1.0000 - val_loss: 1.4906 - val_accuracy: 0.2927 - 274ms/epoch - 91ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.2379 - accuracy: 1.0000 - val_loss: 1.4655 - val_accuracy: 0.2439 - 275ms/epoch - 92ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 1.4890 - val_accuracy: 0.2927 - 277ms/epoch - 92ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 1.4699 - val_accuracy: 0.2195 - 273ms/epoch - 91ms/step\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1890 - accuracy: 1.0000 - val_loss: 1.4685 - val_accuracy: 0.2439 - 276ms/epoch - 92ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.2057 - accuracy: 1.0000 - val_loss: 1.5058 - val_accuracy: 0.2195 - 290ms/epoch - 97ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.2035 - accuracy: 1.0000 - val_loss: 1.4942 - val_accuracy: 0.2683 - 271ms/epoch - 90ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.2025 - accuracy: 1.0000 - val_loss: 1.4981 - val_accuracy: 0.2195 - 283ms/epoch - 94ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 1.4992 - val_accuracy: 0.1951 - 281ms/epoch - 94ms/step\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.2066 - accuracy: 1.0000 - val_loss: 1.4733 - val_accuracy: 0.2683 - 275ms/epoch - 92ms/step\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.2172 - accuracy: 1.0000 - val_loss: 1.4801 - val_accuracy: 0.2439 - 275ms/epoch - 92ms/step\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1952 - accuracy: 1.0000 - val_loss: 1.5141 - val_accuracy: 0.2439 - 297ms/epoch - 99ms/step\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.2041 - accuracy: 1.0000 - val_loss: 1.5333 - val_accuracy: 0.2439 - 274ms/epoch - 91ms/step\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.2064 - accuracy: 1.0000 - val_loss: 1.5184 - val_accuracy: 0.2195 - 271ms/epoch - 90ms/step\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.2000 - accuracy: 1.0000 - val_loss: 1.5142 - val_accuracy: 0.1707 - 286ms/epoch - 95ms/step\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1896 - accuracy: 1.0000 - val_loss: 1.5126 - val_accuracy: 0.2195 - 270ms/epoch - 90ms/step\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1719 - accuracy: 1.0000 - val_loss: 1.5790 - val_accuracy: 0.2195 - 269ms/epoch - 90ms/step\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1772 - accuracy: 1.0000 - val_loss: 1.5266 - val_accuracy: 0.1951 - 285ms/epoch - 95ms/step\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 135: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.2017 - accuracy: 1.0000 - val_loss: 1.5394 - val_accuracy: 0.1951 - 280ms/epoch - 93ms/step\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 136: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1877 - accuracy: 1.0000 - val_loss: 1.5149 - val_accuracy: 0.2195 - 269ms/epoch - 90ms/step\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 137: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1741 - accuracy: 1.0000 - val_loss: 1.5580 - val_accuracy: 0.2195 - 275ms/epoch - 92ms/step\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 138: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1739 - accuracy: 1.0000 - val_loss: 1.5311 - val_accuracy: 0.2195 - 275ms/epoch - 92ms/step\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 139: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1829 - accuracy: 0.9894 - val_loss: 1.5382 - val_accuracy: 0.1951 - 272ms/epoch - 91ms/step\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 140: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1547 - accuracy: 1.0000 - val_loss: 1.5463 - val_accuracy: 0.1707 - 276ms/epoch - 92ms/step\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 141: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1824 - accuracy: 1.0000 - val_loss: 1.5548 - val_accuracy: 0.2683 - 286ms/epoch - 95ms/step\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 142: val_loss did not improve from 1.38607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 0.1910 - accuracy: 1.0000 - val_loss: 1.5741 - val_accuracy: 0.2195 - 274ms/epoch - 91ms/step\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 143: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1925 - accuracy: 1.0000 - val_loss: 1.6391 - val_accuracy: 0.2439 - 292ms/epoch - 97ms/step\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 144: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1676 - accuracy: 1.0000 - val_loss: 1.5981 - val_accuracy: 0.1707 - 283ms/epoch - 94ms/step\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 145: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1900 - accuracy: 1.0000 - val_loss: 1.5585 - val_accuracy: 0.3171 - 297ms/epoch - 99ms/step\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 146: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1780 - accuracy: 1.0000 - val_loss: 1.6354 - val_accuracy: 0.2439 - 277ms/epoch - 92ms/step\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 147: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1521 - accuracy: 1.0000 - val_loss: 1.5634 - val_accuracy: 0.2683 - 269ms/epoch - 90ms/step\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 148: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1630 - accuracy: 1.0000 - val_loss: 1.5894 - val_accuracy: 0.2927 - 287ms/epoch - 96ms/step\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 149: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1677 - accuracy: 1.0000 - val_loss: 1.5648 - val_accuracy: 0.1707 - 277ms/epoch - 92ms/step\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 150: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1720 - accuracy: 1.0000 - val_loss: 1.5884 - val_accuracy: 0.1707 - 272ms/epoch - 91ms/step\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 151: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1799 - accuracy: 1.0000 - val_loss: 1.5469 - val_accuracy: 0.1951 - 294ms/epoch - 98ms/step\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 152: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1635 - accuracy: 1.0000 - val_loss: 1.5911 - val_accuracy: 0.2683 - 280ms/epoch - 93ms/step\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 153: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1658 - accuracy: 1.0000 - val_loss: 1.6657 - val_accuracy: 0.2439 - 267ms/epoch - 89ms/step\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 154: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1610 - accuracy: 1.0000 - val_loss: 1.6005 - val_accuracy: 0.1951 - 265ms/epoch - 88ms/step\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 155: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1789 - accuracy: 1.0000 - val_loss: 1.6409 - val_accuracy: 0.2683 - 277ms/epoch - 92ms/step\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 156: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1613 - accuracy: 1.0000 - val_loss: 1.5983 - val_accuracy: 0.1707 - 274ms/epoch - 91ms/step\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 157: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1699 - accuracy: 1.0000 - val_loss: 1.6591 - val_accuracy: 0.1951 - 272ms/epoch - 91ms/step\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 158: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1640 - accuracy: 1.0000 - val_loss: 1.6682 - val_accuracy: 0.1707 - 274ms/epoch - 91ms/step\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 159: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1559 - accuracy: 1.0000 - val_loss: 1.5553 - val_accuracy: 0.1463 - 280ms/epoch - 93ms/step\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 160: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1356 - accuracy: 1.0000 - val_loss: 1.6463 - val_accuracy: 0.2195 - 273ms/epoch - 91ms/step\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 161: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1485 - accuracy: 1.0000 - val_loss: 1.6214 - val_accuracy: 0.2439 - 288ms/epoch - 96ms/step\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 162: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1413 - accuracy: 1.0000 - val_loss: 1.6735 - val_accuracy: 0.2195 - 275ms/epoch - 92ms/step\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 163: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1279 - accuracy: 1.0000 - val_loss: 1.6687 - val_accuracy: 0.2195 - 284ms/epoch - 95ms/step\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 164: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1589 - accuracy: 1.0000 - val_loss: 1.6707 - val_accuracy: 0.2439 - 272ms/epoch - 91ms/step\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 165: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1491 - accuracy: 1.0000 - val_loss: 1.6285 - val_accuracy: 0.1707 - 280ms/epoch - 93ms/step\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 166: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1707 - accuracy: 1.0000 - val_loss: 1.6793 - val_accuracy: 0.2439 - 278ms/epoch - 93ms/step\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 167: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1528 - accuracy: 1.0000 - val_loss: 1.6836 - val_accuracy: 0.2927 - 288ms/epoch - 96ms/step\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 168: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1447 - accuracy: 1.0000 - val_loss: 1.6620 - val_accuracy: 0.1707 - 272ms/epoch - 91ms/step\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 169: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1387 - accuracy: 1.0000 - val_loss: 1.7090 - val_accuracy: 0.2195 - 268ms/epoch - 89ms/step\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 170: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1523 - accuracy: 1.0000 - val_loss: 1.6369 - val_accuracy: 0.2683 - 282ms/epoch - 94ms/step\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 171: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1596 - accuracy: 1.0000 - val_loss: 1.7330 - val_accuracy: 0.1951 - 273ms/epoch - 91ms/step\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 172: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1466 - accuracy: 1.0000 - val_loss: 1.6854 - val_accuracy: 0.2195 - 262ms/epoch - 87ms/step\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 173: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1552 - accuracy: 1.0000 - val_loss: 1.6235 - val_accuracy: 0.1951 - 288ms/epoch - 96ms/step\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 174: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1447 - accuracy: 1.0000 - val_loss: 1.6635 - val_accuracy: 0.1951 - 274ms/epoch - 91ms/step\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 175: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1295 - accuracy: 1.0000 - val_loss: 1.7096 - val_accuracy: 0.2683 - 275ms/epoch - 92ms/step\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 176: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1509 - accuracy: 1.0000 - val_loss: 1.6664 - val_accuracy: 0.2195 - 281ms/epoch - 94ms/step\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 177: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1408 - accuracy: 1.0000 - val_loss: 1.6578 - val_accuracy: 0.1707 - 286ms/epoch - 95ms/step\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 178: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1259 - accuracy: 1.0000 - val_loss: 1.6235 - val_accuracy: 0.1951 - 273ms/epoch - 91ms/step\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 179: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1393 - accuracy: 1.0000 - val_loss: 1.7292 - val_accuracy: 0.1707 - 280ms/epoch - 93ms/step\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 180: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1258 - accuracy: 1.0000 - val_loss: 1.7105 - val_accuracy: 0.2195 - 282ms/epoch - 94ms/step\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 181: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1369 - accuracy: 1.0000 - val_loss: 1.7034 - val_accuracy: 0.2439 - 271ms/epoch - 90ms/step\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 182: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1345 - accuracy: 1.0000 - val_loss: 1.6790 - val_accuracy: 0.2195 - 268ms/epoch - 89ms/step\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 183: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1830 - accuracy: 0.9894 - val_loss: 1.7874 - val_accuracy: 0.2195 - 272ms/epoch - 91ms/step\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 184: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1353 - accuracy: 1.0000 - val_loss: 1.6757 - val_accuracy: 0.2195 - 289ms/epoch - 96ms/step\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 185: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1615 - accuracy: 1.0000 - val_loss: 1.7218 - val_accuracy: 0.1951 - 290ms/epoch - 97ms/step\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 186: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1491 - accuracy: 1.0000 - val_loss: 1.7735 - val_accuracy: 0.1707 - 283ms/epoch - 94ms/step\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 187: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1266 - accuracy: 1.0000 - val_loss: 1.6941 - val_accuracy: 0.1707 - 273ms/epoch - 91ms/step\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 188: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1248 - accuracy: 1.0000 - val_loss: 1.7143 - val_accuracy: 0.1951 - 277ms/epoch - 92ms/step\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 189: val_loss did not improve from 1.38607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 0.1125 - accuracy: 1.0000 - val_loss: 1.7067 - val_accuracy: 0.2439 - 280ms/epoch - 93ms/step\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 190: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1190 - accuracy: 1.0000 - val_loss: 1.7171 - val_accuracy: 0.1951 - 275ms/epoch - 92ms/step\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 191: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1252 - accuracy: 1.0000 - val_loss: 1.7530 - val_accuracy: 0.1220 - 277ms/epoch - 92ms/step\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 192: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1153 - accuracy: 1.0000 - val_loss: 1.7572 - val_accuracy: 0.1951 - 280ms/epoch - 93ms/step\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 193: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1104 - accuracy: 1.0000 - val_loss: 1.7546 - val_accuracy: 0.1951 - 289ms/epoch - 96ms/step\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 194: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1093 - accuracy: 1.0000 - val_loss: 1.7921 - val_accuracy: 0.1951 - 278ms/epoch - 93ms/step\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 195: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1153 - accuracy: 1.0000 - val_loss: 1.7990 - val_accuracy: 0.1463 - 272ms/epoch - 91ms/step\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 196: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1189 - accuracy: 1.0000 - val_loss: 1.7434 - val_accuracy: 0.2195 - 270ms/epoch - 90ms/step\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 197: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1309 - accuracy: 1.0000 - val_loss: 1.7672 - val_accuracy: 0.2195 - 278ms/epoch - 93ms/step\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 198: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1152 - accuracy: 1.0000 - val_loss: 1.7461 - val_accuracy: 0.1951 - 276ms/epoch - 92ms/step\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 199: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1235 - accuracy: 1.0000 - val_loss: 1.7595 - val_accuracy: 0.1707 - 272ms/epoch - 91ms/step\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 200: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1253 - accuracy: 1.0000 - val_loss: 1.7731 - val_accuracy: 0.2683 - 271ms/epoch - 90ms/step\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 201: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1029 - accuracy: 1.0000 - val_loss: 1.7407 - val_accuracy: 0.2195 - 283ms/epoch - 94ms/step\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 202: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1058 - accuracy: 1.0000 - val_loss: 1.8091 - val_accuracy: 0.2195 - 280ms/epoch - 93ms/step\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 203: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1148 - accuracy: 1.0000 - val_loss: 1.8717 - val_accuracy: 0.1707 - 287ms/epoch - 96ms/step\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 204: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1106 - accuracy: 1.0000 - val_loss: 1.8909 - val_accuracy: 0.2439 - 271ms/epoch - 90ms/step\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 205: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1096 - accuracy: 1.0000 - val_loss: 1.8195 - val_accuracy: 0.1707 - 284ms/epoch - 95ms/step\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 206: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1188 - accuracy: 1.0000 - val_loss: 1.8009 - val_accuracy: 0.1707 - 280ms/epoch - 93ms/step\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 207: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1030 - accuracy: 1.0000 - val_loss: 1.8112 - val_accuracy: 0.1951 - 277ms/epoch - 92ms/step\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 208: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1004 - accuracy: 1.0000 - val_loss: 1.7312 - val_accuracy: 0.2195 - 267ms/epoch - 89ms/step\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 209: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1126 - accuracy: 1.0000 - val_loss: 1.8490 - val_accuracy: 0.2439 - 280ms/epoch - 93ms/step\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 210: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1058 - accuracy: 1.0000 - val_loss: 1.8041 - val_accuracy: 0.1707 - 273ms/epoch - 91ms/step\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 211: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1033 - accuracy: 1.0000 - val_loss: 1.7604 - val_accuracy: 0.2439 - 282ms/epoch - 94ms/step\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 212: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1079 - accuracy: 1.0000 - val_loss: 1.7938 - val_accuracy: 0.2683 - 271ms/epoch - 90ms/step\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 213: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1082 - accuracy: 1.0000 - val_loss: 1.8402 - val_accuracy: 0.2927 - 286ms/epoch - 95ms/step\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 214: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0966 - accuracy: 1.0000 - val_loss: 1.8186 - val_accuracy: 0.2683 - 268ms/epoch - 89ms/step\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 215: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1079 - accuracy: 1.0000 - val_loss: 1.8698 - val_accuracy: 0.2927 - 274ms/epoch - 91ms/step\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 216: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1103 - accuracy: 1.0000 - val_loss: 1.8275 - val_accuracy: 0.2927 - 268ms/epoch - 89ms/step\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 217: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1084 - accuracy: 1.0000 - val_loss: 1.8280 - val_accuracy: 0.2683 - 267ms/epoch - 89ms/step\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 218: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1069 - accuracy: 1.0000 - val_loss: 1.8603 - val_accuracy: 0.1707 - 280ms/epoch - 93ms/step\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 219: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1084 - accuracy: 1.0000 - val_loss: 1.8341 - val_accuracy: 0.2195 - 280ms/epoch - 93ms/step\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 220: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0919 - accuracy: 1.0000 - val_loss: 1.8195 - val_accuracy: 0.2195 - 273ms/epoch - 91ms/step\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 221: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1116 - accuracy: 1.0000 - val_loss: 1.8581 - val_accuracy: 0.1951 - 277ms/epoch - 92ms/step\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 222: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0906 - accuracy: 1.0000 - val_loss: 1.8545 - val_accuracy: 0.1951 - 273ms/epoch - 91ms/step\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 223: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1076 - accuracy: 1.0000 - val_loss: 1.8516 - val_accuracy: 0.2195 - 276ms/epoch - 92ms/step\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 224: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1281 - accuracy: 1.0000 - val_loss: 1.8295 - val_accuracy: 0.1707 - 284ms/epoch - 95ms/step\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 225: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0881 - accuracy: 1.0000 - val_loss: 1.8479 - val_accuracy: 0.2195 - 277ms/epoch - 92ms/step\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 226: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0893 - accuracy: 1.0000 - val_loss: 1.8300 - val_accuracy: 0.2195 - 271ms/epoch - 90ms/step\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 227: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0994 - accuracy: 1.0000 - val_loss: 1.7992 - val_accuracy: 0.2439 - 274ms/epoch - 91ms/step\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 228: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1258 - accuracy: 1.0000 - val_loss: 1.7673 - val_accuracy: 0.2195 - 284ms/epoch - 95ms/step\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 229: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0895 - accuracy: 1.0000 - val_loss: 1.8425 - val_accuracy: 0.2195 - 274ms/epoch - 91ms/step\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 230: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0824 - accuracy: 1.0000 - val_loss: 1.7774 - val_accuracy: 0.2195 - 278ms/epoch - 93ms/step\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 231: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0970 - accuracy: 1.0000 - val_loss: 1.7552 - val_accuracy: 0.1951 - 267ms/epoch - 89ms/step\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 232: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1016 - accuracy: 1.0000 - val_loss: 1.8045 - val_accuracy: 0.1951 - 271ms/epoch - 90ms/step\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 233: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1060 - accuracy: 1.0000 - val_loss: 1.8088 - val_accuracy: 0.1707 - 277ms/epoch - 92ms/step\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 234: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1003 - accuracy: 1.0000 - val_loss: 1.8982 - val_accuracy: 0.2195 - 277ms/epoch - 92ms/step\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 235: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0817 - accuracy: 1.0000 - val_loss: 1.8465 - val_accuracy: 0.2195 - 275ms/epoch - 92ms/step\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 236: val_loss did not improve from 1.38607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 0.0926 - accuracy: 1.0000 - val_loss: 1.9175 - val_accuracy: 0.2683 - 278ms/epoch - 93ms/step\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 237: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0971 - accuracy: 1.0000 - val_loss: 1.9733 - val_accuracy: 0.2927 - 267ms/epoch - 89ms/step\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 238: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0925 - accuracy: 1.0000 - val_loss: 1.8330 - val_accuracy: 0.2683 - 271ms/epoch - 90ms/step\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 239: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0923 - accuracy: 1.0000 - val_loss: 1.7963 - val_accuracy: 0.2927 - 278ms/epoch - 93ms/step\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 240: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0853 - accuracy: 1.0000 - val_loss: 1.8374 - val_accuracy: 0.2683 - 284ms/epoch - 95ms/step\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 241: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0836 - accuracy: 1.0000 - val_loss: 1.8856 - val_accuracy: 0.2439 - 274ms/epoch - 91ms/step\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 242: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1013 - accuracy: 1.0000 - val_loss: 1.8648 - val_accuracy: 0.2195 - 271ms/epoch - 90ms/step\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 243: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0914 - accuracy: 1.0000 - val_loss: 1.8389 - val_accuracy: 0.2195 - 282ms/epoch - 94ms/step\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 244: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0846 - accuracy: 1.0000 - val_loss: 1.8408 - val_accuracy: 0.1951 - 274ms/epoch - 91ms/step\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 245: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1009 - accuracy: 1.0000 - val_loss: 1.8005 - val_accuracy: 0.1951 - 276ms/epoch - 92ms/step\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 246: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1056 - accuracy: 1.0000 - val_loss: 1.9270 - val_accuracy: 0.2195 - 275ms/epoch - 92ms/step\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 247: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0935 - accuracy: 1.0000 - val_loss: 1.8548 - val_accuracy: 0.1951 - 277ms/epoch - 92ms/step\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 248: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0934 - accuracy: 1.0000 - val_loss: 1.9016 - val_accuracy: 0.1707 - 286ms/epoch - 95ms/step\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 249: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0949 - accuracy: 1.0000 - val_loss: 2.0899 - val_accuracy: 0.2439 - 267ms/epoch - 89ms/step\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 250: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1040 - accuracy: 1.0000 - val_loss: 1.9142 - val_accuracy: 0.2683 - 270ms/epoch - 90ms/step\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 251: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.1040 - accuracy: 1.0000 - val_loss: 2.0294 - val_accuracy: 0.2439 - 280ms/epoch - 93ms/step\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 252: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0897 - accuracy: 1.0000 - val_loss: 1.9475 - val_accuracy: 0.2927 - 271ms/epoch - 90ms/step\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 253: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0956 - accuracy: 1.0000 - val_loss: 1.9004 - val_accuracy: 0.2195 - 275ms/epoch - 92ms/step\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 254: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0913 - accuracy: 1.0000 - val_loss: 1.9238 - val_accuracy: 0.2195 - 271ms/epoch - 90ms/step\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 255: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0896 - accuracy: 1.0000 - val_loss: 1.8837 - val_accuracy: 0.2439 - 275ms/epoch - 92ms/step\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 256: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0887 - accuracy: 1.0000 - val_loss: 1.7713 - val_accuracy: 0.2683 - 272ms/epoch - 91ms/step\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 257: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0850 - accuracy: 1.0000 - val_loss: 1.8778 - val_accuracy: 0.2195 - 294ms/epoch - 98ms/step\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 258: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0859 - accuracy: 1.0000 - val_loss: 1.9642 - val_accuracy: 0.2439 - 287ms/epoch - 96ms/step\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 259: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0823 - accuracy: 1.0000 - val_loss: 1.9095 - val_accuracy: 0.2195 - 269ms/epoch - 90ms/step\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 260: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0820 - accuracy: 1.0000 - val_loss: 1.8955 - val_accuracy: 0.2195 - 287ms/epoch - 96ms/step\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 261: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0864 - accuracy: 1.0000 - val_loss: 1.9258 - val_accuracy: 0.1951 - 267ms/epoch - 89ms/step\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 262: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0787 - accuracy: 1.0000 - val_loss: 1.9230 - val_accuracy: 0.2683 - 277ms/epoch - 92ms/step\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 263: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0906 - accuracy: 1.0000 - val_loss: 1.9348 - val_accuracy: 0.2439 - 288ms/epoch - 96ms/step\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 264: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0791 - accuracy: 1.0000 - val_loss: 1.9853 - val_accuracy: 0.2683 - 282ms/epoch - 94ms/step\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 265: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0899 - accuracy: 1.0000 - val_loss: 1.9239 - val_accuracy: 0.2439 - 280ms/epoch - 93ms/step\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 266: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0847 - accuracy: 1.0000 - val_loss: 1.8200 - val_accuracy: 0.2439 - 270ms/epoch - 90ms/step\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 267: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0747 - accuracy: 1.0000 - val_loss: 1.8838 - val_accuracy: 0.2439 - 279ms/epoch - 93ms/step\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 268: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0856 - accuracy: 1.0000 - val_loss: 1.9034 - val_accuracy: 0.2439 - 275ms/epoch - 92ms/step\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 269: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0724 - accuracy: 1.0000 - val_loss: 1.8283 - val_accuracy: 0.2683 - 289ms/epoch - 96ms/step\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 270: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0761 - accuracy: 1.0000 - val_loss: 1.8612 - val_accuracy: 0.2683 - 283ms/epoch - 94ms/step\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 271: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0878 - accuracy: 1.0000 - val_loss: 1.8654 - val_accuracy: 0.2195 - 272ms/epoch - 91ms/step\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 272: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0809 - accuracy: 1.0000 - val_loss: 1.8368 - val_accuracy: 0.2439 - 267ms/epoch - 89ms/step\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 273: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0804 - accuracy: 1.0000 - val_loss: 1.9040 - val_accuracy: 0.3171 - 268ms/epoch - 89ms/step\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 274: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0723 - accuracy: 1.0000 - val_loss: 1.8337 - val_accuracy: 0.2439 - 275ms/epoch - 92ms/step\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 275: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0834 - accuracy: 1.0000 - val_loss: 1.8287 - val_accuracy: 0.2195 - 287ms/epoch - 96ms/step\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 276: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0775 - accuracy: 1.0000 - val_loss: 1.9018 - val_accuracy: 0.2683 - 275ms/epoch - 92ms/step\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 277: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0760 - accuracy: 1.0000 - val_loss: 1.8452 - val_accuracy: 0.2439 - 288ms/epoch - 96ms/step\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 278: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0707 - accuracy: 1.0000 - val_loss: 1.8512 - val_accuracy: 0.1951 - 275ms/epoch - 92ms/step\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 279: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0791 - accuracy: 1.0000 - val_loss: 1.9040 - val_accuracy: 0.2195 - 277ms/epoch - 92ms/step\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 280: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0750 - accuracy: 1.0000 - val_loss: 1.8942 - val_accuracy: 0.2195 - 278ms/epoch - 93ms/step\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 281: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0773 - accuracy: 1.0000 - val_loss: 1.9646 - val_accuracy: 0.2195 - 280ms/epoch - 93ms/step\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 282: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0766 - accuracy: 1.0000 - val_loss: 1.9222 - val_accuracy: 0.1951 - 277ms/epoch - 92ms/step\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 283: val_loss did not improve from 1.38607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 0.0774 - accuracy: 1.0000 - val_loss: 1.9013 - val_accuracy: 0.2195 - 270ms/epoch - 90ms/step\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 284: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0705 - accuracy: 1.0000 - val_loss: 1.9018 - val_accuracy: 0.1951 - 280ms/epoch - 93ms/step\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 285: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0800 - accuracy: 1.0000 - val_loss: 1.8684 - val_accuracy: 0.2439 - 270ms/epoch - 90ms/step\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 286: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0861 - accuracy: 1.0000 - val_loss: 1.8796 - val_accuracy: 0.1951 - 274ms/epoch - 91ms/step\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 287: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0803 - accuracy: 1.0000 - val_loss: 1.9061 - val_accuracy: 0.2439 - 279ms/epoch - 93ms/step\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 288: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0827 - accuracy: 1.0000 - val_loss: 1.8924 - val_accuracy: 0.2195 - 274ms/epoch - 91ms/step\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 289: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0759 - accuracy: 1.0000 - val_loss: 1.9691 - val_accuracy: 0.2439 - 270ms/epoch - 90ms/step\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 290: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0675 - accuracy: 1.0000 - val_loss: 1.9340 - val_accuracy: 0.1951 - 271ms/epoch - 90ms/step\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 291: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0696 - accuracy: 1.0000 - val_loss: 1.9610 - val_accuracy: 0.1951 - 277ms/epoch - 92ms/step\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 292: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0805 - accuracy: 1.0000 - val_loss: 1.8390 - val_accuracy: 0.1463 - 271ms/epoch - 90ms/step\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 293: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0730 - accuracy: 1.0000 - val_loss: 1.9150 - val_accuracy: 0.2195 - 279ms/epoch - 93ms/step\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 294: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0680 - accuracy: 1.0000 - val_loss: 1.9842 - val_accuracy: 0.2195 - 276ms/epoch - 92ms/step\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 295: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0660 - accuracy: 1.0000 - val_loss: 1.9382 - val_accuracy: 0.2683 - 273ms/epoch - 91ms/step\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 296: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0758 - accuracy: 1.0000 - val_loss: 1.8527 - val_accuracy: 0.2683 - 281ms/epoch - 94ms/step\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 297: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0803 - accuracy: 1.0000 - val_loss: 1.9732 - val_accuracy: 0.2439 - 288ms/epoch - 96ms/step\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 298: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0702 - accuracy: 1.0000 - val_loss: 1.9921 - val_accuracy: 0.2439 - 278ms/epoch - 93ms/step\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 299: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0693 - accuracy: 1.0000 - val_loss: 1.8914 - val_accuracy: 0.2439 - 281ms/epoch - 94ms/step\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 300: val_loss did not improve from 1.38607\n",
      "3/3 - 0s - loss: 0.0640 - accuracy: 1.0000 - val_loss: 1.8989 - val_accuracy: 0.2195 - 274ms/epoch - 91ms/step\n",
      "2/2 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2022-11-11 09:26:01.181260: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_8996636\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:591310\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 09:26:05.501957: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_8999701\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:591358\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38591, saving model to checkpoint1.h5\n",
      "3/3 - 6s - loss: 1.4128 - accuracy: 0.2979 - val_loss: 1.3859 - val_accuracy: 0.2927 - 6s/epoch - 2s/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss improved from 1.38591 to 1.38565, saving model to checkpoint1.h5\n",
      "3/3 - 0s - loss: 1.3114 - accuracy: 0.3936 - val_loss: 1.3856 - val_accuracy: 0.2927 - 360ms/epoch - 120ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss improved from 1.38565 to 1.38545, saving model to checkpoint1.h5\n",
      "3/3 - 0s - loss: 1.3219 - accuracy: 0.3511 - val_loss: 1.3855 - val_accuracy: 0.2927 - 326ms/epoch - 109ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss improved from 1.38545 to 1.38531, saving model to checkpoint1.h5\n",
      "3/3 - 0s - loss: 1.2799 - accuracy: 0.4681 - val_loss: 1.3853 - val_accuracy: 0.2927 - 328ms/epoch - 109ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss improved from 1.38531 to 1.38526, saving model to checkpoint1.h5\n",
      "3/3 - 0s - loss: 1.2338 - accuracy: 0.5106 - val_loss: 1.3853 - val_accuracy: 0.2927 - 331ms/epoch - 110ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss improved from 1.38526 to 1.38521, saving model to checkpoint1.h5\n",
      "3/3 - 0s - loss: 1.2351 - accuracy: 0.5532 - val_loss: 1.3852 - val_accuracy: 0.2927 - 323ms/epoch - 108ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss improved from 1.38521 to 1.38514, saving model to checkpoint1.h5\n",
      "3/3 - 0s - loss: 1.2030 - accuracy: 0.5638 - val_loss: 1.3851 - val_accuracy: 0.2927 - 335ms/epoch - 112ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss improved from 1.38514 to 1.38508, saving model to checkpoint1.h5\n",
      "3/3 - 0s - loss: 1.2227 - accuracy: 0.4681 - val_loss: 1.3851 - val_accuracy: 0.2927 - 327ms/epoch - 109ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 1.38508\n",
      "3/3 - 0s - loss: 1.1514 - accuracy: 0.6809 - val_loss: 1.3851 - val_accuracy: 0.2927 - 282ms/epoch - 94ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.38508\n",
      "3/3 - 0s - loss: 1.1238 - accuracy: 0.6277 - val_loss: 1.3853 - val_accuracy: 0.2927 - 279ms/epoch - 93ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.38508\n",
      "3/3 - 0s - loss: 1.1211 - accuracy: 0.6596 - val_loss: 1.3853 - val_accuracy: 0.2927 - 273ms/epoch - 91ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.38508\n",
      "3/3 - 0s - loss: 1.0858 - accuracy: 0.6915 - val_loss: 1.3853 - val_accuracy: 0.2439 - 283ms/epoch - 94ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.38508\n",
      "3/3 - 0s - loss: 1.0764 - accuracy: 0.6489 - val_loss: 1.3852 - val_accuracy: 0.2927 - 291ms/epoch - 97ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss improved from 1.38508 to 1.38502, saving model to checkpoint1.h5\n",
      "3/3 - 0s - loss: 1.0638 - accuracy: 0.7128 - val_loss: 1.3850 - val_accuracy: 0.2195 - 332ms/epoch - 111ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 1.0229 - accuracy: 0.7234 - val_loss: 1.3852 - val_accuracy: 0.2683 - 268ms/epoch - 89ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 1.0318 - accuracy: 0.7128 - val_loss: 1.3854 - val_accuracy: 0.2439 - 284ms/epoch - 95ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 1.0059 - accuracy: 0.7447 - val_loss: 1.3855 - val_accuracy: 0.2927 - 271ms/epoch - 90ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.9768 - accuracy: 0.7766 - val_loss: 1.3855 - val_accuracy: 0.2683 - 280ms/epoch - 93ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.9895 - accuracy: 0.7340 - val_loss: 1.3855 - val_accuracy: 0.2683 - 272ms/epoch - 91ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.9719 - accuracy: 0.7872 - val_loss: 1.3856 - val_accuracy: 0.2683 - 276ms/epoch - 92ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.9402 - accuracy: 0.7979 - val_loss: 1.3856 - val_accuracy: 0.2683 - 271ms/epoch - 90ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.9210 - accuracy: 0.7766 - val_loss: 1.3861 - val_accuracy: 0.2683 - 281ms/epoch - 94ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.9181 - accuracy: 0.7872 - val_loss: 1.3868 - val_accuracy: 0.2683 - 274ms/epoch - 91ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.9211 - accuracy: 0.8191 - val_loss: 1.3866 - val_accuracy: 0.2683 - 303ms/epoch - 101ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.8917 - accuracy: 0.8298 - val_loss: 1.3861 - val_accuracy: 0.2683 - 277ms/epoch - 92ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.8732 - accuracy: 0.8723 - val_loss: 1.3866 - val_accuracy: 0.2683 - 274ms/epoch - 91ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.8778 - accuracy: 0.8085 - val_loss: 1.3871 - val_accuracy: 0.2683 - 281ms/epoch - 94ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.8650 - accuracy: 0.7979 - val_loss: 1.3876 - val_accuracy: 0.2683 - 279ms/epoch - 93ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.8282 - accuracy: 0.8511 - val_loss: 1.3877 - val_accuracy: 0.2683 - 289ms/epoch - 96ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.8013 - accuracy: 0.8617 - val_loss: 1.3877 - val_accuracy: 0.2683 - 277ms/epoch - 92ms/step\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.8112 - accuracy: 0.9043 - val_loss: 1.3880 - val_accuracy: 0.2439 - 282ms/epoch - 94ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.8004 - accuracy: 0.9043 - val_loss: 1.3893 - val_accuracy: 0.2439 - 274ms/epoch - 91ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.7780 - accuracy: 0.8723 - val_loss: 1.3894 - val_accuracy: 0.2683 - 283ms/epoch - 94ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.7620 - accuracy: 0.8936 - val_loss: 1.3884 - val_accuracy: 0.2683 - 266ms/epoch - 89ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.7790 - accuracy: 0.8511 - val_loss: 1.3894 - val_accuracy: 0.2683 - 270ms/epoch - 90ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.7484 - accuracy: 0.9149 - val_loss: 1.3896 - val_accuracy: 0.2683 - 281ms/epoch - 94ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.7164 - accuracy: 0.9149 - val_loss: 1.3892 - val_accuracy: 0.2683 - 274ms/epoch - 91ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.7216 - accuracy: 0.9255 - val_loss: 1.3902 - val_accuracy: 0.2683 - 279ms/epoch - 93ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.7633 - accuracy: 0.8511 - val_loss: 1.3900 - val_accuracy: 0.2927 - 279ms/epoch - 93ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.7101 - accuracy: 0.9362 - val_loss: 1.3916 - val_accuracy: 0.2683 - 273ms/epoch - 91ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.7395 - accuracy: 0.8830 - val_loss: 1.3925 - val_accuracy: 0.2683 - 268ms/epoch - 89ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.7067 - accuracy: 0.9362 - val_loss: 1.3942 - val_accuracy: 0.2683 - 288ms/epoch - 96ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.7066 - accuracy: 0.9362 - val_loss: 1.3946 - val_accuracy: 0.2683 - 271ms/epoch - 90ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.6547 - accuracy: 0.9894 - val_loss: 1.3943 - val_accuracy: 0.2927 - 275ms/epoch - 92ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.6084 - accuracy: 0.9681 - val_loss: 1.3965 - val_accuracy: 0.2683 - 277ms/epoch - 92ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.6506 - accuracy: 0.9255 - val_loss: 1.3963 - val_accuracy: 0.2683 - 275ms/epoch - 92ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.6404 - accuracy: 0.9681 - val_loss: 1.3969 - val_accuracy: 0.2683 - 283ms/epoch - 94ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.6327 - accuracy: 0.9787 - val_loss: 1.3978 - val_accuracy: 0.2683 - 272ms/epoch - 91ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.6010 - accuracy: 0.9574 - val_loss: 1.3971 - val_accuracy: 0.2683 - 270ms/epoch - 90ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.6205 - accuracy: 0.9255 - val_loss: 1.4003 - val_accuracy: 0.2683 - 285ms/epoch - 95ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.5896 - accuracy: 0.9894 - val_loss: 1.4003 - val_accuracy: 0.2927 - 278ms/epoch - 93ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.6002 - accuracy: 0.9681 - val_loss: 1.3990 - val_accuracy: 0.2927 - 291ms/epoch - 97ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.6098 - accuracy: 0.9574 - val_loss: 1.4047 - val_accuracy: 0.2927 - 280ms/epoch - 93ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.5840 - accuracy: 0.9787 - val_loss: 1.4029 - val_accuracy: 0.2683 - 273ms/epoch - 91ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.5584 - accuracy: 0.9787 - val_loss: 1.4034 - val_accuracy: 0.2927 - 277ms/epoch - 92ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.5807 - accuracy: 0.9574 - val_loss: 1.4111 - val_accuracy: 0.2927 - 290ms/epoch - 97ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.5515 - accuracy: 0.9681 - val_loss: 1.4042 - val_accuracy: 0.2927 - 299ms/epoch - 100ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.5924 - accuracy: 0.9362 - val_loss: 1.4021 - val_accuracy: 0.2683 - 291ms/epoch - 97ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.5296 - accuracy: 0.9681 - val_loss: 1.4125 - val_accuracy: 0.2683 - 283ms/epoch - 94ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.5355 - accuracy: 0.9468 - val_loss: 1.4101 - val_accuracy: 0.2683 - 292ms/epoch - 97ms/step\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.5201 - accuracy: 0.9681 - val_loss: 1.4142 - val_accuracy: 0.2927 - 280ms/epoch - 93ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.5008 - accuracy: 0.9894 - val_loss: 1.4155 - val_accuracy: 0.2439 - 271ms/epoch - 90ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.5383 - accuracy: 0.9787 - val_loss: 1.4198 - val_accuracy: 0.2927 - 278ms/epoch - 93ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.5447 - accuracy: 0.9468 - val_loss: 1.4138 - val_accuracy: 0.2683 - 283ms/epoch - 94ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.5346 - accuracy: 0.9574 - val_loss: 1.4122 - val_accuracy: 0.2195 - 292ms/epoch - 97ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.5088 - accuracy: 0.9787 - val_loss: 1.4113 - val_accuracy: 0.2683 - 270ms/epoch - 90ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.5360 - accuracy: 0.9574 - val_loss: 1.4214 - val_accuracy: 0.2683 - 274ms/epoch - 91ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.4684 - accuracy: 1.0000 - val_loss: 1.4111 - val_accuracy: 0.2439 - 279ms/epoch - 93ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.4886 - accuracy: 0.9894 - val_loss: 1.4138 - val_accuracy: 0.2927 - 279ms/epoch - 93ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.4413 - accuracy: 0.9894 - val_loss: 1.4196 - val_accuracy: 0.3171 - 277ms/epoch - 92ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.4592 - accuracy: 0.9894 - val_loss: 1.4131 - val_accuracy: 0.2439 - 277ms/epoch - 92ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.4345 - accuracy: 0.9787 - val_loss: 1.4237 - val_accuracy: 0.2927 - 280ms/epoch - 93ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.4610 - accuracy: 0.9894 - val_loss: 1.4125 - val_accuracy: 0.2927 - 281ms/epoch - 94ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.4265 - accuracy: 1.0000 - val_loss: 1.4209 - val_accuracy: 0.3171 - 268ms/epoch - 89ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.4072 - accuracy: 0.9894 - val_loss: 1.4060 - val_accuracy: 0.2927 - 278ms/epoch - 93ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.4126 - accuracy: 1.0000 - val_loss: 1.4165 - val_accuracy: 0.2683 - 282ms/epoch - 94ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.4084 - accuracy: 0.9894 - val_loss: 1.4201 - val_accuracy: 0.2927 - 283ms/epoch - 94ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.4138 - accuracy: 0.9787 - val_loss: 1.4172 - val_accuracy: 0.3171 - 271ms/epoch - 90ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.4154 - accuracy: 0.9787 - val_loss: 1.4291 - val_accuracy: 0.3171 - 271ms/epoch - 90ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.3814 - accuracy: 1.0000 - val_loss: 1.4128 - val_accuracy: 0.2927 - 272ms/epoch - 91ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.4178 - accuracy: 1.0000 - val_loss: 1.4563 - val_accuracy: 0.2683 - 293ms/epoch - 98ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.4129 - accuracy: 0.9894 - val_loss: 1.3984 - val_accuracy: 0.2439 - 270ms/epoch - 90ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.4120 - accuracy: 1.0000 - val_loss: 1.4148 - val_accuracy: 0.3171 - 302ms/epoch - 101ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.3790 - accuracy: 0.9894 - val_loss: 1.4242 - val_accuracy: 0.2195 - 275ms/epoch - 92ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.3746 - accuracy: 0.9787 - val_loss: 1.4018 - val_accuracy: 0.2439 - 275ms/epoch - 92ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.3429 - accuracy: 1.0000 - val_loss: 1.4152 - val_accuracy: 0.3415 - 283ms/epoch - 94ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.3507 - accuracy: 1.0000 - val_loss: 1.4091 - val_accuracy: 0.2439 - 276ms/epoch - 92ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.3386 - accuracy: 1.0000 - val_loss: 1.4080 - val_accuracy: 0.2927 - 283ms/epoch - 94ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.3558 - accuracy: 0.9894 - val_loss: 1.4081 - val_accuracy: 0.2439 - 270ms/epoch - 90ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.3149 - accuracy: 1.0000 - val_loss: 1.3998 - val_accuracy: 0.1707 - 278ms/epoch - 93ms/step\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.3517 - accuracy: 1.0000 - val_loss: 1.4053 - val_accuracy: 0.2439 - 267ms/epoch - 89ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.3617 - accuracy: 1.0000 - val_loss: 1.3916 - val_accuracy: 0.3171 - 276ms/epoch - 92ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.3188 - accuracy: 1.0000 - val_loss: 1.3980 - val_accuracy: 0.2439 - 284ms/epoch - 95ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 1.38502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 0.3338 - accuracy: 1.0000 - val_loss: 1.4228 - val_accuracy: 0.2195 - 272ms/epoch - 91ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.3322 - accuracy: 1.0000 - val_loss: 1.4035 - val_accuracy: 0.2195 - 276ms/epoch - 92ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.3298 - accuracy: 1.0000 - val_loss: 1.4178 - val_accuracy: 0.1707 - 277ms/epoch - 92ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.3041 - accuracy: 1.0000 - val_loss: 1.4040 - val_accuracy: 0.3171 - 283ms/epoch - 94ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.3054 - accuracy: 0.9894 - val_loss: 1.4102 - val_accuracy: 0.2927 - 278ms/epoch - 93ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.2851 - accuracy: 1.0000 - val_loss: 1.4218 - val_accuracy: 0.1707 - 279ms/epoch - 93ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.3228 - accuracy: 1.0000 - val_loss: 1.4202 - val_accuracy: 0.2439 - 281ms/epoch - 94ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.2998 - accuracy: 1.0000 - val_loss: 1.4389 - val_accuracy: 0.2683 - 282ms/epoch - 94ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.2858 - accuracy: 1.0000 - val_loss: 1.4353 - val_accuracy: 0.2439 - 272ms/epoch - 91ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.2945 - accuracy: 1.0000 - val_loss: 1.4436 - val_accuracy: 0.1951 - 278ms/epoch - 93ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.2659 - accuracy: 1.0000 - val_loss: 1.4262 - val_accuracy: 0.2439 - 274ms/epoch - 91ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.2780 - accuracy: 1.0000 - val_loss: 1.4287 - val_accuracy: 0.2195 - 290ms/epoch - 97ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.2646 - accuracy: 1.0000 - val_loss: 1.4398 - val_accuracy: 0.1951 - 292ms/epoch - 97ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.2730 - accuracy: 1.0000 - val_loss: 1.4329 - val_accuracy: 0.2195 - 273ms/epoch - 91ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.2639 - accuracy: 1.0000 - val_loss: 1.4426 - val_accuracy: 0.2195 - 280ms/epoch - 93ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.2738 - accuracy: 1.0000 - val_loss: 1.4281 - val_accuracy: 0.2195 - 279ms/epoch - 93ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.2563 - accuracy: 1.0000 - val_loss: 1.4389 - val_accuracy: 0.2927 - 290ms/epoch - 97ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.2561 - accuracy: 0.9894 - val_loss: 1.4294 - val_accuracy: 0.1951 - 277ms/epoch - 92ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.2602 - accuracy: 0.9894 - val_loss: 1.4635 - val_accuracy: 0.2439 - 274ms/epoch - 91ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.2502 - accuracy: 1.0000 - val_loss: 1.4628 - val_accuracy: 0.2439 - 281ms/epoch - 94ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.2292 - accuracy: 1.0000 - val_loss: 1.4422 - val_accuracy: 0.2195 - 284ms/epoch - 95ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.2596 - accuracy: 1.0000 - val_loss: 1.4704 - val_accuracy: 0.1707 - 270ms/epoch - 90ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.2334 - accuracy: 1.0000 - val_loss: 1.4654 - val_accuracy: 0.2439 - 279ms/epoch - 93ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.2221 - accuracy: 1.0000 - val_loss: 1.4671 - val_accuracy: 0.2195 - 281ms/epoch - 94ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.2244 - accuracy: 1.0000 - val_loss: 1.4772 - val_accuracy: 0.1951 - 275ms/epoch - 92ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.2737 - accuracy: 0.9894 - val_loss: 1.4839 - val_accuracy: 0.1951 - 290ms/epoch - 97ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.2376 - accuracy: 1.0000 - val_loss: 1.4629 - val_accuracy: 0.2439 - 273ms/epoch - 91ms/step\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.2398 - accuracy: 1.0000 - val_loss: 1.4862 - val_accuracy: 0.1707 - 284ms/epoch - 95ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.2262 - accuracy: 1.0000 - val_loss: 1.4987 - val_accuracy: 0.1951 - 282ms/epoch - 94ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.2370 - accuracy: 1.0000 - val_loss: 1.4999 - val_accuracy: 0.2195 - 296ms/epoch - 99ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.2407 - accuracy: 1.0000 - val_loss: 1.4892 - val_accuracy: 0.1951 - 278ms/epoch - 93ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.2330 - accuracy: 1.0000 - val_loss: 1.4890 - val_accuracy: 0.1951 - 270ms/epoch - 90ms/step\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.2439 - accuracy: 1.0000 - val_loss: 1.4594 - val_accuracy: 0.2439 - 274ms/epoch - 91ms/step\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.2284 - accuracy: 1.0000 - val_loss: 1.4984 - val_accuracy: 0.2195 - 268ms/epoch - 89ms/step\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.2222 - accuracy: 1.0000 - val_loss: 1.5855 - val_accuracy: 0.2195 - 272ms/epoch - 91ms/step\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.2408 - accuracy: 1.0000 - val_loss: 1.5666 - val_accuracy: 0.2927 - 289ms/epoch - 96ms/step\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.2356 - accuracy: 1.0000 - val_loss: 1.5259 - val_accuracy: 0.2195 - 289ms/epoch - 96ms/step\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.2298 - accuracy: 1.0000 - val_loss: 1.5686 - val_accuracy: 0.2195 - 283ms/epoch - 94ms/step\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 1.5182 - val_accuracy: 0.2683 - 275ms/epoch - 92ms/step\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.2315 - accuracy: 1.0000 - val_loss: 1.5426 - val_accuracy: 0.2439 - 285ms/epoch - 95ms/step\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.2072 - accuracy: 1.0000 - val_loss: 1.5772 - val_accuracy: 0.1463 - 276ms/epoch - 92ms/step\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 135: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1716 - accuracy: 1.0000 - val_loss: 1.5403 - val_accuracy: 0.1951 - 285ms/epoch - 95ms/step\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 136: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.2139 - accuracy: 1.0000 - val_loss: 1.5403 - val_accuracy: 0.1951 - 270ms/epoch - 90ms/step\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 137: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1810 - accuracy: 1.0000 - val_loss: 1.5762 - val_accuracy: 0.1707 - 273ms/epoch - 91ms/step\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 138: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1851 - accuracy: 1.0000 - val_loss: 1.5523 - val_accuracy: 0.2195 - 288ms/epoch - 96ms/step\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 139: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1811 - accuracy: 1.0000 - val_loss: 1.5514 - val_accuracy: 0.2195 - 293ms/epoch - 98ms/step\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 140: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1832 - accuracy: 1.0000 - val_loss: 1.5701 - val_accuracy: 0.2195 - 274ms/epoch - 91ms/step\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 141: val_loss did not improve from 1.38502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 0.1638 - accuracy: 1.0000 - val_loss: 1.5562 - val_accuracy: 0.2195 - 280ms/epoch - 93ms/step\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 142: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1660 - accuracy: 1.0000 - val_loss: 1.6137 - val_accuracy: 0.1463 - 275ms/epoch - 92ms/step\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 143: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1985 - accuracy: 0.9894 - val_loss: 1.6042 - val_accuracy: 0.1707 - 272ms/epoch - 91ms/step\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 144: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.2030 - accuracy: 0.9894 - val_loss: 1.5707 - val_accuracy: 0.2195 - 278ms/epoch - 93ms/step\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 145: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1992 - accuracy: 1.0000 - val_loss: 1.6321 - val_accuracy: 0.1707 - 284ms/epoch - 95ms/step\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 146: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1885 - accuracy: 1.0000 - val_loss: 1.6484 - val_accuracy: 0.2195 - 271ms/epoch - 90ms/step\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 147: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1742 - accuracy: 1.0000 - val_loss: 1.5887 - val_accuracy: 0.2927 - 295ms/epoch - 98ms/step\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 148: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1605 - accuracy: 1.0000 - val_loss: 1.6127 - val_accuracy: 0.2195 - 280ms/epoch - 93ms/step\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 149: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1906 - accuracy: 1.0000 - val_loss: 1.6099 - val_accuracy: 0.2683 - 273ms/epoch - 91ms/step\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 150: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1616 - accuracy: 1.0000 - val_loss: 1.5987 - val_accuracy: 0.1951 - 288ms/epoch - 96ms/step\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 151: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1668 - accuracy: 1.0000 - val_loss: 1.5987 - val_accuracy: 0.2683 - 295ms/epoch - 98ms/step\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 152: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1869 - accuracy: 1.0000 - val_loss: 1.6096 - val_accuracy: 0.1951 - 287ms/epoch - 96ms/step\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 153: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1655 - accuracy: 1.0000 - val_loss: 1.6126 - val_accuracy: 0.2195 - 290ms/epoch - 97ms/step\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 154: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1551 - accuracy: 1.0000 - val_loss: 1.6124 - val_accuracy: 0.2439 - 273ms/epoch - 91ms/step\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 155: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1851 - accuracy: 1.0000 - val_loss: 1.6899 - val_accuracy: 0.2439 - 282ms/epoch - 94ms/step\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 156: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1604 - accuracy: 1.0000 - val_loss: 1.6839 - val_accuracy: 0.1707 - 271ms/epoch - 90ms/step\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 157: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1796 - accuracy: 1.0000 - val_loss: 1.6738 - val_accuracy: 0.2195 - 274ms/epoch - 91ms/step\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 158: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1778 - accuracy: 1.0000 - val_loss: 1.6472 - val_accuracy: 0.1951 - 283ms/epoch - 94ms/step\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 159: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1718 - accuracy: 1.0000 - val_loss: 1.6933 - val_accuracy: 0.2195 - 276ms/epoch - 92ms/step\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 160: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1567 - accuracy: 1.0000 - val_loss: 1.6965 - val_accuracy: 0.1951 - 275ms/epoch - 92ms/step\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 161: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1609 - accuracy: 1.0000 - val_loss: 1.6851 - val_accuracy: 0.2195 - 272ms/epoch - 91ms/step\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 162: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1629 - accuracy: 1.0000 - val_loss: 1.6700 - val_accuracy: 0.2439 - 277ms/epoch - 92ms/step\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 163: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1693 - accuracy: 1.0000 - val_loss: 1.6648 - val_accuracy: 0.2195 - 291ms/epoch - 97ms/step\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 164: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1545 - accuracy: 1.0000 - val_loss: 1.6954 - val_accuracy: 0.2683 - 273ms/epoch - 91ms/step\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 165: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1440 - accuracy: 1.0000 - val_loss: 1.7255 - val_accuracy: 0.2195 - 279ms/epoch - 93ms/step\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 166: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1461 - accuracy: 1.0000 - val_loss: 1.7217 - val_accuracy: 0.2927 - 278ms/epoch - 93ms/step\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 167: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1582 - accuracy: 1.0000 - val_loss: 1.7546 - val_accuracy: 0.3171 - 268ms/epoch - 89ms/step\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 168: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1407 - accuracy: 1.0000 - val_loss: 1.7826 - val_accuracy: 0.1951 - 273ms/epoch - 91ms/step\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 169: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1556 - accuracy: 1.0000 - val_loss: 1.7476 - val_accuracy: 0.1463 - 277ms/epoch - 92ms/step\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 170: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1547 - accuracy: 1.0000 - val_loss: 1.7885 - val_accuracy: 0.3415 - 282ms/epoch - 94ms/step\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 171: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1498 - accuracy: 1.0000 - val_loss: 1.7548 - val_accuracy: 0.2927 - 284ms/epoch - 95ms/step\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 172: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1410 - accuracy: 1.0000 - val_loss: 1.7501 - val_accuracy: 0.2195 - 278ms/epoch - 93ms/step\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 173: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1302 - accuracy: 1.0000 - val_loss: 1.7285 - val_accuracy: 0.2683 - 288ms/epoch - 96ms/step\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 174: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1258 - accuracy: 1.0000 - val_loss: 1.7578 - val_accuracy: 0.2439 - 278ms/epoch - 93ms/step\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 175: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1584 - accuracy: 1.0000 - val_loss: 1.7741 - val_accuracy: 0.2683 - 261ms/epoch - 87ms/step\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 176: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1434 - accuracy: 1.0000 - val_loss: 1.7691 - val_accuracy: 0.2439 - 269ms/epoch - 90ms/step\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 177: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1322 - accuracy: 1.0000 - val_loss: 1.8017 - val_accuracy: 0.2195 - 292ms/epoch - 97ms/step\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 178: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1327 - accuracy: 1.0000 - val_loss: 1.7767 - val_accuracy: 0.2927 - 273ms/epoch - 91ms/step\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 179: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1377 - accuracy: 1.0000 - val_loss: 1.7819 - val_accuracy: 0.2439 - 271ms/epoch - 90ms/step\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 180: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1250 - accuracy: 1.0000 - val_loss: 1.8024 - val_accuracy: 0.2439 - 274ms/epoch - 91ms/step\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 181: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1204 - accuracy: 1.0000 - val_loss: 1.8061 - val_accuracy: 0.2195 - 271ms/epoch - 90ms/step\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 182: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1413 - accuracy: 1.0000 - val_loss: 1.7886 - val_accuracy: 0.2439 - 273ms/epoch - 91ms/step\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 183: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1415 - accuracy: 1.0000 - val_loss: 1.8293 - val_accuracy: 0.1951 - 281ms/epoch - 94ms/step\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 184: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1362 - accuracy: 1.0000 - val_loss: 1.8354 - val_accuracy: 0.2683 - 275ms/epoch - 92ms/step\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 185: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1221 - accuracy: 1.0000 - val_loss: 1.8412 - val_accuracy: 0.2195 - 280ms/epoch - 93ms/step\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 186: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1461 - accuracy: 1.0000 - val_loss: 1.8114 - val_accuracy: 0.2683 - 278ms/epoch - 93ms/step\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 187: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1232 - accuracy: 1.0000 - val_loss: 1.8279 - val_accuracy: 0.2927 - 273ms/epoch - 91ms/step\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 188: val_loss did not improve from 1.38502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 0.1335 - accuracy: 1.0000 - val_loss: 1.8512 - val_accuracy: 0.2439 - 278ms/epoch - 93ms/step\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 189: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1276 - accuracy: 1.0000 - val_loss: 1.8490 - val_accuracy: 0.2195 - 291ms/epoch - 97ms/step\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 190: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1271 - accuracy: 1.0000 - val_loss: 1.8466 - val_accuracy: 0.2195 - 275ms/epoch - 92ms/step\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 191: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1352 - accuracy: 1.0000 - val_loss: 1.8143 - val_accuracy: 0.2439 - 284ms/epoch - 95ms/step\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 192: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1203 - accuracy: 1.0000 - val_loss: 1.9088 - val_accuracy: 0.1951 - 270ms/epoch - 90ms/step\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 193: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1737 - accuracy: 1.0000 - val_loss: 1.8264 - val_accuracy: 0.2195 - 296ms/epoch - 99ms/step\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 194: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1322 - accuracy: 1.0000 - val_loss: 1.8387 - val_accuracy: 0.2683 - 274ms/epoch - 91ms/step\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 195: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1412 - accuracy: 1.0000 - val_loss: 1.8769 - val_accuracy: 0.2439 - 285ms/epoch - 95ms/step\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 196: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1269 - accuracy: 1.0000 - val_loss: 1.8624 - val_accuracy: 0.2927 - 277ms/epoch - 92ms/step\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 197: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1511 - accuracy: 1.0000 - val_loss: 1.8436 - val_accuracy: 0.2439 - 270ms/epoch - 90ms/step\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 198: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1300 - accuracy: 1.0000 - val_loss: 1.8967 - val_accuracy: 0.2195 - 296ms/epoch - 99ms/step\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 199: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1499 - accuracy: 1.0000 - val_loss: 1.8788 - val_accuracy: 0.1951 - 272ms/epoch - 91ms/step\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 200: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1387 - accuracy: 1.0000 - val_loss: 1.8262 - val_accuracy: 0.2683 - 267ms/epoch - 89ms/step\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 201: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1278 - accuracy: 1.0000 - val_loss: 1.9052 - val_accuracy: 0.2683 - 284ms/epoch - 95ms/step\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 202: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1170 - accuracy: 1.0000 - val_loss: 1.8525 - val_accuracy: 0.2683 - 271ms/epoch - 90ms/step\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 203: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1207 - accuracy: 1.0000 - val_loss: 1.8546 - val_accuracy: 0.2683 - 286ms/epoch - 95ms/step\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 204: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1186 - accuracy: 1.0000 - val_loss: 1.8985 - val_accuracy: 0.1707 - 279ms/epoch - 93ms/step\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 205: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1274 - accuracy: 1.0000 - val_loss: 1.9251 - val_accuracy: 0.2195 - 285ms/epoch - 95ms/step\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 206: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1297 - accuracy: 1.0000 - val_loss: 1.8310 - val_accuracy: 0.2683 - 284ms/epoch - 95ms/step\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 207: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1413 - accuracy: 1.0000 - val_loss: 1.8152 - val_accuracy: 0.3171 - 276ms/epoch - 92ms/step\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 208: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1195 - accuracy: 1.0000 - val_loss: 2.0639 - val_accuracy: 0.1707 - 284ms/epoch - 95ms/step\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 209: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1254 - accuracy: 1.0000 - val_loss: 1.9490 - val_accuracy: 0.2683 - 282ms/epoch - 94ms/step\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 210: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1291 - accuracy: 1.0000 - val_loss: 2.0016 - val_accuracy: 0.1707 - 289ms/epoch - 96ms/step\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 211: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1323 - accuracy: 1.0000 - val_loss: 1.9941 - val_accuracy: 0.2927 - 294ms/epoch - 98ms/step\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 212: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1313 - accuracy: 1.0000 - val_loss: 1.8936 - val_accuracy: 0.2683 - 279ms/epoch - 93ms/step\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 213: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1199 - accuracy: 1.0000 - val_loss: 1.9711 - val_accuracy: 0.2439 - 298ms/epoch - 99ms/step\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 214: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1371 - accuracy: 1.0000 - val_loss: 2.0388 - val_accuracy: 0.3171 - 274ms/epoch - 91ms/step\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 215: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1198 - accuracy: 1.0000 - val_loss: 2.0757 - val_accuracy: 0.1707 - 285ms/epoch - 95ms/step\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 216: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1360 - accuracy: 1.0000 - val_loss: 1.9739 - val_accuracy: 0.2683 - 281ms/epoch - 94ms/step\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 217: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1338 - accuracy: 1.0000 - val_loss: 1.9450 - val_accuracy: 0.3171 - 278ms/epoch - 93ms/step\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 218: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1100 - accuracy: 1.0000 - val_loss: 1.9548 - val_accuracy: 0.2195 - 270ms/epoch - 90ms/step\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 219: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1249 - accuracy: 1.0000 - val_loss: 1.8692 - val_accuracy: 0.2927 - 297ms/epoch - 99ms/step\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 220: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1047 - accuracy: 1.0000 - val_loss: 1.9121 - val_accuracy: 0.2439 - 275ms/epoch - 92ms/step\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 221: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1071 - accuracy: 1.0000 - val_loss: 2.0047 - val_accuracy: 0.2439 - 288ms/epoch - 96ms/step\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 222: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0984 - accuracy: 1.0000 - val_loss: 1.9552 - val_accuracy: 0.2683 - 285ms/epoch - 95ms/step\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 223: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1026 - accuracy: 1.0000 - val_loss: 2.0239 - val_accuracy: 0.2195 - 277ms/epoch - 92ms/step\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 224: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1246 - accuracy: 1.0000 - val_loss: 2.0163 - val_accuracy: 0.2195 - 276ms/epoch - 92ms/step\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 225: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0908 - accuracy: 1.0000 - val_loss: 2.0243 - val_accuracy: 0.2927 - 280ms/epoch - 93ms/step\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 226: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1118 - accuracy: 1.0000 - val_loss: 2.0303 - val_accuracy: 0.2195 - 282ms/epoch - 94ms/step\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 227: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1153 - accuracy: 1.0000 - val_loss: 2.0353 - val_accuracy: 0.2195 - 270ms/epoch - 90ms/step\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 228: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1093 - accuracy: 1.0000 - val_loss: 2.0935 - val_accuracy: 0.3171 - 274ms/epoch - 91ms/step\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 229: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0971 - accuracy: 1.0000 - val_loss: 2.1486 - val_accuracy: 0.1951 - 287ms/epoch - 96ms/step\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 230: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1059 - accuracy: 1.0000 - val_loss: 1.9519 - val_accuracy: 0.2683 - 267ms/epoch - 89ms/step\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 231: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1023 - accuracy: 1.0000 - val_loss: 1.9170 - val_accuracy: 0.2439 - 283ms/epoch - 94ms/step\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 232: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1060 - accuracy: 1.0000 - val_loss: 1.9949 - val_accuracy: 0.1707 - 272ms/epoch - 91ms/step\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 233: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0911 - accuracy: 1.0000 - val_loss: 1.9303 - val_accuracy: 0.2195 - 273ms/epoch - 91ms/step\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 234: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0967 - accuracy: 1.0000 - val_loss: 2.0058 - val_accuracy: 0.2195 - 274ms/epoch - 91ms/step\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 235: val_loss did not improve from 1.38502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 0.0913 - accuracy: 1.0000 - val_loss: 2.0082 - val_accuracy: 0.2683 - 277ms/epoch - 92ms/step\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 236: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1083 - accuracy: 1.0000 - val_loss: 2.1119 - val_accuracy: 0.1951 - 270ms/epoch - 90ms/step\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 237: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1161 - accuracy: 1.0000 - val_loss: 2.0532 - val_accuracy: 0.2439 - 296ms/epoch - 99ms/step\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 238: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0940 - accuracy: 1.0000 - val_loss: 1.9958 - val_accuracy: 0.3171 - 285ms/epoch - 95ms/step\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 239: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1020 - accuracy: 1.0000 - val_loss: 1.9939 - val_accuracy: 0.2439 - 270ms/epoch - 90ms/step\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 240: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0959 - accuracy: 1.0000 - val_loss: 1.9459 - val_accuracy: 0.2439 - 287ms/epoch - 96ms/step\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 241: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1038 - accuracy: 1.0000 - val_loss: 2.0244 - val_accuracy: 0.2439 - 276ms/epoch - 92ms/step\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 242: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0883 - accuracy: 1.0000 - val_loss: 2.0234 - val_accuracy: 0.2195 - 272ms/epoch - 91ms/step\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 243: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1139 - accuracy: 1.0000 - val_loss: 2.0173 - val_accuracy: 0.2439 - 279ms/epoch - 93ms/step\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 244: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1153 - accuracy: 1.0000 - val_loss: 2.0215 - val_accuracy: 0.2683 - 283ms/epoch - 94ms/step\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 245: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1003 - accuracy: 1.0000 - val_loss: 2.0576 - val_accuracy: 0.2195 - 289ms/epoch - 96ms/step\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 246: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1103 - accuracy: 1.0000 - val_loss: 2.0253 - val_accuracy: 0.2439 - 286ms/epoch - 95ms/step\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 247: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0858 - accuracy: 1.0000 - val_loss: 1.9736 - val_accuracy: 0.2683 - 279ms/epoch - 93ms/step\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 248: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0948 - accuracy: 1.0000 - val_loss: 2.0123 - val_accuracy: 0.2195 - 282ms/epoch - 94ms/step\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 249: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0905 - accuracy: 1.0000 - val_loss: 2.0009 - val_accuracy: 0.3171 - 291ms/epoch - 97ms/step\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 250: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0960 - accuracy: 1.0000 - val_loss: 2.0293 - val_accuracy: 0.2683 - 280ms/epoch - 93ms/step\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 251: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0797 - accuracy: 1.0000 - val_loss: 1.9493 - val_accuracy: 0.2927 - 286ms/epoch - 95ms/step\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 252: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0911 - accuracy: 1.0000 - val_loss: 2.0434 - val_accuracy: 0.2439 - 281ms/epoch - 94ms/step\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 253: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.1102 - accuracy: 1.0000 - val_loss: 2.0417 - val_accuracy: 0.2683 - 282ms/epoch - 94ms/step\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 254: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0746 - accuracy: 1.0000 - val_loss: 2.0033 - val_accuracy: 0.2683 - 284ms/epoch - 95ms/step\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 255: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0937 - accuracy: 1.0000 - val_loss: 2.0176 - val_accuracy: 0.2439 - 286ms/epoch - 95ms/step\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 256: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0939 - accuracy: 1.0000 - val_loss: 2.0282 - val_accuracy: 0.2439 - 291ms/epoch - 97ms/step\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 257: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0825 - accuracy: 1.0000 - val_loss: 2.0048 - val_accuracy: 0.2927 - 282ms/epoch - 94ms/step\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 258: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0874 - accuracy: 1.0000 - val_loss: 1.9759 - val_accuracy: 0.2683 - 280ms/epoch - 93ms/step\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 259: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0896 - accuracy: 1.0000 - val_loss: 2.0404 - val_accuracy: 0.2195 - 276ms/epoch - 92ms/step\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 260: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0759 - accuracy: 1.0000 - val_loss: 2.0801 - val_accuracy: 0.1951 - 270ms/epoch - 90ms/step\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 261: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0904 - accuracy: 1.0000 - val_loss: 2.0637 - val_accuracy: 0.1951 - 283ms/epoch - 94ms/step\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 262: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0881 - accuracy: 1.0000 - val_loss: 1.9707 - val_accuracy: 0.2439 - 267ms/epoch - 89ms/step\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 263: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0762 - accuracy: 1.0000 - val_loss: 1.9995 - val_accuracy: 0.2195 - 270ms/epoch - 90ms/step\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 264: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0854 - accuracy: 1.0000 - val_loss: 2.1052 - val_accuracy: 0.1951 - 268ms/epoch - 89ms/step\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 265: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0880 - accuracy: 1.0000 - val_loss: 2.0812 - val_accuracy: 0.2439 - 274ms/epoch - 91ms/step\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 266: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0686 - accuracy: 1.0000 - val_loss: 2.0612 - val_accuracy: 0.2439 - 280ms/epoch - 93ms/step\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 267: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0811 - accuracy: 1.0000 - val_loss: 2.0521 - val_accuracy: 0.2439 - 275ms/epoch - 92ms/step\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 268: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0715 - accuracy: 1.0000 - val_loss: 2.1645 - val_accuracy: 0.1707 - 269ms/epoch - 90ms/step\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 269: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0774 - accuracy: 1.0000 - val_loss: 2.1273 - val_accuracy: 0.2439 - 279ms/epoch - 93ms/step\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 270: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0844 - accuracy: 1.0000 - val_loss: 2.1164 - val_accuracy: 0.2439 - 293ms/epoch - 98ms/step\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 271: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0722 - accuracy: 1.0000 - val_loss: 2.0929 - val_accuracy: 0.2195 - 268ms/epoch - 89ms/step\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 272: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0894 - accuracy: 1.0000 - val_loss: 2.1016 - val_accuracy: 0.2195 - 283ms/epoch - 94ms/step\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 273: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0869 - accuracy: 1.0000 - val_loss: 2.0968 - val_accuracy: 0.1951 - 285ms/epoch - 95ms/step\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 274: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0761 - accuracy: 1.0000 - val_loss: 2.0906 - val_accuracy: 0.2195 - 278ms/epoch - 93ms/step\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 275: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0866 - accuracy: 1.0000 - val_loss: 1.9819 - val_accuracy: 0.2195 - 277ms/epoch - 92ms/step\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 276: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0746 - accuracy: 1.0000 - val_loss: 1.9864 - val_accuracy: 0.2195 - 268ms/epoch - 89ms/step\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 277: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0854 - accuracy: 1.0000 - val_loss: 2.0063 - val_accuracy: 0.2927 - 277ms/epoch - 92ms/step\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 278: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0806 - accuracy: 1.0000 - val_loss: 2.0248 - val_accuracy: 0.2439 - 282ms/epoch - 94ms/step\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 279: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0785 - accuracy: 1.0000 - val_loss: 2.0895 - val_accuracy: 0.2195 - 289ms/epoch - 96ms/step\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 280: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0683 - accuracy: 1.0000 - val_loss: 2.1585 - val_accuracy: 0.2439 - 276ms/epoch - 92ms/step\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 281: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0885 - accuracy: 1.0000 - val_loss: 2.0865 - val_accuracy: 0.2683 - 270ms/epoch - 90ms/step\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 282: val_loss did not improve from 1.38502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 0.0818 - accuracy: 1.0000 - val_loss: 2.0674 - val_accuracy: 0.3171 - 286ms/epoch - 95ms/step\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 283: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0905 - accuracy: 1.0000 - val_loss: 2.1034 - val_accuracy: 0.3415 - 269ms/epoch - 90ms/step\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 284: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0780 - accuracy: 1.0000 - val_loss: 2.1038 - val_accuracy: 0.3171 - 268ms/epoch - 89ms/step\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 285: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0733 - accuracy: 1.0000 - val_loss: 2.1221 - val_accuracy: 0.2195 - 287ms/epoch - 96ms/step\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 286: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0840 - accuracy: 1.0000 - val_loss: 2.0791 - val_accuracy: 0.2927 - 282ms/epoch - 94ms/step\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 287: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0731 - accuracy: 1.0000 - val_loss: 2.2288 - val_accuracy: 0.2927 - 272ms/epoch - 91ms/step\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 288: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0865 - accuracy: 1.0000 - val_loss: 2.1454 - val_accuracy: 0.2683 - 271ms/epoch - 90ms/step\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 289: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0736 - accuracy: 1.0000 - val_loss: 2.0516 - val_accuracy: 0.2683 - 271ms/epoch - 90ms/step\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 290: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0749 - accuracy: 1.0000 - val_loss: 2.0158 - val_accuracy: 0.2439 - 268ms/epoch - 89ms/step\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 291: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0805 - accuracy: 1.0000 - val_loss: 2.0292 - val_accuracy: 0.2927 - 290ms/epoch - 97ms/step\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 292: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0619 - accuracy: 1.0000 - val_loss: 2.0812 - val_accuracy: 0.2439 - 272ms/epoch - 91ms/step\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 293: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0879 - accuracy: 1.0000 - val_loss: 2.0423 - val_accuracy: 0.2439 - 276ms/epoch - 92ms/step\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 294: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0666 - accuracy: 1.0000 - val_loss: 2.0622 - val_accuracy: 0.1951 - 270ms/epoch - 90ms/step\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 295: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0827 - accuracy: 1.0000 - val_loss: 2.0309 - val_accuracy: 0.2683 - 270ms/epoch - 90ms/step\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 296: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0656 - accuracy: 1.0000 - val_loss: 2.1536 - val_accuracy: 0.2195 - 287ms/epoch - 96ms/step\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 297: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0675 - accuracy: 1.0000 - val_loss: 2.1528 - val_accuracy: 0.2927 - 275ms/epoch - 92ms/step\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 298: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0721 - accuracy: 1.0000 - val_loss: 2.1023 - val_accuracy: 0.2439 - 273ms/epoch - 91ms/step\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 299: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0822 - accuracy: 1.0000 - val_loss: 2.0446 - val_accuracy: 0.2683 - 272ms/epoch - 91ms/step\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 300: val_loss did not improve from 1.38502\n",
      "3/3 - 0s - loss: 0.0828 - accuracy: 1.0000 - val_loss: 2.2100 - val_accuracy: 0.1463 - 281ms/epoch - 94ms/step\n",
      "2/2 [==============================] - 0s 22ms/step\n",
      "Lists\n",
      "[0.24444444444444444, 0.24444444444444444, 0.2, 0.2222222222222222]\n",
      "[0.06111111111111111, 0.06111111111111111, 0.05, 0.1346153846153846]\n",
      "[0.25, 0.25, 0.25, 0.2777777777777778]\n",
      "[0.09821428571428571, 0.09821428571428571, 0.08333333333333334, 0.15]\n",
      "dicts\n",
      "{1: 0.28, 2: 0.2, 3: 0.22777777777777777, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0}\n",
      "{1: 0.179879077643203, 2: 0.06654896421845574, 3: 0.07670940170940171, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0}\n",
      "{1: 0.285120781995782, 2: 0.2456597222222222, 3: 0.2569444444444444, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0}\n",
      "{1: 0.19991143316006618, 2: 0.09862908327582241, 3: 0.1074404761904762, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Number of devices: 2\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 09:27:35.973216: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_9060746\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:595564\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
      "2022-11-11 09:27:40.415335: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_9063816\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:595606\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38643, saving model to checkpoint1.h5\n",
      "4/4 - 6s - loss: 1.4164 - accuracy: 0.3016 - val_loss: 1.3864 - val_accuracy: 0.2593 - 6s/epoch - 1s/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 1.3366 - accuracy: 0.3889 - val_loss: 1.3867 - val_accuracy: 0.2593 - 332ms/epoch - 83ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 1.2888 - accuracy: 0.4524 - val_loss: 1.3871 - val_accuracy: 0.2037 - 347ms/epoch - 87ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 1.2631 - accuracy: 0.4365 - val_loss: 1.3874 - val_accuracy: 0.2037 - 346ms/epoch - 86ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 1.2442 - accuracy: 0.4921 - val_loss: 1.3875 - val_accuracy: 0.2037 - 344ms/epoch - 86ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 1.2211 - accuracy: 0.5397 - val_loss: 1.3875 - val_accuracy: 0.2037 - 326ms/epoch - 82ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 1.2235 - accuracy: 0.4603 - val_loss: 1.3877 - val_accuracy: 0.2037 - 346ms/epoch - 86ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 1.2027 - accuracy: 0.4603 - val_loss: 1.3878 - val_accuracy: 0.2037 - 339ms/epoch - 85ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 1.1669 - accuracy: 0.5635 - val_loss: 1.3881 - val_accuracy: 0.2037 - 331ms/epoch - 83ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 1.1810 - accuracy: 0.5714 - val_loss: 1.3882 - val_accuracy: 0.2037 - 324ms/epoch - 81ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 1.1707 - accuracy: 0.5317 - val_loss: 1.3880 - val_accuracy: 0.2037 - 332ms/epoch - 83ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 1.1483 - accuracy: 0.5476 - val_loss: 1.3882 - val_accuracy: 0.2037 - 325ms/epoch - 81ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 1.1202 - accuracy: 0.5794 - val_loss: 1.3885 - val_accuracy: 0.2037 - 330ms/epoch - 83ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 1.1193 - accuracy: 0.6032 - val_loss: 1.3887 - val_accuracy: 0.2037 - 325ms/epoch - 81ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 1.1100 - accuracy: 0.6587 - val_loss: 1.3892 - val_accuracy: 0.2037 - 344ms/epoch - 86ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 1.1052 - accuracy: 0.6190 - val_loss: 1.3891 - val_accuracy: 0.2037 - 330ms/epoch - 82ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 1.1257 - accuracy: 0.5873 - val_loss: 1.3892 - val_accuracy: 0.2037 - 349ms/epoch - 87ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 1.0913 - accuracy: 0.6190 - val_loss: 1.3900 - val_accuracy: 0.2037 - 325ms/epoch - 81ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 1.0361 - accuracy: 0.6984 - val_loss: 1.3902 - val_accuracy: 0.2222 - 325ms/epoch - 81ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 1.0353 - accuracy: 0.6905 - val_loss: 1.3897 - val_accuracy: 0.2222 - 332ms/epoch - 83ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 1.0591 - accuracy: 0.6270 - val_loss: 1.3900 - val_accuracy: 0.2593 - 333ms/epoch - 83ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 1.0296 - accuracy: 0.6825 - val_loss: 1.3910 - val_accuracy: 0.2222 - 331ms/epoch - 83ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 1.0476 - accuracy: 0.6746 - val_loss: 1.3927 - val_accuracy: 0.2778 - 329ms/epoch - 82ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 1.0412 - accuracy: 0.6667 - val_loss: 1.3923 - val_accuracy: 0.2778 - 346ms/epoch - 87ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.9895 - accuracy: 0.7302 - val_loss: 1.3916 - val_accuracy: 0.2778 - 321ms/epoch - 80ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 1.0115 - accuracy: 0.6667 - val_loss: 1.3921 - val_accuracy: 0.2963 - 328ms/epoch - 82ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.9837 - accuracy: 0.6825 - val_loss: 1.3941 - val_accuracy: 0.2778 - 352ms/epoch - 88ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.9795 - accuracy: 0.7381 - val_loss: 1.3952 - val_accuracy: 0.2778 - 327ms/epoch - 82ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.9334 - accuracy: 0.8016 - val_loss: 1.3949 - val_accuracy: 0.2778 - 335ms/epoch - 84ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.9451 - accuracy: 0.7540 - val_loss: 1.3945 - val_accuracy: 0.2593 - 332ms/epoch - 83ms/step\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.9587 - accuracy: 0.7540 - val_loss: 1.3968 - val_accuracy: 0.2778 - 335ms/epoch - 84ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.9445 - accuracy: 0.7778 - val_loss: 1.3985 - val_accuracy: 0.2778 - 328ms/epoch - 82ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.9265 - accuracy: 0.7222 - val_loss: 1.3975 - val_accuracy: 0.2407 - 325ms/epoch - 81ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.9551 - accuracy: 0.7857 - val_loss: 1.3981 - val_accuracy: 0.2407 - 328ms/epoch - 82ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.9054 - accuracy: 0.8175 - val_loss: 1.3980 - val_accuracy: 0.1852 - 339ms/epoch - 85ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.9426 - accuracy: 0.7778 - val_loss: 1.4021 - val_accuracy: 0.1481 - 339ms/epoch - 85ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.9309 - accuracy: 0.7222 - val_loss: 1.4059 - val_accuracy: 0.2037 - 333ms/epoch - 83ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.9126 - accuracy: 0.7698 - val_loss: 1.4004 - val_accuracy: 0.2222 - 332ms/epoch - 83ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.9017 - accuracy: 0.8095 - val_loss: 1.4023 - val_accuracy: 0.2037 - 332ms/epoch - 83ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.9246 - accuracy: 0.7619 - val_loss: 1.4085 - val_accuracy: 0.2963 - 336ms/epoch - 84ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.9341 - accuracy: 0.7381 - val_loss: 1.4022 - val_accuracy: 0.2037 - 340ms/epoch - 85ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.9113 - accuracy: 0.7778 - val_loss: 1.4076 - val_accuracy: 0.1852 - 324ms/epoch - 81ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.8530 - accuracy: 0.7937 - val_loss: 1.4104 - val_accuracy: 0.2037 - 335ms/epoch - 84ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.8319 - accuracy: 0.8413 - val_loss: 1.4065 - val_accuracy: 0.2222 - 336ms/epoch - 84ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.8192 - accuracy: 0.8095 - val_loss: 1.4079 - val_accuracy: 0.2593 - 328ms/epoch - 82ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.8264 - accuracy: 0.8413 - val_loss: 1.4131 - val_accuracy: 0.2037 - 346ms/epoch - 86ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.8478 - accuracy: 0.8016 - val_loss: 1.4143 - val_accuracy: 0.2593 - 330ms/epoch - 82ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.8006 - accuracy: 0.8254 - val_loss: 1.4150 - val_accuracy: 0.2222 - 329ms/epoch - 82ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.8156 - accuracy: 0.8333 - val_loss: 1.4223 - val_accuracy: 0.2037 - 339ms/epoch - 85ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.8004 - accuracy: 0.8095 - val_loss: 1.4257 - val_accuracy: 0.2222 - 328ms/epoch - 82ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.8048 - accuracy: 0.8492 - val_loss: 1.4185 - val_accuracy: 0.2037 - 336ms/epoch - 84ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.7337 - accuracy: 0.8968 - val_loss: 1.4279 - val_accuracy: 0.2407 - 331ms/epoch - 83ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.8028 - accuracy: 0.8571 - val_loss: 1.4377 - val_accuracy: 0.2222 - 347ms/epoch - 87ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.7575 - accuracy: 0.8968 - val_loss: 1.4360 - val_accuracy: 0.2407 - 336ms/epoch - 84ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.7462 - accuracy: 0.8571 - val_loss: 1.4346 - val_accuracy: 0.2222 - 325ms/epoch - 81ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.7437 - accuracy: 0.8968 - val_loss: 1.4257 - val_accuracy: 0.2593 - 347ms/epoch - 87ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.7634 - accuracy: 0.9048 - val_loss: 1.4493 - val_accuracy: 0.2222 - 328ms/epoch - 82ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.7667 - accuracy: 0.8810 - val_loss: 1.4593 - val_accuracy: 0.2037 - 333ms/epoch - 83ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.8035 - accuracy: 0.7937 - val_loss: 1.4500 - val_accuracy: 0.2222 - 349ms/epoch - 87ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.7809 - accuracy: 0.8571 - val_loss: 1.4568 - val_accuracy: 0.2593 - 337ms/epoch - 84ms/step\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.7540 - accuracy: 0.8889 - val_loss: 1.4604 - val_accuracy: 0.2222 - 330ms/epoch - 82ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.7547 - accuracy: 0.8730 - val_loss: 1.4556 - val_accuracy: 0.2222 - 333ms/epoch - 83ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.7032 - accuracy: 0.8651 - val_loss: 1.4886 - val_accuracy: 0.2037 - 342ms/epoch - 85ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.6922 - accuracy: 0.9286 - val_loss: 1.4609 - val_accuracy: 0.1667 - 324ms/epoch - 81ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.6807 - accuracy: 0.9286 - val_loss: 1.5097 - val_accuracy: 0.1852 - 339ms/epoch - 85ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.6852 - accuracy: 0.8968 - val_loss: 1.4749 - val_accuracy: 0.2407 - 335ms/epoch - 84ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.6441 - accuracy: 0.9365 - val_loss: 1.5026 - val_accuracy: 0.2037 - 342ms/epoch - 85ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.6467 - accuracy: 0.9365 - val_loss: 1.5149 - val_accuracy: 0.2222 - 337ms/epoch - 84ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.6506 - accuracy: 0.9286 - val_loss: 1.4845 - val_accuracy: 0.1852 - 339ms/epoch - 85ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.6168 - accuracy: 0.9444 - val_loss: 1.5140 - val_accuracy: 0.2593 - 326ms/epoch - 82ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.5810 - accuracy: 0.9524 - val_loss: 1.5568 - val_accuracy: 0.2037 - 350ms/epoch - 88ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.5669 - accuracy: 0.9603 - val_loss: 1.4977 - val_accuracy: 0.2222 - 338ms/epoch - 85ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.5933 - accuracy: 0.9206 - val_loss: 1.5815 - val_accuracy: 0.1667 - 329ms/epoch - 82ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.6326 - accuracy: 0.9365 - val_loss: 1.5085 - val_accuracy: 0.2593 - 327ms/epoch - 82ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.6140 - accuracy: 0.9048 - val_loss: 1.5374 - val_accuracy: 0.2593 - 323ms/epoch - 81ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.5692 - accuracy: 0.9603 - val_loss: 1.5475 - val_accuracy: 0.2222 - 329ms/epoch - 82ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.5822 - accuracy: 0.9444 - val_loss: 1.5488 - val_accuracy: 0.2037 - 333ms/epoch - 83ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.5853 - accuracy: 0.9127 - val_loss: 1.5814 - val_accuracy: 0.2593 - 325ms/epoch - 81ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.5677 - accuracy: 0.9603 - val_loss: 1.5631 - val_accuracy: 0.2222 - 341ms/epoch - 85ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.5575 - accuracy: 0.9444 - val_loss: 1.5915 - val_accuracy: 0.2037 - 336ms/epoch - 84ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.5496 - accuracy: 0.9444 - val_loss: 1.5599 - val_accuracy: 0.2222 - 328ms/epoch - 82ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.5426 - accuracy: 0.9444 - val_loss: 1.5961 - val_accuracy: 0.2778 - 341ms/epoch - 85ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.5258 - accuracy: 0.9524 - val_loss: 1.6555 - val_accuracy: 0.2963 - 334ms/epoch - 83ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.5321 - accuracy: 0.9762 - val_loss: 1.5766 - val_accuracy: 0.2593 - 328ms/epoch - 82ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.5230 - accuracy: 0.9683 - val_loss: 1.6077 - val_accuracy: 0.2407 - 343ms/epoch - 86ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.4827 - accuracy: 0.9762 - val_loss: 1.5665 - val_accuracy: 0.2593 - 341ms/epoch - 85ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.5098 - accuracy: 0.9683 - val_loss: 1.6269 - val_accuracy: 0.2407 - 328ms/epoch - 82ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.5028 - accuracy: 0.9444 - val_loss: 1.6235 - val_accuracy: 0.2222 - 347ms/epoch - 87ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.4977 - accuracy: 0.9524 - val_loss: 1.7144 - val_accuracy: 0.2222 - 335ms/epoch - 84ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.4942 - accuracy: 0.9683 - val_loss: 1.6560 - val_accuracy: 0.1667 - 335ms/epoch - 84ms/step\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.4542 - accuracy: 0.9762 - val_loss: 1.6745 - val_accuracy: 0.2407 - 327ms/epoch - 82ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.5233 - accuracy: 0.9524 - val_loss: 1.6771 - val_accuracy: 0.2778 - 335ms/epoch - 84ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.4566 - accuracy: 0.9841 - val_loss: 1.5723 - val_accuracy: 0.1852 - 322ms/epoch - 81ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.4478 - accuracy: 0.9762 - val_loss: 1.5950 - val_accuracy: 0.2222 - 335ms/epoch - 84ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.4394 - accuracy: 0.9841 - val_loss: 1.7604 - val_accuracy: 0.2593 - 341ms/epoch - 85ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 1.38643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.4708 - accuracy: 0.9841 - val_loss: 1.6843 - val_accuracy: 0.2593 - 339ms/epoch - 85ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.4573 - accuracy: 0.9762 - val_loss: 1.6371 - val_accuracy: 0.2222 - 333ms/epoch - 83ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.4617 - accuracy: 0.9524 - val_loss: 1.7423 - val_accuracy: 0.2593 - 332ms/epoch - 83ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.4486 - accuracy: 0.9444 - val_loss: 1.6469 - val_accuracy: 0.1852 - 331ms/epoch - 83ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.4664 - accuracy: 0.9841 - val_loss: 1.7479 - val_accuracy: 0.2407 - 320ms/epoch - 80ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.4603 - accuracy: 0.9762 - val_loss: 1.6947 - val_accuracy: 0.1852 - 334ms/epoch - 83ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.4489 - accuracy: 0.9762 - val_loss: 1.6390 - val_accuracy: 0.2222 - 343ms/epoch - 86ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.4122 - accuracy: 0.9921 - val_loss: 1.6917 - val_accuracy: 0.2037 - 329ms/epoch - 82ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.4280 - accuracy: 0.9841 - val_loss: 1.9350 - val_accuracy: 0.2963 - 333ms/epoch - 83ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.4169 - accuracy: 0.9921 - val_loss: 1.7413 - val_accuracy: 0.2593 - 322ms/epoch - 80ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.4370 - accuracy: 0.9841 - val_loss: 1.5958 - val_accuracy: 0.2593 - 331ms/epoch - 83ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3966 - accuracy: 0.9603 - val_loss: 1.6785 - val_accuracy: 0.2593 - 340ms/epoch - 85ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3694 - accuracy: 0.9841 - val_loss: 1.8795 - val_accuracy: 0.2593 - 332ms/epoch - 83ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3829 - accuracy: 1.0000 - val_loss: 1.6840 - val_accuracy: 0.1852 - 329ms/epoch - 82ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3835 - accuracy: 1.0000 - val_loss: 1.7620 - val_accuracy: 0.2407 - 330ms/epoch - 82ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3512 - accuracy: 0.9921 - val_loss: 1.7728 - val_accuracy: 0.2407 - 323ms/epoch - 81ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3865 - accuracy: 0.9841 - val_loss: 1.6850 - val_accuracy: 0.2407 - 347ms/epoch - 87ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3443 - accuracy: 0.9841 - val_loss: 1.7654 - val_accuracy: 0.2222 - 344ms/epoch - 86ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3406 - accuracy: 1.0000 - val_loss: 1.7174 - val_accuracy: 0.1852 - 339ms/epoch - 85ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3484 - accuracy: 0.9921 - val_loss: 1.8537 - val_accuracy: 0.2963 - 341ms/epoch - 85ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3647 - accuracy: 0.9921 - val_loss: 1.7507 - val_accuracy: 0.2407 - 327ms/epoch - 82ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3821 - accuracy: 0.9921 - val_loss: 1.7314 - val_accuracy: 0.2037 - 336ms/epoch - 84ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.4023 - accuracy: 0.9603 - val_loss: 1.9716 - val_accuracy: 0.2222 - 325ms/epoch - 81ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3386 - accuracy: 1.0000 - val_loss: 1.9063 - val_accuracy: 0.2407 - 342ms/epoch - 85ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3514 - accuracy: 0.9841 - val_loss: 1.8080 - val_accuracy: 0.2407 - 343ms/epoch - 86ms/step\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3229 - accuracy: 0.9921 - val_loss: 1.8115 - val_accuracy: 0.1852 - 327ms/epoch - 82ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3416 - accuracy: 1.0000 - val_loss: 1.8694 - val_accuracy: 0.2222 - 327ms/epoch - 82ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3199 - accuracy: 0.9921 - val_loss: 2.0405 - val_accuracy: 0.2778 - 326ms/epoch - 81ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3147 - accuracy: 1.0000 - val_loss: 1.8735 - val_accuracy: 0.1852 - 329ms/epoch - 82ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3324 - accuracy: 0.9841 - val_loss: 1.7871 - val_accuracy: 0.2778 - 352ms/epoch - 88ms/step\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3540 - accuracy: 0.9841 - val_loss: 1.7771 - val_accuracy: 0.1852 - 329ms/epoch - 82ms/step\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3185 - accuracy: 0.9921 - val_loss: 1.8373 - val_accuracy: 0.1481 - 330ms/epoch - 83ms/step\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3074 - accuracy: 0.9921 - val_loss: 2.0741 - val_accuracy: 0.2778 - 325ms/epoch - 81ms/step\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3057 - accuracy: 0.9921 - val_loss: 1.8751 - val_accuracy: 0.1852 - 337ms/epoch - 84ms/step\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3371 - accuracy: 0.9762 - val_loss: 1.8759 - val_accuracy: 0.2222 - 330ms/epoch - 82ms/step\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3288 - accuracy: 1.0000 - val_loss: 1.9140 - val_accuracy: 0.1852 - 337ms/epoch - 84ms/step\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3009 - accuracy: 0.9921 - val_loss: 1.8156 - val_accuracy: 0.2407 - 340ms/epoch - 85ms/step\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2999 - accuracy: 1.0000 - val_loss: 1.8872 - val_accuracy: 0.2037 - 328ms/epoch - 82ms/step\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3245 - accuracy: 0.9683 - val_loss: 1.9081 - val_accuracy: 0.2778 - 332ms/epoch - 83ms/step\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 135: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2740 - accuracy: 0.9921 - val_loss: 1.7732 - val_accuracy: 0.2963 - 327ms/epoch - 82ms/step\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 136: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.3097 - accuracy: 0.9921 - val_loss: 1.8962 - val_accuracy: 0.2222 - 337ms/epoch - 84ms/step\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 137: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2756 - accuracy: 1.0000 - val_loss: 1.8006 - val_accuracy: 0.2407 - 343ms/epoch - 86ms/step\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 138: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2583 - accuracy: 0.9921 - val_loss: 1.9068 - val_accuracy: 0.2407 - 333ms/epoch - 83ms/step\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 139: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2710 - accuracy: 1.0000 - val_loss: 1.8226 - val_accuracy: 0.2037 - 326ms/epoch - 82ms/step\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 140: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2580 - accuracy: 0.9921 - val_loss: 1.9544 - val_accuracy: 0.2222 - 335ms/epoch - 84ms/step\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 141: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2754 - accuracy: 1.0000 - val_loss: 1.8214 - val_accuracy: 0.2407 - 333ms/epoch - 83ms/step\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 142: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2650 - accuracy: 0.9841 - val_loss: 2.1803 - val_accuracy: 0.2593 - 331ms/epoch - 83ms/step\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 143: val_loss did not improve from 1.38643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.2668 - accuracy: 1.0000 - val_loss: 1.9869 - val_accuracy: 0.2593 - 329ms/epoch - 82ms/step\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 144: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2495 - accuracy: 1.0000 - val_loss: 1.9565 - val_accuracy: 0.1852 - 330ms/epoch - 82ms/step\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 145: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2356 - accuracy: 1.0000 - val_loss: 1.9827 - val_accuracy: 0.1667 - 341ms/epoch - 85ms/step\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 146: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2449 - accuracy: 0.9921 - val_loss: 1.9825 - val_accuracy: 0.2037 - 327ms/epoch - 82ms/step\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 147: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2902 - accuracy: 0.9921 - val_loss: 1.7963 - val_accuracy: 0.1852 - 344ms/epoch - 86ms/step\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 148: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2867 - accuracy: 1.0000 - val_loss: 1.7528 - val_accuracy: 0.2778 - 323ms/epoch - 81ms/step\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 149: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2304 - accuracy: 1.0000 - val_loss: 1.8030 - val_accuracy: 0.1852 - 334ms/epoch - 84ms/step\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 150: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2222 - accuracy: 1.0000 - val_loss: 1.9261 - val_accuracy: 0.2407 - 331ms/epoch - 83ms/step\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 151: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2369 - accuracy: 0.9921 - val_loss: 1.8811 - val_accuracy: 0.2407 - 354ms/epoch - 88ms/step\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 152: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2454 - accuracy: 1.0000 - val_loss: 1.9200 - val_accuracy: 0.2222 - 329ms/epoch - 82ms/step\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 153: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2381 - accuracy: 1.0000 - val_loss: 1.8831 - val_accuracy: 0.2407 - 330ms/epoch - 82ms/step\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 154: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2428 - accuracy: 1.0000 - val_loss: 1.9014 - val_accuracy: 0.2037 - 334ms/epoch - 84ms/step\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 155: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2461 - accuracy: 1.0000 - val_loss: 1.8602 - val_accuracy: 0.2222 - 339ms/epoch - 85ms/step\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 156: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2238 - accuracy: 1.0000 - val_loss: 2.0292 - val_accuracy: 0.2593 - 342ms/epoch - 85ms/step\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 157: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2466 - accuracy: 1.0000 - val_loss: 2.0091 - val_accuracy: 0.2407 - 325ms/epoch - 81ms/step\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 158: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2396 - accuracy: 0.9921 - val_loss: 1.9992 - val_accuracy: 0.2037 - 331ms/epoch - 83ms/step\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 159: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2391 - accuracy: 1.0000 - val_loss: 1.9710 - val_accuracy: 0.2593 - 335ms/epoch - 84ms/step\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 160: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 2.0663 - val_accuracy: 0.2963 - 336ms/epoch - 84ms/step\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 161: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 1.9764 - val_accuracy: 0.2407 - 340ms/epoch - 85ms/step\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 162: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2270 - accuracy: 0.9841 - val_loss: 2.1054 - val_accuracy: 0.1852 - 333ms/epoch - 83ms/step\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 163: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2395 - accuracy: 1.0000 - val_loss: 2.0363 - val_accuracy: 0.1852 - 329ms/epoch - 82ms/step\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 164: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 2.0828 - val_accuracy: 0.1667 - 328ms/epoch - 82ms/step\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 165: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2382 - accuracy: 1.0000 - val_loss: 1.9524 - val_accuracy: 0.1852 - 327ms/epoch - 82ms/step\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 166: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.9584 - val_accuracy: 0.2037 - 324ms/epoch - 81ms/step\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 167: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1916 - accuracy: 1.0000 - val_loss: 2.0168 - val_accuracy: 0.1852 - 348ms/epoch - 87ms/step\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 168: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 2.0290 - val_accuracy: 0.2037 - 338ms/epoch - 84ms/step\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 169: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2073 - accuracy: 0.9921 - val_loss: 2.0232 - val_accuracy: 0.2407 - 334ms/epoch - 84ms/step\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 170: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1967 - accuracy: 1.0000 - val_loss: 1.9790 - val_accuracy: 0.2222 - 331ms/epoch - 83ms/step\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 171: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2019 - accuracy: 1.0000 - val_loss: 2.0282 - val_accuracy: 0.2407 - 347ms/epoch - 87ms/step\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 172: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2003 - accuracy: 1.0000 - val_loss: 2.1489 - val_accuracy: 0.2963 - 338ms/epoch - 84ms/step\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 173: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1925 - accuracy: 0.9921 - val_loss: 2.0585 - val_accuracy: 0.2593 - 331ms/epoch - 83ms/step\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 174: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1954 - accuracy: 0.9921 - val_loss: 2.0661 - val_accuracy: 0.2593 - 332ms/epoch - 83ms/step\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 175: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1785 - accuracy: 0.9921 - val_loss: 2.0962 - val_accuracy: 0.2222 - 349ms/epoch - 87ms/step\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 176: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1709 - accuracy: 0.9921 - val_loss: 2.0794 - val_accuracy: 0.2037 - 327ms/epoch - 82ms/step\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 177: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1938 - accuracy: 1.0000 - val_loss: 2.0053 - val_accuracy: 0.2593 - 356ms/epoch - 89ms/step\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 178: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2148 - accuracy: 0.9921 - val_loss: 2.2672 - val_accuracy: 0.2778 - 335ms/epoch - 84ms/step\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 179: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1943 - accuracy: 1.0000 - val_loss: 1.9149 - val_accuracy: 0.2407 - 337ms/epoch - 84ms/step\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 180: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2238 - accuracy: 1.0000 - val_loss: 1.8668 - val_accuracy: 0.2407 - 334ms/epoch - 83ms/step\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 181: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1654 - accuracy: 1.0000 - val_loss: 1.9175 - val_accuracy: 0.2407 - 346ms/epoch - 87ms/step\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 182: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1928 - accuracy: 1.0000 - val_loss: 1.8912 - val_accuracy: 0.2037 - 335ms/epoch - 84ms/step\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 183: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1790 - accuracy: 1.0000 - val_loss: 1.8843 - val_accuracy: 0.2222 - 346ms/epoch - 87ms/step\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 184: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.2053 - accuracy: 1.0000 - val_loss: 2.0005 - val_accuracy: 0.2407 - 341ms/epoch - 85ms/step\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 185: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1828 - accuracy: 1.0000 - val_loss: 2.1017 - val_accuracy: 0.2037 - 324ms/epoch - 81ms/step\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 186: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1795 - accuracy: 1.0000 - val_loss: 1.8803 - val_accuracy: 0.2222 - 328ms/epoch - 82ms/step\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 187: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1964 - accuracy: 1.0000 - val_loss: 2.1150 - val_accuracy: 0.2778 - 340ms/epoch - 85ms/step\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 188: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1827 - accuracy: 0.9921 - val_loss: 1.9569 - val_accuracy: 0.2407 - 334ms/epoch - 83ms/step\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 189: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1729 - accuracy: 1.0000 - val_loss: 2.2077 - val_accuracy: 0.2407 - 334ms/epoch - 83ms/step\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 190: val_loss did not improve from 1.38643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.1582 - accuracy: 1.0000 - val_loss: 2.0460 - val_accuracy: 0.2593 - 323ms/epoch - 81ms/step\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 191: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1673 - accuracy: 1.0000 - val_loss: 2.1083 - val_accuracy: 0.2593 - 337ms/epoch - 84ms/step\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 192: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1556 - accuracy: 1.0000 - val_loss: 2.1250 - val_accuracy: 0.2407 - 325ms/epoch - 81ms/step\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 193: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1646 - accuracy: 1.0000 - val_loss: 2.3114 - val_accuracy: 0.2407 - 349ms/epoch - 87ms/step\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 194: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1748 - accuracy: 0.9921 - val_loss: 2.2098 - val_accuracy: 0.2037 - 326ms/epoch - 81ms/step\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 195: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1823 - accuracy: 1.0000 - val_loss: 2.0330 - val_accuracy: 0.1852 - 328ms/epoch - 82ms/step\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 196: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1787 - accuracy: 1.0000 - val_loss: 2.0414 - val_accuracy: 0.2037 - 335ms/epoch - 84ms/step\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 197: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1648 - accuracy: 1.0000 - val_loss: 2.0421 - val_accuracy: 0.1852 - 356ms/epoch - 89ms/step\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 198: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1573 - accuracy: 1.0000 - val_loss: 2.1139 - val_accuracy: 0.2037 - 333ms/epoch - 83ms/step\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 199: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1503 - accuracy: 1.0000 - val_loss: 2.0859 - val_accuracy: 0.2593 - 333ms/epoch - 83ms/step\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 200: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1552 - accuracy: 1.0000 - val_loss: 2.1944 - val_accuracy: 0.2778 - 329ms/epoch - 82ms/step\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 201: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1498 - accuracy: 1.0000 - val_loss: 2.2415 - val_accuracy: 0.1852 - 323ms/epoch - 81ms/step\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 202: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1636 - accuracy: 0.9921 - val_loss: 2.2438 - val_accuracy: 0.2778 - 324ms/epoch - 81ms/step\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 203: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1604 - accuracy: 1.0000 - val_loss: 2.2990 - val_accuracy: 0.2222 - 342ms/epoch - 85ms/step\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 204: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1574 - accuracy: 1.0000 - val_loss: 2.3401 - val_accuracy: 0.1852 - 325ms/epoch - 81ms/step\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 205: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1522 - accuracy: 1.0000 - val_loss: 2.1969 - val_accuracy: 0.2222 - 335ms/epoch - 84ms/step\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 206: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1430 - accuracy: 1.0000 - val_loss: 2.1793 - val_accuracy: 0.2222 - 326ms/epoch - 81ms/step\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 207: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1397 - accuracy: 1.0000 - val_loss: 2.0746 - val_accuracy: 0.1852 - 351ms/epoch - 88ms/step\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 208: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1502 - accuracy: 1.0000 - val_loss: 2.1199 - val_accuracy: 0.2037 - 346ms/epoch - 86ms/step\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 209: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1470 - accuracy: 1.0000 - val_loss: 2.1450 - val_accuracy: 0.2407 - 339ms/epoch - 85ms/step\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 210: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1365 - accuracy: 1.0000 - val_loss: 2.1058 - val_accuracy: 0.2407 - 323ms/epoch - 81ms/step\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 211: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1404 - accuracy: 0.9921 - val_loss: 2.2582 - val_accuracy: 0.2778 - 334ms/epoch - 83ms/step\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 212: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1396 - accuracy: 1.0000 - val_loss: 2.2377 - val_accuracy: 0.2407 - 328ms/epoch - 82ms/step\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 213: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1342 - accuracy: 1.0000 - val_loss: 2.0705 - val_accuracy: 0.2037 - 328ms/epoch - 82ms/step\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 214: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1507 - accuracy: 1.0000 - val_loss: 2.0843 - val_accuracy: 0.2222 - 350ms/epoch - 87ms/step\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 215: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1421 - accuracy: 1.0000 - val_loss: 2.1222 - val_accuracy: 0.2222 - 331ms/epoch - 83ms/step\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 216: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1455 - accuracy: 1.0000 - val_loss: 2.2716 - val_accuracy: 0.2778 - 331ms/epoch - 83ms/step\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 217: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1565 - accuracy: 1.0000 - val_loss: 2.1258 - val_accuracy: 0.2593 - 330ms/epoch - 82ms/step\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 218: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1711 - accuracy: 1.0000 - val_loss: 2.1884 - val_accuracy: 0.2222 - 343ms/epoch - 86ms/step\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 219: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1663 - accuracy: 1.0000 - val_loss: 2.1939 - val_accuracy: 0.1667 - 329ms/epoch - 82ms/step\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 220: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1470 - accuracy: 0.9921 - val_loss: 2.1585 - val_accuracy: 0.2222 - 337ms/epoch - 84ms/step\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 221: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1302 - accuracy: 1.0000 - val_loss: 2.2086 - val_accuracy: 0.2037 - 334ms/epoch - 84ms/step\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 222: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1372 - accuracy: 1.0000 - val_loss: 2.3005 - val_accuracy: 0.3148 - 343ms/epoch - 86ms/step\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 223: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1452 - accuracy: 1.0000 - val_loss: 2.2488 - val_accuracy: 0.1667 - 329ms/epoch - 82ms/step\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 224: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1264 - accuracy: 1.0000 - val_loss: 2.3003 - val_accuracy: 0.2593 - 334ms/epoch - 84ms/step\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 225: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1400 - accuracy: 1.0000 - val_loss: 2.2891 - val_accuracy: 0.2778 - 326ms/epoch - 81ms/step\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 226: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1328 - accuracy: 1.0000 - val_loss: 2.4516 - val_accuracy: 0.2593 - 331ms/epoch - 83ms/step\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 227: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1247 - accuracy: 1.0000 - val_loss: 2.4621 - val_accuracy: 0.2222 - 338ms/epoch - 85ms/step\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 228: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1409 - accuracy: 0.9921 - val_loss: 2.1908 - val_accuracy: 0.2222 - 330ms/epoch - 82ms/step\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 229: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1315 - accuracy: 1.0000 - val_loss: 2.3451 - val_accuracy: 0.2037 - 328ms/epoch - 82ms/step\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 230: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1416 - accuracy: 1.0000 - val_loss: 2.4979 - val_accuracy: 0.2778 - 325ms/epoch - 81ms/step\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 231: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1408 - accuracy: 1.0000 - val_loss: 2.5260 - val_accuracy: 0.2963 - 336ms/epoch - 84ms/step\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 232: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1407 - accuracy: 0.9921 - val_loss: 2.3647 - val_accuracy: 0.2778 - 332ms/epoch - 83ms/step\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 233: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1280 - accuracy: 1.0000 - val_loss: 2.0193 - val_accuracy: 0.2593 - 341ms/epoch - 85ms/step\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 234: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1309 - accuracy: 1.0000 - val_loss: 2.0155 - val_accuracy: 0.2593 - 328ms/epoch - 82ms/step\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 235: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1450 - accuracy: 0.9921 - val_loss: 2.0750 - val_accuracy: 0.2407 - 325ms/epoch - 81ms/step\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 236: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1464 - accuracy: 1.0000 - val_loss: 2.0913 - val_accuracy: 0.2222 - 324ms/epoch - 81ms/step\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 237: val_loss did not improve from 1.38643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.1193 - accuracy: 1.0000 - val_loss: 2.1009 - val_accuracy: 0.2593 - 333ms/epoch - 83ms/step\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 238: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1143 - accuracy: 1.0000 - val_loss: 2.2069 - val_accuracy: 0.1852 - 325ms/epoch - 81ms/step\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 239: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1317 - accuracy: 1.0000 - val_loss: 2.2542 - val_accuracy: 0.2407 - 334ms/epoch - 83ms/step\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 240: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1196 - accuracy: 1.0000 - val_loss: 2.0826 - val_accuracy: 0.2222 - 341ms/epoch - 85ms/step\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 241: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1041 - accuracy: 1.0000 - val_loss: 2.0195 - val_accuracy: 0.2222 - 332ms/epoch - 83ms/step\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 242: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1264 - accuracy: 0.9921 - val_loss: 2.0378 - val_accuracy: 0.2037 - 336ms/epoch - 84ms/step\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 243: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1203 - accuracy: 1.0000 - val_loss: 2.0271 - val_accuracy: 0.2037 - 324ms/epoch - 81ms/step\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 244: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1063 - accuracy: 1.0000 - val_loss: 2.0120 - val_accuracy: 0.2407 - 334ms/epoch - 83ms/step\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 245: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1214 - accuracy: 1.0000 - val_loss: 2.0013 - val_accuracy: 0.1852 - 332ms/epoch - 83ms/step\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 246: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1251 - accuracy: 1.0000 - val_loss: 2.1094 - val_accuracy: 0.2037 - 335ms/epoch - 84ms/step\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 247: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1184 - accuracy: 1.0000 - val_loss: 2.2633 - val_accuracy: 0.2407 - 333ms/epoch - 83ms/step\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 248: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1125 - accuracy: 1.0000 - val_loss: 2.1466 - val_accuracy: 0.2222 - 331ms/epoch - 83ms/step\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 249: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1227 - accuracy: 1.0000 - val_loss: 2.1474 - val_accuracy: 0.2037 - 323ms/epoch - 81ms/step\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 250: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1365 - accuracy: 0.9921 - val_loss: 2.3093 - val_accuracy: 0.2222 - 323ms/epoch - 81ms/step\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 251: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1161 - accuracy: 1.0000 - val_loss: 2.2685 - val_accuracy: 0.2222 - 332ms/epoch - 83ms/step\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 252: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1144 - accuracy: 1.0000 - val_loss: 2.0658 - val_accuracy: 0.1852 - 344ms/epoch - 86ms/step\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 253: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1142 - accuracy: 1.0000 - val_loss: 2.1355 - val_accuracy: 0.1481 - 331ms/epoch - 83ms/step\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 254: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1078 - accuracy: 1.0000 - val_loss: 2.3307 - val_accuracy: 0.2222 - 348ms/epoch - 87ms/step\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 255: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1080 - accuracy: 1.0000 - val_loss: 2.1969 - val_accuracy: 0.2037 - 339ms/epoch - 85ms/step\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 256: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1198 - accuracy: 1.0000 - val_loss: 2.1726 - val_accuracy: 0.2037 - 325ms/epoch - 81ms/step\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 257: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1033 - accuracy: 0.9921 - val_loss: 2.1519 - val_accuracy: 0.1667 - 332ms/epoch - 83ms/step\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 258: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0998 - accuracy: 1.0000 - val_loss: 2.1520 - val_accuracy: 0.1852 - 326ms/epoch - 82ms/step\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 259: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1128 - accuracy: 1.0000 - val_loss: 2.1347 - val_accuracy: 0.2037 - 328ms/epoch - 82ms/step\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 260: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0972 - accuracy: 1.0000 - val_loss: 2.1004 - val_accuracy: 0.2222 - 339ms/epoch - 85ms/step\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 261: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1160 - accuracy: 1.0000 - val_loss: 2.2394 - val_accuracy: 0.1852 - 336ms/epoch - 84ms/step\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 262: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1242 - accuracy: 1.0000 - val_loss: 2.4132 - val_accuracy: 0.2593 - 335ms/epoch - 84ms/step\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 263: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1081 - accuracy: 1.0000 - val_loss: 2.3737 - val_accuracy: 0.2593 - 334ms/epoch - 84ms/step\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 264: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1183 - accuracy: 1.0000 - val_loss: 2.3113 - val_accuracy: 0.2407 - 322ms/epoch - 80ms/step\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 265: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1036 - accuracy: 1.0000 - val_loss: 2.1896 - val_accuracy: 0.2222 - 348ms/epoch - 87ms/step\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 266: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0997 - accuracy: 1.0000 - val_loss: 2.0852 - val_accuracy: 0.2222 - 334ms/epoch - 84ms/step\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 267: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0977 - accuracy: 1.0000 - val_loss: 2.1592 - val_accuracy: 0.2593 - 323ms/epoch - 81ms/step\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 268: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0972 - accuracy: 1.0000 - val_loss: 2.2755 - val_accuracy: 0.2593 - 333ms/epoch - 83ms/step\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 269: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1164 - accuracy: 1.0000 - val_loss: 2.2442 - val_accuracy: 0.2037 - 351ms/epoch - 88ms/step\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 270: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0950 - accuracy: 1.0000 - val_loss: 2.2190 - val_accuracy: 0.2778 - 334ms/epoch - 83ms/step\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 271: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0984 - accuracy: 1.0000 - val_loss: 2.3489 - val_accuracy: 0.2407 - 323ms/epoch - 81ms/step\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 272: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1208 - accuracy: 1.0000 - val_loss: 2.4407 - val_accuracy: 0.2222 - 326ms/epoch - 81ms/step\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 273: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0956 - accuracy: 1.0000 - val_loss: 2.3653 - val_accuracy: 0.2037 - 331ms/epoch - 83ms/step\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 274: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0873 - accuracy: 1.0000 - val_loss: 2.2263 - val_accuracy: 0.2778 - 327ms/epoch - 82ms/step\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 275: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1033 - accuracy: 1.0000 - val_loss: 2.2347 - val_accuracy: 0.2037 - 347ms/epoch - 87ms/step\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 276: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0952 - accuracy: 1.0000 - val_loss: 2.2327 - val_accuracy: 0.2037 - 339ms/epoch - 85ms/step\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 277: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1005 - accuracy: 1.0000 - val_loss: 2.2660 - val_accuracy: 0.2037 - 327ms/epoch - 82ms/step\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 278: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0996 - accuracy: 1.0000 - val_loss: 2.3622 - val_accuracy: 0.2593 - 334ms/epoch - 83ms/step\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 279: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0885 - accuracy: 1.0000 - val_loss: 2.3609 - val_accuracy: 0.2222 - 342ms/epoch - 85ms/step\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 280: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1155 - accuracy: 1.0000 - val_loss: 2.2200 - val_accuracy: 0.1852 - 332ms/epoch - 83ms/step\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 281: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1051 - accuracy: 1.0000 - val_loss: 2.2987 - val_accuracy: 0.2593 - 337ms/epoch - 84ms/step\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 282: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1032 - accuracy: 1.0000 - val_loss: 2.2699 - val_accuracy: 0.2037 - 336ms/epoch - 84ms/step\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 283: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0840 - accuracy: 1.0000 - val_loss: 2.3380 - val_accuracy: 0.2407 - 335ms/epoch - 84ms/step\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 284: val_loss did not improve from 1.38643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.0986 - accuracy: 1.0000 - val_loss: 2.2894 - val_accuracy: 0.2963 - 324ms/epoch - 81ms/step\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 285: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0988 - accuracy: 1.0000 - val_loss: 2.1487 - val_accuracy: 0.2407 - 325ms/epoch - 81ms/step\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 286: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1088 - accuracy: 1.0000 - val_loss: 2.2371 - val_accuracy: 0.1852 - 326ms/epoch - 82ms/step\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 287: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0896 - accuracy: 1.0000 - val_loss: 2.6225 - val_accuracy: 0.1852 - 347ms/epoch - 87ms/step\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 288: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1068 - accuracy: 1.0000 - val_loss: 2.1985 - val_accuracy: 0.2037 - 337ms/epoch - 84ms/step\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 289: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0903 - accuracy: 1.0000 - val_loss: 2.1460 - val_accuracy: 0.2407 - 355ms/epoch - 89ms/step\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 290: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0925 - accuracy: 1.0000 - val_loss: 2.1753 - val_accuracy: 0.2037 - 331ms/epoch - 83ms/step\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 291: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1060 - accuracy: 0.9841 - val_loss: 2.2848 - val_accuracy: 0.2222 - 331ms/epoch - 83ms/step\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 292: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1015 - accuracy: 1.0000 - val_loss: 2.3285 - val_accuracy: 0.2407 - 346ms/epoch - 87ms/step\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 293: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1164 - accuracy: 1.0000 - val_loss: 2.3739 - val_accuracy: 0.2963 - 336ms/epoch - 84ms/step\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 294: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1040 - accuracy: 1.0000 - val_loss: 2.2005 - val_accuracy: 0.2222 - 329ms/epoch - 82ms/step\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 295: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1046 - accuracy: 1.0000 - val_loss: 2.2563 - val_accuracy: 0.2037 - 334ms/epoch - 84ms/step\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 296: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1087 - accuracy: 1.0000 - val_loss: 2.3294 - val_accuracy: 0.2407 - 332ms/epoch - 83ms/step\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 297: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0908 - accuracy: 1.0000 - val_loss: 2.1857 - val_accuracy: 0.2222 - 327ms/epoch - 82ms/step\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 298: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.1049 - accuracy: 1.0000 - val_loss: 2.1371 - val_accuracy: 0.1296 - 326ms/epoch - 81ms/step\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 299: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0888 - accuracy: 1.0000 - val_loss: 2.1557 - val_accuracy: 0.2593 - 337ms/epoch - 84ms/step\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 300: val_loss did not improve from 1.38643\n",
      "4/4 - 0s - loss: 0.0803 - accuracy: 1.0000 - val_loss: 2.1203 - val_accuracy: 0.2778 - 325ms/epoch - 81ms/step\n",
      "2/2 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2022-11-11 09:29:24.922559: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_9125054\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:599818\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 09:29:28.826269: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_9128124\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:599860\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38576, saving model to checkpoint1.h5\n",
      "4/4 - 5s - loss: 1.4396 - accuracy: 0.2302 - val_loss: 1.3858 - val_accuracy: 0.3333 - 5s/epoch - 1s/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss improved from 1.38576 to 1.38573, saving model to checkpoint1.h5\n",
      "4/4 - 1s - loss: 1.3397 - accuracy: 0.3730 - val_loss: 1.3857 - val_accuracy: 0.3333 - 730ms/epoch - 183ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss improved from 1.38573 to 1.38563, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 1.3322 - accuracy: 0.4048 - val_loss: 1.3856 - val_accuracy: 0.3333 - 391ms/epoch - 98ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss did not improve from 1.38563\n",
      "4/4 - 0s - loss: 1.2869 - accuracy: 0.4603 - val_loss: 1.3856 - val_accuracy: 0.3333 - 333ms/epoch - 83ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss did not improve from 1.38563\n",
      "4/4 - 0s - loss: 1.2650 - accuracy: 0.4603 - val_loss: 1.3857 - val_accuracy: 0.3333 - 330ms/epoch - 82ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss improved from 1.38563 to 1.38559, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 1.2649 - accuracy: 0.4444 - val_loss: 1.3856 - val_accuracy: 0.3333 - 403ms/epoch - 101ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss improved from 1.38559 to 1.38534, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 1.2231 - accuracy: 0.5159 - val_loss: 1.3853 - val_accuracy: 0.3333 - 397ms/epoch - 99ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 1.38534\n",
      "4/4 - 0s - loss: 1.2037 - accuracy: 0.5476 - val_loss: 1.3855 - val_accuracy: 0.3333 - 338ms/epoch - 85ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss improved from 1.38534 to 1.38531, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 1.2227 - accuracy: 0.5317 - val_loss: 1.3853 - val_accuracy: 0.3333 - 399ms/epoch - 100ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss improved from 1.38531 to 1.38488, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 1.1981 - accuracy: 0.5476 - val_loss: 1.3849 - val_accuracy: 0.3333 - 395ms/epoch - 99ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss improved from 1.38488 to 1.38454, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 1.1473 - accuracy: 0.5952 - val_loss: 1.3845 - val_accuracy: 0.3333 - 404ms/epoch - 101ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.38454\n",
      "4/4 - 0s - loss: 1.1205 - accuracy: 0.6111 - val_loss: 1.3852 - val_accuracy: 0.3333 - 334ms/epoch - 83ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.38454\n",
      "4/4 - 0s - loss: 1.1240 - accuracy: 0.6032 - val_loss: 1.3846 - val_accuracy: 0.3333 - 352ms/epoch - 88ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss improved from 1.38454 to 1.38419, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 1.1315 - accuracy: 0.5873 - val_loss: 1.3842 - val_accuracy: 0.3333 - 401ms/epoch - 100ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.38419\n",
      "4/4 - 0s - loss: 1.1246 - accuracy: 0.6190 - val_loss: 1.3843 - val_accuracy: 0.3333 - 344ms/epoch - 86ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss improved from 1.38419 to 1.38358, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 1.1128 - accuracy: 0.6349 - val_loss: 1.3836 - val_accuracy: 0.3333 - 400ms/epoch - 100ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 1.38358\n",
      "4/4 - 0s - loss: 1.0967 - accuracy: 0.6270 - val_loss: 1.3836 - val_accuracy: 0.3333 - 341ms/epoch - 85ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 1.38358\n",
      "4/4 - 0s - loss: 1.0724 - accuracy: 0.7143 - val_loss: 1.3837 - val_accuracy: 0.3333 - 334ms/epoch - 83ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss improved from 1.38358 to 1.38343, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 1.0295 - accuracy: 0.6984 - val_loss: 1.3834 - val_accuracy: 0.3333 - 398ms/epoch - 99ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss improved from 1.38343 to 1.38244, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 1.0498 - accuracy: 0.6508 - val_loss: 1.3824 - val_accuracy: 0.3333 - 386ms/epoch - 96ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss improved from 1.38244 to 1.38183, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.9975 - accuracy: 0.6825 - val_loss: 1.3818 - val_accuracy: 0.3333 - 396ms/epoch - 99ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 1.38183\n",
      "4/4 - 0s - loss: 1.0229 - accuracy: 0.6667 - val_loss: 1.3829 - val_accuracy: 0.3333 - 334ms/epoch - 84ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss improved from 1.38183 to 1.38093, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 1.0292 - accuracy: 0.7381 - val_loss: 1.3809 - val_accuracy: 0.3333 - 390ms/epoch - 97ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 1.38093\n",
      "4/4 - 0s - loss: 1.0118 - accuracy: 0.7460 - val_loss: 1.3810 - val_accuracy: 0.3333 - 346ms/epoch - 86ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.38093\n",
      "4/4 - 0s - loss: 0.9704 - accuracy: 0.7540 - val_loss: 1.3812 - val_accuracy: 0.3333 - 346ms/epoch - 87ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss improved from 1.38093 to 1.37928, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.9703 - accuracy: 0.7540 - val_loss: 1.3793 - val_accuracy: 0.3333 - 491ms/epoch - 123ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 1.37928\n",
      "4/4 - 0s - loss: 0.9960 - accuracy: 0.6905 - val_loss: 1.3807 - val_accuracy: 0.3333 - 347ms/epoch - 87ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss improved from 1.37928 to 1.37927, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.9686 - accuracy: 0.7460 - val_loss: 1.3793 - val_accuracy: 0.3333 - 396ms/epoch - 99ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 1.37927\n",
      "4/4 - 0s - loss: 0.9669 - accuracy: 0.7937 - val_loss: 1.3799 - val_accuracy: 0.3333 - 337ms/epoch - 84ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 1.37927\n",
      "4/4 - 0s - loss: 0.9567 - accuracy: 0.7619 - val_loss: 1.3798 - val_accuracy: 0.3333 - 339ms/epoch - 85ms/step\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss improved from 1.37927 to 1.37853, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.9578 - accuracy: 0.6905 - val_loss: 1.3785 - val_accuracy: 0.3333 - 388ms/epoch - 97ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss improved from 1.37853 to 1.37701, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.9206 - accuracy: 0.7857 - val_loss: 1.3770 - val_accuracy: 0.3333 - 388ms/epoch - 97ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 1.37701\n",
      "4/4 - 0s - loss: 0.9337 - accuracy: 0.8175 - val_loss: 1.3778 - val_accuracy: 0.3333 - 337ms/epoch - 84ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 1.37701\n",
      "4/4 - 0s - loss: 0.8882 - accuracy: 0.7857 - val_loss: 1.3777 - val_accuracy: 0.3333 - 332ms/epoch - 83ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 1.37701\n",
      "4/4 - 0s - loss: 0.9259 - accuracy: 0.7302 - val_loss: 1.3772 - val_accuracy: 0.3333 - 343ms/epoch - 86ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss improved from 1.37701 to 1.37640, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.8793 - accuracy: 0.8333 - val_loss: 1.3764 - val_accuracy: 0.3333 - 384ms/epoch - 96ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 1.37640\n",
      "4/4 - 0s - loss: 0.9276 - accuracy: 0.7698 - val_loss: 1.3768 - val_accuracy: 0.3333 - 350ms/epoch - 88ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 1.37640\n",
      "4/4 - 0s - loss: 0.8951 - accuracy: 0.7540 - val_loss: 1.3774 - val_accuracy: 0.3333 - 337ms/epoch - 84ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss improved from 1.37640 to 1.37600, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.8675 - accuracy: 0.8254 - val_loss: 1.3760 - val_accuracy: 0.3333 - 394ms/epoch - 98ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss improved from 1.37600 to 1.37454, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.8653 - accuracy: 0.7857 - val_loss: 1.3745 - val_accuracy: 0.3333 - 391ms/epoch - 98ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 1.37454\n",
      "4/4 - 0s - loss: 0.8276 - accuracy: 0.8333 - val_loss: 1.3773 - val_accuracy: 0.3333 - 328ms/epoch - 82ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss improved from 1.37454 to 1.37310, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.8508 - accuracy: 0.8571 - val_loss: 1.3731 - val_accuracy: 0.3333 - 388ms/epoch - 97ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.8619 - accuracy: 0.8492 - val_loss: 1.3751 - val_accuracy: 0.3333 - 344ms/epoch - 86ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.8443 - accuracy: 0.8333 - val_loss: 1.3769 - val_accuracy: 0.3333 - 335ms/epoch - 84ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.8233 - accuracy: 0.8175 - val_loss: 1.3766 - val_accuracy: 0.3333 - 334ms/epoch - 84ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.8413 - accuracy: 0.8175 - val_loss: 1.3787 - val_accuracy: 0.3333 - 345ms/epoch - 86ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.8233 - accuracy: 0.8254 - val_loss: 1.3769 - val_accuracy: 0.3333 - 329ms/epoch - 82ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.8206 - accuracy: 0.8810 - val_loss: 1.3773 - val_accuracy: 0.3333 - 350ms/epoch - 87ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.8221 - accuracy: 0.8095 - val_loss: 1.3802 - val_accuracy: 0.3333 - 342ms/epoch - 85ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.7968 - accuracy: 0.8651 - val_loss: 1.3822 - val_accuracy: 0.3333 - 345ms/epoch - 86ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.7984 - accuracy: 0.8254 - val_loss: 1.3804 - val_accuracy: 0.3333 - 343ms/epoch - 86ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.7642 - accuracy: 0.8810 - val_loss: 1.3840 - val_accuracy: 0.3333 - 351ms/epoch - 88ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.7765 - accuracy: 0.8175 - val_loss: 1.3840 - val_accuracy: 0.3333 - 332ms/epoch - 83ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.7818 - accuracy: 0.8651 - val_loss: 1.3823 - val_accuracy: 0.3333 - 340ms/epoch - 85ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.7613 - accuracy: 0.8730 - val_loss: 1.3844 - val_accuracy: 0.3333 - 346ms/epoch - 86ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.7176 - accuracy: 0.9048 - val_loss: 1.3960 - val_accuracy: 0.2963 - 343ms/epoch - 86ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.7349 - accuracy: 0.8968 - val_loss: 1.3913 - val_accuracy: 0.3333 - 358ms/epoch - 90ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.7331 - accuracy: 0.8810 - val_loss: 1.3936 - val_accuracy: 0.3333 - 340ms/epoch - 85ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.6946 - accuracy: 0.9286 - val_loss: 1.3978 - val_accuracy: 0.2593 - 343ms/epoch - 86ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.6871 - accuracy: 0.8889 - val_loss: 1.3977 - val_accuracy: 0.3333 - 347ms/epoch - 87ms/step\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.6721 - accuracy: 0.9365 - val_loss: 1.4020 - val_accuracy: 0.3333 - 331ms/epoch - 83ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.7000 - accuracy: 0.9048 - val_loss: 1.4097 - val_accuracy: 0.3333 - 336ms/epoch - 84ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.6936 - accuracy: 0.8810 - val_loss: 1.4170 - val_accuracy: 0.3333 - 358ms/epoch - 90ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.7051 - accuracy: 0.8810 - val_loss: 1.4174 - val_accuracy: 0.2963 - 345ms/epoch - 86ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.6770 - accuracy: 0.8889 - val_loss: 1.4152 - val_accuracy: 0.2593 - 328ms/epoch - 82ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.6672 - accuracy: 0.9127 - val_loss: 1.4521 - val_accuracy: 0.3333 - 338ms/epoch - 85ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.6887 - accuracy: 0.8968 - val_loss: 1.4365 - val_accuracy: 0.2407 - 342ms/epoch - 85ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.6759 - accuracy: 0.8968 - val_loss: 1.4300 - val_accuracy: 0.3333 - 360ms/epoch - 90ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.6248 - accuracy: 0.9365 - val_loss: 1.4156 - val_accuracy: 0.2593 - 337ms/epoch - 84ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.6318 - accuracy: 0.9048 - val_loss: 1.4589 - val_accuracy: 0.2963 - 352ms/epoch - 88ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.6301 - accuracy: 0.9286 - val_loss: 1.4297 - val_accuracy: 0.2407 - 332ms/epoch - 83ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.6624 - accuracy: 0.8968 - val_loss: 1.4561 - val_accuracy: 0.2037 - 341ms/epoch - 85ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.6076 - accuracy: 0.9127 - val_loss: 1.4974 - val_accuracy: 0.3333 - 334ms/epoch - 83ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.6382 - accuracy: 0.9048 - val_loss: 1.4645 - val_accuracy: 0.2407 - 332ms/epoch - 83ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.6290 - accuracy: 0.8968 - val_loss: 1.5561 - val_accuracy: 0.3148 - 346ms/epoch - 86ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.6207 - accuracy: 0.9206 - val_loss: 1.4781 - val_accuracy: 0.2778 - 342ms/epoch - 85ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.5934 - accuracy: 0.9524 - val_loss: 1.4735 - val_accuracy: 0.2593 - 330ms/epoch - 83ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.6187 - accuracy: 0.9365 - val_loss: 1.4803 - val_accuracy: 0.2593 - 340ms/epoch - 85ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.5824 - accuracy: 0.9444 - val_loss: 1.4998 - val_accuracy: 0.2037 - 330ms/epoch - 83ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.5588 - accuracy: 0.9603 - val_loss: 1.4934 - val_accuracy: 0.2778 - 344ms/epoch - 86ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.5768 - accuracy: 0.9365 - val_loss: 1.5171 - val_accuracy: 0.2407 - 334ms/epoch - 84ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.5647 - accuracy: 0.9444 - val_loss: 1.5448 - val_accuracy: 0.2037 - 329ms/epoch - 82ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.5582 - accuracy: 0.9524 - val_loss: 1.5772 - val_accuracy: 0.2593 - 330ms/epoch - 82ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.5101 - accuracy: 0.9683 - val_loss: 1.5214 - val_accuracy: 0.2593 - 340ms/epoch - 85ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.5460 - accuracy: 0.9683 - val_loss: 1.5363 - val_accuracy: 0.2593 - 331ms/epoch - 83ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.5359 - accuracy: 0.9762 - val_loss: 1.5400 - val_accuracy: 0.2593 - 332ms/epoch - 83ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.4802 - accuracy: 1.0000 - val_loss: 1.5318 - val_accuracy: 0.2407 - 332ms/epoch - 83ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.5183 - accuracy: 0.9603 - val_loss: 1.5641 - val_accuracy: 0.2593 - 342ms/epoch - 85ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.5220 - accuracy: 0.9444 - val_loss: 1.6131 - val_accuracy: 0.2407 - 351ms/epoch - 88ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.4971 - accuracy: 0.9603 - val_loss: 1.5771 - val_accuracy: 0.2037 - 351ms/epoch - 88ms/step\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 1.37310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.4852 - accuracy: 0.9841 - val_loss: 1.6796 - val_accuracy: 0.2593 - 345ms/epoch - 86ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.5254 - accuracy: 0.9365 - val_loss: 1.7963 - val_accuracy: 0.3333 - 348ms/epoch - 87ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.5176 - accuracy: 0.9444 - val_loss: 1.6028 - val_accuracy: 0.2037 - 334ms/epoch - 84ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.5145 - accuracy: 0.9603 - val_loss: 1.5769 - val_accuracy: 0.2037 - 345ms/epoch - 86ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.4638 - accuracy: 0.9841 - val_loss: 1.7018 - val_accuracy: 0.2778 - 342ms/epoch - 86ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.4761 - accuracy: 0.9603 - val_loss: 1.7029 - val_accuracy: 0.2593 - 340ms/epoch - 85ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.4626 - accuracy: 0.9524 - val_loss: 1.6714 - val_accuracy: 0.2222 - 346ms/epoch - 86ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.4639 - accuracy: 0.9921 - val_loss: 1.6712 - val_accuracy: 0.2407 - 332ms/epoch - 83ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.4304 - accuracy: 0.9762 - val_loss: 1.5986 - val_accuracy: 0.2593 - 350ms/epoch - 87ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.4054 - accuracy: 0.9921 - val_loss: 1.6079 - val_accuracy: 0.2593 - 342ms/epoch - 86ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.4222 - accuracy: 0.9841 - val_loss: 1.5874 - val_accuracy: 0.2778 - 329ms/epoch - 82ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.4253 - accuracy: 0.9841 - val_loss: 1.6615 - val_accuracy: 0.3148 - 354ms/epoch - 89ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.4119 - accuracy: 0.9921 - val_loss: 1.7047 - val_accuracy: 0.2593 - 335ms/epoch - 84ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.4111 - accuracy: 0.9921 - val_loss: 1.6736 - val_accuracy: 0.2593 - 332ms/epoch - 83ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.4360 - accuracy: 0.9841 - val_loss: 1.6722 - val_accuracy: 0.3148 - 332ms/epoch - 83ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.4059 - accuracy: 1.0000 - val_loss: 1.6316 - val_accuracy: 0.2593 - 333ms/epoch - 83ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.3974 - accuracy: 0.9683 - val_loss: 1.6281 - val_accuracy: 0.2407 - 340ms/epoch - 85ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.3864 - accuracy: 0.9762 - val_loss: 1.6435 - val_accuracy: 0.2222 - 351ms/epoch - 88ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.4535 - accuracy: 0.9841 - val_loss: 1.6747 - val_accuracy: 0.2593 - 338ms/epoch - 85ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.4161 - accuracy: 0.9762 - val_loss: 1.6414 - val_accuracy: 0.2593 - 334ms/epoch - 84ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.4227 - accuracy: 0.9921 - val_loss: 1.7421 - val_accuracy: 0.2593 - 338ms/epoch - 85ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.3794 - accuracy: 0.9683 - val_loss: 1.6995 - val_accuracy: 0.2778 - 340ms/epoch - 85ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.3871 - accuracy: 0.9921 - val_loss: 1.7713 - val_accuracy: 0.2222 - 330ms/epoch - 83ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.3776 - accuracy: 0.9921 - val_loss: 1.7328 - val_accuracy: 0.1852 - 344ms/epoch - 86ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.3339 - accuracy: 0.9921 - val_loss: 1.8163 - val_accuracy: 0.2037 - 333ms/epoch - 83ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.3797 - accuracy: 0.9921 - val_loss: 1.7196 - val_accuracy: 0.2037 - 329ms/epoch - 82ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.3651 - accuracy: 0.9841 - val_loss: 1.7691 - val_accuracy: 0.1852 - 334ms/epoch - 84ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.3759 - accuracy: 0.9841 - val_loss: 1.8177 - val_accuracy: 0.2593 - 353ms/epoch - 88ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.3895 - accuracy: 0.9762 - val_loss: 1.7433 - val_accuracy: 0.2593 - 346ms/epoch - 86ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.4650 - accuracy: 0.9762 - val_loss: 1.7530 - val_accuracy: 0.2593 - 363ms/epoch - 91ms/step\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.4386 - accuracy: 0.9683 - val_loss: 1.7580 - val_accuracy: 0.2037 - 330ms/epoch - 83ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.4146 - accuracy: 0.9603 - val_loss: 2.0249 - val_accuracy: 0.2407 - 340ms/epoch - 85ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.3982 - accuracy: 0.9683 - val_loss: 1.7733 - val_accuracy: 0.1852 - 331ms/epoch - 83ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.3719 - accuracy: 0.9921 - val_loss: 1.8236 - val_accuracy: 0.2037 - 351ms/epoch - 88ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.3598 - accuracy: 0.9841 - val_loss: 1.7697 - val_accuracy: 0.2778 - 336ms/epoch - 84ms/step\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.3424 - accuracy: 0.9921 - val_loss: 1.7137 - val_accuracy: 0.2222 - 337ms/epoch - 84ms/step\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.3814 - accuracy: 0.9683 - val_loss: 1.7712 - val_accuracy: 0.2778 - 335ms/epoch - 84ms/step\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.3356 - accuracy: 0.9921 - val_loss: 1.8010 - val_accuracy: 0.2593 - 348ms/epoch - 87ms/step\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.3456 - accuracy: 0.9841 - val_loss: 1.7747 - val_accuracy: 0.2407 - 332ms/epoch - 83ms/step\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.3109 - accuracy: 1.0000 - val_loss: 1.7783 - val_accuracy: 0.2407 - 340ms/epoch - 85ms/step\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.3019 - accuracy: 0.9921 - val_loss: 1.7109 - val_accuracy: 0.2222 - 348ms/epoch - 87ms/step\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2980 - accuracy: 1.0000 - val_loss: 1.7424 - val_accuracy: 0.2222 - 349ms/epoch - 87ms/step\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.3043 - accuracy: 0.9921 - val_loss: 1.7229 - val_accuracy: 0.2037 - 336ms/epoch - 84ms/step\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2897 - accuracy: 0.9841 - val_loss: 1.7484 - val_accuracy: 0.2407 - 329ms/epoch - 82ms/step\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 135: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2871 - accuracy: 1.0000 - val_loss: 1.7553 - val_accuracy: 0.2407 - 333ms/epoch - 83ms/step\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 136: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.3266 - accuracy: 0.9921 - val_loss: 1.7351 - val_accuracy: 0.2407 - 340ms/epoch - 85ms/step\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 137: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.3180 - accuracy: 0.9841 - val_loss: 1.8044 - val_accuracy: 0.2407 - 333ms/epoch - 83ms/step\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 138: val_loss did not improve from 1.37310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.2948 - accuracy: 0.9921 - val_loss: 1.7725 - val_accuracy: 0.2222 - 340ms/epoch - 85ms/step\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 139: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2972 - accuracy: 0.9921 - val_loss: 1.7535 - val_accuracy: 0.2593 - 352ms/epoch - 88ms/step\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 140: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2807 - accuracy: 1.0000 - val_loss: 1.7251 - val_accuracy: 0.2222 - 353ms/epoch - 88ms/step\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 141: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2795 - accuracy: 1.0000 - val_loss: 1.8770 - val_accuracy: 0.2593 - 327ms/epoch - 82ms/step\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 142: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2821 - accuracy: 0.9921 - val_loss: 1.8042 - val_accuracy: 0.1667 - 333ms/epoch - 83ms/step\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 143: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.3082 - accuracy: 0.9841 - val_loss: 1.8093 - val_accuracy: 0.2407 - 333ms/epoch - 83ms/step\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 144: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2641 - accuracy: 0.9921 - val_loss: 1.8057 - val_accuracy: 0.2593 - 345ms/epoch - 86ms/step\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 145: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2751 - accuracy: 1.0000 - val_loss: 1.8162 - val_accuracy: 0.2037 - 336ms/epoch - 84ms/step\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 146: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2729 - accuracy: 0.9841 - val_loss: 1.8624 - val_accuracy: 0.2222 - 334ms/epoch - 83ms/step\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 147: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2439 - accuracy: 0.9921 - val_loss: 1.8267 - val_accuracy: 0.2407 - 347ms/epoch - 87ms/step\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 148: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2340 - accuracy: 1.0000 - val_loss: 1.8536 - val_accuracy: 0.2222 - 339ms/epoch - 85ms/step\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 149: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2396 - accuracy: 1.0000 - val_loss: 1.7926 - val_accuracy: 0.2407 - 345ms/epoch - 86ms/step\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 150: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2659 - accuracy: 0.9921 - val_loss: 1.9189 - val_accuracy: 0.2037 - 343ms/epoch - 86ms/step\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 151: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2621 - accuracy: 1.0000 - val_loss: 1.9509 - val_accuracy: 0.2407 - 329ms/epoch - 82ms/step\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 152: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2662 - accuracy: 0.9921 - val_loss: 1.7966 - val_accuracy: 0.1852 - 340ms/epoch - 85ms/step\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 153: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2777 - accuracy: 0.9921 - val_loss: 1.8244 - val_accuracy: 0.2407 - 339ms/epoch - 85ms/step\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 154: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2847 - accuracy: 0.9841 - val_loss: 1.8498 - val_accuracy: 0.2037 - 338ms/epoch - 85ms/step\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 155: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2593 - accuracy: 1.0000 - val_loss: 1.8736 - val_accuracy: 0.2407 - 339ms/epoch - 85ms/step\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 156: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2429 - accuracy: 1.0000 - val_loss: 1.8942 - val_accuracy: 0.2963 - 340ms/epoch - 85ms/step\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 157: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2400 - accuracy: 1.0000 - val_loss: 1.8095 - val_accuracy: 0.2037 - 348ms/epoch - 87ms/step\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 158: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2495 - accuracy: 1.0000 - val_loss: 1.9305 - val_accuracy: 0.2963 - 345ms/epoch - 86ms/step\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 159: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2261 - accuracy: 1.0000 - val_loss: 1.8500 - val_accuracy: 0.2222 - 337ms/epoch - 84ms/step\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 160: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2848 - accuracy: 1.0000 - val_loss: 1.8705 - val_accuracy: 0.2593 - 343ms/epoch - 86ms/step\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 161: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2364 - accuracy: 1.0000 - val_loss: 1.8523 - val_accuracy: 0.2593 - 333ms/epoch - 83ms/step\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 162: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2299 - accuracy: 0.9921 - val_loss: 1.8499 - val_accuracy: 0.2407 - 344ms/epoch - 86ms/step\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 163: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2228 - accuracy: 0.9921 - val_loss: 1.8352 - val_accuracy: 0.2593 - 334ms/epoch - 83ms/step\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 164: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2293 - accuracy: 1.0000 - val_loss: 1.7953 - val_accuracy: 0.2222 - 336ms/epoch - 84ms/step\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 165: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2471 - accuracy: 0.9921 - val_loss: 1.9554 - val_accuracy: 0.2593 - 341ms/epoch - 85ms/step\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 166: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2436 - accuracy: 1.0000 - val_loss: 1.8746 - val_accuracy: 0.2222 - 335ms/epoch - 84ms/step\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 167: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2359 - accuracy: 0.9841 - val_loss: 1.8776 - val_accuracy: 0.2593 - 342ms/epoch - 85ms/step\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 168: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2295 - accuracy: 0.9921 - val_loss: 1.8495 - val_accuracy: 0.2222 - 354ms/epoch - 89ms/step\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 169: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2202 - accuracy: 1.0000 - val_loss: 1.9397 - val_accuracy: 0.2778 - 361ms/epoch - 90ms/step\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 170: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2060 - accuracy: 1.0000 - val_loss: 1.9088 - val_accuracy: 0.2407 - 339ms/epoch - 85ms/step\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 171: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 2.0415 - val_accuracy: 0.2407 - 332ms/epoch - 83ms/step\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 172: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1902 - accuracy: 1.0000 - val_loss: 1.9198 - val_accuracy: 0.2778 - 329ms/epoch - 82ms/step\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 173: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2065 - accuracy: 0.9921 - val_loss: 1.8394 - val_accuracy: 0.2222 - 349ms/epoch - 87ms/step\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 174: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 1.8324 - val_accuracy: 0.2407 - 337ms/epoch - 84ms/step\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 175: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1991 - accuracy: 1.0000 - val_loss: 1.9531 - val_accuracy: 0.2222 - 348ms/epoch - 87ms/step\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 176: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2183 - accuracy: 1.0000 - val_loss: 2.0262 - val_accuracy: 0.2222 - 346ms/epoch - 86ms/step\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 177: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2038 - accuracy: 1.0000 - val_loss: 1.9040 - val_accuracy: 0.2407 - 360ms/epoch - 90ms/step\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 178: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 1.8821 - val_accuracy: 0.2778 - 339ms/epoch - 85ms/step\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 179: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2018 - accuracy: 1.0000 - val_loss: 1.8842 - val_accuracy: 0.2222 - 343ms/epoch - 86ms/step\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 180: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 1.9632 - val_accuracy: 0.2037 - 340ms/epoch - 85ms/step\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 181: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 1.9343 - val_accuracy: 0.2222 - 362ms/epoch - 90ms/step\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 182: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2068 - accuracy: 0.9921 - val_loss: 1.8913 - val_accuracy: 0.2222 - 338ms/epoch - 84ms/step\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 183: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1952 - accuracy: 1.0000 - val_loss: 1.9201 - val_accuracy: 0.2222 - 330ms/epoch - 82ms/step\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 184: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 2.0085 - val_accuracy: 0.2222 - 335ms/epoch - 84ms/step\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 185: val_loss did not improve from 1.37310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.1998 - accuracy: 0.9921 - val_loss: 2.0267 - val_accuracy: 0.2222 - 348ms/epoch - 87ms/step\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 186: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2391 - accuracy: 0.9921 - val_loss: 1.9566 - val_accuracy: 0.2222 - 338ms/epoch - 85ms/step\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 187: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 1.9195 - val_accuracy: 0.2593 - 334ms/epoch - 83ms/step\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 188: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 2.0695 - val_accuracy: 0.1852 - 340ms/epoch - 85ms/step\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 189: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1765 - accuracy: 1.0000 - val_loss: 2.2930 - val_accuracy: 0.2037 - 336ms/epoch - 84ms/step\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 190: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1818 - accuracy: 1.0000 - val_loss: 2.1231 - val_accuracy: 0.2222 - 347ms/epoch - 87ms/step\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 191: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2248 - accuracy: 1.0000 - val_loss: 1.8634 - val_accuracy: 0.2593 - 338ms/epoch - 85ms/step\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 192: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.2168 - accuracy: 0.9921 - val_loss: 1.9538 - val_accuracy: 0.2222 - 351ms/epoch - 88ms/step\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 193: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1829 - accuracy: 1.0000 - val_loss: 2.0463 - val_accuracy: 0.2037 - 340ms/epoch - 85ms/step\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 194: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1961 - accuracy: 1.0000 - val_loss: 2.0879 - val_accuracy: 0.1667 - 344ms/epoch - 86ms/step\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 195: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1969 - accuracy: 1.0000 - val_loss: 2.0152 - val_accuracy: 0.2407 - 340ms/epoch - 85ms/step\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 196: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1767 - accuracy: 1.0000 - val_loss: 1.9464 - val_accuracy: 0.2407 - 346ms/epoch - 86ms/step\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 197: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1710 - accuracy: 1.0000 - val_loss: 1.8558 - val_accuracy: 0.2778 - 370ms/epoch - 92ms/step\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 198: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1624 - accuracy: 1.0000 - val_loss: 1.8904 - val_accuracy: 0.2407 - 341ms/epoch - 85ms/step\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 199: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1678 - accuracy: 1.0000 - val_loss: 1.9055 - val_accuracy: 0.2407 - 330ms/epoch - 83ms/step\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 200: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1797 - accuracy: 1.0000 - val_loss: 1.8988 - val_accuracy: 0.1852 - 341ms/epoch - 85ms/step\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 201: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1797 - accuracy: 1.0000 - val_loss: 1.9258 - val_accuracy: 0.2407 - 338ms/epoch - 84ms/step\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 202: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1782 - accuracy: 0.9921 - val_loss: 1.8950 - val_accuracy: 0.2593 - 351ms/epoch - 88ms/step\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 203: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1959 - accuracy: 0.9921 - val_loss: 1.8560 - val_accuracy: 0.2222 - 337ms/epoch - 84ms/step\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 204: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1588 - accuracy: 1.0000 - val_loss: 1.8660 - val_accuracy: 0.2407 - 339ms/epoch - 85ms/step\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 205: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1573 - accuracy: 1.0000 - val_loss: 1.8850 - val_accuracy: 0.2222 - 341ms/epoch - 85ms/step\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 206: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1477 - accuracy: 1.0000 - val_loss: 1.9584 - val_accuracy: 0.1852 - 332ms/epoch - 83ms/step\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 207: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1517 - accuracy: 0.9921 - val_loss: 1.8641 - val_accuracy: 0.2593 - 331ms/epoch - 83ms/step\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 208: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1809 - accuracy: 1.0000 - val_loss: 1.9582 - val_accuracy: 0.2222 - 343ms/epoch - 86ms/step\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 209: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1650 - accuracy: 0.9921 - val_loss: 1.9631 - val_accuracy: 0.2222 - 338ms/epoch - 84ms/step\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 210: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1686 - accuracy: 1.0000 - val_loss: 2.0480 - val_accuracy: 0.2593 - 346ms/epoch - 86ms/step\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 211: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1670 - accuracy: 1.0000 - val_loss: 2.0031 - val_accuracy: 0.2222 - 325ms/epoch - 81ms/step\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 212: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1790 - accuracy: 0.9921 - val_loss: 1.9759 - val_accuracy: 0.2778 - 334ms/epoch - 83ms/step\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 213: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1463 - accuracy: 1.0000 - val_loss: 1.9642 - val_accuracy: 0.2407 - 334ms/epoch - 83ms/step\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 214: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1469 - accuracy: 1.0000 - val_loss: 2.0028 - val_accuracy: 0.2593 - 338ms/epoch - 84ms/step\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 215: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1426 - accuracy: 1.0000 - val_loss: 1.9401 - val_accuracy: 0.2407 - 343ms/epoch - 86ms/step\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 216: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1576 - accuracy: 0.9921 - val_loss: 1.9197 - val_accuracy: 0.2778 - 349ms/epoch - 87ms/step\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 217: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1464 - accuracy: 1.0000 - val_loss: 1.8638 - val_accuracy: 0.2407 - 343ms/epoch - 86ms/step\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 218: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1365 - accuracy: 1.0000 - val_loss: 1.8828 - val_accuracy: 0.2593 - 334ms/epoch - 84ms/step\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 219: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1462 - accuracy: 1.0000 - val_loss: 1.9140 - val_accuracy: 0.2407 - 332ms/epoch - 83ms/step\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 220: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1367 - accuracy: 1.0000 - val_loss: 2.0412 - val_accuracy: 0.2593 - 327ms/epoch - 82ms/step\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 221: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1473 - accuracy: 1.0000 - val_loss: 2.0537 - val_accuracy: 0.2593 - 347ms/epoch - 87ms/step\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 222: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1483 - accuracy: 1.0000 - val_loss: 2.0812 - val_accuracy: 0.2037 - 346ms/epoch - 86ms/step\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 223: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1507 - accuracy: 1.0000 - val_loss: 1.9359 - val_accuracy: 0.2222 - 340ms/epoch - 85ms/step\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 224: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1513 - accuracy: 0.9921 - val_loss: 1.8791 - val_accuracy: 0.2778 - 333ms/epoch - 83ms/step\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 225: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1360 - accuracy: 1.0000 - val_loss: 1.9338 - val_accuracy: 0.2593 - 329ms/epoch - 82ms/step\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 226: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1652 - accuracy: 1.0000 - val_loss: 1.9881 - val_accuracy: 0.2593 - 331ms/epoch - 83ms/step\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 227: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1628 - accuracy: 1.0000 - val_loss: 1.9896 - val_accuracy: 0.2778 - 327ms/epoch - 82ms/step\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 228: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1558 - accuracy: 1.0000 - val_loss: 1.9509 - val_accuracy: 0.2037 - 348ms/epoch - 87ms/step\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 229: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1506 - accuracy: 1.0000 - val_loss: 1.9718 - val_accuracy: 0.2407 - 338ms/epoch - 85ms/step\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 230: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1466 - accuracy: 1.0000 - val_loss: 1.9140 - val_accuracy: 0.2037 - 331ms/epoch - 83ms/step\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 231: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1424 - accuracy: 1.0000 - val_loss: 1.9217 - val_accuracy: 0.2593 - 367ms/epoch - 92ms/step\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 232: val_loss did not improve from 1.37310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.1246 - accuracy: 1.0000 - val_loss: 2.0188 - val_accuracy: 0.2963 - 351ms/epoch - 88ms/step\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 233: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1389 - accuracy: 1.0000 - val_loss: 1.9513 - val_accuracy: 0.2407 - 347ms/epoch - 87ms/step\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 234: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1346 - accuracy: 1.0000 - val_loss: 1.9253 - val_accuracy: 0.2778 - 349ms/epoch - 87ms/step\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 235: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1397 - accuracy: 1.0000 - val_loss: 1.9658 - val_accuracy: 0.2593 - 340ms/epoch - 85ms/step\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 236: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1160 - accuracy: 1.0000 - val_loss: 1.9272 - val_accuracy: 0.2407 - 336ms/epoch - 84ms/step\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 237: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1293 - accuracy: 1.0000 - val_loss: 1.9838 - val_accuracy: 0.2407 - 338ms/epoch - 84ms/step\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 238: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1180 - accuracy: 1.0000 - val_loss: 1.9735 - val_accuracy: 0.2778 - 349ms/epoch - 87ms/step\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 239: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1397 - accuracy: 1.0000 - val_loss: 2.0044 - val_accuracy: 0.2407 - 332ms/epoch - 83ms/step\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 240: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1128 - accuracy: 1.0000 - val_loss: 2.0484 - val_accuracy: 0.2593 - 346ms/epoch - 87ms/step\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 241: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1620 - accuracy: 0.9841 - val_loss: 1.9624 - val_accuracy: 0.3148 - 334ms/epoch - 83ms/step\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 242: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1133 - accuracy: 1.0000 - val_loss: 1.9556 - val_accuracy: 0.2593 - 336ms/epoch - 84ms/step\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 243: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1186 - accuracy: 1.0000 - val_loss: 1.9867 - val_accuracy: 0.2407 - 355ms/epoch - 89ms/step\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 244: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1306 - accuracy: 1.0000 - val_loss: 1.9656 - val_accuracy: 0.2222 - 343ms/epoch - 86ms/step\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 245: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1107 - accuracy: 1.0000 - val_loss: 1.9600 - val_accuracy: 0.2037 - 339ms/epoch - 85ms/step\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 246: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1265 - accuracy: 1.0000 - val_loss: 1.9263 - val_accuracy: 0.2593 - 347ms/epoch - 87ms/step\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 247: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1402 - accuracy: 1.0000 - val_loss: 1.8413 - val_accuracy: 0.2778 - 331ms/epoch - 83ms/step\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 248: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1307 - accuracy: 1.0000 - val_loss: 1.9646 - val_accuracy: 0.2778 - 343ms/epoch - 86ms/step\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 249: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1420 - accuracy: 1.0000 - val_loss: 1.9618 - val_accuracy: 0.2593 - 339ms/epoch - 85ms/step\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 250: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1434 - accuracy: 1.0000 - val_loss: 2.0667 - val_accuracy: 0.3519 - 347ms/epoch - 87ms/step\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 251: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1427 - accuracy: 0.9921 - val_loss: 1.9648 - val_accuracy: 0.2222 - 339ms/epoch - 85ms/step\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 252: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1464 - accuracy: 1.0000 - val_loss: 1.9995 - val_accuracy: 0.2593 - 340ms/epoch - 85ms/step\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 253: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1355 - accuracy: 1.0000 - val_loss: 1.8356 - val_accuracy: 0.2778 - 330ms/epoch - 82ms/step\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 254: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1336 - accuracy: 1.0000 - val_loss: 2.0133 - val_accuracy: 0.2407 - 330ms/epoch - 83ms/step\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 255: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1209 - accuracy: 1.0000 - val_loss: 2.0852 - val_accuracy: 0.1667 - 334ms/epoch - 83ms/step\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 256: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1515 - accuracy: 1.0000 - val_loss: 2.1384 - val_accuracy: 0.2037 - 334ms/epoch - 84ms/step\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 257: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1435 - accuracy: 0.9921 - val_loss: 2.1257 - val_accuracy: 0.2222 - 333ms/epoch - 83ms/step\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 258: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1343 - accuracy: 0.9921 - val_loss: 1.9364 - val_accuracy: 0.2593 - 349ms/epoch - 87ms/step\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 259: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1434 - accuracy: 1.0000 - val_loss: 1.9175 - val_accuracy: 0.1852 - 339ms/epoch - 85ms/step\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 260: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1125 - accuracy: 1.0000 - val_loss: 1.9655 - val_accuracy: 0.2222 - 334ms/epoch - 84ms/step\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 261: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1110 - accuracy: 1.0000 - val_loss: 2.0323 - val_accuracy: 0.2222 - 337ms/epoch - 84ms/step\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 262: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1148 - accuracy: 1.0000 - val_loss: 2.0048 - val_accuracy: 0.2407 - 336ms/epoch - 84ms/step\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 263: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1044 - accuracy: 1.0000 - val_loss: 2.0164 - val_accuracy: 0.2778 - 342ms/epoch - 85ms/step\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 264: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1039 - accuracy: 1.0000 - val_loss: 2.0176 - val_accuracy: 0.2593 - 340ms/epoch - 85ms/step\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 265: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1025 - accuracy: 1.0000 - val_loss: 1.9000 - val_accuracy: 0.2778 - 347ms/epoch - 87ms/step\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 266: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1285 - accuracy: 1.0000 - val_loss: 1.8906 - val_accuracy: 0.2407 - 333ms/epoch - 83ms/step\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 267: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1139 - accuracy: 1.0000 - val_loss: 1.9124 - val_accuracy: 0.2593 - 334ms/epoch - 83ms/step\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 268: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1160 - accuracy: 1.0000 - val_loss: 1.9359 - val_accuracy: 0.2407 - 332ms/epoch - 83ms/step\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 269: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1324 - accuracy: 1.0000 - val_loss: 1.8957 - val_accuracy: 0.2407 - 331ms/epoch - 83ms/step\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 270: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1122 - accuracy: 1.0000 - val_loss: 1.9222 - val_accuracy: 0.2222 - 346ms/epoch - 87ms/step\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 271: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1180 - accuracy: 1.0000 - val_loss: 1.9602 - val_accuracy: 0.2963 - 334ms/epoch - 83ms/step\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 272: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1440 - accuracy: 0.9921 - val_loss: 1.9460 - val_accuracy: 0.2222 - 342ms/epoch - 86ms/step\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 273: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1161 - accuracy: 1.0000 - val_loss: 2.0898 - val_accuracy: 0.2222 - 344ms/epoch - 86ms/step\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 274: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1182 - accuracy: 1.0000 - val_loss: 2.1488 - val_accuracy: 0.2407 - 341ms/epoch - 85ms/step\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 275: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1132 - accuracy: 0.9921 - val_loss: 2.1942 - val_accuracy: 0.2407 - 353ms/epoch - 88ms/step\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 276: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1158 - accuracy: 1.0000 - val_loss: 2.0602 - val_accuracy: 0.2037 - 339ms/epoch - 85ms/step\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 277: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1142 - accuracy: 1.0000 - val_loss: 1.9750 - val_accuracy: 0.2593 - 343ms/epoch - 86ms/step\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 278: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1023 - accuracy: 1.0000 - val_loss: 2.1565 - val_accuracy: 0.2037 - 331ms/epoch - 83ms/step\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 279: val_loss did not improve from 1.37310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.1133 - accuracy: 1.0000 - val_loss: 2.1081 - val_accuracy: 0.1111 - 352ms/epoch - 88ms/step\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 280: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1078 - accuracy: 1.0000 - val_loss: 2.0146 - val_accuracy: 0.2778 - 356ms/epoch - 89ms/step\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 281: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1185 - accuracy: 1.0000 - val_loss: 1.8774 - val_accuracy: 0.2407 - 335ms/epoch - 84ms/step\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 282: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1059 - accuracy: 1.0000 - val_loss: 1.9048 - val_accuracy: 0.2407 - 341ms/epoch - 85ms/step\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 283: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.0997 - accuracy: 1.0000 - val_loss: 1.8915 - val_accuracy: 0.2222 - 337ms/epoch - 84ms/step\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 284: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1178 - accuracy: 0.9921 - val_loss: 1.9411 - val_accuracy: 0.2037 - 338ms/epoch - 84ms/step\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 285: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1120 - accuracy: 1.0000 - val_loss: 2.0466 - val_accuracy: 0.2407 - 334ms/epoch - 83ms/step\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 286: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1147 - accuracy: 1.0000 - val_loss: 1.9907 - val_accuracy: 0.2593 - 352ms/epoch - 88ms/step\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 287: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1268 - accuracy: 1.0000 - val_loss: 2.0177 - val_accuracy: 0.2407 - 346ms/epoch - 86ms/step\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 288: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1129 - accuracy: 1.0000 - val_loss: 1.9379 - val_accuracy: 0.2778 - 336ms/epoch - 84ms/step\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 289: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1033 - accuracy: 1.0000 - val_loss: 1.9223 - val_accuracy: 0.2407 - 339ms/epoch - 85ms/step\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 290: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.0924 - accuracy: 1.0000 - val_loss: 1.9141 - val_accuracy: 0.2222 - 331ms/epoch - 83ms/step\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 291: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1107 - accuracy: 1.0000 - val_loss: 1.9717 - val_accuracy: 0.2407 - 337ms/epoch - 84ms/step\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 292: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1160 - accuracy: 1.0000 - val_loss: 2.0313 - val_accuracy: 0.2593 - 337ms/epoch - 84ms/step\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 293: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1190 - accuracy: 1.0000 - val_loss: 1.8847 - val_accuracy: 0.2593 - 352ms/epoch - 88ms/step\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 294: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1110 - accuracy: 0.9921 - val_loss: 2.0611 - val_accuracy: 0.2222 - 336ms/epoch - 84ms/step\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 295: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1082 - accuracy: 0.9841 - val_loss: 2.2071 - val_accuracy: 0.1852 - 367ms/epoch - 92ms/step\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 296: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1237 - accuracy: 1.0000 - val_loss: 1.9596 - val_accuracy: 0.2222 - 336ms/epoch - 84ms/step\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 297: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1129 - accuracy: 1.0000 - val_loss: 1.9071 - val_accuracy: 0.2407 - 330ms/epoch - 82ms/step\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 298: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.0960 - accuracy: 1.0000 - val_loss: 1.9258 - val_accuracy: 0.2778 - 353ms/epoch - 88ms/step\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 299: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1073 - accuracy: 1.0000 - val_loss: 1.9011 - val_accuracy: 0.2778 - 339ms/epoch - 85ms/step\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 300: val_loss did not improve from 1.37310\n",
      "4/4 - 0s - loss: 0.1154 - accuracy: 1.0000 - val_loss: 2.1087 - val_accuracy: 0.2593 - 346ms/epoch - 86ms/step\n",
      "2/2 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2022-11-11 09:31:16.745441: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_9192764\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:604072\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 09:31:20.799601: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_9195834\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:604114\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38630, saving model to checkpoint1.h5\n",
      "4/4 - 5s - loss: 1.4426 - accuracy: 0.2381 - val_loss: 1.3863 - val_accuracy: 0.2037 - 5s/epoch - 1s/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 1.3518 - accuracy: 0.3254 - val_loss: 1.3864 - val_accuracy: 0.2778 - 326ms/epoch - 82ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 1.3306 - accuracy: 0.3571 - val_loss: 1.3865 - val_accuracy: 0.2593 - 338ms/epoch - 85ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 1.3178 - accuracy: 0.4444 - val_loss: 1.3866 - val_accuracy: 0.2593 - 324ms/epoch - 81ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 1.2524 - accuracy: 0.4365 - val_loss: 1.3866 - val_accuracy: 0.2593 - 331ms/epoch - 83ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 1.2551 - accuracy: 0.5317 - val_loss: 1.3866 - val_accuracy: 0.2593 - 330ms/epoch - 82ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 1.2521 - accuracy: 0.5159 - val_loss: 1.3867 - val_accuracy: 0.2593 - 329ms/epoch - 82ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 1.2305 - accuracy: 0.5714 - val_loss: 1.3867 - val_accuracy: 0.2593 - 335ms/epoch - 84ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 1.2107 - accuracy: 0.5476 - val_loss: 1.3867 - val_accuracy: 0.2593 - 343ms/epoch - 86ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 1.1599 - accuracy: 0.6508 - val_loss: 1.3868 - val_accuracy: 0.2593 - 345ms/epoch - 86ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 1.1701 - accuracy: 0.5794 - val_loss: 1.3870 - val_accuracy: 0.2593 - 329ms/epoch - 82ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 1.1361 - accuracy: 0.6270 - val_loss: 1.3871 - val_accuracy: 0.2407 - 325ms/epoch - 81ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 1.1186 - accuracy: 0.6349 - val_loss: 1.3872 - val_accuracy: 0.2593 - 330ms/epoch - 83ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 1.1558 - accuracy: 0.6349 - val_loss: 1.3872 - val_accuracy: 0.2222 - 322ms/epoch - 80ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 1.1269 - accuracy: 0.6508 - val_loss: 1.3873 - val_accuracy: 0.2593 - 337ms/epoch - 84ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 1.0890 - accuracy: 0.6984 - val_loss: 1.3875 - val_accuracy: 0.2778 - 325ms/epoch - 81ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 1.0473 - accuracy: 0.7143 - val_loss: 1.3876 - val_accuracy: 0.2593 - 319ms/epoch - 80ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 1.0604 - accuracy: 0.7302 - val_loss: 1.3875 - val_accuracy: 0.2778 - 344ms/epoch - 86ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 1.0538 - accuracy: 0.7063 - val_loss: 1.3880 - val_accuracy: 0.3148 - 323ms/epoch - 81ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 1.0592 - accuracy: 0.6984 - val_loss: 1.3884 - val_accuracy: 0.2593 - 328ms/epoch - 82ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 1.0468 - accuracy: 0.7302 - val_loss: 1.3883 - val_accuracy: 0.2407 - 335ms/epoch - 84ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 1.0242 - accuracy: 0.6984 - val_loss: 1.3889 - val_accuracy: 0.2407 - 336ms/epoch - 84ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 1.0095 - accuracy: 0.7460 - val_loss: 1.3892 - val_accuracy: 0.2407 - 336ms/epoch - 84ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 1.0040 - accuracy: 0.7619 - val_loss: 1.3893 - val_accuracy: 0.2963 - 348ms/epoch - 87ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.9904 - accuracy: 0.7381 - val_loss: 1.3892 - val_accuracy: 0.2963 - 349ms/epoch - 87ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.9850 - accuracy: 0.7619 - val_loss: 1.3892 - val_accuracy: 0.2407 - 323ms/epoch - 81ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.9815 - accuracy: 0.8016 - val_loss: 1.3895 - val_accuracy: 0.2407 - 323ms/epoch - 81ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.9657 - accuracy: 0.7698 - val_loss: 1.3905 - val_accuracy: 0.2222 - 327ms/epoch - 82ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.9603 - accuracy: 0.8016 - val_loss: 1.3901 - val_accuracy: 0.2222 - 322ms/epoch - 80ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.9117 - accuracy: 0.8413 - val_loss: 1.3910 - val_accuracy: 0.1852 - 343ms/epoch - 86ms/step\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.9384 - accuracy: 0.7937 - val_loss: 1.3913 - val_accuracy: 0.2593 - 332ms/epoch - 83ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.9108 - accuracy: 0.7857 - val_loss: 1.3912 - val_accuracy: 0.2222 - 335ms/epoch - 84ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.9053 - accuracy: 0.8254 - val_loss: 1.3921 - val_accuracy: 0.2407 - 330ms/epoch - 82ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.9212 - accuracy: 0.7619 - val_loss: 1.3926 - val_accuracy: 0.2407 - 331ms/epoch - 83ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.9059 - accuracy: 0.7619 - val_loss: 1.3918 - val_accuracy: 0.2778 - 323ms/epoch - 81ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.8892 - accuracy: 0.8095 - val_loss: 1.3923 - val_accuracy: 0.2407 - 338ms/epoch - 84ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.8712 - accuracy: 0.8095 - val_loss: 1.3954 - val_accuracy: 0.2407 - 336ms/epoch - 84ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.8870 - accuracy: 0.8254 - val_loss: 1.3946 - val_accuracy: 0.2407 - 340ms/epoch - 85ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.8409 - accuracy: 0.8333 - val_loss: 1.3954 - val_accuracy: 0.2407 - 321ms/epoch - 80ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.8494 - accuracy: 0.7857 - val_loss: 1.3957 - val_accuracy: 0.2407 - 324ms/epoch - 81ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.8355 - accuracy: 0.8810 - val_loss: 1.3967 - val_accuracy: 0.2407 - 330ms/epoch - 83ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.8467 - accuracy: 0.8095 - val_loss: 1.4002 - val_accuracy: 0.2407 - 344ms/epoch - 86ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.7991 - accuracy: 0.8968 - val_loss: 1.3973 - val_accuracy: 0.2593 - 324ms/epoch - 81ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.8213 - accuracy: 0.8254 - val_loss: 1.4046 - val_accuracy: 0.2407 - 321ms/epoch - 80ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.8263 - accuracy: 0.8333 - val_loss: 1.3998 - val_accuracy: 0.2407 - 326ms/epoch - 81ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.7745 - accuracy: 0.8889 - val_loss: 1.4004 - val_accuracy: 0.2407 - 336ms/epoch - 84ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.8116 - accuracy: 0.8413 - val_loss: 1.4035 - val_accuracy: 0.2407 - 320ms/epoch - 80ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.7746 - accuracy: 0.8889 - val_loss: 1.3957 - val_accuracy: 0.2407 - 343ms/epoch - 86ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.7698 - accuracy: 0.9206 - val_loss: 1.4017 - val_accuracy: 0.2407 - 324ms/epoch - 81ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.7270 - accuracy: 0.8492 - val_loss: 1.4074 - val_accuracy: 0.2407 - 323ms/epoch - 81ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.7607 - accuracy: 0.8810 - val_loss: 1.3994 - val_accuracy: 0.2407 - 326ms/epoch - 82ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.7661 - accuracy: 0.8571 - val_loss: 1.4048 - val_accuracy: 0.2407 - 324ms/epoch - 81ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.7390 - accuracy: 0.8651 - val_loss: 1.4027 - val_accuracy: 0.2407 - 334ms/epoch - 83ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.7428 - accuracy: 0.8810 - val_loss: 1.4021 - val_accuracy: 0.2407 - 337ms/epoch - 84ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.7084 - accuracy: 0.9206 - val_loss: 1.4135 - val_accuracy: 0.2407 - 336ms/epoch - 84ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.6962 - accuracy: 0.9365 - val_loss: 1.4011 - val_accuracy: 0.2407 - 330ms/epoch - 82ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.6885 - accuracy: 0.9365 - val_loss: 1.4053 - val_accuracy: 0.2407 - 336ms/epoch - 84ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.6999 - accuracy: 0.9365 - val_loss: 1.4095 - val_accuracy: 0.2407 - 339ms/epoch - 85ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.7119 - accuracy: 0.9286 - val_loss: 1.4106 - val_accuracy: 0.2407 - 333ms/epoch - 83ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.6571 - accuracy: 0.9286 - val_loss: 1.4166 - val_accuracy: 0.2778 - 344ms/epoch - 86ms/step\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.6629 - accuracy: 0.9048 - val_loss: 1.3923 - val_accuracy: 0.2407 - 332ms/epoch - 83ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.6920 - accuracy: 0.9206 - val_loss: 1.4208 - val_accuracy: 0.2407 - 332ms/epoch - 83ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.7047 - accuracy: 0.8968 - val_loss: 1.4105 - val_accuracy: 0.2037 - 331ms/epoch - 83ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.6911 - accuracy: 0.8730 - val_loss: 1.4281 - val_accuracy: 0.2407 - 330ms/epoch - 82ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.6309 - accuracy: 0.9365 - val_loss: 1.4020 - val_accuracy: 0.2222 - 323ms/epoch - 81ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.6136 - accuracy: 0.9683 - val_loss: 1.4224 - val_accuracy: 0.2407 - 330ms/epoch - 83ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.6503 - accuracy: 0.8968 - val_loss: 1.4402 - val_accuracy: 0.2222 - 328ms/epoch - 82ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.6618 - accuracy: 0.9206 - val_loss: 1.4388 - val_accuracy: 0.2407 - 323ms/epoch - 81ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.6239 - accuracy: 0.9286 - val_loss: 1.4213 - val_accuracy: 0.2407 - 327ms/epoch - 82ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.5884 - accuracy: 0.9365 - val_loss: 1.4579 - val_accuracy: 0.2037 - 323ms/epoch - 81ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.5741 - accuracy: 0.9524 - val_loss: 1.4332 - val_accuracy: 0.2222 - 339ms/epoch - 85ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.6289 - accuracy: 0.9286 - val_loss: 1.4528 - val_accuracy: 0.2222 - 328ms/epoch - 82ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.5778 - accuracy: 0.9206 - val_loss: 1.4463 - val_accuracy: 0.1852 - 327ms/epoch - 82ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.5627 - accuracy: 0.9524 - val_loss: 1.4394 - val_accuracy: 0.2037 - 336ms/epoch - 84ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.5819 - accuracy: 0.9603 - val_loss: 1.4468 - val_accuracy: 0.1852 - 324ms/epoch - 81ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.5994 - accuracy: 0.9365 - val_loss: 1.4330 - val_accuracy: 0.2407 - 323ms/epoch - 81ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.5652 - accuracy: 0.9286 - val_loss: 1.4573 - val_accuracy: 0.1852 - 335ms/epoch - 84ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.5487 - accuracy: 0.9762 - val_loss: 1.4304 - val_accuracy: 0.2593 - 332ms/epoch - 83ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.5264 - accuracy: 0.9762 - val_loss: 1.4632 - val_accuracy: 0.2407 - 325ms/epoch - 81ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.5313 - accuracy: 0.9762 - val_loss: 1.4313 - val_accuracy: 0.1852 - 350ms/epoch - 88ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.5150 - accuracy: 0.9762 - val_loss: 1.4634 - val_accuracy: 0.2407 - 322ms/epoch - 80ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.5219 - accuracy: 0.9444 - val_loss: 1.4493 - val_accuracy: 0.1481 - 323ms/epoch - 81ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.5717 - accuracy: 0.9683 - val_loss: 1.4739 - val_accuracy: 0.2407 - 331ms/epoch - 83ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.5290 - accuracy: 0.9683 - val_loss: 1.4381 - val_accuracy: 0.2222 - 326ms/epoch - 81ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.5457 - accuracy: 0.9524 - val_loss: 1.4793 - val_accuracy: 0.2778 - 334ms/epoch - 84ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.4947 - accuracy: 0.9683 - val_loss: 1.4541 - val_accuracy: 0.2222 - 331ms/epoch - 83ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.5092 - accuracy: 0.9603 - val_loss: 1.4446 - val_accuracy: 0.1852 - 327ms/epoch - 82ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.4818 - accuracy: 0.9841 - val_loss: 1.4467 - val_accuracy: 0.1852 - 323ms/epoch - 81ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.4850 - accuracy: 0.9921 - val_loss: 1.4799 - val_accuracy: 0.2407 - 344ms/epoch - 86ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.4804 - accuracy: 0.9444 - val_loss: 1.4455 - val_accuracy: 0.1296 - 328ms/epoch - 82ms/step\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.4740 - accuracy: 0.9762 - val_loss: 1.4412 - val_accuracy: 0.2407 - 329ms/epoch - 82ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.4418 - accuracy: 0.9841 - val_loss: 1.4466 - val_accuracy: 0.1481 - 326ms/epoch - 82ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.4413 - accuracy: 0.9841 - val_loss: 1.4587 - val_accuracy: 0.1667 - 334ms/epoch - 84ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.4331 - accuracy: 0.9683 - val_loss: 1.4802 - val_accuracy: 0.1852 - 326ms/epoch - 81ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.4308 - accuracy: 0.9921 - val_loss: 1.4725 - val_accuracy: 0.2037 - 336ms/epoch - 84ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 1.38630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.3944 - accuracy: 0.9921 - val_loss: 1.4553 - val_accuracy: 0.1667 - 343ms/epoch - 86ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.4334 - accuracy: 0.9921 - val_loss: 1.4703 - val_accuracy: 0.1667 - 331ms/epoch - 83ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.3981 - accuracy: 0.9683 - val_loss: 1.4706 - val_accuracy: 0.2222 - 324ms/epoch - 81ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.4430 - accuracy: 0.9841 - val_loss: 1.5245 - val_accuracy: 0.2222 - 322ms/epoch - 80ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.4129 - accuracy: 0.9841 - val_loss: 1.4757 - val_accuracy: 0.2222 - 328ms/epoch - 82ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.3961 - accuracy: 1.0000 - val_loss: 1.5043 - val_accuracy: 0.1852 - 323ms/epoch - 81ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.4005 - accuracy: 0.9841 - val_loss: 1.4725 - val_accuracy: 0.2037 - 326ms/epoch - 82ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.3998 - accuracy: 0.9921 - val_loss: 1.5051 - val_accuracy: 0.1852 - 329ms/epoch - 82ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.4145 - accuracy: 0.9683 - val_loss: 1.4810 - val_accuracy: 0.1852 - 336ms/epoch - 84ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.3706 - accuracy: 1.0000 - val_loss: 1.4923 - val_accuracy: 0.1852 - 337ms/epoch - 84ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.3638 - accuracy: 0.9841 - val_loss: 1.4945 - val_accuracy: 0.1667 - 338ms/epoch - 85ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.4069 - accuracy: 0.9841 - val_loss: 1.5173 - val_accuracy: 0.2222 - 338ms/epoch - 85ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.3692 - accuracy: 0.9841 - val_loss: 1.5081 - val_accuracy: 0.2407 - 337ms/epoch - 84ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.3749 - accuracy: 0.9921 - val_loss: 1.5211 - val_accuracy: 0.1481 - 341ms/epoch - 85ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.3760 - accuracy: 0.9762 - val_loss: 1.5068 - val_accuracy: 0.2407 - 345ms/epoch - 86ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.3401 - accuracy: 0.9921 - val_loss: 1.5568 - val_accuracy: 0.1667 - 334ms/epoch - 83ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.3662 - accuracy: 1.0000 - val_loss: 1.5033 - val_accuracy: 0.2037 - 342ms/epoch - 86ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.3667 - accuracy: 1.0000 - val_loss: 1.4704 - val_accuracy: 0.1667 - 321ms/epoch - 80ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.3348 - accuracy: 1.0000 - val_loss: 1.5107 - val_accuracy: 0.1296 - 330ms/epoch - 82ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.3512 - accuracy: 0.9921 - val_loss: 1.4608 - val_accuracy: 0.2407 - 334ms/epoch - 83ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.3302 - accuracy: 0.9921 - val_loss: 1.4619 - val_accuracy: 0.2593 - 332ms/epoch - 83ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.3521 - accuracy: 0.9841 - val_loss: 1.5399 - val_accuracy: 0.2222 - 334ms/epoch - 84ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.3677 - accuracy: 0.9683 - val_loss: 1.5113 - val_accuracy: 0.1852 - 365ms/epoch - 91ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.3229 - accuracy: 1.0000 - val_loss: 1.5069 - val_accuracy: 0.2593 - 332ms/epoch - 83ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.3389 - accuracy: 1.0000 - val_loss: 1.5185 - val_accuracy: 0.2037 - 341ms/epoch - 85ms/step\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.3308 - accuracy: 1.0000 - val_loss: 1.5403 - val_accuracy: 0.2407 - 335ms/epoch - 84ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.3375 - accuracy: 0.9921 - val_loss: 1.5627 - val_accuracy: 0.2037 - 324ms/epoch - 81ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.3314 - accuracy: 0.9921 - val_loss: 1.6000 - val_accuracy: 0.1667 - 331ms/epoch - 83ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.3241 - accuracy: 0.9921 - val_loss: 1.5700 - val_accuracy: 0.1852 - 323ms/epoch - 81ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.3215 - accuracy: 1.0000 - val_loss: 1.6675 - val_accuracy: 0.2222 - 322ms/epoch - 81ms/step\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.3230 - accuracy: 1.0000 - val_loss: 1.6306 - val_accuracy: 0.2222 - 335ms/epoch - 84ms/step\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.3376 - accuracy: 0.9841 - val_loss: 1.5977 - val_accuracy: 0.2222 - 328ms/epoch - 82ms/step\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.3188 - accuracy: 0.9762 - val_loss: 1.6156 - val_accuracy: 0.1481 - 323ms/epoch - 81ms/step\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2917 - accuracy: 0.9762 - val_loss: 1.6416 - val_accuracy: 0.1481 - 321ms/epoch - 80ms/step\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2933 - accuracy: 0.9921 - val_loss: 1.5651 - val_accuracy: 0.2407 - 335ms/epoch - 84ms/step\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2772 - accuracy: 1.0000 - val_loss: 1.5336 - val_accuracy: 0.2037 - 339ms/epoch - 85ms/step\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2784 - accuracy: 1.0000 - val_loss: 1.5988 - val_accuracy: 0.2037 - 331ms/epoch - 83ms/step\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.3111 - accuracy: 0.9841 - val_loss: 1.6586 - val_accuracy: 0.2037 - 333ms/epoch - 83ms/step\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2938 - accuracy: 1.0000 - val_loss: 1.6018 - val_accuracy: 0.2222 - 334ms/epoch - 84ms/step\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 135: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2775 - accuracy: 1.0000 - val_loss: 1.6075 - val_accuracy: 0.1852 - 329ms/epoch - 82ms/step\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 136: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.3101 - accuracy: 0.9683 - val_loss: 1.6134 - val_accuracy: 0.1667 - 354ms/epoch - 89ms/step\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 137: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2914 - accuracy: 1.0000 - val_loss: 1.5748 - val_accuracy: 0.2222 - 327ms/epoch - 82ms/step\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 138: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2803 - accuracy: 1.0000 - val_loss: 1.6093 - val_accuracy: 0.1667 - 334ms/epoch - 83ms/step\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 139: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2888 - accuracy: 0.9762 - val_loss: 1.6148 - val_accuracy: 0.1667 - 336ms/epoch - 84ms/step\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 140: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2675 - accuracy: 0.9841 - val_loss: 1.6340 - val_accuracy: 0.2778 - 341ms/epoch - 85ms/step\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 141: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2615 - accuracy: 0.9921 - val_loss: 1.5796 - val_accuracy: 0.1296 - 328ms/epoch - 82ms/step\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 142: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2475 - accuracy: 1.0000 - val_loss: 1.6223 - val_accuracy: 0.1852 - 325ms/epoch - 81ms/step\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 143: val_loss did not improve from 1.38630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.2626 - accuracy: 1.0000 - val_loss: 1.6611 - val_accuracy: 0.2037 - 344ms/epoch - 86ms/step\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 144: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2729 - accuracy: 0.9841 - val_loss: 1.6978 - val_accuracy: 0.2407 - 341ms/epoch - 85ms/step\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 145: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2923 - accuracy: 0.9921 - val_loss: 1.6698 - val_accuracy: 0.2222 - 337ms/epoch - 84ms/step\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 146: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2615 - accuracy: 1.0000 - val_loss: 1.6409 - val_accuracy: 0.1667 - 323ms/epoch - 81ms/step\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 147: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2789 - accuracy: 0.9762 - val_loss: 1.6398 - val_accuracy: 0.2037 - 334ms/epoch - 84ms/step\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 148: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2270 - accuracy: 1.0000 - val_loss: 1.6613 - val_accuracy: 0.1852 - 346ms/epoch - 87ms/step\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 149: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2535 - accuracy: 1.0000 - val_loss: 1.6480 - val_accuracy: 0.1667 - 331ms/epoch - 83ms/step\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 150: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2399 - accuracy: 1.0000 - val_loss: 1.6331 - val_accuracy: 0.2407 - 327ms/epoch - 82ms/step\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 151: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2663 - accuracy: 1.0000 - val_loss: 1.6317 - val_accuracy: 0.2778 - 325ms/epoch - 81ms/step\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 152: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2387 - accuracy: 1.0000 - val_loss: 1.6691 - val_accuracy: 0.2593 - 335ms/epoch - 84ms/step\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 153: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2416 - accuracy: 0.9921 - val_loss: 1.6361 - val_accuracy: 0.1852 - 331ms/epoch - 83ms/step\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 154: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2305 - accuracy: 1.0000 - val_loss: 1.6714 - val_accuracy: 0.2222 - 321ms/epoch - 80ms/step\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 155: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2320 - accuracy: 0.9921 - val_loss: 1.6332 - val_accuracy: 0.2407 - 324ms/epoch - 81ms/step\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 156: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2362 - accuracy: 1.0000 - val_loss: 1.7180 - val_accuracy: 0.1481 - 340ms/epoch - 85ms/step\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 157: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 1.6872 - val_accuracy: 0.1667 - 331ms/epoch - 83ms/step\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 158: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 1.6732 - val_accuracy: 0.2037 - 328ms/epoch - 82ms/step\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 159: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1991 - accuracy: 0.9921 - val_loss: 1.6500 - val_accuracy: 0.2593 - 332ms/epoch - 83ms/step\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 160: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2112 - accuracy: 0.9921 - val_loss: 1.6671 - val_accuracy: 0.2407 - 332ms/epoch - 83ms/step\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 161: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 1.6853 - val_accuracy: 0.2037 - 326ms/epoch - 81ms/step\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 162: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 1.7267 - val_accuracy: 0.2593 - 339ms/epoch - 85ms/step\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 163: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2174 - accuracy: 0.9921 - val_loss: 1.6717 - val_accuracy: 0.2222 - 331ms/epoch - 83ms/step\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 164: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2248 - accuracy: 0.9921 - val_loss: 1.7648 - val_accuracy: 0.2778 - 319ms/epoch - 80ms/step\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 165: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2065 - accuracy: 1.0000 - val_loss: 2.0029 - val_accuracy: 0.2037 - 332ms/epoch - 83ms/step\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 166: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2252 - accuracy: 0.9841 - val_loss: 1.7235 - val_accuracy: 0.2037 - 331ms/epoch - 83ms/step\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 167: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2222 - accuracy: 1.0000 - val_loss: 1.8442 - val_accuracy: 0.1481 - 330ms/epoch - 83ms/step\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 168: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2048 - accuracy: 1.0000 - val_loss: 1.8379 - val_accuracy: 0.2593 - 339ms/epoch - 85ms/step\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 169: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2173 - accuracy: 1.0000 - val_loss: 1.8412 - val_accuracy: 0.2593 - 346ms/epoch - 86ms/step\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 170: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1926 - accuracy: 1.0000 - val_loss: 1.7626 - val_accuracy: 0.2593 - 336ms/epoch - 84ms/step\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 171: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2016 - accuracy: 1.0000 - val_loss: 1.6942 - val_accuracy: 0.2778 - 326ms/epoch - 82ms/step\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 172: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 1.7242 - val_accuracy: 0.2407 - 329ms/epoch - 82ms/step\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 173: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1808 - accuracy: 1.0000 - val_loss: 1.6706 - val_accuracy: 0.2222 - 367ms/epoch - 92ms/step\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 174: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1901 - accuracy: 1.0000 - val_loss: 1.7381 - val_accuracy: 0.2407 - 327ms/epoch - 82ms/step\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 175: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1783 - accuracy: 1.0000 - val_loss: 1.7244 - val_accuracy: 0.2593 - 322ms/epoch - 81ms/step\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 176: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1677 - accuracy: 0.9921 - val_loss: 1.6837 - val_accuracy: 0.2407 - 335ms/epoch - 84ms/step\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 177: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2005 - accuracy: 1.0000 - val_loss: 1.6921 - val_accuracy: 0.2222 - 335ms/epoch - 84ms/step\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 178: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1921 - accuracy: 0.9841 - val_loss: 1.6683 - val_accuracy: 0.2222 - 340ms/epoch - 85ms/step\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 179: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2198 - accuracy: 0.9921 - val_loss: 1.7819 - val_accuracy: 0.2593 - 323ms/epoch - 81ms/step\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 180: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2046 - accuracy: 1.0000 - val_loss: 1.8017 - val_accuracy: 0.1667 - 336ms/epoch - 84ms/step\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 181: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1965 - accuracy: 0.9921 - val_loss: 1.7200 - val_accuracy: 0.2222 - 345ms/epoch - 86ms/step\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 182: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1909 - accuracy: 1.0000 - val_loss: 1.9187 - val_accuracy: 0.2222 - 330ms/epoch - 82ms/step\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 183: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1851 - accuracy: 1.0000 - val_loss: 1.8899 - val_accuracy: 0.2222 - 328ms/epoch - 82ms/step\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 184: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.2037 - accuracy: 1.0000 - val_loss: 1.8165 - val_accuracy: 0.2222 - 324ms/epoch - 81ms/step\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 185: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1960 - accuracy: 1.0000 - val_loss: 1.9185 - val_accuracy: 0.1481 - 331ms/epoch - 83ms/step\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 186: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1919 - accuracy: 1.0000 - val_loss: 2.0065 - val_accuracy: 0.2222 - 336ms/epoch - 84ms/step\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 187: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1864 - accuracy: 0.9921 - val_loss: 1.7482 - val_accuracy: 0.2037 - 329ms/epoch - 82ms/step\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 188: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1754 - accuracy: 1.0000 - val_loss: 1.7780 - val_accuracy: 0.2407 - 327ms/epoch - 82ms/step\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 189: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1817 - accuracy: 1.0000 - val_loss: 1.7711 - val_accuracy: 0.2593 - 332ms/epoch - 83ms/step\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 190: val_loss did not improve from 1.38630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.1672 - accuracy: 1.0000 - val_loss: 1.7446 - val_accuracy: 0.2778 - 323ms/epoch - 81ms/step\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 191: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1582 - accuracy: 1.0000 - val_loss: 1.7307 - val_accuracy: 0.2037 - 343ms/epoch - 86ms/step\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 192: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1749 - accuracy: 1.0000 - val_loss: 1.7651 - val_accuracy: 0.2407 - 340ms/epoch - 85ms/step\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 193: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1490 - accuracy: 1.0000 - val_loss: 1.7204 - val_accuracy: 0.2222 - 342ms/epoch - 85ms/step\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 194: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1624 - accuracy: 1.0000 - val_loss: 1.7388 - val_accuracy: 0.1852 - 322ms/epoch - 81ms/step\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 195: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1600 - accuracy: 1.0000 - val_loss: 1.7503 - val_accuracy: 0.2593 - 339ms/epoch - 85ms/step\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 196: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1608 - accuracy: 1.0000 - val_loss: 1.8134 - val_accuracy: 0.2037 - 322ms/epoch - 81ms/step\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 197: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1501 - accuracy: 1.0000 - val_loss: 1.7750 - val_accuracy: 0.1667 - 326ms/epoch - 81ms/step\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 198: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1541 - accuracy: 1.0000 - val_loss: 1.7088 - val_accuracy: 0.2407 - 338ms/epoch - 85ms/step\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 199: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1701 - accuracy: 1.0000 - val_loss: 1.6703 - val_accuracy: 0.2037 - 329ms/epoch - 82ms/step\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 200: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1535 - accuracy: 1.0000 - val_loss: 1.6756 - val_accuracy: 0.2407 - 357ms/epoch - 89ms/step\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 201: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1610 - accuracy: 1.0000 - val_loss: 1.6790 - val_accuracy: 0.2778 - 324ms/epoch - 81ms/step\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 202: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1683 - accuracy: 1.0000 - val_loss: 1.7795 - val_accuracy: 0.2037 - 335ms/epoch - 84ms/step\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 203: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1468 - accuracy: 1.0000 - val_loss: 1.7486 - val_accuracy: 0.2593 - 342ms/epoch - 85ms/step\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 204: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1646 - accuracy: 1.0000 - val_loss: 1.7546 - val_accuracy: 0.2778 - 343ms/epoch - 86ms/step\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 205: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1419 - accuracy: 1.0000 - val_loss: 1.6926 - val_accuracy: 0.2778 - 323ms/epoch - 81ms/step\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 206: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1473 - accuracy: 1.0000 - val_loss: 1.6755 - val_accuracy: 0.2778 - 328ms/epoch - 82ms/step\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 207: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1605 - accuracy: 1.0000 - val_loss: 1.6967 - val_accuracy: 0.2407 - 324ms/epoch - 81ms/step\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 208: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1466 - accuracy: 1.0000 - val_loss: 1.7781 - val_accuracy: 0.2222 - 338ms/epoch - 84ms/step\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 209: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1587 - accuracy: 1.0000 - val_loss: 1.8275 - val_accuracy: 0.2222 - 328ms/epoch - 82ms/step\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 210: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1548 - accuracy: 1.0000 - val_loss: 1.8749 - val_accuracy: 0.2222 - 337ms/epoch - 84ms/step\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 211: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1497 - accuracy: 1.0000 - val_loss: 1.8434 - val_accuracy: 0.2778 - 332ms/epoch - 83ms/step\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 212: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1409 - accuracy: 1.0000 - val_loss: 1.7672 - val_accuracy: 0.2593 - 326ms/epoch - 81ms/step\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 213: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1328 - accuracy: 1.0000 - val_loss: 1.8169 - val_accuracy: 0.2037 - 327ms/epoch - 82ms/step\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 214: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1412 - accuracy: 1.0000 - val_loss: 1.7713 - val_accuracy: 0.2778 - 329ms/epoch - 82ms/step\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 215: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1518 - accuracy: 1.0000 - val_loss: 1.8335 - val_accuracy: 0.2222 - 328ms/epoch - 82ms/step\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 216: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1256 - accuracy: 1.0000 - val_loss: 1.7835 - val_accuracy: 0.1852 - 340ms/epoch - 85ms/step\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 217: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1357 - accuracy: 1.0000 - val_loss: 1.7718 - val_accuracy: 0.2778 - 335ms/epoch - 84ms/step\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 218: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1356 - accuracy: 1.0000 - val_loss: 1.7760 - val_accuracy: 0.2778 - 333ms/epoch - 83ms/step\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 219: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1478 - accuracy: 1.0000 - val_loss: 1.7413 - val_accuracy: 0.2037 - 327ms/epoch - 82ms/step\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 220: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1306 - accuracy: 1.0000 - val_loss: 1.7190 - val_accuracy: 0.2037 - 325ms/epoch - 81ms/step\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 221: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1455 - accuracy: 1.0000 - val_loss: 1.7511 - val_accuracy: 0.1481 - 322ms/epoch - 81ms/step\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 222: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1555 - accuracy: 0.9921 - val_loss: 1.7833 - val_accuracy: 0.1667 - 343ms/epoch - 86ms/step\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 223: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1293 - accuracy: 1.0000 - val_loss: 1.7342 - val_accuracy: 0.2407 - 331ms/epoch - 83ms/step\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 224: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1214 - accuracy: 1.0000 - val_loss: 1.6686 - val_accuracy: 0.1852 - 346ms/epoch - 86ms/step\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 225: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1300 - accuracy: 1.0000 - val_loss: 1.7302 - val_accuracy: 0.2222 - 329ms/epoch - 82ms/step\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 226: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1409 - accuracy: 1.0000 - val_loss: 1.7548 - val_accuracy: 0.2037 - 325ms/epoch - 81ms/step\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 227: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1305 - accuracy: 1.0000 - val_loss: 1.7243 - val_accuracy: 0.2407 - 333ms/epoch - 83ms/step\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 228: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1199 - accuracy: 1.0000 - val_loss: 1.8850 - val_accuracy: 0.2222 - 342ms/epoch - 85ms/step\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 229: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1229 - accuracy: 1.0000 - val_loss: 1.9009 - val_accuracy: 0.3148 - 330ms/epoch - 82ms/step\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 230: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1277 - accuracy: 1.0000 - val_loss: 1.8665 - val_accuracy: 0.2222 - 342ms/epoch - 86ms/step\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 231: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1104 - accuracy: 1.0000 - val_loss: 1.8774 - val_accuracy: 0.2037 - 336ms/epoch - 84ms/step\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 232: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1354 - accuracy: 1.0000 - val_loss: 1.8350 - val_accuracy: 0.2963 - 326ms/epoch - 81ms/step\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 233: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1239 - accuracy: 1.0000 - val_loss: 1.6750 - val_accuracy: 0.2222 - 332ms/epoch - 83ms/step\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 234: val_loss did not improve from 1.38630\n",
      "4/4 - 1s - loss: 0.1203 - accuracy: 1.0000 - val_loss: 1.7435 - val_accuracy: 0.2963 - 690ms/epoch - 173ms/step\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 235: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1268 - accuracy: 1.0000 - val_loss: 1.6470 - val_accuracy: 0.2778 - 350ms/epoch - 87ms/step\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 236: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1224 - accuracy: 0.9921 - val_loss: 1.6773 - val_accuracy: 0.2407 - 337ms/epoch - 84ms/step\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 237: val_loss did not improve from 1.38630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.1352 - accuracy: 1.0000 - val_loss: 1.7667 - val_accuracy: 0.1852 - 355ms/epoch - 89ms/step\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 238: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1490 - accuracy: 0.9921 - val_loss: 1.8789 - val_accuracy: 0.2222 - 344ms/epoch - 86ms/step\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 239: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1254 - accuracy: 1.0000 - val_loss: 1.8916 - val_accuracy: 0.2407 - 344ms/epoch - 86ms/step\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 240: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1267 - accuracy: 1.0000 - val_loss: 2.1149 - val_accuracy: 0.2037 - 341ms/epoch - 85ms/step\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 241: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1375 - accuracy: 1.0000 - val_loss: 1.8794 - val_accuracy: 0.2222 - 355ms/epoch - 89ms/step\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 242: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1227 - accuracy: 1.0000 - val_loss: 1.7580 - val_accuracy: 0.2037 - 342ms/epoch - 85ms/step\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 243: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1127 - accuracy: 1.0000 - val_loss: 1.7958 - val_accuracy: 0.2407 - 337ms/epoch - 84ms/step\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 244: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1233 - accuracy: 1.0000 - val_loss: 1.7902 - val_accuracy: 0.2778 - 333ms/epoch - 83ms/step\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 245: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1208 - accuracy: 1.0000 - val_loss: 1.9111 - val_accuracy: 0.1852 - 355ms/epoch - 89ms/step\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 246: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1053 - accuracy: 1.0000 - val_loss: 1.8919 - val_accuracy: 0.2222 - 352ms/epoch - 88ms/step\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 247: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1301 - accuracy: 1.0000 - val_loss: 1.8959 - val_accuracy: 0.1852 - 340ms/epoch - 85ms/step\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 248: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1202 - accuracy: 1.0000 - val_loss: 1.8051 - val_accuracy: 0.1667 - 333ms/epoch - 83ms/step\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 249: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1497 - accuracy: 1.0000 - val_loss: 1.7829 - val_accuracy: 0.2037 - 345ms/epoch - 86ms/step\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 250: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1036 - accuracy: 1.0000 - val_loss: 1.7422 - val_accuracy: 0.1667 - 345ms/epoch - 86ms/step\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 251: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1199 - accuracy: 1.0000 - val_loss: 1.6907 - val_accuracy: 0.2407 - 348ms/epoch - 87ms/step\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 252: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1272 - accuracy: 1.0000 - val_loss: 1.7533 - val_accuracy: 0.2593 - 342ms/epoch - 85ms/step\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 253: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1086 - accuracy: 1.0000 - val_loss: 1.7528 - val_accuracy: 0.2593 - 346ms/epoch - 86ms/step\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 254: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1055 - accuracy: 1.0000 - val_loss: 1.7816 - val_accuracy: 0.2593 - 351ms/epoch - 88ms/step\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 255: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1046 - accuracy: 1.0000 - val_loss: 2.0020 - val_accuracy: 0.2778 - 343ms/epoch - 86ms/step\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 256: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1368 - accuracy: 1.0000 - val_loss: 1.8635 - val_accuracy: 0.2222 - 337ms/epoch - 84ms/step\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 257: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1139 - accuracy: 1.0000 - val_loss: 1.7419 - val_accuracy: 0.2407 - 333ms/epoch - 83ms/step\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 258: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1310 - accuracy: 1.0000 - val_loss: 1.7496 - val_accuracy: 0.2407 - 347ms/epoch - 87ms/step\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 259: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1173 - accuracy: 1.0000 - val_loss: 1.7748 - val_accuracy: 0.1296 - 339ms/epoch - 85ms/step\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 260: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1126 - accuracy: 1.0000 - val_loss: 1.8387 - val_accuracy: 0.1852 - 341ms/epoch - 85ms/step\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 261: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1135 - accuracy: 1.0000 - val_loss: 1.7673 - val_accuracy: 0.1852 - 339ms/epoch - 85ms/step\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 262: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1027 - accuracy: 1.0000 - val_loss: 1.7814 - val_accuracy: 0.1481 - 345ms/epoch - 86ms/step\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 263: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1026 - accuracy: 1.0000 - val_loss: 1.7895 - val_accuracy: 0.2037 - 329ms/epoch - 82ms/step\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 264: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1059 - accuracy: 1.0000 - val_loss: 1.7784 - val_accuracy: 0.1852 - 332ms/epoch - 83ms/step\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 265: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1048 - accuracy: 1.0000 - val_loss: 1.8499 - val_accuracy: 0.2222 - 359ms/epoch - 90ms/step\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 266: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1277 - accuracy: 0.9921 - val_loss: 2.1312 - val_accuracy: 0.2222 - 341ms/epoch - 85ms/step\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 267: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1374 - accuracy: 1.0000 - val_loss: 1.8360 - val_accuracy: 0.2222 - 347ms/epoch - 87ms/step\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 268: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1374 - accuracy: 0.9841 - val_loss: 2.0061 - val_accuracy: 0.2778 - 344ms/epoch - 86ms/step\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 269: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1252 - accuracy: 1.0000 - val_loss: 1.8220 - val_accuracy: 0.2222 - 347ms/epoch - 87ms/step\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 270: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1202 - accuracy: 1.0000 - val_loss: 1.7402 - val_accuracy: 0.1667 - 343ms/epoch - 86ms/step\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 271: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1046 - accuracy: 1.0000 - val_loss: 1.8509 - val_accuracy: 0.2222 - 335ms/epoch - 84ms/step\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 272: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1275 - accuracy: 1.0000 - val_loss: 1.8095 - val_accuracy: 0.2407 - 346ms/epoch - 86ms/step\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 273: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1173 - accuracy: 1.0000 - val_loss: 2.0968 - val_accuracy: 0.2407 - 344ms/epoch - 86ms/step\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 274: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1023 - accuracy: 1.0000 - val_loss: 2.1265 - val_accuracy: 0.2407 - 350ms/epoch - 88ms/step\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 275: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1033 - accuracy: 1.0000 - val_loss: 2.1350 - val_accuracy: 0.1852 - 340ms/epoch - 85ms/step\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 276: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1105 - accuracy: 1.0000 - val_loss: 1.8617 - val_accuracy: 0.2222 - 333ms/epoch - 83ms/step\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 277: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1066 - accuracy: 1.0000 - val_loss: 1.7818 - val_accuracy: 0.2222 - 342ms/epoch - 85ms/step\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 278: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1178 - accuracy: 1.0000 - val_loss: 1.7871 - val_accuracy: 0.3333 - 351ms/epoch - 88ms/step\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 279: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.0941 - accuracy: 1.0000 - val_loss: 2.0694 - val_accuracy: 0.2222 - 343ms/epoch - 86ms/step\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 280: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1123 - accuracy: 1.0000 - val_loss: 2.0601 - val_accuracy: 0.3148 - 343ms/epoch - 86ms/step\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 281: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.0963 - accuracy: 1.0000 - val_loss: 1.8280 - val_accuracy: 0.2778 - 339ms/epoch - 85ms/step\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 282: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.0961 - accuracy: 1.0000 - val_loss: 1.9988 - val_accuracy: 0.2963 - 351ms/epoch - 88ms/step\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 283: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.0840 - accuracy: 1.0000 - val_loss: 1.8803 - val_accuracy: 0.3148 - 332ms/epoch - 83ms/step\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 284: val_loss did not improve from 1.38630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.0950 - accuracy: 1.0000 - val_loss: 1.9894 - val_accuracy: 0.2407 - 339ms/epoch - 85ms/step\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 285: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.0921 - accuracy: 1.0000 - val_loss: 1.8895 - val_accuracy: 0.1852 - 331ms/epoch - 83ms/step\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 286: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1044 - accuracy: 1.0000 - val_loss: 1.9065 - val_accuracy: 0.1667 - 334ms/epoch - 83ms/step\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 287: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1134 - accuracy: 1.0000 - val_loss: 1.9433 - val_accuracy: 0.2037 - 341ms/epoch - 85ms/step\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 288: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.0903 - accuracy: 1.0000 - val_loss: 1.9541 - val_accuracy: 0.2778 - 343ms/epoch - 86ms/step\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 289: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1032 - accuracy: 1.0000 - val_loss: 2.0047 - val_accuracy: 0.2407 - 342ms/epoch - 86ms/step\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 290: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1158 - accuracy: 0.9921 - val_loss: 1.9291 - val_accuracy: 0.2593 - 345ms/epoch - 86ms/step\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 291: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1323 - accuracy: 1.0000 - val_loss: 1.8566 - val_accuracy: 0.2407 - 347ms/epoch - 87ms/step\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 292: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.0929 - accuracy: 1.0000 - val_loss: 2.0390 - val_accuracy: 0.2222 - 343ms/epoch - 86ms/step\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 293: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1032 - accuracy: 1.0000 - val_loss: 1.9616 - val_accuracy: 0.2778 - 350ms/epoch - 87ms/step\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 294: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.0932 - accuracy: 1.0000 - val_loss: 1.8301 - val_accuracy: 0.2407 - 335ms/epoch - 84ms/step\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 295: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1006 - accuracy: 1.0000 - val_loss: 1.6847 - val_accuracy: 0.2037 - 338ms/epoch - 85ms/step\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 296: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1154 - accuracy: 1.0000 - val_loss: 1.7697 - val_accuracy: 0.2222 - 333ms/epoch - 83ms/step\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 297: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1029 - accuracy: 1.0000 - val_loss: 1.8484 - val_accuracy: 0.2407 - 354ms/epoch - 89ms/step\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 298: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.0911 - accuracy: 1.0000 - val_loss: 1.7418 - val_accuracy: 0.2778 - 333ms/epoch - 83ms/step\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 299: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.1007 - accuracy: 1.0000 - val_loss: 1.8266 - val_accuracy: 0.2037 - 350ms/epoch - 87ms/step\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 300: val_loss did not improve from 1.38630\n",
      "4/4 - 0s - loss: 0.0829 - accuracy: 1.0000 - val_loss: 1.9758 - val_accuracy: 0.2593 - 338ms/epoch - 85ms/step\n",
      "2/2 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2022-11-11 09:33:05.843694: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_9257072\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:608326\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 09:33:09.848310: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_9260142\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:608368\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38632, saving model to checkpoint1.h5\n",
      "4/4 - 5s - loss: 1.4135 - accuracy: 0.3016 - val_loss: 1.3863 - val_accuracy: 0.2593 - 5s/epoch - 1s/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 1.3246 - accuracy: 0.3730 - val_loss: 1.3863 - val_accuracy: 0.2593 - 337ms/epoch - 84ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss improved from 1.38632 to 1.38631, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 1.3326 - accuracy: 0.3492 - val_loss: 1.3863 - val_accuracy: 0.2963 - 391ms/epoch - 98ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss improved from 1.38631 to 1.38630, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 1.3003 - accuracy: 0.3810 - val_loss: 1.3863 - val_accuracy: 0.2778 - 381ms/epoch - 95ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss improved from 1.38630 to 1.38627, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 1.2855 - accuracy: 0.4048 - val_loss: 1.3863 - val_accuracy: 0.2222 - 395ms/epoch - 99ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 1.2724 - accuracy: 0.4444 - val_loss: 1.3863 - val_accuracy: 0.2407 - 329ms/epoch - 82ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 1.2536 - accuracy: 0.4683 - val_loss: 1.3864 - val_accuracy: 0.2407 - 320ms/epoch - 80ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 1.2318 - accuracy: 0.5238 - val_loss: 1.3864 - val_accuracy: 0.2407 - 336ms/epoch - 84ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 1.2094 - accuracy: 0.4762 - val_loss: 1.3864 - val_accuracy: 0.2222 - 319ms/epoch - 80ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 1.1941 - accuracy: 0.5952 - val_loss: 1.3863 - val_accuracy: 0.2407 - 333ms/epoch - 83ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 1.1710 - accuracy: 0.5794 - val_loss: 1.3863 - val_accuracy: 0.2407 - 336ms/epoch - 84ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 1.1342 - accuracy: 0.6746 - val_loss: 1.3863 - val_accuracy: 0.3333 - 327ms/epoch - 82ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 1.1493 - accuracy: 0.6429 - val_loss: 1.3864 - val_accuracy: 0.3148 - 326ms/epoch - 81ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 1.1355 - accuracy: 0.5873 - val_loss: 1.3866 - val_accuracy: 0.2778 - 331ms/epoch - 83ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 1.1025 - accuracy: 0.6508 - val_loss: 1.3867 - val_accuracy: 0.2407 - 334ms/epoch - 84ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 1.0730 - accuracy: 0.6905 - val_loss: 1.3869 - val_accuracy: 0.2037 - 346ms/epoch - 87ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 1.0968 - accuracy: 0.6270 - val_loss: 1.3869 - val_accuracy: 0.2593 - 336ms/epoch - 84ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 1.0648 - accuracy: 0.6905 - val_loss: 1.3868 - val_accuracy: 0.2593 - 323ms/epoch - 81ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 1.0756 - accuracy: 0.6429 - val_loss: 1.3869 - val_accuracy: 0.2407 - 329ms/epoch - 82ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 1.0282 - accuracy: 0.7143 - val_loss: 1.3868 - val_accuracy: 0.2037 - 320ms/epoch - 80ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 1.0530 - accuracy: 0.6429 - val_loss: 1.3873 - val_accuracy: 0.2593 - 327ms/epoch - 82ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 1.0378 - accuracy: 0.7222 - val_loss: 1.3881 - val_accuracy: 0.2222 - 322ms/epoch - 80ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 1.0546 - accuracy: 0.6905 - val_loss: 1.3878 - val_accuracy: 0.2037 - 336ms/epoch - 84ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.9946 - accuracy: 0.7540 - val_loss: 1.3878 - val_accuracy: 0.2037 - 335ms/epoch - 84ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.9968 - accuracy: 0.7222 - val_loss: 1.3876 - val_accuracy: 0.2593 - 334ms/epoch - 84ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.9572 - accuracy: 0.7698 - val_loss: 1.3880 - val_accuracy: 0.2407 - 320ms/epoch - 80ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.9623 - accuracy: 0.7460 - val_loss: 1.3885 - val_accuracy: 0.1667 - 332ms/epoch - 83ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.9564 - accuracy: 0.7857 - val_loss: 1.3893 - val_accuracy: 0.2222 - 339ms/epoch - 85ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.9538 - accuracy: 0.7063 - val_loss: 1.3890 - val_accuracy: 0.2593 - 337ms/epoch - 84ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.8834 - accuracy: 0.7857 - val_loss: 1.3881 - val_accuracy: 0.2593 - 336ms/epoch - 84ms/step\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.9193 - accuracy: 0.8175 - val_loss: 1.3880 - val_accuracy: 0.2593 - 337ms/epoch - 84ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.9174 - accuracy: 0.7698 - val_loss: 1.3895 - val_accuracy: 0.2407 - 341ms/epoch - 85ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.9175 - accuracy: 0.7302 - val_loss: 1.3892 - val_accuracy: 0.1667 - 340ms/epoch - 85ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.9097 - accuracy: 0.8095 - val_loss: 1.3887 - val_accuracy: 0.2407 - 323ms/epoch - 81ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.9325 - accuracy: 0.8016 - val_loss: 1.3915 - val_accuracy: 0.1667 - 341ms/epoch - 85ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.8610 - accuracy: 0.7937 - val_loss: 1.3890 - val_accuracy: 0.2407 - 325ms/epoch - 81ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.9021 - accuracy: 0.7460 - val_loss: 1.3885 - val_accuracy: 0.2407 - 335ms/epoch - 84ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.8813 - accuracy: 0.8175 - val_loss: 1.3890 - val_accuracy: 0.2593 - 338ms/epoch - 84ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.8256 - accuracy: 0.8571 - val_loss: 1.3936 - val_accuracy: 0.2593 - 323ms/epoch - 81ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.8087 - accuracy: 0.8492 - val_loss: 1.3900 - val_accuracy: 0.2778 - 334ms/epoch - 83ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.8626 - accuracy: 0.7937 - val_loss: 1.3923 - val_accuracy: 0.2407 - 326ms/epoch - 81ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.8580 - accuracy: 0.8175 - val_loss: 1.3933 - val_accuracy: 0.2593 - 338ms/epoch - 84ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.8251 - accuracy: 0.8254 - val_loss: 1.3891 - val_accuracy: 0.2778 - 329ms/epoch - 82ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.8133 - accuracy: 0.8016 - val_loss: 1.3921 - val_accuracy: 0.2037 - 331ms/epoch - 83ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.8045 - accuracy: 0.8413 - val_loss: 1.3924 - val_accuracy: 0.2222 - 326ms/epoch - 81ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.8113 - accuracy: 0.8492 - val_loss: 1.3891 - val_accuracy: 0.2963 - 326ms/epoch - 81ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.8057 - accuracy: 0.8730 - val_loss: 1.3950 - val_accuracy: 0.2407 - 342ms/epoch - 86ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.7702 - accuracy: 0.8810 - val_loss: 1.3924 - val_accuracy: 0.2593 - 337ms/epoch - 84ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.7731 - accuracy: 0.8651 - val_loss: 1.3932 - val_accuracy: 0.2407 - 326ms/epoch - 81ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.7860 - accuracy: 0.8730 - val_loss: 1.3935 - val_accuracy: 0.2037 - 340ms/epoch - 85ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.7847 - accuracy: 0.8571 - val_loss: 1.3935 - val_accuracy: 0.2407 - 324ms/epoch - 81ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.7553 - accuracy: 0.8968 - val_loss: 1.3991 - val_accuracy: 0.1481 - 349ms/epoch - 87ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.7634 - accuracy: 0.9048 - val_loss: 1.3977 - val_accuracy: 0.2222 - 352ms/epoch - 88ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.7638 - accuracy: 0.8889 - val_loss: 1.3956 - val_accuracy: 0.2593 - 330ms/epoch - 82ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.7463 - accuracy: 0.8413 - val_loss: 1.4050 - val_accuracy: 0.2222 - 324ms/epoch - 81ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.7254 - accuracy: 0.8651 - val_loss: 1.4043 - val_accuracy: 0.2222 - 336ms/epoch - 84ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.7242 - accuracy: 0.9048 - val_loss: 1.3945 - val_accuracy: 0.1852 - 328ms/epoch - 82ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.7609 - accuracy: 0.8413 - val_loss: 1.4044 - val_accuracy: 0.2037 - 321ms/epoch - 80ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.7209 - accuracy: 0.8889 - val_loss: 1.4062 - val_accuracy: 0.2222 - 347ms/epoch - 87ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.6953 - accuracy: 0.9206 - val_loss: 1.4016 - val_accuracy: 0.2037 - 344ms/epoch - 86ms/step\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.7291 - accuracy: 0.8571 - val_loss: 1.4001 - val_accuracy: 0.2407 - 335ms/epoch - 84ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.6702 - accuracy: 0.9048 - val_loss: 1.4083 - val_accuracy: 0.2407 - 327ms/epoch - 82ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.6536 - accuracy: 0.9286 - val_loss: 1.4055 - val_accuracy: 0.2222 - 322ms/epoch - 81ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.6621 - accuracy: 0.9365 - val_loss: 1.4118 - val_accuracy: 0.2407 - 335ms/epoch - 84ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.6214 - accuracy: 0.9365 - val_loss: 1.4151 - val_accuracy: 0.1667 - 330ms/epoch - 82ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.6283 - accuracy: 0.9444 - val_loss: 1.4139 - val_accuracy: 0.1852 - 327ms/epoch - 82ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.6148 - accuracy: 0.9048 - val_loss: 1.4030 - val_accuracy: 0.2778 - 333ms/epoch - 83ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.6545 - accuracy: 0.9286 - val_loss: 1.4071 - val_accuracy: 0.2407 - 335ms/epoch - 84ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.6356 - accuracy: 0.9286 - val_loss: 1.4272 - val_accuracy: 0.1852 - 326ms/epoch - 81ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.6515 - accuracy: 0.9206 - val_loss: 1.4179 - val_accuracy: 0.1852 - 320ms/epoch - 80ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.6083 - accuracy: 0.9444 - val_loss: 1.4261 - val_accuracy: 0.1852 - 335ms/epoch - 84ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.6344 - accuracy: 0.9206 - val_loss: 1.4226 - val_accuracy: 0.1852 - 323ms/epoch - 81ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.6064 - accuracy: 0.9524 - val_loss: 1.4291 - val_accuracy: 0.2593 - 339ms/epoch - 85ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.5814 - accuracy: 0.9683 - val_loss: 1.4275 - val_accuracy: 0.1481 - 361ms/epoch - 90ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.5717 - accuracy: 0.9206 - val_loss: 1.4289 - val_accuracy: 0.1852 - 334ms/epoch - 84ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.5615 - accuracy: 0.9365 - val_loss: 1.4392 - val_accuracy: 0.1667 - 330ms/epoch - 83ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.5827 - accuracy: 0.9524 - val_loss: 1.4468 - val_accuracy: 0.2778 - 328ms/epoch - 82ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.5537 - accuracy: 0.9603 - val_loss: 1.4296 - val_accuracy: 0.2407 - 338ms/epoch - 84ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.5542 - accuracy: 0.9524 - val_loss: 1.4405 - val_accuracy: 0.2037 - 338ms/epoch - 85ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.5495 - accuracy: 0.9365 - val_loss: 1.4456 - val_accuracy: 0.2222 - 334ms/epoch - 83ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.5596 - accuracy: 0.9206 - val_loss: 1.4479 - val_accuracy: 0.1852 - 332ms/epoch - 83ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.5521 - accuracy: 0.9444 - val_loss: 1.4461 - val_accuracy: 0.1481 - 323ms/epoch - 81ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.5454 - accuracy: 0.9762 - val_loss: 1.4665 - val_accuracy: 0.2037 - 333ms/epoch - 83ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.5269 - accuracy: 0.9603 - val_loss: 1.4818 - val_accuracy: 0.1481 - 329ms/epoch - 82ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.5302 - accuracy: 0.9444 - val_loss: 1.4639 - val_accuracy: 0.2037 - 327ms/epoch - 82ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.5214 - accuracy: 0.9603 - val_loss: 1.4792 - val_accuracy: 0.2222 - 333ms/epoch - 83ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.5062 - accuracy: 0.9365 - val_loss: 1.4732 - val_accuracy: 0.1667 - 330ms/epoch - 83ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.5327 - accuracy: 0.9603 - val_loss: 1.4880 - val_accuracy: 0.1852 - 335ms/epoch - 84ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.5030 - accuracy: 0.9762 - val_loss: 1.5875 - val_accuracy: 0.2407 - 342ms/epoch - 85ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.4927 - accuracy: 0.9524 - val_loss: 1.5050 - val_accuracy: 0.1667 - 334ms/epoch - 84ms/step\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.4611 - accuracy: 0.9762 - val_loss: 1.5189 - val_accuracy: 0.2593 - 339ms/epoch - 85ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.5058 - accuracy: 0.9762 - val_loss: 1.5160 - val_accuracy: 0.1667 - 350ms/epoch - 87ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.5048 - accuracy: 0.9683 - val_loss: 1.4802 - val_accuracy: 0.2407 - 322ms/epoch - 81ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.4979 - accuracy: 0.9444 - val_loss: 1.5093 - val_accuracy: 0.1667 - 325ms/epoch - 81ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 1.38627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.4708 - accuracy: 0.9841 - val_loss: 1.5295 - val_accuracy: 0.1667 - 342ms/epoch - 86ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.4513 - accuracy: 0.9603 - val_loss: 1.5027 - val_accuracy: 0.2037 - 338ms/epoch - 85ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.4813 - accuracy: 0.9365 - val_loss: 1.5381 - val_accuracy: 0.1481 - 333ms/epoch - 83ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.4711 - accuracy: 0.9841 - val_loss: 1.5510 - val_accuracy: 0.1852 - 341ms/epoch - 85ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.4761 - accuracy: 0.9524 - val_loss: 1.5554 - val_accuracy: 0.1481 - 346ms/epoch - 86ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.4121 - accuracy: 0.9683 - val_loss: 1.5407 - val_accuracy: 0.1296 - 337ms/epoch - 84ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.4048 - accuracy: 0.9921 - val_loss: 1.5291 - val_accuracy: 0.1852 - 337ms/epoch - 84ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.3824 - accuracy: 1.0000 - val_loss: 1.5405 - val_accuracy: 0.2037 - 334ms/epoch - 84ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.4008 - accuracy: 0.9921 - val_loss: 1.5505 - val_accuracy: 0.1852 - 330ms/epoch - 83ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.4222 - accuracy: 0.9762 - val_loss: 1.5842 - val_accuracy: 0.2037 - 330ms/epoch - 83ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.4416 - accuracy: 0.9603 - val_loss: 1.5508 - val_accuracy: 0.1852 - 331ms/epoch - 83ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.4111 - accuracy: 0.9841 - val_loss: 1.6033 - val_accuracy: 0.1667 - 341ms/epoch - 85ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.4234 - accuracy: 0.9921 - val_loss: 1.6180 - val_accuracy: 0.1852 - 327ms/epoch - 82ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.3995 - accuracy: 1.0000 - val_loss: 1.6637 - val_accuracy: 0.1852 - 329ms/epoch - 82ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.4270 - accuracy: 1.0000 - val_loss: 1.6013 - val_accuracy: 0.1481 - 328ms/epoch - 82ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.4123 - accuracy: 0.9603 - val_loss: 1.7423 - val_accuracy: 0.1667 - 336ms/epoch - 84ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.3962 - accuracy: 0.9841 - val_loss: 1.6093 - val_accuracy: 0.1852 - 337ms/epoch - 84ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.3746 - accuracy: 0.9762 - val_loss: 1.6159 - val_accuracy: 0.1667 - 333ms/epoch - 83ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.3948 - accuracy: 0.9603 - val_loss: 1.7459 - val_accuracy: 0.1296 - 335ms/epoch - 84ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.4034 - accuracy: 0.9683 - val_loss: 1.5999 - val_accuracy: 0.1852 - 328ms/epoch - 82ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.3827 - accuracy: 0.9762 - val_loss: 1.7354 - val_accuracy: 0.1481 - 329ms/epoch - 82ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.3625 - accuracy: 0.9841 - val_loss: 1.6524 - val_accuracy: 0.2037 - 342ms/epoch - 86ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.3468 - accuracy: 0.9841 - val_loss: 1.7037 - val_accuracy: 0.1296 - 330ms/epoch - 82ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.3776 - accuracy: 0.9841 - val_loss: 1.6546 - val_accuracy: 0.1667 - 333ms/epoch - 83ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.3539 - accuracy: 1.0000 - val_loss: 1.6534 - val_accuracy: 0.2037 - 337ms/epoch - 84ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.4014 - accuracy: 0.9762 - val_loss: 1.7141 - val_accuracy: 0.1481 - 352ms/epoch - 88ms/step\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.3543 - accuracy: 0.9841 - val_loss: 1.7572 - val_accuracy: 0.2037 - 324ms/epoch - 81ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.3613 - accuracy: 0.9762 - val_loss: 1.7115 - val_accuracy: 0.1667 - 329ms/epoch - 82ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.3426 - accuracy: 0.9762 - val_loss: 1.7938 - val_accuracy: 0.1481 - 326ms/epoch - 81ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.3699 - accuracy: 0.9762 - val_loss: 1.7071 - val_accuracy: 0.1296 - 331ms/epoch - 83ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.3235 - accuracy: 0.9921 - val_loss: 1.7577 - val_accuracy: 0.1296 - 330ms/epoch - 83ms/step\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.3199 - accuracy: 1.0000 - val_loss: 1.6806 - val_accuracy: 0.1481 - 331ms/epoch - 83ms/step\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.3220 - accuracy: 0.9921 - val_loss: 1.9276 - val_accuracy: 0.1852 - 338ms/epoch - 84ms/step\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.3321 - accuracy: 0.9841 - val_loss: 1.7015 - val_accuracy: 0.1852 - 326ms/epoch - 82ms/step\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.3116 - accuracy: 1.0000 - val_loss: 1.7701 - val_accuracy: 0.2037 - 331ms/epoch - 83ms/step\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.3141 - accuracy: 1.0000 - val_loss: 1.7754 - val_accuracy: 0.1852 - 322ms/epoch - 81ms/step\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2968 - accuracy: 0.9921 - val_loss: 1.7070 - val_accuracy: 0.2222 - 334ms/epoch - 84ms/step\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.3262 - accuracy: 1.0000 - val_loss: 1.8528 - val_accuracy: 0.1852 - 341ms/epoch - 85ms/step\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.3069 - accuracy: 0.9921 - val_loss: 1.8399 - val_accuracy: 0.1852 - 329ms/epoch - 82ms/step\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.3349 - accuracy: 0.9841 - val_loss: 1.7309 - val_accuracy: 0.1852 - 329ms/epoch - 82ms/step\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 135: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.3286 - accuracy: 0.9841 - val_loss: 1.9247 - val_accuracy: 0.1852 - 324ms/epoch - 81ms/step\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 136: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2947 - accuracy: 0.9841 - val_loss: 1.7701 - val_accuracy: 0.2037 - 335ms/epoch - 84ms/step\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 137: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.3148 - accuracy: 0.9921 - val_loss: 1.8588 - val_accuracy: 0.1481 - 359ms/epoch - 90ms/step\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 138: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.3034 - accuracy: 1.0000 - val_loss: 1.7956 - val_accuracy: 0.1296 - 335ms/epoch - 84ms/step\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 139: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2931 - accuracy: 1.0000 - val_loss: 1.8542 - val_accuracy: 0.1296 - 336ms/epoch - 84ms/step\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 140: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2807 - accuracy: 1.0000 - val_loss: 1.8241 - val_accuracy: 0.1667 - 344ms/epoch - 86ms/step\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 141: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2716 - accuracy: 1.0000 - val_loss: 1.8547 - val_accuracy: 0.1481 - 323ms/epoch - 81ms/step\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 142: val_loss did not improve from 1.38627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.3151 - accuracy: 0.9841 - val_loss: 1.9237 - val_accuracy: 0.1296 - 334ms/epoch - 83ms/step\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 143: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.3021 - accuracy: 0.9921 - val_loss: 1.8032 - val_accuracy: 0.2222 - 342ms/epoch - 85ms/step\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 144: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2999 - accuracy: 0.9921 - val_loss: 1.8905 - val_accuracy: 0.1111 - 329ms/epoch - 82ms/step\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 145: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2793 - accuracy: 0.9921 - val_loss: 1.8415 - val_accuracy: 0.1667 - 332ms/epoch - 83ms/step\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 146: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2710 - accuracy: 0.9921 - val_loss: 1.8680 - val_accuracy: 0.1481 - 339ms/epoch - 85ms/step\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 147: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2781 - accuracy: 0.9921 - val_loss: 1.8790 - val_accuracy: 0.1481 - 324ms/epoch - 81ms/step\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 148: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2919 - accuracy: 0.9921 - val_loss: 1.8989 - val_accuracy: 0.1111 - 344ms/epoch - 86ms/step\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 149: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2592 - accuracy: 1.0000 - val_loss: 1.8521 - val_accuracy: 0.1481 - 336ms/epoch - 84ms/step\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 150: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2695 - accuracy: 1.0000 - val_loss: 1.7913 - val_accuracy: 0.1296 - 328ms/epoch - 82ms/step\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 151: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2789 - accuracy: 0.9921 - val_loss: 1.8185 - val_accuracy: 0.1481 - 324ms/epoch - 81ms/step\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 152: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2600 - accuracy: 1.0000 - val_loss: 1.8539 - val_accuracy: 0.1481 - 327ms/epoch - 82ms/step\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 153: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2768 - accuracy: 0.9921 - val_loss: 1.9889 - val_accuracy: 0.1111 - 331ms/epoch - 83ms/step\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 154: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2758 - accuracy: 0.9921 - val_loss: 1.9135 - val_accuracy: 0.2222 - 336ms/epoch - 84ms/step\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 155: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2801 - accuracy: 0.9921 - val_loss: 2.0763 - val_accuracy: 0.1481 - 331ms/epoch - 83ms/step\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 156: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2457 - accuracy: 0.9921 - val_loss: 1.9446 - val_accuracy: 0.1852 - 338ms/epoch - 85ms/step\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 157: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2636 - accuracy: 1.0000 - val_loss: 2.0002 - val_accuracy: 0.2037 - 330ms/epoch - 83ms/step\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 158: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2646 - accuracy: 0.9921 - val_loss: 1.8316 - val_accuracy: 0.2037 - 324ms/epoch - 81ms/step\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 159: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2900 - accuracy: 0.9921 - val_loss: 1.9847 - val_accuracy: 0.1481 - 335ms/epoch - 84ms/step\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 160: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2828 - accuracy: 1.0000 - val_loss: 1.9951 - val_accuracy: 0.1852 - 325ms/epoch - 81ms/step\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 161: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2604 - accuracy: 1.0000 - val_loss: 2.1607 - val_accuracy: 0.2222 - 329ms/epoch - 82ms/step\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 162: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2835 - accuracy: 0.9762 - val_loss: 2.1030 - val_accuracy: 0.2222 - 326ms/epoch - 81ms/step\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 163: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2363 - accuracy: 0.9921 - val_loss: 2.2658 - val_accuracy: 0.1852 - 324ms/epoch - 81ms/step\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 164: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2542 - accuracy: 0.9921 - val_loss: 1.9049 - val_accuracy: 0.2222 - 325ms/epoch - 81ms/step\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 165: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2598 - accuracy: 1.0000 - val_loss: 1.9227 - val_accuracy: 0.2037 - 326ms/epoch - 82ms/step\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 166: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2740 - accuracy: 0.9841 - val_loss: 1.8986 - val_accuracy: 0.1852 - 325ms/epoch - 81ms/step\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 167: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2410 - accuracy: 0.9921 - val_loss: 2.0448 - val_accuracy: 0.2037 - 351ms/epoch - 88ms/step\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 168: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 2.0166 - val_accuracy: 0.2037 - 327ms/epoch - 82ms/step\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 169: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2303 - accuracy: 0.9921 - val_loss: 1.9586 - val_accuracy: 0.1667 - 348ms/epoch - 87ms/step\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 170: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2630 - accuracy: 0.9762 - val_loss: 1.8831 - val_accuracy: 0.2222 - 321ms/epoch - 80ms/step\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 171: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2298 - accuracy: 0.9921 - val_loss: 1.8885 - val_accuracy: 0.2037 - 325ms/epoch - 81ms/step\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 172: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2408 - accuracy: 1.0000 - val_loss: 1.9122 - val_accuracy: 0.2037 - 325ms/epoch - 81ms/step\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 173: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2285 - accuracy: 1.0000 - val_loss: 1.9760 - val_accuracy: 0.1481 - 340ms/epoch - 85ms/step\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 174: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2233 - accuracy: 1.0000 - val_loss: 1.9919 - val_accuracy: 0.1667 - 330ms/epoch - 82ms/step\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 175: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2303 - accuracy: 1.0000 - val_loss: 1.9100 - val_accuracy: 0.2037 - 336ms/epoch - 84ms/step\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 176: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2289 - accuracy: 1.0000 - val_loss: 1.9580 - val_accuracy: 0.1852 - 322ms/epoch - 80ms/step\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 177: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2047 - accuracy: 0.9921 - val_loss: 2.0061 - val_accuracy: 0.2037 - 330ms/epoch - 83ms/step\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 178: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2465 - accuracy: 1.0000 - val_loss: 1.9361 - val_accuracy: 0.2037 - 325ms/epoch - 81ms/step\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 179: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2404 - accuracy: 0.9841 - val_loss: 1.9876 - val_accuracy: 0.1296 - 328ms/epoch - 82ms/step\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 180: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2308 - accuracy: 0.9921 - val_loss: 1.9376 - val_accuracy: 0.1481 - 331ms/epoch - 83ms/step\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 181: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2016 - accuracy: 1.0000 - val_loss: 2.0370 - val_accuracy: 0.1667 - 329ms/epoch - 82ms/step\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 182: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2257 - accuracy: 1.0000 - val_loss: 1.8992 - val_accuracy: 0.2222 - 334ms/epoch - 83ms/step\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 183: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1933 - accuracy: 1.0000 - val_loss: 1.9361 - val_accuracy: 0.2407 - 340ms/epoch - 85ms/step\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 184: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2056 - accuracy: 1.0000 - val_loss: 1.9926 - val_accuracy: 0.1296 - 328ms/epoch - 82ms/step\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 185: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2247 - accuracy: 1.0000 - val_loss: 1.9412 - val_accuracy: 0.1667 - 337ms/epoch - 84ms/step\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 186: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1863 - accuracy: 1.0000 - val_loss: 1.9563 - val_accuracy: 0.1852 - 341ms/epoch - 85ms/step\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 187: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2124 - accuracy: 0.9921 - val_loss: 2.0307 - val_accuracy: 0.1852 - 336ms/epoch - 84ms/step\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 188: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 2.0236 - val_accuracy: 0.1481 - 330ms/epoch - 83ms/step\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 189: val_loss did not improve from 1.38627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.2071 - accuracy: 0.9921 - val_loss: 1.9942 - val_accuracy: 0.1852 - 331ms/epoch - 83ms/step\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 190: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1689 - accuracy: 1.0000 - val_loss: 2.0122 - val_accuracy: 0.2037 - 337ms/epoch - 84ms/step\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 191: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2026 - accuracy: 1.0000 - val_loss: 2.0300 - val_accuracy: 0.1481 - 360ms/epoch - 90ms/step\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 192: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1723 - accuracy: 1.0000 - val_loss: 2.0083 - val_accuracy: 0.1481 - 326ms/epoch - 82ms/step\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 193: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1749 - accuracy: 1.0000 - val_loss: 1.9895 - val_accuracy: 0.1481 - 341ms/epoch - 85ms/step\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 194: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1756 - accuracy: 0.9921 - val_loss: 1.9391 - val_accuracy: 0.2037 - 325ms/epoch - 81ms/step\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 195: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1710 - accuracy: 1.0000 - val_loss: 2.0774 - val_accuracy: 0.1111 - 338ms/epoch - 84ms/step\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 196: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1751 - accuracy: 1.0000 - val_loss: 2.0408 - val_accuracy: 0.1296 - 336ms/epoch - 84ms/step\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 197: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1953 - accuracy: 1.0000 - val_loss: 1.9981 - val_accuracy: 0.1481 - 344ms/epoch - 86ms/step\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 198: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2080 - accuracy: 0.9921 - val_loss: 2.0040 - val_accuracy: 0.1481 - 322ms/epoch - 80ms/step\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 199: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1699 - accuracy: 1.0000 - val_loss: 1.9953 - val_accuracy: 0.1667 - 335ms/epoch - 84ms/step\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 200: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1617 - accuracy: 1.0000 - val_loss: 2.0148 - val_accuracy: 0.1667 - 321ms/epoch - 80ms/step\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 201: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.2026 - accuracy: 0.9762 - val_loss: 2.0204 - val_accuracy: 0.2037 - 344ms/epoch - 86ms/step\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 202: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1879 - accuracy: 1.0000 - val_loss: 2.1065 - val_accuracy: 0.1296 - 321ms/epoch - 80ms/step\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 203: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1913 - accuracy: 0.9921 - val_loss: 2.1210 - val_accuracy: 0.2037 - 340ms/epoch - 85ms/step\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 204: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1904 - accuracy: 1.0000 - val_loss: 2.1173 - val_accuracy: 0.1481 - 329ms/epoch - 82ms/step\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 205: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1535 - accuracy: 1.0000 - val_loss: 2.0527 - val_accuracy: 0.1852 - 343ms/epoch - 86ms/step\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 206: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1805 - accuracy: 1.0000 - val_loss: 2.0745 - val_accuracy: 0.1481 - 332ms/epoch - 83ms/step\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 207: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1735 - accuracy: 1.0000 - val_loss: 1.9816 - val_accuracy: 0.1667 - 335ms/epoch - 84ms/step\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 208: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1776 - accuracy: 1.0000 - val_loss: 2.0810 - val_accuracy: 0.1296 - 341ms/epoch - 85ms/step\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 209: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1960 - accuracy: 0.9921 - val_loss: 2.0085 - val_accuracy: 0.1481 - 336ms/epoch - 84ms/step\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 210: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1954 - accuracy: 1.0000 - val_loss: 1.9489 - val_accuracy: 0.1852 - 337ms/epoch - 84ms/step\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 211: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1592 - accuracy: 1.0000 - val_loss: 2.1408 - val_accuracy: 0.1667 - 336ms/epoch - 84ms/step\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 212: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1836 - accuracy: 1.0000 - val_loss: 2.0376 - val_accuracy: 0.1852 - 341ms/epoch - 85ms/step\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 213: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1641 - accuracy: 1.0000 - val_loss: 2.0400 - val_accuracy: 0.1667 - 330ms/epoch - 82ms/step\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 214: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1565 - accuracy: 1.0000 - val_loss: 2.1199 - val_accuracy: 0.1296 - 345ms/epoch - 86ms/step\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 215: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1666 - accuracy: 1.0000 - val_loss: 2.0169 - val_accuracy: 0.2037 - 335ms/epoch - 84ms/step\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 216: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1692 - accuracy: 1.0000 - val_loss: 2.0345 - val_accuracy: 0.2037 - 336ms/epoch - 84ms/step\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 217: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1679 - accuracy: 1.0000 - val_loss: 2.1269 - val_accuracy: 0.2222 - 335ms/epoch - 84ms/step\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 218: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1655 - accuracy: 1.0000 - val_loss: 2.0083 - val_accuracy: 0.1852 - 321ms/epoch - 80ms/step\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 219: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1846 - accuracy: 1.0000 - val_loss: 2.6585 - val_accuracy: 0.2037 - 329ms/epoch - 82ms/step\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 220: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1588 - accuracy: 1.0000 - val_loss: 2.4664 - val_accuracy: 0.2037 - 331ms/epoch - 83ms/step\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 221: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1644 - accuracy: 0.9921 - val_loss: 2.3147 - val_accuracy: 0.2037 - 338ms/epoch - 85ms/step\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 222: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1529 - accuracy: 1.0000 - val_loss: 2.0448 - val_accuracy: 0.2407 - 325ms/epoch - 81ms/step\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 223: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1609 - accuracy: 1.0000 - val_loss: 2.0937 - val_accuracy: 0.1481 - 334ms/epoch - 83ms/step\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 224: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1291 - accuracy: 1.0000 - val_loss: 1.9900 - val_accuracy: 0.1667 - 325ms/epoch - 81ms/step\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 225: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1594 - accuracy: 1.0000 - val_loss: 2.0099 - val_accuracy: 0.2037 - 336ms/epoch - 84ms/step\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 226: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1628 - accuracy: 1.0000 - val_loss: 2.1052 - val_accuracy: 0.1852 - 332ms/epoch - 83ms/step\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 227: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1492 - accuracy: 1.0000 - val_loss: 2.1416 - val_accuracy: 0.1852 - 342ms/epoch - 86ms/step\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 228: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1543 - accuracy: 0.9921 - val_loss: 2.0822 - val_accuracy: 0.2037 - 333ms/epoch - 83ms/step\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 229: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1666 - accuracy: 1.0000 - val_loss: 2.0704 - val_accuracy: 0.2037 - 325ms/epoch - 81ms/step\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 230: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1559 - accuracy: 1.0000 - val_loss: 2.0357 - val_accuracy: 0.1852 - 328ms/epoch - 82ms/step\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 231: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1416 - accuracy: 1.0000 - val_loss: 2.0014 - val_accuracy: 0.2037 - 339ms/epoch - 85ms/step\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 232: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1547 - accuracy: 1.0000 - val_loss: 2.1205 - val_accuracy: 0.1667 - 337ms/epoch - 84ms/step\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 233: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1299 - accuracy: 1.0000 - val_loss: 2.2476 - val_accuracy: 0.1296 - 344ms/epoch - 86ms/step\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 234: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1491 - accuracy: 1.0000 - val_loss: 2.0208 - val_accuracy: 0.2037 - 341ms/epoch - 85ms/step\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 235: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1532 - accuracy: 0.9921 - val_loss: 1.9975 - val_accuracy: 0.1852 - 341ms/epoch - 85ms/step\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 236: val_loss did not improve from 1.38627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.1503 - accuracy: 1.0000 - val_loss: 2.0662 - val_accuracy: 0.2037 - 325ms/epoch - 81ms/step\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 237: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1627 - accuracy: 1.0000 - val_loss: 2.0815 - val_accuracy: 0.2037 - 331ms/epoch - 83ms/step\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 238: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1152 - accuracy: 1.0000 - val_loss: 2.0897 - val_accuracy: 0.1667 - 331ms/epoch - 83ms/step\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 239: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1319 - accuracy: 1.0000 - val_loss: 2.0925 - val_accuracy: 0.2222 - 337ms/epoch - 84ms/step\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 240: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1326 - accuracy: 1.0000 - val_loss: 2.0588 - val_accuracy: 0.1667 - 346ms/epoch - 86ms/step\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 241: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1348 - accuracy: 0.9921 - val_loss: 2.1112 - val_accuracy: 0.2037 - 332ms/epoch - 83ms/step\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 242: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1513 - accuracy: 1.0000 - val_loss: 2.0091 - val_accuracy: 0.2222 - 328ms/epoch - 82ms/step\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 243: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1430 - accuracy: 1.0000 - val_loss: 2.0212 - val_accuracy: 0.1667 - 339ms/epoch - 85ms/step\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 244: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1312 - accuracy: 1.0000 - val_loss: 2.0013 - val_accuracy: 0.1852 - 334ms/epoch - 83ms/step\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 245: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1383 - accuracy: 0.9921 - val_loss: 2.0932 - val_accuracy: 0.1481 - 348ms/epoch - 87ms/step\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 246: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1412 - accuracy: 0.9921 - val_loss: 2.0694 - val_accuracy: 0.1667 - 338ms/epoch - 84ms/step\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 247: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1256 - accuracy: 1.0000 - val_loss: 2.1408 - val_accuracy: 0.2037 - 326ms/epoch - 81ms/step\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 248: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1310 - accuracy: 1.0000 - val_loss: 2.1013 - val_accuracy: 0.2037 - 336ms/epoch - 84ms/step\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 249: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1391 - accuracy: 1.0000 - val_loss: 2.1520 - val_accuracy: 0.1852 - 336ms/epoch - 84ms/step\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 250: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1278 - accuracy: 1.0000 - val_loss: 2.0322 - val_accuracy: 0.1852 - 324ms/epoch - 81ms/step\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 251: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1439 - accuracy: 1.0000 - val_loss: 2.1764 - val_accuracy: 0.1111 - 338ms/epoch - 84ms/step\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 252: val_loss did not improve from 1.38627\n",
      "4/4 - 1s - loss: 0.1454 - accuracy: 0.9921 - val_loss: 2.0142 - val_accuracy: 0.2222 - 651ms/epoch - 163ms/step\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 253: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1461 - accuracy: 1.0000 - val_loss: 2.1298 - val_accuracy: 0.2037 - 334ms/epoch - 84ms/step\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 254: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1425 - accuracy: 1.0000 - val_loss: 2.2019 - val_accuracy: 0.1481 - 342ms/epoch - 85ms/step\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 255: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1830 - accuracy: 0.9921 - val_loss: 2.1412 - val_accuracy: 0.2037 - 335ms/epoch - 84ms/step\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 256: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1785 - accuracy: 0.9921 - val_loss: 1.9695 - val_accuracy: 0.2037 - 342ms/epoch - 86ms/step\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 257: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1454 - accuracy: 1.0000 - val_loss: 2.1073 - val_accuracy: 0.1852 - 336ms/epoch - 84ms/step\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 258: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1138 - accuracy: 1.0000 - val_loss: 2.2029 - val_accuracy: 0.2222 - 335ms/epoch - 84ms/step\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 259: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1343 - accuracy: 1.0000 - val_loss: 2.1369 - val_accuracy: 0.1852 - 333ms/epoch - 83ms/step\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 260: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1211 - accuracy: 0.9921 - val_loss: 2.0483 - val_accuracy: 0.2037 - 346ms/epoch - 86ms/step\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 261: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1371 - accuracy: 1.0000 - val_loss: 2.1964 - val_accuracy: 0.1852 - 335ms/epoch - 84ms/step\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 262: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1452 - accuracy: 1.0000 - val_loss: 2.1118 - val_accuracy: 0.2037 - 336ms/epoch - 84ms/step\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 263: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1286 - accuracy: 0.9921 - val_loss: 2.1855 - val_accuracy: 0.1111 - 352ms/epoch - 88ms/step\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 264: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1293 - accuracy: 1.0000 - val_loss: 2.1786 - val_accuracy: 0.1296 - 349ms/epoch - 87ms/step\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 265: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1383 - accuracy: 0.9841 - val_loss: 2.1829 - val_accuracy: 0.1667 - 351ms/epoch - 88ms/step\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 266: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1476 - accuracy: 1.0000 - val_loss: 2.0807 - val_accuracy: 0.1852 - 344ms/epoch - 86ms/step\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 267: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1467 - accuracy: 1.0000 - val_loss: 2.1399 - val_accuracy: 0.1667 - 341ms/epoch - 85ms/step\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 268: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1361 - accuracy: 0.9921 - val_loss: 2.1819 - val_accuracy: 0.1111 - 337ms/epoch - 84ms/step\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 269: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1173 - accuracy: 1.0000 - val_loss: 2.0777 - val_accuracy: 0.2037 - 347ms/epoch - 87ms/step\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 270: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1333 - accuracy: 1.0000 - val_loss: 2.3191 - val_accuracy: 0.2037 - 345ms/epoch - 86ms/step\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 271: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1252 - accuracy: 1.0000 - val_loss: 2.1836 - val_accuracy: 0.2222 - 332ms/epoch - 83ms/step\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 272: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1227 - accuracy: 1.0000 - val_loss: 2.1428 - val_accuracy: 0.1667 - 343ms/epoch - 86ms/step\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 273: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1140 - accuracy: 0.9921 - val_loss: 2.1111 - val_accuracy: 0.1481 - 332ms/epoch - 83ms/step\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 274: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1274 - accuracy: 1.0000 - val_loss: 2.0134 - val_accuracy: 0.2222 - 350ms/epoch - 87ms/step\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 275: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1103 - accuracy: 1.0000 - val_loss: 2.4581 - val_accuracy: 0.2222 - 324ms/epoch - 81ms/step\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 276: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1184 - accuracy: 1.0000 - val_loss: 2.4178 - val_accuracy: 0.2407 - 335ms/epoch - 84ms/step\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 277: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1205 - accuracy: 1.0000 - val_loss: 2.3216 - val_accuracy: 0.2407 - 345ms/epoch - 86ms/step\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 278: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1232 - accuracy: 1.0000 - val_loss: 2.2324 - val_accuracy: 0.1481 - 351ms/epoch - 88ms/step\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 279: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1051 - accuracy: 1.0000 - val_loss: 2.1968 - val_accuracy: 0.2222 - 331ms/epoch - 83ms/step\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 280: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1203 - accuracy: 1.0000 - val_loss: 2.1358 - val_accuracy: 0.1481 - 333ms/epoch - 83ms/step\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 281: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1037 - accuracy: 1.0000 - val_loss: 2.1233 - val_accuracy: 0.1667 - 349ms/epoch - 87ms/step\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 282: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1305 - accuracy: 1.0000 - val_loss: 2.1445 - val_accuracy: 0.2222 - 333ms/epoch - 83ms/step\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 283: val_loss did not improve from 1.38627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.1078 - accuracy: 1.0000 - val_loss: 2.0855 - val_accuracy: 0.1667 - 356ms/epoch - 89ms/step\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 284: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.0976 - accuracy: 1.0000 - val_loss: 2.0974 - val_accuracy: 0.1852 - 342ms/epoch - 86ms/step\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 285: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1187 - accuracy: 1.0000 - val_loss: 2.1272 - val_accuracy: 0.1296 - 330ms/epoch - 83ms/step\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 286: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1294 - accuracy: 1.0000 - val_loss: 2.0783 - val_accuracy: 0.1667 - 342ms/epoch - 86ms/step\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 287: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1068 - accuracy: 1.0000 - val_loss: 2.2109 - val_accuracy: 0.2037 - 343ms/epoch - 86ms/step\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 288: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1069 - accuracy: 1.0000 - val_loss: 2.0559 - val_accuracy: 0.1852 - 337ms/epoch - 84ms/step\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 289: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1057 - accuracy: 1.0000 - val_loss: 2.0885 - val_accuracy: 0.1852 - 332ms/epoch - 83ms/step\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 290: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1173 - accuracy: 1.0000 - val_loss: 2.1700 - val_accuracy: 0.1667 - 337ms/epoch - 84ms/step\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 291: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1211 - accuracy: 1.0000 - val_loss: 2.1237 - val_accuracy: 0.1481 - 331ms/epoch - 83ms/step\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 292: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1254 - accuracy: 1.0000 - val_loss: 2.1018 - val_accuracy: 0.1296 - 341ms/epoch - 85ms/step\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 293: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1116 - accuracy: 1.0000 - val_loss: 2.1407 - val_accuracy: 0.1296 - 334ms/epoch - 84ms/step\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 294: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1014 - accuracy: 1.0000 - val_loss: 2.0644 - val_accuracy: 0.2222 - 350ms/epoch - 88ms/step\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 295: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.0957 - accuracy: 1.0000 - val_loss: 2.0959 - val_accuracy: 0.1852 - 332ms/epoch - 83ms/step\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 296: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1214 - accuracy: 0.9841 - val_loss: 2.1479 - val_accuracy: 0.1852 - 330ms/epoch - 82ms/step\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 297: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1044 - accuracy: 1.0000 - val_loss: 2.1445 - val_accuracy: 0.1852 - 332ms/epoch - 83ms/step\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 298: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.0922 - accuracy: 1.0000 - val_loss: 2.0655 - val_accuracy: 0.1667 - 329ms/epoch - 82ms/step\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 299: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.0925 - accuracy: 1.0000 - val_loss: 2.1049 - val_accuracy: 0.1852 - 346ms/epoch - 86ms/step\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 300: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 0.1201 - accuracy: 1.0000 - val_loss: 2.1914 - val_accuracy: 0.1852 - 327ms/epoch - 82ms/step\n",
      "2/2 [==============================] - 0s 22ms/step\n",
      "Lists\n",
      "[0.18333333333333332, 0.1, 0.2, 0.25]\n",
      "[0.04583333333333333, 0.025, 0.09428571428571428, 0.14583333333333331]\n",
      "[0.25, 0.25, 0.22499999999999998, 0.24158653846153846]\n",
      "[0.07746478873239436, 0.045454545454545456, 0.13285714285714284, 0.14821981424148606]\n",
      "dicts\n",
      "{1: 0.28, 2: 0.2, 3: 0.22777777777777777, 4: 0.18333333333333335, 5: 0, 6: 0, 7: 0, 8: 0}\n",
      "{1: 0.179879077643203, 2: 0.06654896421845574, 3: 0.07670940170940171, 4: 0.07773809523809523, 5: 0, 6: 0, 7: 0, 8: 0}\n",
      "{1: 0.285120781995782, 2: 0.2456597222222222, 3: 0.2569444444444444, 4: 0.2416466346153846, 5: 0, 6: 0, 7: 0, 8: 0}\n",
      "{1: 0.19991143316006618, 2: 0.09862908327582241, 3: 0.1074404761904762, 4: 0.10099907282139219, 5: 0, 6: 0, 7: 0, 8: 0}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Number of devices: 2\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 09:34:56.793500: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_9321872\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:612580\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
      "2022-11-11 09:35:00.769317: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_9324942\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:612622\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38638, saving model to checkpoint1.h5\n",
      "4/4 - 5s - loss: 1.4447 - accuracy: 0.3095 - val_loss: 1.3864 - val_accuracy: 0.2037 - 5s/epoch - 1s/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 1.3358 - accuracy: 0.3492 - val_loss: 1.3865 - val_accuracy: 0.2037 - 339ms/epoch - 85ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 1.3089 - accuracy: 0.3889 - val_loss: 1.3865 - val_accuracy: 0.1481 - 329ms/epoch - 82ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 1.2623 - accuracy: 0.4841 - val_loss: 1.3866 - val_accuracy: 0.1481 - 324ms/epoch - 81ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 1.2222 - accuracy: 0.5159 - val_loss: 1.3866 - val_accuracy: 0.2037 - 330ms/epoch - 83ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 1.1909 - accuracy: 0.6032 - val_loss: 1.3870 - val_accuracy: 0.2037 - 333ms/epoch - 83ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 1.1764 - accuracy: 0.5952 - val_loss: 1.3871 - val_accuracy: 0.2037 - 323ms/epoch - 81ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 1.1428 - accuracy: 0.6270 - val_loss: 1.3873 - val_accuracy: 0.2037 - 332ms/epoch - 83ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 1.1490 - accuracy: 0.5317 - val_loss: 1.3875 - val_accuracy: 0.2037 - 335ms/epoch - 84ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 1.1184 - accuracy: 0.6190 - val_loss: 1.3875 - val_accuracy: 0.2037 - 326ms/epoch - 81ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 1.0861 - accuracy: 0.6190 - val_loss: 1.3874 - val_accuracy: 0.2037 - 336ms/epoch - 84ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 1.0844 - accuracy: 0.6270 - val_loss: 1.3875 - val_accuracy: 0.2037 - 328ms/epoch - 82ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 1.0701 - accuracy: 0.6270 - val_loss: 1.3876 - val_accuracy: 0.2037 - 336ms/epoch - 84ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 1.0507 - accuracy: 0.7460 - val_loss: 1.3874 - val_accuracy: 0.2037 - 322ms/epoch - 81ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 1.0314 - accuracy: 0.6825 - val_loss: 1.3878 - val_accuracy: 0.2037 - 319ms/epoch - 80ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 1.0076 - accuracy: 0.6746 - val_loss: 1.3877 - val_accuracy: 0.2037 - 348ms/epoch - 87ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 1.0263 - accuracy: 0.6587 - val_loss: 1.3875 - val_accuracy: 0.2037 - 327ms/epoch - 82ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.9833 - accuracy: 0.7619 - val_loss: 1.3884 - val_accuracy: 0.2037 - 325ms/epoch - 81ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 1.0004 - accuracy: 0.6984 - val_loss: 1.3880 - val_accuracy: 0.2037 - 328ms/epoch - 82ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.9604 - accuracy: 0.7222 - val_loss: 1.3866 - val_accuracy: 0.2778 - 335ms/epoch - 84ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.9404 - accuracy: 0.7619 - val_loss: 1.3866 - val_accuracy: 0.2593 - 328ms/epoch - 82ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.9245 - accuracy: 0.8016 - val_loss: 1.3879 - val_accuracy: 0.1852 - 327ms/epoch - 82ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.9010 - accuracy: 0.8095 - val_loss: 1.3891 - val_accuracy: 0.2037 - 340ms/epoch - 85ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.9232 - accuracy: 0.7937 - val_loss: 1.3895 - val_accuracy: 0.2037 - 322ms/epoch - 80ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.9075 - accuracy: 0.7937 - val_loss: 1.3881 - val_accuracy: 0.2037 - 327ms/epoch - 82ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.8647 - accuracy: 0.7937 - val_loss: 1.3877 - val_accuracy: 0.2407 - 333ms/epoch - 83ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.8935 - accuracy: 0.8175 - val_loss: 1.3872 - val_accuracy: 0.2778 - 326ms/epoch - 81ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.8652 - accuracy: 0.7937 - val_loss: 1.3880 - val_accuracy: 0.2963 - 339ms/epoch - 85ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.8148 - accuracy: 0.8254 - val_loss: 1.3888 - val_accuracy: 0.2593 - 325ms/epoch - 81ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.8254 - accuracy: 0.8413 - val_loss: 1.3895 - val_accuracy: 0.2778 - 331ms/epoch - 83ms/step\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.8379 - accuracy: 0.8413 - val_loss: 1.3883 - val_accuracy: 0.2593 - 326ms/epoch - 82ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.8217 - accuracy: 0.7937 - val_loss: 1.3914 - val_accuracy: 0.2963 - 323ms/epoch - 81ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.8045 - accuracy: 0.8810 - val_loss: 1.3923 - val_accuracy: 0.2778 - 321ms/epoch - 80ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.7915 - accuracy: 0.8651 - val_loss: 1.3922 - val_accuracy: 0.3148 - 335ms/epoch - 84ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.8043 - accuracy: 0.8175 - val_loss: 1.3881 - val_accuracy: 0.2963 - 328ms/epoch - 82ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.7621 - accuracy: 0.8730 - val_loss: 1.3934 - val_accuracy: 0.2593 - 339ms/epoch - 85ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.7647 - accuracy: 0.8651 - val_loss: 1.3942 - val_accuracy: 0.2778 - 325ms/epoch - 81ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.7416 - accuracy: 0.8968 - val_loss: 1.3928 - val_accuracy: 0.2778 - 336ms/epoch - 84ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.7266 - accuracy: 0.9286 - val_loss: 1.3932 - val_accuracy: 0.2963 - 330ms/epoch - 83ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.6797 - accuracy: 0.9365 - val_loss: 1.3992 - val_accuracy: 0.3148 - 328ms/epoch - 82ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.7180 - accuracy: 0.8730 - val_loss: 1.3920 - val_accuracy: 0.3519 - 326ms/epoch - 82ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.6926 - accuracy: 0.9286 - val_loss: 1.4056 - val_accuracy: 0.2407 - 342ms/epoch - 86ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.7021 - accuracy: 0.8968 - val_loss: 1.4020 - val_accuracy: 0.2778 - 328ms/epoch - 82ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.6741 - accuracy: 0.9365 - val_loss: 1.3975 - val_accuracy: 0.3333 - 335ms/epoch - 84ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.6745 - accuracy: 0.9048 - val_loss: 1.4063 - val_accuracy: 0.2963 - 344ms/epoch - 86ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.6404 - accuracy: 0.8968 - val_loss: 1.3964 - val_accuracy: 0.3148 - 336ms/epoch - 84ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.6480 - accuracy: 0.9206 - val_loss: 1.3976 - val_accuracy: 0.3148 - 335ms/epoch - 84ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.6180 - accuracy: 0.9603 - val_loss: 1.4154 - val_accuracy: 0.2222 - 331ms/epoch - 83ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.6193 - accuracy: 0.9444 - val_loss: 1.4008 - val_accuracy: 0.3148 - 334ms/epoch - 83ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.5776 - accuracy: 0.9603 - val_loss: 1.4019 - val_accuracy: 0.2778 - 328ms/epoch - 82ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.6173 - accuracy: 0.8889 - val_loss: 1.4162 - val_accuracy: 0.2778 - 336ms/epoch - 84ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.5946 - accuracy: 0.9603 - val_loss: 1.4064 - val_accuracy: 0.2778 - 351ms/epoch - 88ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.5879 - accuracy: 0.9683 - val_loss: 1.4162 - val_accuracy: 0.2963 - 331ms/epoch - 83ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.5701 - accuracy: 0.9603 - val_loss: 1.4156 - val_accuracy: 0.2593 - 329ms/epoch - 82ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.5702 - accuracy: 0.9603 - val_loss: 1.4248 - val_accuracy: 0.2593 - 327ms/epoch - 82ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.5577 - accuracy: 0.9683 - val_loss: 1.4211 - val_accuracy: 0.2778 - 353ms/epoch - 88ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.5109 - accuracy: 0.9683 - val_loss: 1.4366 - val_accuracy: 0.2593 - 328ms/epoch - 82ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.5319 - accuracy: 0.9683 - val_loss: 1.4398 - val_accuracy: 0.2593 - 346ms/epoch - 86ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.5062 - accuracy: 0.9762 - val_loss: 1.4178 - val_accuracy: 0.2222 - 353ms/epoch - 88ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.4843 - accuracy: 0.9762 - val_loss: 1.4435 - val_accuracy: 0.2593 - 345ms/epoch - 86ms/step\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.5071 - accuracy: 0.9524 - val_loss: 1.4437 - val_accuracy: 0.2407 - 324ms/epoch - 81ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.4987 - accuracy: 0.9762 - val_loss: 1.4408 - val_accuracy: 0.2407 - 332ms/epoch - 83ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.4757 - accuracy: 0.9683 - val_loss: 1.4698 - val_accuracy: 0.2963 - 322ms/epoch - 80ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.4851 - accuracy: 0.9762 - val_loss: 1.4393 - val_accuracy: 0.2963 - 331ms/epoch - 83ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.4799 - accuracy: 0.9683 - val_loss: 1.4329 - val_accuracy: 0.2778 - 327ms/epoch - 82ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.4914 - accuracy: 0.9603 - val_loss: 1.4365 - val_accuracy: 0.2778 - 321ms/epoch - 80ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.4674 - accuracy: 0.9921 - val_loss: 1.4426 - val_accuracy: 0.2778 - 337ms/epoch - 84ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.4591 - accuracy: 0.9683 - val_loss: 1.4714 - val_accuracy: 0.2593 - 319ms/epoch - 80ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.4261 - accuracy: 1.0000 - val_loss: 1.4418 - val_accuracy: 0.2593 - 323ms/epoch - 81ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.4305 - accuracy: 0.9841 - val_loss: 1.5014 - val_accuracy: 0.2963 - 345ms/epoch - 86ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.4004 - accuracy: 1.0000 - val_loss: 1.5096 - val_accuracy: 0.2593 - 328ms/epoch - 82ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.4278 - accuracy: 0.9921 - val_loss: 1.4522 - val_accuracy: 0.2778 - 323ms/epoch - 81ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.4052 - accuracy: 0.9841 - val_loss: 1.4955 - val_accuracy: 0.2407 - 324ms/epoch - 81ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.4191 - accuracy: 0.9762 - val_loss: 1.4804 - val_accuracy: 0.2407 - 331ms/epoch - 83ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.4206 - accuracy: 0.9841 - val_loss: 1.5018 - val_accuracy: 0.2037 - 327ms/epoch - 82ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.4328 - accuracy: 0.9683 - val_loss: 1.4803 - val_accuracy: 0.2593 - 339ms/epoch - 85ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.4099 - accuracy: 0.9762 - val_loss: 1.5284 - val_accuracy: 0.2222 - 326ms/epoch - 82ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.3980 - accuracy: 0.9921 - val_loss: 1.4897 - val_accuracy: 0.2037 - 321ms/epoch - 80ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.3684 - accuracy: 0.9921 - val_loss: 1.5009 - val_accuracy: 0.2037 - 324ms/epoch - 81ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.3930 - accuracy: 0.9921 - val_loss: 1.4852 - val_accuracy: 0.2407 - 322ms/epoch - 81ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.3642 - accuracy: 1.0000 - val_loss: 1.5466 - val_accuracy: 0.2222 - 331ms/epoch - 83ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.3427 - accuracy: 1.0000 - val_loss: 1.5623 - val_accuracy: 0.2037 - 336ms/epoch - 84ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.3441 - accuracy: 0.9841 - val_loss: 1.5068 - val_accuracy: 0.2593 - 326ms/epoch - 81ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.3586 - accuracy: 0.9921 - val_loss: 1.5060 - val_accuracy: 0.2963 - 342ms/epoch - 85ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.3240 - accuracy: 1.0000 - val_loss: 1.5743 - val_accuracy: 0.2778 - 327ms/epoch - 82ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.3394 - accuracy: 0.9921 - val_loss: 1.4936 - val_accuracy: 0.3148 - 335ms/epoch - 84ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.3538 - accuracy: 0.9921 - val_loss: 1.4985 - val_accuracy: 0.2778 - 317ms/epoch - 79ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.3389 - accuracy: 0.9921 - val_loss: 1.5786 - val_accuracy: 0.3148 - 324ms/epoch - 81ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.3317 - accuracy: 0.9841 - val_loss: 1.5404 - val_accuracy: 0.2963 - 334ms/epoch - 83ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.3326 - accuracy: 1.0000 - val_loss: 1.5298 - val_accuracy: 0.2593 - 323ms/epoch - 81ms/step\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.3037 - accuracy: 1.0000 - val_loss: 1.5869 - val_accuracy: 0.2222 - 342ms/epoch - 85ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.3176 - accuracy: 1.0000 - val_loss: 1.5041 - val_accuracy: 0.2963 - 322ms/epoch - 80ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.3082 - accuracy: 0.9921 - val_loss: 1.5716 - val_accuracy: 0.2778 - 351ms/epoch - 88ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.3276 - accuracy: 0.9841 - val_loss: 1.5103 - val_accuracy: 0.3148 - 348ms/epoch - 87ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.3138 - accuracy: 0.9921 - val_loss: 1.4861 - val_accuracy: 0.3148 - 325ms/epoch - 81ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 1.38638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.3330 - accuracy: 0.9921 - val_loss: 1.5331 - val_accuracy: 0.2593 - 343ms/epoch - 86ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.3005 - accuracy: 0.9921 - val_loss: 1.5215 - val_accuracy: 0.2778 - 339ms/epoch - 85ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2858 - accuracy: 1.0000 - val_loss: 1.6194 - val_accuracy: 0.2963 - 334ms/epoch - 84ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2881 - accuracy: 1.0000 - val_loss: 1.5792 - val_accuracy: 0.3333 - 321ms/epoch - 80ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2869 - accuracy: 1.0000 - val_loss: 1.6920 - val_accuracy: 0.2963 - 337ms/epoch - 84ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2618 - accuracy: 1.0000 - val_loss: 1.6787 - val_accuracy: 0.3148 - 326ms/epoch - 81ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.3014 - accuracy: 0.9921 - val_loss: 1.6482 - val_accuracy: 0.2778 - 345ms/epoch - 86ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2870 - accuracy: 1.0000 - val_loss: 1.6942 - val_accuracy: 0.2778 - 333ms/epoch - 83ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2904 - accuracy: 0.9921 - val_loss: 1.6044 - val_accuracy: 0.2778 - 330ms/epoch - 82ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.3004 - accuracy: 0.9921 - val_loss: 1.5942 - val_accuracy: 0.2407 - 334ms/epoch - 83ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2697 - accuracy: 1.0000 - val_loss: 1.7533 - val_accuracy: 0.2222 - 330ms/epoch - 83ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2757 - accuracy: 1.0000 - val_loss: 1.6538 - val_accuracy: 0.2593 - 332ms/epoch - 83ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2927 - accuracy: 1.0000 - val_loss: 1.7316 - val_accuracy: 0.2778 - 325ms/epoch - 81ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2634 - accuracy: 0.9921 - val_loss: 1.9118 - val_accuracy: 0.2593 - 325ms/epoch - 81ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2556 - accuracy: 1.0000 - val_loss: 1.6670 - val_accuracy: 0.2222 - 328ms/epoch - 82ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2753 - accuracy: 1.0000 - val_loss: 1.7386 - val_accuracy: 0.2963 - 330ms/epoch - 82ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2785 - accuracy: 0.9921 - val_loss: 1.5527 - val_accuracy: 0.2222 - 343ms/epoch - 86ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2562 - accuracy: 1.0000 - val_loss: 1.7696 - val_accuracy: 0.2963 - 342ms/epoch - 86ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2917 - accuracy: 0.9921 - val_loss: 1.6568 - val_accuracy: 0.2778 - 337ms/epoch - 84ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2623 - accuracy: 0.9921 - val_loss: 1.9129 - val_accuracy: 0.2593 - 342ms/epoch - 86ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2421 - accuracy: 1.0000 - val_loss: 1.6828 - val_accuracy: 0.2593 - 326ms/epoch - 82ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2238 - accuracy: 1.0000 - val_loss: 1.8783 - val_accuracy: 0.2037 - 348ms/epoch - 87ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2460 - accuracy: 0.9921 - val_loss: 1.7619 - val_accuracy: 0.2963 - 338ms/epoch - 85ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2631 - accuracy: 1.0000 - val_loss: 1.8876 - val_accuracy: 0.2407 - 323ms/epoch - 81ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2456 - accuracy: 0.9921 - val_loss: 1.7810 - val_accuracy: 0.1667 - 329ms/epoch - 82ms/step\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2626 - accuracy: 0.9921 - val_loss: 1.7057 - val_accuracy: 0.2778 - 341ms/epoch - 85ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2491 - accuracy: 0.9841 - val_loss: 1.7213 - val_accuracy: 0.2407 - 327ms/epoch - 82ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2419 - accuracy: 0.9921 - val_loss: 1.7440 - val_accuracy: 0.3333 - 330ms/epoch - 83ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 1.6855 - val_accuracy: 0.2963 - 327ms/epoch - 82ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2301 - accuracy: 1.0000 - val_loss: 1.7781 - val_accuracy: 0.2963 - 327ms/epoch - 82ms/step\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2531 - accuracy: 0.9921 - val_loss: 1.7451 - val_accuracy: 0.2593 - 327ms/epoch - 82ms/step\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2345 - accuracy: 0.9841 - val_loss: 1.9389 - val_accuracy: 0.2778 - 325ms/epoch - 81ms/step\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 1.7732 - val_accuracy: 0.1111 - 333ms/epoch - 83ms/step\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2256 - accuracy: 1.0000 - val_loss: 1.9134 - val_accuracy: 0.2222 - 321ms/epoch - 80ms/step\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2245 - accuracy: 1.0000 - val_loss: 1.7645 - val_accuracy: 0.2222 - 343ms/epoch - 86ms/step\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2278 - accuracy: 1.0000 - val_loss: 1.8991 - val_accuracy: 0.2037 - 334ms/epoch - 83ms/step\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2305 - accuracy: 0.9921 - val_loss: 1.7682 - val_accuracy: 0.2593 - 337ms/epoch - 84ms/step\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 1.6834 - val_accuracy: 0.3333 - 321ms/epoch - 80ms/step\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2240 - accuracy: 1.0000 - val_loss: 1.6465 - val_accuracy: 0.3148 - 333ms/epoch - 83ms/step\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 135: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2061 - accuracy: 1.0000 - val_loss: 1.7247 - val_accuracy: 0.2963 - 336ms/epoch - 84ms/step\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 136: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2119 - accuracy: 0.9921 - val_loss: 1.7619 - val_accuracy: 0.2037 - 341ms/epoch - 85ms/step\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 137: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 1.7298 - val_accuracy: 0.2407 - 329ms/epoch - 82ms/step\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 138: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.2043 - accuracy: 1.0000 - val_loss: 1.7335 - val_accuracy: 0.2963 - 324ms/epoch - 81ms/step\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 139: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1771 - accuracy: 1.0000 - val_loss: 1.7639 - val_accuracy: 0.2593 - 327ms/epoch - 82ms/step\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 140: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1885 - accuracy: 1.0000 - val_loss: 1.8250 - val_accuracy: 0.2037 - 332ms/epoch - 83ms/step\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 141: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1910 - accuracy: 1.0000 - val_loss: 1.7898 - val_accuracy: 0.2222 - 325ms/epoch - 81ms/step\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 142: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1866 - accuracy: 1.0000 - val_loss: 1.7800 - val_accuracy: 0.2407 - 342ms/epoch - 86ms/step\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 143: val_loss did not improve from 1.38638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.1871 - accuracy: 1.0000 - val_loss: 1.7754 - val_accuracy: 0.2593 - 336ms/epoch - 84ms/step\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 144: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1706 - accuracy: 1.0000 - val_loss: 1.8333 - val_accuracy: 0.2593 - 329ms/epoch - 82ms/step\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 145: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1807 - accuracy: 0.9921 - val_loss: 1.9813 - val_accuracy: 0.2407 - 326ms/epoch - 82ms/step\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 146: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1764 - accuracy: 1.0000 - val_loss: 1.9296 - val_accuracy: 0.2037 - 331ms/epoch - 83ms/step\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 147: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1751 - accuracy: 1.0000 - val_loss: 1.8704 - val_accuracy: 0.2222 - 332ms/epoch - 83ms/step\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 148: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1578 - accuracy: 1.0000 - val_loss: 1.9019 - val_accuracy: 0.2222 - 336ms/epoch - 84ms/step\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 149: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1687 - accuracy: 1.0000 - val_loss: 1.7917 - val_accuracy: 0.2222 - 327ms/epoch - 82ms/step\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 150: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1696 - accuracy: 1.0000 - val_loss: 1.8138 - val_accuracy: 0.2963 - 344ms/epoch - 86ms/step\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 151: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1632 - accuracy: 1.0000 - val_loss: 1.8187 - val_accuracy: 0.3148 - 338ms/epoch - 84ms/step\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 152: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1837 - accuracy: 1.0000 - val_loss: 1.9145 - val_accuracy: 0.2407 - 331ms/epoch - 83ms/step\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 153: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1904 - accuracy: 1.0000 - val_loss: 1.8320 - val_accuracy: 0.2222 - 330ms/epoch - 82ms/step\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 154: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1480 - accuracy: 1.0000 - val_loss: 1.8640 - val_accuracy: 0.2222 - 334ms/epoch - 84ms/step\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 155: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1631 - accuracy: 1.0000 - val_loss: 1.9816 - val_accuracy: 0.2037 - 331ms/epoch - 83ms/step\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 156: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1719 - accuracy: 1.0000 - val_loss: 1.9002 - val_accuracy: 0.2037 - 343ms/epoch - 86ms/step\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 157: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1623 - accuracy: 1.0000 - val_loss: 1.8188 - val_accuracy: 0.2963 - 337ms/epoch - 84ms/step\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 158: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1795 - accuracy: 1.0000 - val_loss: 1.9032 - val_accuracy: 0.2037 - 328ms/epoch - 82ms/step\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 159: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1714 - accuracy: 1.0000 - val_loss: 1.9105 - val_accuracy: 0.2963 - 334ms/epoch - 83ms/step\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 160: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1590 - accuracy: 1.0000 - val_loss: 1.8946 - val_accuracy: 0.2593 - 327ms/epoch - 82ms/step\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 161: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1515 - accuracy: 1.0000 - val_loss: 1.9653 - val_accuracy: 0.2037 - 343ms/epoch - 86ms/step\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 162: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1594 - accuracy: 1.0000 - val_loss: 2.0409 - val_accuracy: 0.2037 - 319ms/epoch - 80ms/step\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 163: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1748 - accuracy: 0.9921 - val_loss: 1.8101 - val_accuracy: 0.1852 - 344ms/epoch - 86ms/step\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 164: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1608 - accuracy: 1.0000 - val_loss: 2.0104 - val_accuracy: 0.2037 - 337ms/epoch - 84ms/step\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 165: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1740 - accuracy: 0.9921 - val_loss: 2.0016 - val_accuracy: 0.2222 - 324ms/epoch - 81ms/step\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 166: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1585 - accuracy: 0.9921 - val_loss: 2.0400 - val_accuracy: 0.1852 - 336ms/epoch - 84ms/step\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 167: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1623 - accuracy: 1.0000 - val_loss: 1.9298 - val_accuracy: 0.1852 - 319ms/epoch - 80ms/step\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 168: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1454 - accuracy: 1.0000 - val_loss: 1.9542 - val_accuracy: 0.2593 - 335ms/epoch - 84ms/step\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 169: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1604 - accuracy: 1.0000 - val_loss: 1.8662 - val_accuracy: 0.2407 - 323ms/epoch - 81ms/step\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 170: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1569 - accuracy: 1.0000 - val_loss: 1.8955 - val_accuracy: 0.2593 - 339ms/epoch - 85ms/step\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 171: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1552 - accuracy: 1.0000 - val_loss: 1.8980 - val_accuracy: 0.3148 - 337ms/epoch - 84ms/step\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 172: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1515 - accuracy: 1.0000 - val_loss: 1.8866 - val_accuracy: 0.2037 - 326ms/epoch - 82ms/step\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 173: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1558 - accuracy: 1.0000 - val_loss: 1.9773 - val_accuracy: 0.1667 - 329ms/epoch - 82ms/step\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 174: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1558 - accuracy: 1.0000 - val_loss: 1.9698 - val_accuracy: 0.2222 - 331ms/epoch - 83ms/step\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 175: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1346 - accuracy: 1.0000 - val_loss: 2.0903 - val_accuracy: 0.1852 - 325ms/epoch - 81ms/step\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 176: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1429 - accuracy: 1.0000 - val_loss: 2.0449 - val_accuracy: 0.1852 - 325ms/epoch - 81ms/step\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 177: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1408 - accuracy: 1.0000 - val_loss: 2.0468 - val_accuracy: 0.2037 - 321ms/epoch - 80ms/step\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 178: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1427 - accuracy: 1.0000 - val_loss: 1.9486 - val_accuracy: 0.2407 - 329ms/epoch - 82ms/step\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 179: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1357 - accuracy: 1.0000 - val_loss: 1.9531 - val_accuracy: 0.2222 - 321ms/epoch - 80ms/step\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 180: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1439 - accuracy: 1.0000 - val_loss: 1.9901 - val_accuracy: 0.2222 - 355ms/epoch - 89ms/step\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 181: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1326 - accuracy: 1.0000 - val_loss: 2.0379 - val_accuracy: 0.2593 - 331ms/epoch - 83ms/step\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 182: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1263 - accuracy: 1.0000 - val_loss: 2.0277 - val_accuracy: 0.1852 - 325ms/epoch - 81ms/step\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 183: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1276 - accuracy: 1.0000 - val_loss: 2.0906 - val_accuracy: 0.2407 - 332ms/epoch - 83ms/step\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 184: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1362 - accuracy: 1.0000 - val_loss: 2.0188 - val_accuracy: 0.2222 - 324ms/epoch - 81ms/step\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 185: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1351 - accuracy: 1.0000 - val_loss: 1.9073 - val_accuracy: 0.2593 - 330ms/epoch - 82ms/step\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 186: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1575 - accuracy: 1.0000 - val_loss: 2.1617 - val_accuracy: 0.2778 - 343ms/epoch - 86ms/step\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 187: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1463 - accuracy: 1.0000 - val_loss: 1.9321 - val_accuracy: 0.2037 - 336ms/epoch - 84ms/step\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 188: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1451 - accuracy: 1.0000 - val_loss: 2.1110 - val_accuracy: 0.2037 - 329ms/epoch - 82ms/step\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 189: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1401 - accuracy: 1.0000 - val_loss: 2.0044 - val_accuracy: 0.2222 - 326ms/epoch - 82ms/step\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 190: val_loss did not improve from 1.38638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.1236 - accuracy: 1.0000 - val_loss: 2.0776 - val_accuracy: 0.2037 - 354ms/epoch - 88ms/step\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 191: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1449 - accuracy: 1.0000 - val_loss: 2.2051 - val_accuracy: 0.2222 - 352ms/epoch - 88ms/step\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 192: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1209 - accuracy: 1.0000 - val_loss: 2.1453 - val_accuracy: 0.2593 - 329ms/epoch - 82ms/step\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 193: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1342 - accuracy: 1.0000 - val_loss: 1.9904 - val_accuracy: 0.2407 - 345ms/epoch - 86ms/step\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 194: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1302 - accuracy: 1.0000 - val_loss: 1.9823 - val_accuracy: 0.2778 - 321ms/epoch - 80ms/step\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 195: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1072 - accuracy: 1.0000 - val_loss: 1.9907 - val_accuracy: 0.3148 - 341ms/epoch - 85ms/step\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 196: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1409 - accuracy: 1.0000 - val_loss: 2.0260 - val_accuracy: 0.2963 - 338ms/epoch - 84ms/step\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 197: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1211 - accuracy: 1.0000 - val_loss: 2.0761 - val_accuracy: 0.2407 - 332ms/epoch - 83ms/step\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 198: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1290 - accuracy: 0.9921 - val_loss: 2.1852 - val_accuracy: 0.2407 - 331ms/epoch - 83ms/step\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 199: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1074 - accuracy: 1.0000 - val_loss: 2.2478 - val_accuracy: 0.2593 - 335ms/epoch - 84ms/step\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 200: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1261 - accuracy: 1.0000 - val_loss: 2.1960 - val_accuracy: 0.1852 - 330ms/epoch - 83ms/step\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 201: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1473 - accuracy: 0.9921 - val_loss: 2.1347 - val_accuracy: 0.2037 - 320ms/epoch - 80ms/step\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 202: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1360 - accuracy: 1.0000 - val_loss: 2.7298 - val_accuracy: 0.2222 - 352ms/epoch - 88ms/step\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 203: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1594 - accuracy: 1.0000 - val_loss: 2.0680 - val_accuracy: 0.2407 - 328ms/epoch - 82ms/step\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 204: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1270 - accuracy: 0.9921 - val_loss: 2.0941 - val_accuracy: 0.2222 - 323ms/epoch - 81ms/step\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 205: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1299 - accuracy: 1.0000 - val_loss: 1.9637 - val_accuracy: 0.2593 - 325ms/epoch - 81ms/step\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 206: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1157 - accuracy: 1.0000 - val_loss: 2.1660 - val_accuracy: 0.2222 - 324ms/epoch - 81ms/step\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 207: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1264 - accuracy: 1.0000 - val_loss: 2.0470 - val_accuracy: 0.2037 - 329ms/epoch - 82ms/step\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 208: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1187 - accuracy: 0.9921 - val_loss: 2.2538 - val_accuracy: 0.2037 - 342ms/epoch - 86ms/step\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 209: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1131 - accuracy: 1.0000 - val_loss: 2.1396 - val_accuracy: 0.2222 - 333ms/epoch - 83ms/step\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 210: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1456 - accuracy: 1.0000 - val_loss: 2.3839 - val_accuracy: 0.2037 - 334ms/epoch - 83ms/step\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 211: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1485 - accuracy: 0.9921 - val_loss: 2.1802 - val_accuracy: 0.1667 - 324ms/epoch - 81ms/step\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 212: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1398 - accuracy: 1.0000 - val_loss: 2.5394 - val_accuracy: 0.1852 - 345ms/epoch - 86ms/step\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 213: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1214 - accuracy: 1.0000 - val_loss: 3.1809 - val_accuracy: 0.2222 - 336ms/epoch - 84ms/step\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 214: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1060 - accuracy: 1.0000 - val_loss: 2.7286 - val_accuracy: 0.2037 - 340ms/epoch - 85ms/step\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 215: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1221 - accuracy: 1.0000 - val_loss: 2.5836 - val_accuracy: 0.1852 - 321ms/epoch - 80ms/step\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 216: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1064 - accuracy: 1.0000 - val_loss: 2.3154 - val_accuracy: 0.1852 - 335ms/epoch - 84ms/step\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 217: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1138 - accuracy: 1.0000 - val_loss: 2.3170 - val_accuracy: 0.1852 - 335ms/epoch - 84ms/step\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 218: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1058 - accuracy: 1.0000 - val_loss: 2.3415 - val_accuracy: 0.1852 - 324ms/epoch - 81ms/step\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 219: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1006 - accuracy: 1.0000 - val_loss: 2.3915 - val_accuracy: 0.1111 - 327ms/epoch - 82ms/step\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 220: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1088 - accuracy: 1.0000 - val_loss: 2.3235 - val_accuracy: 0.2222 - 329ms/epoch - 82ms/step\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 221: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0967 - accuracy: 1.0000 - val_loss: 2.1712 - val_accuracy: 0.2222 - 334ms/epoch - 84ms/step\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 222: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1099 - accuracy: 1.0000 - val_loss: 2.1919 - val_accuracy: 0.2407 - 329ms/epoch - 82ms/step\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 223: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1011 - accuracy: 1.0000 - val_loss: 2.1295 - val_accuracy: 0.2222 - 327ms/epoch - 82ms/step\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 224: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0957 - accuracy: 1.0000 - val_loss: 2.1978 - val_accuracy: 0.2222 - 328ms/epoch - 82ms/step\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 225: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1038 - accuracy: 1.0000 - val_loss: 2.2432 - val_accuracy: 0.1852 - 327ms/epoch - 82ms/step\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 226: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1047 - accuracy: 1.0000 - val_loss: 2.0622 - val_accuracy: 0.2407 - 342ms/epoch - 86ms/step\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 227: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1216 - accuracy: 1.0000 - val_loss: 2.0859 - val_accuracy: 0.2222 - 348ms/epoch - 87ms/step\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 228: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1029 - accuracy: 1.0000 - val_loss: 2.0473 - val_accuracy: 0.2407 - 331ms/epoch - 83ms/step\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 229: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1099 - accuracy: 1.0000 - val_loss: 2.0835 - val_accuracy: 0.1667 - 347ms/epoch - 87ms/step\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 230: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1175 - accuracy: 1.0000 - val_loss: 2.1307 - val_accuracy: 0.2593 - 339ms/epoch - 85ms/step\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 231: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1047 - accuracy: 1.0000 - val_loss: 2.1403 - val_accuracy: 0.2778 - 325ms/epoch - 81ms/step\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 232: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1013 - accuracy: 1.0000 - val_loss: 2.1817 - val_accuracy: 0.2222 - 324ms/epoch - 81ms/step\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 233: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1068 - accuracy: 1.0000 - val_loss: 2.1255 - val_accuracy: 0.2037 - 325ms/epoch - 81ms/step\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 234: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0951 - accuracy: 1.0000 - val_loss: 2.1234 - val_accuracy: 0.2222 - 322ms/epoch - 80ms/step\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 235: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1049 - accuracy: 1.0000 - val_loss: 2.0384 - val_accuracy: 0.2222 - 327ms/epoch - 82ms/step\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 236: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1002 - accuracy: 1.0000 - val_loss: 2.0100 - val_accuracy: 0.2593 - 320ms/epoch - 80ms/step\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 237: val_loss did not improve from 1.38638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.0834 - accuracy: 1.0000 - val_loss: 2.0558 - val_accuracy: 0.2593 - 330ms/epoch - 82ms/step\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 238: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0912 - accuracy: 1.0000 - val_loss: 2.1087 - val_accuracy: 0.2222 - 336ms/epoch - 84ms/step\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 239: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0884 - accuracy: 1.0000 - val_loss: 2.2656 - val_accuracy: 0.1852 - 328ms/epoch - 82ms/step\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 240: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0996 - accuracy: 1.0000 - val_loss: 2.3100 - val_accuracy: 0.1852 - 324ms/epoch - 81ms/step\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 241: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0877 - accuracy: 1.0000 - val_loss: 2.3296 - val_accuracy: 0.1852 - 337ms/epoch - 84ms/step\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 242: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1004 - accuracy: 1.0000 - val_loss: 2.2611 - val_accuracy: 0.1852 - 327ms/epoch - 82ms/step\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 243: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0931 - accuracy: 1.0000 - val_loss: 2.0460 - val_accuracy: 0.2407 - 351ms/epoch - 88ms/step\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 244: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1057 - accuracy: 1.0000 - val_loss: 2.2181 - val_accuracy: 0.2407 - 334ms/epoch - 84ms/step\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 245: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0982 - accuracy: 1.0000 - val_loss: 2.0614 - val_accuracy: 0.2407 - 340ms/epoch - 85ms/step\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 246: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0885 - accuracy: 1.0000 - val_loss: 2.0713 - val_accuracy: 0.2407 - 330ms/epoch - 83ms/step\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 247: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0936 - accuracy: 1.0000 - val_loss: 2.0701 - val_accuracy: 0.2037 - 346ms/epoch - 86ms/step\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 248: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0858 - accuracy: 1.0000 - val_loss: 2.0121 - val_accuracy: 0.2407 - 321ms/epoch - 80ms/step\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 249: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0887 - accuracy: 1.0000 - val_loss: 2.0077 - val_accuracy: 0.2407 - 325ms/epoch - 81ms/step\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 250: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0769 - accuracy: 1.0000 - val_loss: 2.1540 - val_accuracy: 0.2593 - 330ms/epoch - 83ms/step\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 251: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0912 - accuracy: 1.0000 - val_loss: 2.1276 - val_accuracy: 0.2222 - 337ms/epoch - 84ms/step\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 252: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0808 - accuracy: 1.0000 - val_loss: 2.1780 - val_accuracy: 0.2222 - 328ms/epoch - 82ms/step\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 253: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0691 - accuracy: 1.0000 - val_loss: 2.1429 - val_accuracy: 0.2037 - 326ms/epoch - 82ms/step\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 254: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0826 - accuracy: 1.0000 - val_loss: 2.0553 - val_accuracy: 0.3148 - 322ms/epoch - 80ms/step\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 255: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0782 - accuracy: 1.0000 - val_loss: 2.0326 - val_accuracy: 0.2222 - 322ms/epoch - 80ms/step\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 256: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0827 - accuracy: 1.0000 - val_loss: 2.0509 - val_accuracy: 0.2407 - 330ms/epoch - 83ms/step\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 257: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0871 - accuracy: 1.0000 - val_loss: 2.2052 - val_accuracy: 0.2222 - 347ms/epoch - 87ms/step\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 258: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0901 - accuracy: 1.0000 - val_loss: 2.0913 - val_accuracy: 0.2593 - 330ms/epoch - 82ms/step\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 259: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0803 - accuracy: 1.0000 - val_loss: 2.2010 - val_accuracy: 0.2778 - 334ms/epoch - 83ms/step\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 260: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0868 - accuracy: 1.0000 - val_loss: 2.1593 - val_accuracy: 0.2593 - 327ms/epoch - 82ms/step\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 261: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0873 - accuracy: 1.0000 - val_loss: 2.0729 - val_accuracy: 0.2407 - 320ms/epoch - 80ms/step\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 262: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0889 - accuracy: 1.0000 - val_loss: 2.1673 - val_accuracy: 0.2407 - 355ms/epoch - 89ms/step\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 263: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0753 - accuracy: 1.0000 - val_loss: 2.2073 - val_accuracy: 0.1481 - 337ms/epoch - 84ms/step\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 264: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0877 - accuracy: 1.0000 - val_loss: 1.9925 - val_accuracy: 0.2222 - 320ms/epoch - 80ms/step\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 265: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0887 - accuracy: 1.0000 - val_loss: 2.0614 - val_accuracy: 0.2222 - 326ms/epoch - 82ms/step\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 266: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0814 - accuracy: 1.0000 - val_loss: 2.1812 - val_accuracy: 0.2407 - 326ms/epoch - 81ms/step\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 267: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0771 - accuracy: 1.0000 - val_loss: 2.1707 - val_accuracy: 0.2407 - 338ms/epoch - 84ms/step\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 268: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0735 - accuracy: 1.0000 - val_loss: 2.1433 - val_accuracy: 0.2037 - 341ms/epoch - 85ms/step\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 269: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0827 - accuracy: 1.0000 - val_loss: 2.1018 - val_accuracy: 0.2037 - 344ms/epoch - 86ms/step\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 270: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0778 - accuracy: 1.0000 - val_loss: 2.0453 - val_accuracy: 0.2778 - 340ms/epoch - 85ms/step\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 271: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0691 - accuracy: 1.0000 - val_loss: 2.0752 - val_accuracy: 0.2593 - 333ms/epoch - 83ms/step\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 272: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0814 - accuracy: 1.0000 - val_loss: 1.9681 - val_accuracy: 0.2407 - 325ms/epoch - 81ms/step\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 273: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0840 - accuracy: 1.0000 - val_loss: 2.0937 - val_accuracy: 0.2222 - 331ms/epoch - 83ms/step\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 274: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0843 - accuracy: 1.0000 - val_loss: 2.0924 - val_accuracy: 0.2593 - 329ms/epoch - 82ms/step\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 275: val_loss did not improve from 1.38638\n",
      "4/4 - 1s - loss: 0.0727 - accuracy: 1.0000 - val_loss: 2.0078 - val_accuracy: 0.2963 - 710ms/epoch - 178ms/step\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 276: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0822 - accuracy: 1.0000 - val_loss: 1.9341 - val_accuracy: 0.2593 - 335ms/epoch - 84ms/step\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 277: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0927 - accuracy: 1.0000 - val_loss: 2.1284 - val_accuracy: 0.2407 - 330ms/epoch - 82ms/step\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 278: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1027 - accuracy: 1.0000 - val_loss: 2.0878 - val_accuracy: 0.3333 - 348ms/epoch - 87ms/step\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 279: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0796 - accuracy: 1.0000 - val_loss: 3.5450 - val_accuracy: 0.3148 - 345ms/epoch - 86ms/step\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 280: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0863 - accuracy: 1.0000 - val_loss: 3.3964 - val_accuracy: 0.3333 - 337ms/epoch - 84ms/step\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 281: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0797 - accuracy: 1.0000 - val_loss: 2.1942 - val_accuracy: 0.2593 - 346ms/epoch - 86ms/step\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 282: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0882 - accuracy: 1.0000 - val_loss: 2.1678 - val_accuracy: 0.2407 - 353ms/epoch - 88ms/step\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 283: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0778 - accuracy: 1.0000 - val_loss: 2.0807 - val_accuracy: 0.2407 - 336ms/epoch - 84ms/step\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 284: val_loss did not improve from 1.38638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.0879 - accuracy: 1.0000 - val_loss: 2.0923 - val_accuracy: 0.2778 - 335ms/epoch - 84ms/step\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 285: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.1024 - accuracy: 1.0000 - val_loss: 2.0211 - val_accuracy: 0.3148 - 332ms/epoch - 83ms/step\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 286: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0855 - accuracy: 0.9921 - val_loss: 2.1680 - val_accuracy: 0.2778 - 334ms/epoch - 84ms/step\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 287: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0991 - accuracy: 1.0000 - val_loss: 2.4853 - val_accuracy: 0.1667 - 340ms/epoch - 85ms/step\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 288: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0852 - accuracy: 1.0000 - val_loss: 2.8886 - val_accuracy: 0.1667 - 345ms/epoch - 86ms/step\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 289: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0810 - accuracy: 1.0000 - val_loss: 2.4504 - val_accuracy: 0.2593 - 346ms/epoch - 86ms/step\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 290: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0735 - accuracy: 1.0000 - val_loss: 2.3758 - val_accuracy: 0.2222 - 333ms/epoch - 83ms/step\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 291: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0750 - accuracy: 1.0000 - val_loss: 2.2820 - val_accuracy: 0.2222 - 343ms/epoch - 86ms/step\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 292: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0712 - accuracy: 1.0000 - val_loss: 2.3141 - val_accuracy: 0.2222 - 335ms/epoch - 84ms/step\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 293: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0716 - accuracy: 1.0000 - val_loss: 2.4583 - val_accuracy: 0.1667 - 340ms/epoch - 85ms/step\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 294: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0871 - accuracy: 1.0000 - val_loss: 2.3235 - val_accuracy: 0.1852 - 327ms/epoch - 82ms/step\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 295: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0773 - accuracy: 1.0000 - val_loss: 2.3750 - val_accuracy: 0.2222 - 336ms/epoch - 84ms/step\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 296: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0863 - accuracy: 1.0000 - val_loss: 2.3501 - val_accuracy: 0.2407 - 332ms/epoch - 83ms/step\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 297: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0740 - accuracy: 1.0000 - val_loss: 2.6037 - val_accuracy: 0.2778 - 332ms/epoch - 83ms/step\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 298: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0554 - accuracy: 1.0000 - val_loss: 2.5270 - val_accuracy: 0.2593 - 332ms/epoch - 83ms/step\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 299: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0645 - accuracy: 1.0000 - val_loss: 2.5629 - val_accuracy: 0.2778 - 329ms/epoch - 82ms/step\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 300: val_loss did not improve from 1.38638\n",
      "4/4 - 0s - loss: 0.0625 - accuracy: 1.0000 - val_loss: 2.5488 - val_accuracy: 0.2407 - 343ms/epoch - 86ms/step\n",
      "2/2 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2022-11-11 09:36:45.256969: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_9386180\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:616834\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 09:36:49.281122: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_9389250\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:616876\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38653, saving model to checkpoint1.h5\n",
      "4/4 - 5s - loss: 1.4792 - accuracy: 0.2460 - val_loss: 1.3865 - val_accuracy: 0.2407 - 5s/epoch - 1s/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss improved from 1.38653 to 1.38635, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 1.3476 - accuracy: 0.3254 - val_loss: 1.3864 - val_accuracy: 0.2407 - 385ms/epoch - 96ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss improved from 1.38635 to 1.38619, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 1.3139 - accuracy: 0.4286 - val_loss: 1.3862 - val_accuracy: 0.3148 - 398ms/epoch - 100ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss improved from 1.38619 to 1.38597, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 1.2762 - accuracy: 0.4762 - val_loss: 1.3860 - val_accuracy: 0.2963 - 387ms/epoch - 97ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss improved from 1.38597 to 1.38575, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 1.2585 - accuracy: 0.4921 - val_loss: 1.3858 - val_accuracy: 0.2963 - 398ms/epoch - 99ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss improved from 1.38575 to 1.38565, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 1.2244 - accuracy: 0.5476 - val_loss: 1.3857 - val_accuracy: 0.2963 - 384ms/epoch - 96ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 1.38565\n",
      "4/4 - 0s - loss: 1.2131 - accuracy: 0.5714 - val_loss: 1.3857 - val_accuracy: 0.2963 - 333ms/epoch - 83ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 1.38565\n",
      "4/4 - 0s - loss: 1.1900 - accuracy: 0.4921 - val_loss: 1.3857 - val_accuracy: 0.2963 - 345ms/epoch - 86ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 1.38565\n",
      "4/4 - 0s - loss: 1.1403 - accuracy: 0.6032 - val_loss: 1.3858 - val_accuracy: 0.3148 - 348ms/epoch - 87ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.38565\n",
      "4/4 - 0s - loss: 1.1098 - accuracy: 0.6349 - val_loss: 1.3857 - val_accuracy: 0.3148 - 331ms/epoch - 83ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.38565\n",
      "4/4 - 0s - loss: 1.1057 - accuracy: 0.6508 - val_loss: 1.3857 - val_accuracy: 0.2037 - 347ms/epoch - 87ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss improved from 1.38565 to 1.38550, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 1.0744 - accuracy: 0.6905 - val_loss: 1.3855 - val_accuracy: 0.1852 - 386ms/epoch - 97ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss improved from 1.38550 to 1.38544, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 1.0646 - accuracy: 0.6429 - val_loss: 1.3854 - val_accuracy: 0.2593 - 381ms/epoch - 95ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 1.38544\n",
      "4/4 - 0s - loss: 1.0361 - accuracy: 0.7381 - val_loss: 1.3857 - val_accuracy: 0.2778 - 323ms/epoch - 81ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.38544\n",
      "4/4 - 0s - loss: 1.0197 - accuracy: 0.7540 - val_loss: 1.3857 - val_accuracy: 0.2407 - 355ms/epoch - 89ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 1.38544\n",
      "4/4 - 0s - loss: 1.0380 - accuracy: 0.6429 - val_loss: 1.3858 - val_accuracy: 0.2407 - 355ms/epoch - 89ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 1.38544\n",
      "4/4 - 0s - loss: 0.9993 - accuracy: 0.7698 - val_loss: 1.3856 - val_accuracy: 0.2407 - 332ms/epoch - 83ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss improved from 1.38544 to 1.38531, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.9953 - accuracy: 0.7460 - val_loss: 1.3853 - val_accuracy: 0.2407 - 386ms/epoch - 96ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.9473 - accuracy: 0.7778 - val_loss: 1.3856 - val_accuracy: 0.2407 - 323ms/epoch - 81ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.9292 - accuracy: 0.7857 - val_loss: 1.3859 - val_accuracy: 0.2407 - 337ms/epoch - 84ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.9245 - accuracy: 0.8175 - val_loss: 1.3861 - val_accuracy: 0.2407 - 327ms/epoch - 82ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.9269 - accuracy: 0.7857 - val_loss: 1.3861 - val_accuracy: 0.2407 - 325ms/epoch - 81ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.9145 - accuracy: 0.8095 - val_loss: 1.3860 - val_accuracy: 0.2407 - 332ms/epoch - 83ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.9247 - accuracy: 0.7698 - val_loss: 1.3865 - val_accuracy: 0.2407 - 336ms/epoch - 84ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.9061 - accuracy: 0.8333 - val_loss: 1.3860 - val_accuracy: 0.2407 - 328ms/epoch - 82ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.8775 - accuracy: 0.8175 - val_loss: 1.3868 - val_accuracy: 0.2407 - 334ms/epoch - 84ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.8763 - accuracy: 0.8254 - val_loss: 1.3866 - val_accuracy: 0.2407 - 341ms/epoch - 85ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.8470 - accuracy: 0.8492 - val_loss: 1.3865 - val_accuracy: 0.2407 - 330ms/epoch - 83ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.8335 - accuracy: 0.8333 - val_loss: 1.3876 - val_accuracy: 0.2407 - 332ms/epoch - 83ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.8050 - accuracy: 0.8333 - val_loss: 1.3885 - val_accuracy: 0.2407 - 335ms/epoch - 84ms/step\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.8080 - accuracy: 0.8730 - val_loss: 1.3878 - val_accuracy: 0.2407 - 344ms/epoch - 86ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.8066 - accuracy: 0.8492 - val_loss: 1.3877 - val_accuracy: 0.2407 - 339ms/epoch - 85ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.7585 - accuracy: 0.8889 - val_loss: 1.3883 - val_accuracy: 0.2407 - 347ms/epoch - 87ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.7846 - accuracy: 0.8571 - val_loss: 1.3918 - val_accuracy: 0.2407 - 330ms/epoch - 82ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.7891 - accuracy: 0.8571 - val_loss: 1.3888 - val_accuracy: 0.2407 - 333ms/epoch - 83ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.7376 - accuracy: 0.9286 - val_loss: 1.3912 - val_accuracy: 0.2407 - 326ms/epoch - 82ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.7643 - accuracy: 0.8968 - val_loss: 1.3923 - val_accuracy: 0.2593 - 342ms/epoch - 86ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.7162 - accuracy: 0.9206 - val_loss: 1.3942 - val_accuracy: 0.2407 - 322ms/epoch - 80ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.7422 - accuracy: 0.9127 - val_loss: 1.3910 - val_accuracy: 0.2407 - 349ms/epoch - 87ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.7018 - accuracy: 0.9206 - val_loss: 1.3926 - val_accuracy: 0.2407 - 325ms/epoch - 81ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.6757 - accuracy: 0.9286 - val_loss: 1.3922 - val_accuracy: 0.2407 - 339ms/epoch - 85ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.6631 - accuracy: 0.9127 - val_loss: 1.3975 - val_accuracy: 0.2407 - 328ms/epoch - 82ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.6236 - accuracy: 0.9603 - val_loss: 1.3974 - val_accuracy: 0.2407 - 356ms/epoch - 89ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.6546 - accuracy: 0.9365 - val_loss: 1.4022 - val_accuracy: 0.2593 - 324ms/epoch - 81ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.6456 - accuracy: 0.9524 - val_loss: 1.3980 - val_accuracy: 0.2407 - 325ms/epoch - 81ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.6361 - accuracy: 0.9365 - val_loss: 1.4032 - val_accuracy: 0.2593 - 334ms/epoch - 84ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.6158 - accuracy: 0.9762 - val_loss: 1.4009 - val_accuracy: 0.2407 - 324ms/epoch - 81ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.5890 - accuracy: 0.9603 - val_loss: 1.4148 - val_accuracy: 0.2407 - 345ms/epoch - 86ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.5914 - accuracy: 0.9603 - val_loss: 1.4097 - val_accuracy: 0.2407 - 334ms/epoch - 83ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.6052 - accuracy: 0.9206 - val_loss: 1.4009 - val_accuracy: 0.2407 - 344ms/epoch - 86ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.5654 - accuracy: 0.9603 - val_loss: 1.4048 - val_accuracy: 0.2407 - 350ms/epoch - 87ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.5495 - accuracy: 0.9603 - val_loss: 1.4043 - val_accuracy: 0.2407 - 325ms/epoch - 81ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.5498 - accuracy: 0.9841 - val_loss: 1.4013 - val_accuracy: 0.2778 - 328ms/epoch - 82ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.5185 - accuracy: 0.9683 - val_loss: 1.4103 - val_accuracy: 0.2407 - 342ms/epoch - 85ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.5106 - accuracy: 0.9921 - val_loss: 1.4186 - val_accuracy: 0.2593 - 328ms/epoch - 82ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.5048 - accuracy: 0.9762 - val_loss: 1.4072 - val_accuracy: 0.2407 - 318ms/epoch - 79ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.4859 - accuracy: 0.9921 - val_loss: 1.4303 - val_accuracy: 0.2963 - 345ms/epoch - 86ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.5098 - accuracy: 0.9603 - val_loss: 1.4112 - val_accuracy: 0.2593 - 326ms/epoch - 81ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.4593 - accuracy: 0.9683 - val_loss: 1.4130 - val_accuracy: 0.2593 - 355ms/epoch - 89ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.4833 - accuracy: 0.9841 - val_loss: 1.4139 - val_accuracy: 0.2963 - 333ms/epoch - 83ms/step\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.4628 - accuracy: 0.9921 - val_loss: 1.4379 - val_accuracy: 0.2407 - 336ms/epoch - 84ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.4599 - accuracy: 0.9603 - val_loss: 1.4204 - val_accuracy: 0.2222 - 338ms/epoch - 84ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.4521 - accuracy: 0.9683 - val_loss: 1.4417 - val_accuracy: 0.2778 - 342ms/epoch - 85ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.4443 - accuracy: 0.9921 - val_loss: 1.4075 - val_accuracy: 0.2407 - 342ms/epoch - 85ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.4212 - accuracy: 0.9841 - val_loss: 1.4418 - val_accuracy: 0.2222 - 334ms/epoch - 83ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.4396 - accuracy: 0.9762 - val_loss: 1.4263 - val_accuracy: 0.2963 - 335ms/epoch - 84ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.4052 - accuracy: 0.9921 - val_loss: 1.4485 - val_accuracy: 0.2407 - 323ms/epoch - 81ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.4284 - accuracy: 0.9841 - val_loss: 1.4174 - val_accuracy: 0.3333 - 322ms/epoch - 81ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.3934 - accuracy: 0.9841 - val_loss: 1.4518 - val_accuracy: 0.3333 - 347ms/epoch - 87ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.4158 - accuracy: 0.9921 - val_loss: 1.3964 - val_accuracy: 0.2963 - 343ms/epoch - 86ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.3908 - accuracy: 0.9683 - val_loss: 1.4766 - val_accuracy: 0.2593 - 353ms/epoch - 88ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.3979 - accuracy: 0.9841 - val_loss: 1.4268 - val_accuracy: 0.2778 - 320ms/epoch - 80ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.3774 - accuracy: 0.9841 - val_loss: 1.4212 - val_accuracy: 0.3333 - 321ms/epoch - 80ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.3577 - accuracy: 0.9921 - val_loss: 1.4439 - val_accuracy: 0.2963 - 334ms/epoch - 83ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.3715 - accuracy: 0.9921 - val_loss: 1.4318 - val_accuracy: 0.2222 - 340ms/epoch - 85ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.3739 - accuracy: 0.9603 - val_loss: 1.4413 - val_accuracy: 0.2963 - 336ms/epoch - 84ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.3417 - accuracy: 0.9921 - val_loss: 1.4330 - val_accuracy: 0.3333 - 328ms/epoch - 82ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.3636 - accuracy: 0.9921 - val_loss: 1.4531 - val_accuracy: 0.3148 - 321ms/epoch - 80ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.3588 - accuracy: 0.9841 - val_loss: 1.4868 - val_accuracy: 0.2593 - 323ms/epoch - 81ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.3638 - accuracy: 1.0000 - val_loss: 1.4739 - val_accuracy: 0.2593 - 323ms/epoch - 81ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.3359 - accuracy: 0.9921 - val_loss: 1.4762 - val_accuracy: 0.2407 - 328ms/epoch - 82ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.3586 - accuracy: 1.0000 - val_loss: 1.4369 - val_accuracy: 0.2593 - 341ms/epoch - 85ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.3164 - accuracy: 1.0000 - val_loss: 1.4688 - val_accuracy: 0.2963 - 326ms/epoch - 81ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.2935 - accuracy: 0.9921 - val_loss: 1.4795 - val_accuracy: 0.2778 - 326ms/epoch - 82ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.3005 - accuracy: 1.0000 - val_loss: 1.4591 - val_accuracy: 0.3148 - 333ms/epoch - 83ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.2864 - accuracy: 1.0000 - val_loss: 1.4728 - val_accuracy: 0.2593 - 332ms/epoch - 83ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.3153 - accuracy: 1.0000 - val_loss: 1.4723 - val_accuracy: 0.2407 - 350ms/epoch - 88ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.2772 - accuracy: 1.0000 - val_loss: 1.4462 - val_accuracy: 0.2778 - 320ms/epoch - 80ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.3161 - accuracy: 1.0000 - val_loss: 1.4542 - val_accuracy: 0.2593 - 323ms/epoch - 81ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.3027 - accuracy: 0.9683 - val_loss: 1.4896 - val_accuracy: 0.2593 - 330ms/epoch - 83ms/step\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.2935 - accuracy: 1.0000 - val_loss: 1.4814 - val_accuracy: 0.3519 - 343ms/epoch - 86ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.3100 - accuracy: 0.9921 - val_loss: 1.5104 - val_accuracy: 0.2593 - 332ms/epoch - 83ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.2879 - accuracy: 1.0000 - val_loss: 1.5136 - val_accuracy: 0.2778 - 354ms/epoch - 89ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 1.38531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.3098 - accuracy: 0.9921 - val_loss: 1.5633 - val_accuracy: 0.2407 - 331ms/epoch - 83ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.2876 - accuracy: 1.0000 - val_loss: 1.4480 - val_accuracy: 0.2407 - 329ms/epoch - 82ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.2801 - accuracy: 1.0000 - val_loss: 1.5033 - val_accuracy: 0.3333 - 326ms/epoch - 82ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.2798 - accuracy: 0.9921 - val_loss: 1.5593 - val_accuracy: 0.2037 - 336ms/epoch - 84ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.2811 - accuracy: 1.0000 - val_loss: 1.5664 - val_accuracy: 0.2963 - 326ms/epoch - 81ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.2569 - accuracy: 0.9921 - val_loss: 1.5336 - val_accuracy: 0.2963 - 342ms/epoch - 86ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.2579 - accuracy: 1.0000 - val_loss: 1.5137 - val_accuracy: 0.2963 - 324ms/epoch - 81ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.2658 - accuracy: 1.0000 - val_loss: 1.5642 - val_accuracy: 0.2407 - 338ms/epoch - 84ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.2530 - accuracy: 1.0000 - val_loss: 1.5519 - val_accuracy: 0.2407 - 328ms/epoch - 82ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.2710 - accuracy: 0.9921 - val_loss: 1.5303 - val_accuracy: 0.2593 - 328ms/epoch - 82ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.2330 - accuracy: 1.0000 - val_loss: 1.5428 - val_accuracy: 0.2593 - 320ms/epoch - 80ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.2445 - accuracy: 1.0000 - val_loss: 1.5690 - val_accuracy: 0.2778 - 329ms/epoch - 82ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.6288 - val_accuracy: 0.1667 - 349ms/epoch - 87ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.2468 - accuracy: 1.0000 - val_loss: 1.5729 - val_accuracy: 0.2407 - 334ms/epoch - 83ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.2243 - accuracy: 1.0000 - val_loss: 1.5658 - val_accuracy: 0.2593 - 333ms/epoch - 83ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.2272 - accuracy: 1.0000 - val_loss: 1.5704 - val_accuracy: 0.2593 - 324ms/epoch - 81ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.2342 - accuracy: 0.9841 - val_loss: 1.5999 - val_accuracy: 0.2778 - 328ms/epoch - 82ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.2304 - accuracy: 1.0000 - val_loss: 1.6530 - val_accuracy: 0.2778 - 334ms/epoch - 83ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.2268 - accuracy: 1.0000 - val_loss: 1.6130 - val_accuracy: 0.2593 - 336ms/epoch - 84ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.2210 - accuracy: 0.9921 - val_loss: 1.6212 - val_accuracy: 0.2407 - 328ms/epoch - 82ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.2453 - accuracy: 0.9921 - val_loss: 1.6000 - val_accuracy: 0.2037 - 348ms/epoch - 87ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 1.5714 - val_accuracy: 0.2593 - 345ms/epoch - 86ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.2211 - accuracy: 1.0000 - val_loss: 1.5859 - val_accuracy: 0.2778 - 336ms/epoch - 84ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.2176 - accuracy: 1.0000 - val_loss: 1.6615 - val_accuracy: 0.2407 - 340ms/epoch - 85ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.2229 - accuracy: 1.0000 - val_loss: 1.6347 - val_accuracy: 0.2407 - 348ms/epoch - 87ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.2546 - accuracy: 0.9921 - val_loss: 1.6340 - val_accuracy: 0.2593 - 339ms/epoch - 85ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.2240 - accuracy: 0.9921 - val_loss: 1.7137 - val_accuracy: 0.2593 - 330ms/epoch - 82ms/step\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.2321 - accuracy: 0.9921 - val_loss: 1.7110 - val_accuracy: 0.2593 - 341ms/epoch - 85ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 1.7227 - val_accuracy: 0.2222 - 334ms/epoch - 83ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 1.7439 - val_accuracy: 0.2778 - 332ms/epoch - 83ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.2075 - accuracy: 1.0000 - val_loss: 1.6901 - val_accuracy: 0.2593 - 329ms/epoch - 82ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1927 - accuracy: 1.0000 - val_loss: 1.7613 - val_accuracy: 0.2593 - 327ms/epoch - 82ms/step\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 1.7761 - val_accuracy: 0.2407 - 330ms/epoch - 82ms/step\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.2180 - accuracy: 1.0000 - val_loss: 1.7388 - val_accuracy: 0.2222 - 330ms/epoch - 82ms/step\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.2211 - accuracy: 0.9921 - val_loss: 1.7963 - val_accuracy: 0.2778 - 325ms/epoch - 81ms/step\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1777 - accuracy: 1.0000 - val_loss: 1.7731 - val_accuracy: 0.2407 - 342ms/epoch - 85ms/step\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1778 - accuracy: 1.0000 - val_loss: 1.7734 - val_accuracy: 0.2222 - 342ms/epoch - 85ms/step\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1879 - accuracy: 1.0000 - val_loss: 1.7513 - val_accuracy: 0.2222 - 321ms/epoch - 80ms/step\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1877 - accuracy: 1.0000 - val_loss: 1.7443 - val_accuracy: 0.2593 - 350ms/epoch - 87ms/step\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1952 - accuracy: 1.0000 - val_loss: 1.7106 - val_accuracy: 0.2593 - 342ms/epoch - 85ms/step\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1893 - accuracy: 1.0000 - val_loss: 1.7957 - val_accuracy: 0.1667 - 325ms/epoch - 81ms/step\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 135: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1735 - accuracy: 1.0000 - val_loss: 1.7825 - val_accuracy: 0.2222 - 343ms/epoch - 86ms/step\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 136: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1958 - accuracy: 0.9921 - val_loss: 1.7730 - val_accuracy: 0.1852 - 334ms/epoch - 83ms/step\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 137: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1601 - accuracy: 1.0000 - val_loss: 1.7804 - val_accuracy: 0.1296 - 325ms/epoch - 81ms/step\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 138: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1843 - accuracy: 1.0000 - val_loss: 1.7411 - val_accuracy: 0.2222 - 346ms/epoch - 86ms/step\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 139: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1969 - accuracy: 1.0000 - val_loss: 1.8179 - val_accuracy: 0.2222 - 333ms/epoch - 83ms/step\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 140: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1719 - accuracy: 1.0000 - val_loss: 1.8527 - val_accuracy: 0.1296 - 331ms/epoch - 83ms/step\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 141: val_loss did not improve from 1.38531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.1802 - accuracy: 1.0000 - val_loss: 1.8092 - val_accuracy: 0.1852 - 336ms/epoch - 84ms/step\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 142: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1767 - accuracy: 1.0000 - val_loss: 1.8425 - val_accuracy: 0.2778 - 333ms/epoch - 83ms/step\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 143: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1741 - accuracy: 1.0000 - val_loss: 1.8031 - val_accuracy: 0.1481 - 324ms/epoch - 81ms/step\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 144: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1618 - accuracy: 1.0000 - val_loss: 1.8274 - val_accuracy: 0.0741 - 342ms/epoch - 86ms/step\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 145: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1580 - accuracy: 1.0000 - val_loss: 1.8315 - val_accuracy: 0.1667 - 354ms/epoch - 88ms/step\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 146: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1686 - accuracy: 0.9921 - val_loss: 1.8230 - val_accuracy: 0.1481 - 323ms/epoch - 81ms/step\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 147: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1496 - accuracy: 1.0000 - val_loss: 1.8286 - val_accuracy: 0.1667 - 330ms/epoch - 82ms/step\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 148: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1639 - accuracy: 1.0000 - val_loss: 1.8079 - val_accuracy: 0.2593 - 327ms/epoch - 82ms/step\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 149: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1646 - accuracy: 1.0000 - val_loss: 1.8723 - val_accuracy: 0.1852 - 324ms/epoch - 81ms/step\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 150: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1552 - accuracy: 1.0000 - val_loss: 1.8969 - val_accuracy: 0.2222 - 333ms/epoch - 83ms/step\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 151: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1882 - accuracy: 0.9921 - val_loss: 1.9127 - val_accuracy: 0.2222 - 328ms/epoch - 82ms/step\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 152: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1781 - accuracy: 1.0000 - val_loss: 1.8811 - val_accuracy: 0.2037 - 321ms/epoch - 80ms/step\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 153: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1830 - accuracy: 0.9921 - val_loss: 1.8033 - val_accuracy: 0.1852 - 332ms/epoch - 83ms/step\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 154: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1480 - accuracy: 1.0000 - val_loss: 1.8228 - val_accuracy: 0.2037 - 325ms/epoch - 81ms/step\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 155: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1434 - accuracy: 1.0000 - val_loss: 1.8513 - val_accuracy: 0.2222 - 327ms/epoch - 82ms/step\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 156: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1491 - accuracy: 1.0000 - val_loss: 1.9537 - val_accuracy: 0.2593 - 331ms/epoch - 83ms/step\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 157: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1420 - accuracy: 1.0000 - val_loss: 1.9239 - val_accuracy: 0.1667 - 325ms/epoch - 81ms/step\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 158: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1568 - accuracy: 1.0000 - val_loss: 2.0080 - val_accuracy: 0.2037 - 336ms/epoch - 84ms/step\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 159: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1446 - accuracy: 1.0000 - val_loss: 1.9377 - val_accuracy: 0.1667 - 341ms/epoch - 85ms/step\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 160: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1228 - accuracy: 1.0000 - val_loss: 1.9421 - val_accuracy: 0.1111 - 323ms/epoch - 81ms/step\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 161: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1345 - accuracy: 1.0000 - val_loss: 1.9548 - val_accuracy: 0.1111 - 341ms/epoch - 85ms/step\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 162: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1650 - accuracy: 0.9921 - val_loss: 1.9284 - val_accuracy: 0.1296 - 326ms/epoch - 82ms/step\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 163: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1545 - accuracy: 1.0000 - val_loss: 1.9383 - val_accuracy: 0.1481 - 349ms/epoch - 87ms/step\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 164: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1629 - accuracy: 1.0000 - val_loss: 1.9362 - val_accuracy: 0.1852 - 342ms/epoch - 86ms/step\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 165: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1588 - accuracy: 1.0000 - val_loss: 1.9843 - val_accuracy: 0.1852 - 335ms/epoch - 84ms/step\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 166: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1620 - accuracy: 1.0000 - val_loss: 1.9464 - val_accuracy: 0.2222 - 326ms/epoch - 81ms/step\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 167: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1479 - accuracy: 1.0000 - val_loss: 1.9391 - val_accuracy: 0.2222 - 341ms/epoch - 85ms/step\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 168: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1523 - accuracy: 1.0000 - val_loss: 1.9431 - val_accuracy: 0.2037 - 316ms/epoch - 79ms/step\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 169: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1594 - accuracy: 1.0000 - val_loss: 1.9565 - val_accuracy: 0.2407 - 334ms/epoch - 84ms/step\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 170: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1539 - accuracy: 1.0000 - val_loss: 2.0224 - val_accuracy: 0.1852 - 321ms/epoch - 80ms/step\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 171: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1291 - accuracy: 1.0000 - val_loss: 2.0079 - val_accuracy: 0.1296 - 327ms/epoch - 82ms/step\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 172: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1410 - accuracy: 1.0000 - val_loss: 1.8856 - val_accuracy: 0.1852 - 320ms/epoch - 80ms/step\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 173: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1422 - accuracy: 1.0000 - val_loss: 1.9823 - val_accuracy: 0.2222 - 329ms/epoch - 82ms/step\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 174: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1244 - accuracy: 1.0000 - val_loss: 1.9092 - val_accuracy: 0.1852 - 336ms/epoch - 84ms/step\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 175: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1276 - accuracy: 1.0000 - val_loss: 1.9919 - val_accuracy: 0.1852 - 320ms/epoch - 80ms/step\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 176: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1210 - accuracy: 1.0000 - val_loss: 2.0130 - val_accuracy: 0.1667 - 329ms/epoch - 82ms/step\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 177: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1222 - accuracy: 1.0000 - val_loss: 1.9503 - val_accuracy: 0.2407 - 329ms/epoch - 82ms/step\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 178: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1363 - accuracy: 1.0000 - val_loss: 2.0878 - val_accuracy: 0.2407 - 324ms/epoch - 81ms/step\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 179: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1190 - accuracy: 1.0000 - val_loss: 2.1716 - val_accuracy: 0.1481 - 333ms/epoch - 83ms/step\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 180: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1097 - accuracy: 1.0000 - val_loss: 2.0410 - val_accuracy: 0.1111 - 320ms/epoch - 80ms/step\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 181: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1533 - accuracy: 1.0000 - val_loss: 1.9791 - val_accuracy: 0.1667 - 338ms/epoch - 84ms/step\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 182: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0976 - accuracy: 1.0000 - val_loss: 2.0223 - val_accuracy: 0.2222 - 322ms/epoch - 80ms/step\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 183: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1218 - accuracy: 1.0000 - val_loss: 2.0831 - val_accuracy: 0.1481 - 330ms/epoch - 83ms/step\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 184: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1082 - accuracy: 1.0000 - val_loss: 2.0081 - val_accuracy: 0.1481 - 333ms/epoch - 83ms/step\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 185: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1131 - accuracy: 1.0000 - val_loss: 2.0197 - val_accuracy: 0.2037 - 324ms/epoch - 81ms/step\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 186: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1199 - accuracy: 1.0000 - val_loss: 2.0508 - val_accuracy: 0.2037 - 342ms/epoch - 85ms/step\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 187: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1259 - accuracy: 1.0000 - val_loss: 2.1812 - val_accuracy: 0.1481 - 329ms/epoch - 82ms/step\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 188: val_loss did not improve from 1.38531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.1047 - accuracy: 1.0000 - val_loss: 2.0636 - val_accuracy: 0.1296 - 355ms/epoch - 89ms/step\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 189: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1045 - accuracy: 1.0000 - val_loss: 2.0419 - val_accuracy: 0.1296 - 347ms/epoch - 87ms/step\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 190: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1083 - accuracy: 1.0000 - val_loss: 2.0897 - val_accuracy: 0.1296 - 336ms/epoch - 84ms/step\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 191: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1070 - accuracy: 1.0000 - val_loss: 2.0132 - val_accuracy: 0.1481 - 320ms/epoch - 80ms/step\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 192: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1110 - accuracy: 1.0000 - val_loss: 2.0893 - val_accuracy: 0.1667 - 325ms/epoch - 81ms/step\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 193: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1156 - accuracy: 1.0000 - val_loss: 2.0027 - val_accuracy: 0.1667 - 332ms/epoch - 83ms/step\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 194: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1160 - accuracy: 1.0000 - val_loss: 2.1137 - val_accuracy: 0.1852 - 324ms/epoch - 81ms/step\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 195: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1150 - accuracy: 1.0000 - val_loss: 1.9612 - val_accuracy: 0.2037 - 348ms/epoch - 87ms/step\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 196: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1376 - accuracy: 1.0000 - val_loss: 2.1120 - val_accuracy: 0.2037 - 334ms/epoch - 84ms/step\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 197: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1167 - accuracy: 1.0000 - val_loss: 2.0906 - val_accuracy: 0.1296 - 322ms/epoch - 81ms/step\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 198: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1138 - accuracy: 1.0000 - val_loss: 2.0685 - val_accuracy: 0.1296 - 323ms/epoch - 81ms/step\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 199: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1093 - accuracy: 1.0000 - val_loss: 2.0165 - val_accuracy: 0.1481 - 325ms/epoch - 81ms/step\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 200: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1277 - accuracy: 1.0000 - val_loss: 2.2567 - val_accuracy: 0.1667 - 325ms/epoch - 81ms/step\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 201: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1072 - accuracy: 1.0000 - val_loss: 2.2502 - val_accuracy: 0.1852 - 336ms/epoch - 84ms/step\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 202: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1056 - accuracy: 1.0000 - val_loss: 2.2219 - val_accuracy: 0.1296 - 335ms/epoch - 84ms/step\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 203: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1039 - accuracy: 1.0000 - val_loss: 2.5198 - val_accuracy: 0.1852 - 336ms/epoch - 84ms/step\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 204: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1053 - accuracy: 1.0000 - val_loss: 2.0703 - val_accuracy: 0.2222 - 336ms/epoch - 84ms/step\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 205: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1018 - accuracy: 1.0000 - val_loss: 2.0977 - val_accuracy: 0.1852 - 329ms/epoch - 82ms/step\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 206: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0988 - accuracy: 1.0000 - val_loss: 2.1959 - val_accuracy: 0.2593 - 334ms/epoch - 83ms/step\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 207: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1011 - accuracy: 1.0000 - val_loss: 2.2384 - val_accuracy: 0.2593 - 349ms/epoch - 87ms/step\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 208: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1025 - accuracy: 1.0000 - val_loss: 2.3257 - val_accuracy: 0.2222 - 345ms/epoch - 86ms/step\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 209: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1339 - accuracy: 1.0000 - val_loss: 2.2872 - val_accuracy: 0.2222 - 332ms/epoch - 83ms/step\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 210: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0915 - accuracy: 1.0000 - val_loss: 2.3376 - val_accuracy: 0.2037 - 323ms/epoch - 81ms/step\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 211: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0943 - accuracy: 1.0000 - val_loss: 2.2102 - val_accuracy: 0.2037 - 333ms/epoch - 83ms/step\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 212: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0955 - accuracy: 1.0000 - val_loss: 2.0419 - val_accuracy: 0.1852 - 358ms/epoch - 90ms/step\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 213: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1203 - accuracy: 1.0000 - val_loss: 2.0830 - val_accuracy: 0.2037 - 330ms/epoch - 82ms/step\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 214: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1041 - accuracy: 1.0000 - val_loss: 2.8865 - val_accuracy: 0.2037 - 327ms/epoch - 82ms/step\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 215: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0905 - accuracy: 1.0000 - val_loss: 2.6367 - val_accuracy: 0.1852 - 326ms/epoch - 81ms/step\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 216: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0919 - accuracy: 1.0000 - val_loss: 2.3404 - val_accuracy: 0.1667 - 322ms/epoch - 81ms/step\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 217: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1058 - accuracy: 0.9921 - val_loss: 2.2086 - val_accuracy: 0.1296 - 360ms/epoch - 90ms/step\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 218: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1080 - accuracy: 1.0000 - val_loss: 2.2097 - val_accuracy: 0.1296 - 361ms/epoch - 90ms/step\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 219: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0954 - accuracy: 1.0000 - val_loss: 2.0701 - val_accuracy: 0.1296 - 327ms/epoch - 82ms/step\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 220: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1037 - accuracy: 1.0000 - val_loss: 2.0231 - val_accuracy: 0.1296 - 334ms/epoch - 83ms/step\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 221: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0926 - accuracy: 1.0000 - val_loss: 2.1577 - val_accuracy: 0.1296 - 335ms/epoch - 84ms/step\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 222: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0929 - accuracy: 1.0000 - val_loss: 2.0757 - val_accuracy: 0.2222 - 332ms/epoch - 83ms/step\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 223: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0911 - accuracy: 1.0000 - val_loss: 2.0528 - val_accuracy: 0.2222 - 323ms/epoch - 81ms/step\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 224: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0888 - accuracy: 1.0000 - val_loss: 2.1519 - val_accuracy: 0.2037 - 351ms/epoch - 88ms/step\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 225: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0906 - accuracy: 1.0000 - val_loss: 2.1335 - val_accuracy: 0.1852 - 331ms/epoch - 83ms/step\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 226: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0899 - accuracy: 1.0000 - val_loss: 2.0817 - val_accuracy: 0.1667 - 332ms/epoch - 83ms/step\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 227: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0926 - accuracy: 1.0000 - val_loss: 2.0359 - val_accuracy: 0.2593 - 325ms/epoch - 81ms/step\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 228: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0977 - accuracy: 1.0000 - val_loss: 2.0483 - val_accuracy: 0.2222 - 333ms/epoch - 83ms/step\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 229: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0855 - accuracy: 1.0000 - val_loss: 2.0548 - val_accuracy: 0.1852 - 325ms/epoch - 81ms/step\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 230: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0767 - accuracy: 1.0000 - val_loss: 2.0458 - val_accuracy: 0.1667 - 327ms/epoch - 82ms/step\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 231: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1030 - accuracy: 1.0000 - val_loss: 2.1900 - val_accuracy: 0.1481 - 350ms/epoch - 88ms/step\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 232: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0969 - accuracy: 1.0000 - val_loss: 2.1836 - val_accuracy: 0.1481 - 325ms/epoch - 81ms/step\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 233: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0830 - accuracy: 1.0000 - val_loss: 2.1648 - val_accuracy: 0.2037 - 352ms/epoch - 88ms/step\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 234: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0837 - accuracy: 1.0000 - val_loss: 2.2371 - val_accuracy: 0.1481 - 332ms/epoch - 83ms/step\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 235: val_loss did not improve from 1.38531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.0839 - accuracy: 1.0000 - val_loss: 2.1126 - val_accuracy: 0.1481 - 325ms/epoch - 81ms/step\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 236: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0839 - accuracy: 1.0000 - val_loss: 2.2782 - val_accuracy: 0.1481 - 337ms/epoch - 84ms/step\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 237: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0920 - accuracy: 1.0000 - val_loss: 2.1521 - val_accuracy: 0.1481 - 331ms/epoch - 83ms/step\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 238: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0839 - accuracy: 1.0000 - val_loss: 2.2118 - val_accuracy: 0.1296 - 337ms/epoch - 84ms/step\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 239: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0879 - accuracy: 1.0000 - val_loss: 2.1083 - val_accuracy: 0.2593 - 347ms/epoch - 87ms/step\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 240: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0883 - accuracy: 1.0000 - val_loss: 2.1579 - val_accuracy: 0.1852 - 343ms/epoch - 86ms/step\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 241: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0855 - accuracy: 1.0000 - val_loss: 2.1347 - val_accuracy: 0.2222 - 336ms/epoch - 84ms/step\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 242: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0915 - accuracy: 1.0000 - val_loss: 2.1434 - val_accuracy: 0.1852 - 321ms/epoch - 80ms/step\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 243: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0850 - accuracy: 1.0000 - val_loss: 2.1843 - val_accuracy: 0.1852 - 347ms/epoch - 87ms/step\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 244: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0792 - accuracy: 1.0000 - val_loss: 2.1476 - val_accuracy: 0.2037 - 351ms/epoch - 88ms/step\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 245: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0749 - accuracy: 1.0000 - val_loss: 2.0683 - val_accuracy: 0.1852 - 345ms/epoch - 86ms/step\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 246: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0906 - accuracy: 1.0000 - val_loss: 2.1180 - val_accuracy: 0.1852 - 334ms/epoch - 83ms/step\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 247: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0705 - accuracy: 1.0000 - val_loss: 2.1631 - val_accuracy: 0.1852 - 331ms/epoch - 83ms/step\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 248: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0818 - accuracy: 1.0000 - val_loss: 2.1221 - val_accuracy: 0.2037 - 338ms/epoch - 85ms/step\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 249: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0708 - accuracy: 1.0000 - val_loss: 2.1849 - val_accuracy: 0.1667 - 349ms/epoch - 87ms/step\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 250: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0851 - accuracy: 1.0000 - val_loss: 2.1819 - val_accuracy: 0.1667 - 334ms/epoch - 83ms/step\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 251: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0821 - accuracy: 1.0000 - val_loss: 2.2052 - val_accuracy: 0.1667 - 334ms/epoch - 84ms/step\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 252: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0725 - accuracy: 1.0000 - val_loss: 2.2287 - val_accuracy: 0.1852 - 323ms/epoch - 81ms/step\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 253: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0651 - accuracy: 1.0000 - val_loss: 2.2446 - val_accuracy: 0.1852 - 332ms/epoch - 83ms/step\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 254: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0840 - accuracy: 1.0000 - val_loss: 2.3462 - val_accuracy: 0.2222 - 321ms/epoch - 80ms/step\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 255: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0718 - accuracy: 1.0000 - val_loss: 2.2326 - val_accuracy: 0.2407 - 336ms/epoch - 84ms/step\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 256: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0795 - accuracy: 1.0000 - val_loss: 2.3294 - val_accuracy: 0.2037 - 345ms/epoch - 86ms/step\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 257: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0645 - accuracy: 1.0000 - val_loss: 2.1464 - val_accuracy: 0.2407 - 323ms/epoch - 81ms/step\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 258: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.1034 - accuracy: 1.0000 - val_loss: 2.2325 - val_accuracy: 0.1852 - 327ms/epoch - 82ms/step\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 259: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0704 - accuracy: 1.0000 - val_loss: 2.2646 - val_accuracy: 0.1852 - 328ms/epoch - 82ms/step\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 260: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0749 - accuracy: 1.0000 - val_loss: 2.2636 - val_accuracy: 0.1296 - 329ms/epoch - 82ms/step\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 261: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0862 - accuracy: 0.9921 - val_loss: 2.5893 - val_accuracy: 0.2222 - 341ms/epoch - 85ms/step\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 262: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0737 - accuracy: 1.0000 - val_loss: 3.1839 - val_accuracy: 0.2037 - 332ms/epoch - 83ms/step\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 263: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0592 - accuracy: 1.0000 - val_loss: 2.4071 - val_accuracy: 0.1852 - 336ms/epoch - 84ms/step\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 264: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0717 - accuracy: 1.0000 - val_loss: 2.2500 - val_accuracy: 0.1667 - 320ms/epoch - 80ms/step\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 265: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0723 - accuracy: 1.0000 - val_loss: 2.4046 - val_accuracy: 0.2407 - 323ms/epoch - 81ms/step\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 266: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0682 - accuracy: 1.0000 - val_loss: 2.3670 - val_accuracy: 0.2037 - 334ms/epoch - 84ms/step\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 267: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0607 - accuracy: 1.0000 - val_loss: 2.2370 - val_accuracy: 0.1667 - 343ms/epoch - 86ms/step\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 268: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0832 - accuracy: 1.0000 - val_loss: 2.2047 - val_accuracy: 0.1111 - 324ms/epoch - 81ms/step\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 269: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0736 - accuracy: 1.0000 - val_loss: 2.2893 - val_accuracy: 0.1296 - 336ms/epoch - 84ms/step\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 270: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0587 - accuracy: 1.0000 - val_loss: 2.2712 - val_accuracy: 0.1667 - 330ms/epoch - 83ms/step\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 271: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0710 - accuracy: 1.0000 - val_loss: 2.1747 - val_accuracy: 0.2037 - 322ms/epoch - 81ms/step\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 272: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0814 - accuracy: 1.0000 - val_loss: 2.1913 - val_accuracy: 0.1852 - 319ms/epoch - 80ms/step\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 273: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0845 - accuracy: 1.0000 - val_loss: 2.1649 - val_accuracy: 0.1852 - 337ms/epoch - 84ms/step\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 274: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0632 - accuracy: 1.0000 - val_loss: 2.1343 - val_accuracy: 0.1667 - 334ms/epoch - 83ms/step\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 275: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0841 - accuracy: 1.0000 - val_loss: 2.1620 - val_accuracy: 0.1852 - 326ms/epoch - 81ms/step\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 276: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0707 - accuracy: 1.0000 - val_loss: 2.1830 - val_accuracy: 0.1296 - 339ms/epoch - 85ms/step\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 277: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0649 - accuracy: 1.0000 - val_loss: 2.1981 - val_accuracy: 0.2037 - 335ms/epoch - 84ms/step\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 278: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0685 - accuracy: 1.0000 - val_loss: 2.1727 - val_accuracy: 0.1852 - 338ms/epoch - 84ms/step\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 279: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0647 - accuracy: 1.0000 - val_loss: 2.1933 - val_accuracy: 0.1111 - 345ms/epoch - 86ms/step\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 280: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0539 - accuracy: 1.0000 - val_loss: 2.1548 - val_accuracy: 0.0926 - 319ms/epoch - 80ms/step\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 281: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0655 - accuracy: 1.0000 - val_loss: 2.1876 - val_accuracy: 0.1667 - 334ms/epoch - 83ms/step\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 282: val_loss did not improve from 1.38531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.0615 - accuracy: 1.0000 - val_loss: 2.1999 - val_accuracy: 0.1852 - 330ms/epoch - 82ms/step\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 283: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0702 - accuracy: 1.0000 - val_loss: 2.1551 - val_accuracy: 0.1667 - 324ms/epoch - 81ms/step\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 284: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0632 - accuracy: 1.0000 - val_loss: 2.1283 - val_accuracy: 0.1481 - 332ms/epoch - 83ms/step\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 285: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0611 - accuracy: 1.0000 - val_loss: 2.1590 - val_accuracy: 0.1481 - 351ms/epoch - 88ms/step\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 286: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0607 - accuracy: 1.0000 - val_loss: 2.2028 - val_accuracy: 0.1852 - 325ms/epoch - 81ms/step\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 287: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0763 - accuracy: 1.0000 - val_loss: 2.1621 - val_accuracy: 0.1481 - 329ms/epoch - 82ms/step\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 288: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0719 - accuracy: 1.0000 - val_loss: 2.2486 - val_accuracy: 0.1852 - 330ms/epoch - 83ms/step\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 289: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0641 - accuracy: 1.0000 - val_loss: 2.2885 - val_accuracy: 0.2222 - 351ms/epoch - 88ms/step\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 290: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0676 - accuracy: 1.0000 - val_loss: 2.3355 - val_accuracy: 0.1667 - 351ms/epoch - 88ms/step\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 291: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0651 - accuracy: 1.0000 - val_loss: 2.2351 - val_accuracy: 0.1852 - 328ms/epoch - 82ms/step\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 292: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0692 - accuracy: 1.0000 - val_loss: 2.2982 - val_accuracy: 0.2037 - 335ms/epoch - 84ms/step\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 293: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0630 - accuracy: 1.0000 - val_loss: 2.4212 - val_accuracy: 0.2222 - 333ms/epoch - 83ms/step\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 294: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0636 - accuracy: 1.0000 - val_loss: 2.3143 - val_accuracy: 0.2222 - 324ms/epoch - 81ms/step\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 295: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0715 - accuracy: 1.0000 - val_loss: 2.2156 - val_accuracy: 0.2037 - 326ms/epoch - 82ms/step\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 296: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0543 - accuracy: 1.0000 - val_loss: 2.3660 - val_accuracy: 0.2037 - 315ms/epoch - 79ms/step\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 297: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0527 - accuracy: 1.0000 - val_loss: 2.2625 - val_accuracy: 0.2037 - 333ms/epoch - 83ms/step\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 298: val_loss did not improve from 1.38531\n",
      "4/4 - 1s - loss: 0.0635 - accuracy: 1.0000 - val_loss: 2.3413 - val_accuracy: 0.1852 - 685ms/epoch - 171ms/step\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 299: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0643 - accuracy: 1.0000 - val_loss: 2.1823 - val_accuracy: 0.1667 - 334ms/epoch - 83ms/step\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 300: val_loss did not improve from 1.38531\n",
      "4/4 - 0s - loss: 0.0586 - accuracy: 1.0000 - val_loss: 2.1088 - val_accuracy: 0.1852 - 332ms/epoch - 83ms/step\n",
      "2/2 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2022-11-11 09:38:34.486515: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_9451784\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:621088\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 09:38:38.494477: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_9454854\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:621130\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38604, saving model to checkpoint1.h5\n",
      "4/4 - 5s - loss: 1.4490 - accuracy: 0.3095 - val_loss: 1.3860 - val_accuracy: 0.2593 - 5s/epoch - 1s/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss did not improve from 1.38604\n",
      "4/4 - 0s - loss: 1.3439 - accuracy: 0.3651 - val_loss: 1.3862 - val_accuracy: 0.2593 - 330ms/epoch - 83ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss did not improve from 1.38604\n",
      "4/4 - 0s - loss: 1.2871 - accuracy: 0.4762 - val_loss: 1.3865 - val_accuracy: 0.2222 - 343ms/epoch - 86ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss did not improve from 1.38604\n",
      "4/4 - 0s - loss: 1.2741 - accuracy: 0.4524 - val_loss: 1.3868 - val_accuracy: 0.1852 - 326ms/epoch - 81ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss did not improve from 1.38604\n",
      "4/4 - 0s - loss: 1.2042 - accuracy: 0.5556 - val_loss: 1.3869 - val_accuracy: 0.1852 - 335ms/epoch - 84ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.38604\n",
      "4/4 - 0s - loss: 1.2121 - accuracy: 0.5794 - val_loss: 1.3871 - val_accuracy: 0.1852 - 341ms/epoch - 85ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 1.38604\n",
      "4/4 - 0s - loss: 1.1889 - accuracy: 0.6190 - val_loss: 1.3874 - val_accuracy: 0.1852 - 331ms/epoch - 83ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 1.38604\n",
      "4/4 - 0s - loss: 1.1835 - accuracy: 0.5317 - val_loss: 1.3878 - val_accuracy: 0.1852 - 345ms/epoch - 86ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 1.38604\n",
      "4/4 - 0s - loss: 1.1165 - accuracy: 0.6508 - val_loss: 1.3876 - val_accuracy: 0.1667 - 335ms/epoch - 84ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.38604\n",
      "4/4 - 0s - loss: 1.1119 - accuracy: 0.6667 - val_loss: 1.3876 - val_accuracy: 0.1667 - 338ms/epoch - 84ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.38604\n",
      "4/4 - 0s - loss: 1.0452 - accuracy: 0.6984 - val_loss: 1.3881 - val_accuracy: 0.1852 - 322ms/epoch - 81ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.38604\n",
      "4/4 - 0s - loss: 1.0366 - accuracy: 0.6746 - val_loss: 1.3881 - val_accuracy: 0.1667 - 332ms/epoch - 83ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.38604\n",
      "4/4 - 0s - loss: 1.0290 - accuracy: 0.6984 - val_loss: 1.3878 - val_accuracy: 0.1852 - 322ms/epoch - 81ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 1.38604\n",
      "4/4 - 0s - loss: 1.0176 - accuracy: 0.7381 - val_loss: 1.3873 - val_accuracy: 0.2037 - 325ms/epoch - 81ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.38604\n",
      "4/4 - 0s - loss: 0.9826 - accuracy: 0.7222 - val_loss: 1.3876 - val_accuracy: 0.1667 - 331ms/epoch - 83ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 1.38604\n",
      "4/4 - 0s - loss: 0.9718 - accuracy: 0.7460 - val_loss: 1.3866 - val_accuracy: 0.2037 - 344ms/epoch - 86ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 1.38604\n",
      "4/4 - 0s - loss: 0.9359 - accuracy: 0.7540 - val_loss: 1.3871 - val_accuracy: 0.2222 - 329ms/epoch - 82ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 1.38604\n",
      "4/4 - 0s - loss: 0.9378 - accuracy: 0.7143 - val_loss: 1.3865 - val_accuracy: 0.2407 - 336ms/epoch - 84ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss improved from 1.38604 to 1.38568, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.9252 - accuracy: 0.7619 - val_loss: 1.3857 - val_accuracy: 0.2407 - 376ms/epoch - 94ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss improved from 1.38568 to 1.38455, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.9203 - accuracy: 0.7540 - val_loss: 1.3845 - val_accuracy: 0.2778 - 385ms/epoch - 96ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss improved from 1.38455 to 1.38450, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.9254 - accuracy: 0.7381 - val_loss: 1.3845 - val_accuracy: 0.2593 - 385ms/epoch - 96ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 1.38450\n",
      "4/4 - 0s - loss: 0.8978 - accuracy: 0.8016 - val_loss: 1.3847 - val_accuracy: 0.2593 - 325ms/epoch - 81ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss improved from 1.38450 to 1.38258, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.8968 - accuracy: 0.8095 - val_loss: 1.3826 - val_accuracy: 0.3148 - 389ms/epoch - 97ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 1.38258\n",
      "4/4 - 0s - loss: 0.8489 - accuracy: 0.8333 - val_loss: 1.3828 - val_accuracy: 0.2963 - 326ms/epoch - 82ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss improved from 1.38258 to 1.38139, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.8428 - accuracy: 0.8254 - val_loss: 1.3814 - val_accuracy: 0.3333 - 393ms/epoch - 98ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss improved from 1.38139 to 1.38114, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.8363 - accuracy: 0.8254 - val_loss: 1.3811 - val_accuracy: 0.2778 - 375ms/epoch - 94ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss improved from 1.38114 to 1.37984, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.8082 - accuracy: 0.8492 - val_loss: 1.3798 - val_accuracy: 0.2593 - 378ms/epoch - 95ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 1.37984\n",
      "4/4 - 0s - loss: 0.8372 - accuracy: 0.8175 - val_loss: 1.3803 - val_accuracy: 0.2593 - 337ms/epoch - 84ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss improved from 1.37984 to 1.37747, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.8285 - accuracy: 0.8175 - val_loss: 1.3775 - val_accuracy: 0.3704 - 391ms/epoch - 98ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 1.37747\n",
      "4/4 - 0s - loss: 0.7879 - accuracy: 0.8413 - val_loss: 1.3789 - val_accuracy: 0.2593 - 343ms/epoch - 86ms/step\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 1.37747\n",
      "4/4 - 0s - loss: 0.7750 - accuracy: 0.8651 - val_loss: 1.3775 - val_accuracy: 0.2593 - 322ms/epoch - 80ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss improved from 1.37747 to 1.37411, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.7854 - accuracy: 0.8095 - val_loss: 1.3741 - val_accuracy: 0.3333 - 386ms/epoch - 97ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 1.37411\n",
      "4/4 - 0s - loss: 0.7493 - accuracy: 0.8810 - val_loss: 1.3750 - val_accuracy: 0.2593 - 335ms/epoch - 84ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss improved from 1.37411 to 1.37336, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.7491 - accuracy: 0.8651 - val_loss: 1.3734 - val_accuracy: 0.2778 - 405ms/epoch - 101ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 1.37336\n",
      "4/4 - 0s - loss: 0.7272 - accuracy: 0.8810 - val_loss: 1.3738 - val_accuracy: 0.2593 - 325ms/epoch - 81ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss improved from 1.37336 to 1.37039, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.6730 - accuracy: 0.9048 - val_loss: 1.3704 - val_accuracy: 0.3519 - 382ms/epoch - 95ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 1.37039\n",
      "4/4 - 0s - loss: 0.6873 - accuracy: 0.8889 - val_loss: 1.3723 - val_accuracy: 0.2593 - 343ms/epoch - 86ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 1.37039\n",
      "4/4 - 0s - loss: 0.7078 - accuracy: 0.8730 - val_loss: 1.3719 - val_accuracy: 0.2963 - 328ms/epoch - 82ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 1.37039\n",
      "4/4 - 0s - loss: 0.6819 - accuracy: 0.8889 - val_loss: 1.3744 - val_accuracy: 0.2593 - 325ms/epoch - 81ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss improved from 1.37039 to 1.36978, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.6809 - accuracy: 0.9048 - val_loss: 1.3698 - val_accuracy: 0.2778 - 388ms/epoch - 97ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 1.36978\n",
      "4/4 - 0s - loss: 0.6638 - accuracy: 0.9444 - val_loss: 1.3710 - val_accuracy: 0.3148 - 320ms/epoch - 80ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss improved from 1.36978 to 1.36909, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.6586 - accuracy: 0.9444 - val_loss: 1.3691 - val_accuracy: 0.3148 - 395ms/epoch - 99ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 1.36909\n",
      "4/4 - 0s - loss: 0.6329 - accuracy: 0.9286 - val_loss: 1.3714 - val_accuracy: 0.3148 - 339ms/epoch - 85ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 1.36909\n",
      "4/4 - 0s - loss: 0.5948 - accuracy: 0.9365 - val_loss: 1.3696 - val_accuracy: 0.3148 - 326ms/epoch - 81ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 1.36909\n",
      "4/4 - 0s - loss: 0.6149 - accuracy: 0.8889 - val_loss: 1.3760 - val_accuracy: 0.2778 - 326ms/epoch - 82ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 1.36909\n",
      "4/4 - 0s - loss: 0.6243 - accuracy: 0.9444 - val_loss: 1.3720 - val_accuracy: 0.3333 - 343ms/epoch - 86ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss improved from 1.36909 to 1.36857, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.5860 - accuracy: 0.9365 - val_loss: 1.3686 - val_accuracy: 0.3704 - 377ms/epoch - 94ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.5829 - accuracy: 0.9444 - val_loss: 1.3708 - val_accuracy: 0.3519 - 326ms/epoch - 81ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.5610 - accuracy: 0.9524 - val_loss: 1.3772 - val_accuracy: 0.3148 - 333ms/epoch - 83ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.5190 - accuracy: 0.9683 - val_loss: 1.3784 - val_accuracy: 0.3333 - 342ms/epoch - 86ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.5351 - accuracy: 0.9524 - val_loss: 1.3845 - val_accuracy: 0.3333 - 330ms/epoch - 83ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.5240 - accuracy: 0.9841 - val_loss: 1.3792 - val_accuracy: 0.3519 - 338ms/epoch - 84ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.4992 - accuracy: 0.9683 - val_loss: 1.3762 - val_accuracy: 0.3148 - 343ms/epoch - 86ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.5080 - accuracy: 0.9683 - val_loss: 1.3959 - val_accuracy: 0.3148 - 338ms/epoch - 85ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.4743 - accuracy: 0.9683 - val_loss: 1.3934 - val_accuracy: 0.3148 - 328ms/epoch - 82ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.4596 - accuracy: 0.9841 - val_loss: 1.3877 - val_accuracy: 0.3148 - 329ms/epoch - 82ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.4410 - accuracy: 0.9841 - val_loss: 1.4115 - val_accuracy: 0.3148 - 322ms/epoch - 81ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.4276 - accuracy: 0.9921 - val_loss: 1.3940 - val_accuracy: 0.2963 - 350ms/epoch - 87ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.4251 - accuracy: 0.9921 - val_loss: 1.4090 - val_accuracy: 0.3333 - 332ms/epoch - 83ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.4446 - accuracy: 0.9762 - val_loss: 1.4038 - val_accuracy: 0.2963 - 329ms/epoch - 82ms/step\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.4339 - accuracy: 0.9921 - val_loss: 1.4096 - val_accuracy: 0.3333 - 341ms/epoch - 85ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.4831 - accuracy: 0.9841 - val_loss: 1.4162 - val_accuracy: 0.2778 - 335ms/epoch - 84ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.4248 - accuracy: 0.9921 - val_loss: 1.4223 - val_accuracy: 0.3333 - 321ms/epoch - 80ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.4530 - accuracy: 0.9603 - val_loss: 1.4450 - val_accuracy: 0.3148 - 340ms/epoch - 85ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.4210 - accuracy: 0.9762 - val_loss: 1.4253 - val_accuracy: 0.3333 - 343ms/epoch - 86ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.4224 - accuracy: 0.9841 - val_loss: 1.4279 - val_accuracy: 0.3333 - 335ms/epoch - 84ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.4078 - accuracy: 0.9841 - val_loss: 1.4256 - val_accuracy: 0.3333 - 330ms/epoch - 82ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.3925 - accuracy: 1.0000 - val_loss: 1.4265 - val_accuracy: 0.3148 - 329ms/epoch - 82ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.4232 - accuracy: 0.9841 - val_loss: 1.4222 - val_accuracy: 0.2778 - 320ms/epoch - 80ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.3781 - accuracy: 0.9762 - val_loss: 1.4461 - val_accuracy: 0.3333 - 338ms/epoch - 84ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.3943 - accuracy: 0.9921 - val_loss: 1.4418 - val_accuracy: 0.3148 - 333ms/epoch - 83ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.3666 - accuracy: 0.9841 - val_loss: 1.4641 - val_accuracy: 0.2963 - 329ms/epoch - 82ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.3531 - accuracy: 0.9921 - val_loss: 1.4270 - val_accuracy: 0.3333 - 316ms/epoch - 79ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.3524 - accuracy: 0.9921 - val_loss: 1.4662 - val_accuracy: 0.2778 - 336ms/epoch - 84ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.3448 - accuracy: 1.0000 - val_loss: 1.4617 - val_accuracy: 0.2963 - 330ms/epoch - 82ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.3202 - accuracy: 0.9921 - val_loss: 1.4851 - val_accuracy: 0.3333 - 352ms/epoch - 88ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.3950 - accuracy: 0.9921 - val_loss: 1.4376 - val_accuracy: 0.2778 - 335ms/epoch - 84ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.3341 - accuracy: 1.0000 - val_loss: 1.5083 - val_accuracy: 0.2963 - 332ms/epoch - 83ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.3673 - accuracy: 0.9841 - val_loss: 1.4706 - val_accuracy: 0.3148 - 332ms/epoch - 83ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.3278 - accuracy: 1.0000 - val_loss: 1.4716 - val_accuracy: 0.3148 - 333ms/epoch - 83ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.3071 - accuracy: 1.0000 - val_loss: 1.4872 - val_accuracy: 0.3148 - 344ms/epoch - 86ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.2987 - accuracy: 1.0000 - val_loss: 1.4565 - val_accuracy: 0.3148 - 343ms/epoch - 86ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.3254 - accuracy: 0.9841 - val_loss: 1.5783 - val_accuracy: 0.2963 - 343ms/epoch - 86ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.2996 - accuracy: 1.0000 - val_loss: 1.4680 - val_accuracy: 0.3148 - 335ms/epoch - 84ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.3233 - accuracy: 0.9841 - val_loss: 1.5277 - val_accuracy: 0.3148 - 324ms/epoch - 81ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.3105 - accuracy: 1.0000 - val_loss: 1.4720 - val_accuracy: 0.3519 - 324ms/epoch - 81ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.3007 - accuracy: 1.0000 - val_loss: 1.5113 - val_accuracy: 0.2963 - 326ms/epoch - 81ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.2941 - accuracy: 1.0000 - val_loss: 1.5458 - val_accuracy: 0.3148 - 344ms/epoch - 86ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.2878 - accuracy: 0.9921 - val_loss: 1.5785 - val_accuracy: 0.3333 - 335ms/epoch - 84ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.2944 - accuracy: 0.9841 - val_loss: 1.4856 - val_accuracy: 0.2778 - 330ms/epoch - 82ms/step\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.2657 - accuracy: 1.0000 - val_loss: 1.5969 - val_accuracy: 0.2963 - 327ms/epoch - 82ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.2603 - accuracy: 1.0000 - val_loss: 1.5142 - val_accuracy: 0.3333 - 334ms/epoch - 83ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 1.36857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.2542 - accuracy: 1.0000 - val_loss: 1.6359 - val_accuracy: 0.3333 - 333ms/epoch - 83ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.2660 - accuracy: 1.0000 - val_loss: 1.4956 - val_accuracy: 0.3148 - 335ms/epoch - 84ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.2306 - accuracy: 1.0000 - val_loss: 1.6526 - val_accuracy: 0.3148 - 327ms/epoch - 82ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.2459 - accuracy: 0.9841 - val_loss: 1.5604 - val_accuracy: 0.2963 - 327ms/epoch - 82ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.2474 - accuracy: 0.9921 - val_loss: 1.5820 - val_accuracy: 0.3333 - 337ms/epoch - 84ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.2461 - accuracy: 1.0000 - val_loss: 1.5783 - val_accuracy: 0.2963 - 339ms/epoch - 85ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.2503 - accuracy: 1.0000 - val_loss: 1.4975 - val_accuracy: 0.2407 - 337ms/epoch - 84ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.2554 - accuracy: 1.0000 - val_loss: 1.6734 - val_accuracy: 0.3148 - 337ms/epoch - 84ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.2637 - accuracy: 1.0000 - val_loss: 1.5483 - val_accuracy: 0.3148 - 337ms/epoch - 84ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.2280 - accuracy: 1.0000 - val_loss: 1.7280 - val_accuracy: 0.2778 - 322ms/epoch - 80ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.2327 - accuracy: 1.0000 - val_loss: 1.5583 - val_accuracy: 0.2778 - 333ms/epoch - 83ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.2491 - accuracy: 0.9921 - val_loss: 1.6981 - val_accuracy: 0.3519 - 333ms/epoch - 83ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.2629 - accuracy: 1.0000 - val_loss: 1.5379 - val_accuracy: 0.3148 - 326ms/epoch - 81ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.2434 - accuracy: 0.9921 - val_loss: 1.6536 - val_accuracy: 0.2963 - 346ms/epoch - 86ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.2512 - accuracy: 0.9921 - val_loss: 1.5683 - val_accuracy: 0.3333 - 330ms/epoch - 83ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.2348 - accuracy: 1.0000 - val_loss: 1.5312 - val_accuracy: 0.2593 - 335ms/epoch - 84ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.2494 - accuracy: 1.0000 - val_loss: 1.7712 - val_accuracy: 0.3333 - 329ms/epoch - 82ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.2451 - accuracy: 1.0000 - val_loss: 1.5886 - val_accuracy: 0.3148 - 327ms/epoch - 82ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.3040 - accuracy: 0.9921 - val_loss: 1.7223 - val_accuracy: 0.2778 - 330ms/epoch - 83ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.2537 - accuracy: 1.0000 - val_loss: 1.7317 - val_accuracy: 0.2593 - 331ms/epoch - 83ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 1.6047 - val_accuracy: 0.2407 - 342ms/epoch - 86ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.2220 - accuracy: 1.0000 - val_loss: 1.6945 - val_accuracy: 0.2407 - 352ms/epoch - 88ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.2414 - accuracy: 1.0000 - val_loss: 1.5579 - val_accuracy: 0.2963 - 324ms/epoch - 81ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 1.6432 - val_accuracy: 0.2778 - 349ms/epoch - 87ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.2240 - accuracy: 1.0000 - val_loss: 1.6587 - val_accuracy: 0.2963 - 342ms/epoch - 86ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 1.6152 - val_accuracy: 0.2222 - 332ms/epoch - 83ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1973 - accuracy: 1.0000 - val_loss: 1.6217 - val_accuracy: 0.2963 - 324ms/epoch - 81ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1944 - accuracy: 1.0000 - val_loss: 1.6323 - val_accuracy: 0.3333 - 334ms/epoch - 83ms/step\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1897 - accuracy: 1.0000 - val_loss: 1.6416 - val_accuracy: 0.3148 - 331ms/epoch - 83ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1983 - accuracy: 1.0000 - val_loss: 1.6401 - val_accuracy: 0.2593 - 335ms/epoch - 84ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1739 - accuracy: 1.0000 - val_loss: 1.6397 - val_accuracy: 0.2407 - 323ms/epoch - 81ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1731 - accuracy: 1.0000 - val_loss: 1.6204 - val_accuracy: 0.2037 - 339ms/epoch - 85ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.2233 - accuracy: 0.9921 - val_loss: 1.6320 - val_accuracy: 0.2778 - 329ms/epoch - 82ms/step\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1733 - accuracy: 1.0000 - val_loss: 1.6685 - val_accuracy: 0.2407 - 330ms/epoch - 83ms/step\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1837 - accuracy: 1.0000 - val_loss: 1.6330 - val_accuracy: 0.2037 - 335ms/epoch - 84ms/step\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1868 - accuracy: 1.0000 - val_loss: 1.6440 - val_accuracy: 0.2593 - 323ms/epoch - 81ms/step\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1590 - accuracy: 1.0000 - val_loss: 1.6281 - val_accuracy: 0.2778 - 345ms/epoch - 86ms/step\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1807 - accuracy: 1.0000 - val_loss: 1.6814 - val_accuracy: 0.3148 - 330ms/epoch - 83ms/step\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1782 - accuracy: 1.0000 - val_loss: 1.6815 - val_accuracy: 0.2963 - 323ms/epoch - 81ms/step\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1669 - accuracy: 1.0000 - val_loss: 1.6453 - val_accuracy: 0.2593 - 321ms/epoch - 80ms/step\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1887 - accuracy: 1.0000 - val_loss: 1.7330 - val_accuracy: 0.2963 - 327ms/epoch - 82ms/step\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.2088 - accuracy: 0.9921 - val_loss: 1.6680 - val_accuracy: 0.3333 - 323ms/epoch - 81ms/step\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 135: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1938 - accuracy: 1.0000 - val_loss: 1.7753 - val_accuracy: 0.2593 - 343ms/epoch - 86ms/step\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 136: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1974 - accuracy: 0.9921 - val_loss: 2.0543 - val_accuracy: 0.2778 - 353ms/epoch - 88ms/step\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 137: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1941 - accuracy: 1.0000 - val_loss: 1.7401 - val_accuracy: 0.2037 - 328ms/epoch - 82ms/step\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 138: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.2028 - accuracy: 1.0000 - val_loss: 1.7424 - val_accuracy: 0.2963 - 320ms/epoch - 80ms/step\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 139: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1668 - accuracy: 1.0000 - val_loss: 1.6997 - val_accuracy: 0.2593 - 322ms/epoch - 80ms/step\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 140: val_loss did not improve from 1.36857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.1604 - accuracy: 0.9921 - val_loss: 1.7189 - val_accuracy: 0.2037 - 341ms/epoch - 85ms/step\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 141: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1675 - accuracy: 1.0000 - val_loss: 1.7548 - val_accuracy: 0.2037 - 322ms/epoch - 80ms/step\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 142: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1619 - accuracy: 1.0000 - val_loss: 1.8065 - val_accuracy: 0.1667 - 335ms/epoch - 84ms/step\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 143: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1561 - accuracy: 1.0000 - val_loss: 1.7493 - val_accuracy: 0.2037 - 324ms/epoch - 81ms/step\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 144: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1430 - accuracy: 1.0000 - val_loss: 1.7450 - val_accuracy: 0.2037 - 340ms/epoch - 85ms/step\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 145: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1521 - accuracy: 1.0000 - val_loss: 1.7637 - val_accuracy: 0.2222 - 325ms/epoch - 81ms/step\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 146: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1640 - accuracy: 1.0000 - val_loss: 1.7850 - val_accuracy: 0.2037 - 349ms/epoch - 87ms/step\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 147: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1308 - accuracy: 1.0000 - val_loss: 1.7339 - val_accuracy: 0.2778 - 342ms/epoch - 86ms/step\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 148: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1507 - accuracy: 1.0000 - val_loss: 1.6870 - val_accuracy: 0.2778 - 330ms/epoch - 83ms/step\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 149: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1598 - accuracy: 1.0000 - val_loss: 1.7384 - val_accuracy: 0.2222 - 337ms/epoch - 84ms/step\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 150: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1418 - accuracy: 1.0000 - val_loss: 1.7546 - val_accuracy: 0.2593 - 329ms/epoch - 82ms/step\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 151: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1435 - accuracy: 1.0000 - val_loss: 1.7141 - val_accuracy: 0.2037 - 343ms/epoch - 86ms/step\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 152: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1400 - accuracy: 1.0000 - val_loss: 1.7565 - val_accuracy: 0.2407 - 338ms/epoch - 84ms/step\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 153: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1379 - accuracy: 1.0000 - val_loss: 1.8199 - val_accuracy: 0.2778 - 319ms/epoch - 80ms/step\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 154: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1333 - accuracy: 1.0000 - val_loss: 1.7630 - val_accuracy: 0.3148 - 341ms/epoch - 85ms/step\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 155: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1313 - accuracy: 1.0000 - val_loss: 1.7522 - val_accuracy: 0.2407 - 335ms/epoch - 84ms/step\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 156: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1635 - accuracy: 1.0000 - val_loss: 1.8127 - val_accuracy: 0.2037 - 321ms/epoch - 80ms/step\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 157: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1398 - accuracy: 1.0000 - val_loss: 1.8018 - val_accuracy: 0.2037 - 340ms/epoch - 85ms/step\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 158: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1206 - accuracy: 1.0000 - val_loss: 1.7839 - val_accuracy: 0.2593 - 339ms/epoch - 85ms/step\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 159: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1335 - accuracy: 1.0000 - val_loss: 1.7789 - val_accuracy: 0.2222 - 327ms/epoch - 82ms/step\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 160: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1367 - accuracy: 1.0000 - val_loss: 1.8366 - val_accuracy: 0.2407 - 340ms/epoch - 85ms/step\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 161: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1382 - accuracy: 1.0000 - val_loss: 1.8502 - val_accuracy: 0.2037 - 329ms/epoch - 82ms/step\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 162: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1536 - accuracy: 1.0000 - val_loss: 1.9643 - val_accuracy: 0.1481 - 334ms/epoch - 83ms/step\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 163: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1703 - accuracy: 0.9921 - val_loss: 1.8618 - val_accuracy: 0.2037 - 335ms/epoch - 84ms/step\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 164: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1463 - accuracy: 1.0000 - val_loss: 1.8015 - val_accuracy: 0.2037 - 330ms/epoch - 83ms/step\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 165: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1409 - accuracy: 1.0000 - val_loss: 1.8292 - val_accuracy: 0.2037 - 324ms/epoch - 81ms/step\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 166: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1486 - accuracy: 1.0000 - val_loss: 1.9230 - val_accuracy: 0.1667 - 334ms/epoch - 84ms/step\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 167: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1460 - accuracy: 1.0000 - val_loss: 1.9402 - val_accuracy: 0.1667 - 322ms/epoch - 80ms/step\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 168: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1372 - accuracy: 1.0000 - val_loss: 1.9093 - val_accuracy: 0.1852 - 337ms/epoch - 84ms/step\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 169: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1449 - accuracy: 1.0000 - val_loss: 1.9801 - val_accuracy: 0.1667 - 334ms/epoch - 84ms/step\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 170: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1368 - accuracy: 1.0000 - val_loss: 2.0248 - val_accuracy: 0.2222 - 325ms/epoch - 81ms/step\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 171: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1271 - accuracy: 1.0000 - val_loss: 1.9978 - val_accuracy: 0.2222 - 321ms/epoch - 80ms/step\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 172: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1158 - accuracy: 1.0000 - val_loss: 1.9303 - val_accuracy: 0.1852 - 341ms/epoch - 85ms/step\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 173: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1428 - accuracy: 1.0000 - val_loss: 1.8417 - val_accuracy: 0.2037 - 330ms/epoch - 83ms/step\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 174: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1326 - accuracy: 1.0000 - val_loss: 1.9601 - val_accuracy: 0.1852 - 330ms/epoch - 82ms/step\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 175: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1177 - accuracy: 1.0000 - val_loss: 1.8384 - val_accuracy: 0.2222 - 338ms/epoch - 85ms/step\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 176: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1378 - accuracy: 1.0000 - val_loss: 1.8682 - val_accuracy: 0.2593 - 338ms/epoch - 85ms/step\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 177: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1240 - accuracy: 1.0000 - val_loss: 1.8263 - val_accuracy: 0.2407 - 333ms/epoch - 83ms/step\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 178: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1171 - accuracy: 1.0000 - val_loss: 1.8309 - val_accuracy: 0.2037 - 331ms/epoch - 83ms/step\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 179: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1212 - accuracy: 1.0000 - val_loss: 1.9042 - val_accuracy: 0.1296 - 340ms/epoch - 85ms/step\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 180: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1182 - accuracy: 1.0000 - val_loss: 1.7828 - val_accuracy: 0.2407 - 337ms/epoch - 84ms/step\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 181: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1079 - accuracy: 1.0000 - val_loss: 1.9112 - val_accuracy: 0.2037 - 321ms/epoch - 80ms/step\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 182: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1380 - accuracy: 1.0000 - val_loss: 1.8889 - val_accuracy: 0.2037 - 330ms/epoch - 82ms/step\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 183: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1265 - accuracy: 1.0000 - val_loss: 1.9022 - val_accuracy: 0.1481 - 321ms/epoch - 80ms/step\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 184: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1419 - accuracy: 1.0000 - val_loss: 1.8273 - val_accuracy: 0.2593 - 339ms/epoch - 85ms/step\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 185: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1146 - accuracy: 1.0000 - val_loss: 1.8131 - val_accuracy: 0.2037 - 329ms/epoch - 82ms/step\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 186: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1215 - accuracy: 1.0000 - val_loss: 1.8268 - val_accuracy: 0.1852 - 344ms/epoch - 86ms/step\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 187: val_loss did not improve from 1.36857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.1237 - accuracy: 1.0000 - val_loss: 1.8237 - val_accuracy: 0.2222 - 333ms/epoch - 83ms/step\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 188: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1124 - accuracy: 1.0000 - val_loss: 1.8959 - val_accuracy: 0.2222 - 324ms/epoch - 81ms/step\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 189: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1046 - accuracy: 1.0000 - val_loss: 1.9863 - val_accuracy: 0.1481 - 340ms/epoch - 85ms/step\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 190: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1106 - accuracy: 1.0000 - val_loss: 2.0502 - val_accuracy: 0.1667 - 339ms/epoch - 85ms/step\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 191: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1102 - accuracy: 1.0000 - val_loss: 1.8499 - val_accuracy: 0.2407 - 326ms/epoch - 82ms/step\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 192: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1014 - accuracy: 1.0000 - val_loss: 1.8271 - val_accuracy: 0.2407 - 322ms/epoch - 81ms/step\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 193: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1053 - accuracy: 1.0000 - val_loss: 1.9765 - val_accuracy: 0.1667 - 339ms/epoch - 85ms/step\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 194: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1270 - accuracy: 1.0000 - val_loss: 1.9048 - val_accuracy: 0.2407 - 321ms/epoch - 80ms/step\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 195: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0896 - accuracy: 1.0000 - val_loss: 1.9086 - val_accuracy: 0.1852 - 324ms/epoch - 81ms/step\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 196: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1111 - accuracy: 1.0000 - val_loss: 2.0106 - val_accuracy: 0.1667 - 343ms/epoch - 86ms/step\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 197: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0954 - accuracy: 1.0000 - val_loss: 1.9293 - val_accuracy: 0.2222 - 336ms/epoch - 84ms/step\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 198: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1085 - accuracy: 1.0000 - val_loss: 2.0187 - val_accuracy: 0.1852 - 328ms/epoch - 82ms/step\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 199: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1210 - accuracy: 1.0000 - val_loss: 1.9952 - val_accuracy: 0.1852 - 324ms/epoch - 81ms/step\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 200: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1099 - accuracy: 1.0000 - val_loss: 2.1863 - val_accuracy: 0.1667 - 339ms/epoch - 85ms/step\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 201: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1075 - accuracy: 1.0000 - val_loss: 1.9258 - val_accuracy: 0.1481 - 318ms/epoch - 80ms/step\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 202: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1124 - accuracy: 1.0000 - val_loss: 1.9931 - val_accuracy: 0.1852 - 336ms/epoch - 84ms/step\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 203: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1053 - accuracy: 1.0000 - val_loss: 1.8961 - val_accuracy: 0.1852 - 330ms/epoch - 82ms/step\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 204: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0979 - accuracy: 1.0000 - val_loss: 1.9200 - val_accuracy: 0.2222 - 323ms/epoch - 81ms/step\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 205: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1160 - accuracy: 1.0000 - val_loss: 1.9542 - val_accuracy: 0.1481 - 328ms/epoch - 82ms/step\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 206: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1022 - accuracy: 1.0000 - val_loss: 1.9031 - val_accuracy: 0.2407 - 325ms/epoch - 81ms/step\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 207: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0843 - accuracy: 1.0000 - val_loss: 2.0582 - val_accuracy: 0.2407 - 323ms/epoch - 81ms/step\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 208: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0969 - accuracy: 1.0000 - val_loss: 1.9555 - val_accuracy: 0.1852 - 351ms/epoch - 88ms/step\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 209: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0971 - accuracy: 1.0000 - val_loss: 1.9758 - val_accuracy: 0.2037 - 325ms/epoch - 81ms/step\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 210: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0890 - accuracy: 1.0000 - val_loss: 1.8902 - val_accuracy: 0.2037 - 322ms/epoch - 81ms/step\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 211: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1072 - accuracy: 1.0000 - val_loss: 1.9977 - val_accuracy: 0.2222 - 344ms/epoch - 86ms/step\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 212: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0890 - accuracy: 1.0000 - val_loss: 1.9799 - val_accuracy: 0.1667 - 331ms/epoch - 83ms/step\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 213: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0936 - accuracy: 1.0000 - val_loss: 2.0064 - val_accuracy: 0.1852 - 334ms/epoch - 83ms/step\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 214: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0855 - accuracy: 1.0000 - val_loss: 2.1024 - val_accuracy: 0.2037 - 342ms/epoch - 86ms/step\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 215: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1079 - accuracy: 1.0000 - val_loss: 2.1138 - val_accuracy: 0.1481 - 332ms/epoch - 83ms/step\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 216: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0959 - accuracy: 1.0000 - val_loss: 2.0903 - val_accuracy: 0.1852 - 338ms/epoch - 84ms/step\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 217: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0845 - accuracy: 1.0000 - val_loss: 2.0023 - val_accuracy: 0.1852 - 318ms/epoch - 80ms/step\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 218: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0940 - accuracy: 1.0000 - val_loss: 1.8769 - val_accuracy: 0.2037 - 323ms/epoch - 81ms/step\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 219: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0900 - accuracy: 1.0000 - val_loss: 1.9088 - val_accuracy: 0.2222 - 325ms/epoch - 81ms/step\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 220: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0951 - accuracy: 1.0000 - val_loss: 1.8845 - val_accuracy: 0.1852 - 334ms/epoch - 83ms/step\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 221: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0865 - accuracy: 1.0000 - val_loss: 1.8663 - val_accuracy: 0.1852 - 335ms/epoch - 84ms/step\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 222: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1032 - accuracy: 1.0000 - val_loss: 1.8369 - val_accuracy: 0.2037 - 337ms/epoch - 84ms/step\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 223: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0805 - accuracy: 1.0000 - val_loss: 1.9796 - val_accuracy: 0.1667 - 355ms/epoch - 89ms/step\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 224: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0869 - accuracy: 1.0000 - val_loss: 2.0035 - val_accuracy: 0.1667 - 325ms/epoch - 81ms/step\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 225: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0776 - accuracy: 1.0000 - val_loss: 1.8976 - val_accuracy: 0.2222 - 327ms/epoch - 82ms/step\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 226: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0862 - accuracy: 1.0000 - val_loss: 1.8472 - val_accuracy: 0.2037 - 327ms/epoch - 82ms/step\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 227: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0813 - accuracy: 1.0000 - val_loss: 1.9751 - val_accuracy: 0.2037 - 336ms/epoch - 84ms/step\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 228: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0807 - accuracy: 1.0000 - val_loss: 1.8356 - val_accuracy: 0.2222 - 324ms/epoch - 81ms/step\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 229: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0831 - accuracy: 1.0000 - val_loss: 1.8726 - val_accuracy: 0.2407 - 330ms/epoch - 83ms/step\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 230: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0864 - accuracy: 1.0000 - val_loss: 1.8257 - val_accuracy: 0.2407 - 335ms/epoch - 84ms/step\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 231: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0751 - accuracy: 1.0000 - val_loss: 1.8823 - val_accuracy: 0.1667 - 334ms/epoch - 84ms/step\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 232: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0981 - accuracy: 1.0000 - val_loss: 1.8854 - val_accuracy: 0.2222 - 339ms/epoch - 85ms/step\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 233: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0799 - accuracy: 1.0000 - val_loss: 2.1999 - val_accuracy: 0.3333 - 342ms/epoch - 86ms/step\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 234: val_loss did not improve from 1.36857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.0752 - accuracy: 1.0000 - val_loss: 2.0858 - val_accuracy: 0.2037 - 328ms/epoch - 82ms/step\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 235: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0911 - accuracy: 1.0000 - val_loss: 2.0025 - val_accuracy: 0.1667 - 336ms/epoch - 84ms/step\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 236: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0887 - accuracy: 1.0000 - val_loss: 2.1233 - val_accuracy: 0.1667 - 339ms/epoch - 85ms/step\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 237: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0824 - accuracy: 1.0000 - val_loss: 2.1539 - val_accuracy: 0.1667 - 332ms/epoch - 83ms/step\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 238: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0937 - accuracy: 1.0000 - val_loss: 2.0812 - val_accuracy: 0.1667 - 339ms/epoch - 85ms/step\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 239: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1003 - accuracy: 0.9921 - val_loss: 2.1514 - val_accuracy: 0.2407 - 335ms/epoch - 84ms/step\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 240: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0784 - accuracy: 1.0000 - val_loss: 2.1476 - val_accuracy: 0.1667 - 338ms/epoch - 84ms/step\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 241: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0812 - accuracy: 1.0000 - val_loss: 2.2316 - val_accuracy: 0.1667 - 322ms/epoch - 81ms/step\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 242: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0863 - accuracy: 1.0000 - val_loss: 2.1140 - val_accuracy: 0.2037 - 326ms/epoch - 81ms/step\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 243: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0969 - accuracy: 1.0000 - val_loss: 2.0341 - val_accuracy: 0.1852 - 342ms/epoch - 86ms/step\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 244: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0928 - accuracy: 1.0000 - val_loss: 1.9461 - val_accuracy: 0.1852 - 340ms/epoch - 85ms/step\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 245: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0783 - accuracy: 1.0000 - val_loss: 2.0835 - val_accuracy: 0.1667 - 338ms/epoch - 85ms/step\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 246: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0781 - accuracy: 1.0000 - val_loss: 2.1419 - val_accuracy: 0.1667 - 325ms/epoch - 81ms/step\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 247: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0705 - accuracy: 1.0000 - val_loss: 1.9906 - val_accuracy: 0.1667 - 333ms/epoch - 83ms/step\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 248: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0672 - accuracy: 1.0000 - val_loss: 2.0851 - val_accuracy: 0.1852 - 331ms/epoch - 83ms/step\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 249: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0630 - accuracy: 1.0000 - val_loss: 1.9526 - val_accuracy: 0.1667 - 353ms/epoch - 88ms/step\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 250: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0749 - accuracy: 1.0000 - val_loss: 1.9332 - val_accuracy: 0.1667 - 338ms/epoch - 84ms/step\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 251: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0775 - accuracy: 1.0000 - val_loss: 1.9744 - val_accuracy: 0.2222 - 332ms/epoch - 83ms/step\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 252: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0772 - accuracy: 1.0000 - val_loss: 1.8247 - val_accuracy: 0.2407 - 337ms/epoch - 84ms/step\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 253: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0672 - accuracy: 1.0000 - val_loss: 1.8733 - val_accuracy: 0.2407 - 333ms/epoch - 83ms/step\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 254: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0828 - accuracy: 1.0000 - val_loss: 2.0798 - val_accuracy: 0.1481 - 335ms/epoch - 84ms/step\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 255: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0855 - accuracy: 1.0000 - val_loss: 1.9910 - val_accuracy: 0.1852 - 325ms/epoch - 81ms/step\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 256: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0903 - accuracy: 1.0000 - val_loss: 2.4411 - val_accuracy: 0.1852 - 342ms/epoch - 85ms/step\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 257: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0726 - accuracy: 1.0000 - val_loss: 2.0022 - val_accuracy: 0.2407 - 322ms/epoch - 81ms/step\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 258: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0912 - accuracy: 1.0000 - val_loss: 2.2873 - val_accuracy: 0.1481 - 322ms/epoch - 81ms/step\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 259: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0717 - accuracy: 1.0000 - val_loss: 1.8572 - val_accuracy: 0.1852 - 346ms/epoch - 87ms/step\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 260: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0696 - accuracy: 1.0000 - val_loss: 2.1044 - val_accuracy: 0.2037 - 329ms/epoch - 82ms/step\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 261: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0666 - accuracy: 1.0000 - val_loss: 2.2960 - val_accuracy: 0.1481 - 335ms/epoch - 84ms/step\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 262: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0857 - accuracy: 1.0000 - val_loss: 2.1092 - val_accuracy: 0.1296 - 334ms/epoch - 84ms/step\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 263: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0698 - accuracy: 1.0000 - val_loss: 2.0834 - val_accuracy: 0.1481 - 336ms/epoch - 84ms/step\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 264: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0653 - accuracy: 1.0000 - val_loss: 1.9483 - val_accuracy: 0.1852 - 331ms/epoch - 83ms/step\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 265: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0702 - accuracy: 1.0000 - val_loss: 2.0444 - val_accuracy: 0.1667 - 333ms/epoch - 83ms/step\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 266: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0636 - accuracy: 1.0000 - val_loss: 2.0228 - val_accuracy: 0.1481 - 323ms/epoch - 81ms/step\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 267: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0758 - accuracy: 1.0000 - val_loss: 1.9955 - val_accuracy: 0.1667 - 333ms/epoch - 83ms/step\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 268: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0738 - accuracy: 1.0000 - val_loss: 2.0390 - val_accuracy: 0.1852 - 350ms/epoch - 88ms/step\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 269: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0851 - accuracy: 1.0000 - val_loss: 1.9159 - val_accuracy: 0.1667 - 326ms/epoch - 81ms/step\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 270: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0589 - accuracy: 1.0000 - val_loss: 2.1029 - val_accuracy: 0.2037 - 338ms/epoch - 85ms/step\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 271: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0700 - accuracy: 1.0000 - val_loss: 2.2664 - val_accuracy: 0.1296 - 345ms/epoch - 86ms/step\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 272: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0594 - accuracy: 1.0000 - val_loss: 1.9744 - val_accuracy: 0.1296 - 330ms/epoch - 83ms/step\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 273: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0712 - accuracy: 1.0000 - val_loss: 2.0611 - val_accuracy: 0.1667 - 353ms/epoch - 88ms/step\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 274: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0888 - accuracy: 0.9921 - val_loss: 1.8892 - val_accuracy: 0.1481 - 337ms/epoch - 84ms/step\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 275: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0620 - accuracy: 1.0000 - val_loss: 1.9918 - val_accuracy: 0.2037 - 330ms/epoch - 83ms/step\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 276: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0735 - accuracy: 1.0000 - val_loss: 1.9758 - val_accuracy: 0.2407 - 329ms/epoch - 82ms/step\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 277: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0864 - accuracy: 1.0000 - val_loss: 1.9944 - val_accuracy: 0.2222 - 323ms/epoch - 81ms/step\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 278: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0612 - accuracy: 1.0000 - val_loss: 1.9085 - val_accuracy: 0.2222 - 326ms/epoch - 81ms/step\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 279: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0703 - accuracy: 1.0000 - val_loss: 2.0334 - val_accuracy: 0.2778 - 332ms/epoch - 83ms/step\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 280: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0657 - accuracy: 1.0000 - val_loss: 1.9466 - val_accuracy: 0.2037 - 334ms/epoch - 84ms/step\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 281: val_loss did not improve from 1.36857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.0758 - accuracy: 1.0000 - val_loss: 1.8731 - val_accuracy: 0.2222 - 342ms/epoch - 85ms/step\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 282: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.1169 - accuracy: 0.9921 - val_loss: 1.8913 - val_accuracy: 0.2593 - 332ms/epoch - 83ms/step\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 283: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0939 - accuracy: 0.9921 - val_loss: 1.9127 - val_accuracy: 0.1667 - 341ms/epoch - 85ms/step\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 284: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0845 - accuracy: 1.0000 - val_loss: 1.9189 - val_accuracy: 0.1667 - 320ms/epoch - 80ms/step\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 285: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0791 - accuracy: 1.0000 - val_loss: 2.1365 - val_accuracy: 0.1481 - 322ms/epoch - 81ms/step\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 286: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0747 - accuracy: 1.0000 - val_loss: 2.1007 - val_accuracy: 0.1667 - 332ms/epoch - 83ms/step\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 287: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0820 - accuracy: 1.0000 - val_loss: 2.1478 - val_accuracy: 0.1481 - 325ms/epoch - 81ms/step\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 288: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0645 - accuracy: 1.0000 - val_loss: 2.0572 - val_accuracy: 0.1667 - 360ms/epoch - 90ms/step\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 289: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0629 - accuracy: 1.0000 - val_loss: 2.0742 - val_accuracy: 0.1296 - 339ms/epoch - 85ms/step\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 290: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0948 - accuracy: 1.0000 - val_loss: 2.1210 - val_accuracy: 0.1667 - 328ms/epoch - 82ms/step\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 291: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0743 - accuracy: 1.0000 - val_loss: 2.2824 - val_accuracy: 0.2407 - 331ms/epoch - 83ms/step\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 292: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0661 - accuracy: 1.0000 - val_loss: 2.3408 - val_accuracy: 0.1111 - 328ms/epoch - 82ms/step\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 293: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0822 - accuracy: 1.0000 - val_loss: 1.9038 - val_accuracy: 0.2593 - 328ms/epoch - 82ms/step\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 294: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0643 - accuracy: 1.0000 - val_loss: 2.1293 - val_accuracy: 0.1667 - 333ms/epoch - 83ms/step\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 295: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0674 - accuracy: 1.0000 - val_loss: 1.9753 - val_accuracy: 0.2407 - 330ms/epoch - 82ms/step\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 296: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0634 - accuracy: 1.0000 - val_loss: 1.9465 - val_accuracy: 0.2407 - 326ms/epoch - 81ms/step\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 297: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0632 - accuracy: 1.0000 - val_loss: 1.9627 - val_accuracy: 0.2407 - 322ms/epoch - 81ms/step\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 298: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0645 - accuracy: 1.0000 - val_loss: 2.0113 - val_accuracy: 0.1852 - 341ms/epoch - 85ms/step\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 299: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0563 - accuracy: 1.0000 - val_loss: 2.0596 - val_accuracy: 0.1296 - 336ms/epoch - 84ms/step\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 300: val_loss did not improve from 1.36857\n",
      "4/4 - 0s - loss: 0.0694 - accuracy: 1.0000 - val_loss: 1.8742 - val_accuracy: 0.2407 - 323ms/epoch - 81ms/step\n",
      "2/2 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2022-11-11 09:40:23.433075: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_9518360\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:625342\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 09:40:27.870512: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_9521430\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:625384\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38650, saving model to checkpoint1.h5\n",
      "4/4 - 6s - loss: 1.3979 - accuracy: 0.3571 - val_loss: 1.3865 - val_accuracy: 0.2407 - 6s/epoch - 1s/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 1.3416 - accuracy: 0.3492 - val_loss: 1.3866 - val_accuracy: 0.2407 - 335ms/epoch - 84ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 1.3179 - accuracy: 0.3730 - val_loss: 1.3867 - val_accuracy: 0.2407 - 335ms/epoch - 84ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 1.2875 - accuracy: 0.4603 - val_loss: 1.3867 - val_accuracy: 0.2407 - 339ms/epoch - 85ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 1.2602 - accuracy: 0.4762 - val_loss: 1.3867 - val_accuracy: 0.2407 - 336ms/epoch - 84ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 1.2215 - accuracy: 0.5794 - val_loss: 1.3868 - val_accuracy: 0.2407 - 338ms/epoch - 84ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 1.2137 - accuracy: 0.5476 - val_loss: 1.3870 - val_accuracy: 0.2407 - 330ms/epoch - 83ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 1.2071 - accuracy: 0.5079 - val_loss: 1.3871 - val_accuracy: 0.2407 - 330ms/epoch - 82ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 1.1643 - accuracy: 0.6111 - val_loss: 1.3872 - val_accuracy: 0.2407 - 342ms/epoch - 86ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 1.1267 - accuracy: 0.6746 - val_loss: 1.3871 - val_accuracy: 0.2407 - 352ms/epoch - 88ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 1.1435 - accuracy: 0.6111 - val_loss: 1.3873 - val_accuracy: 0.2407 - 327ms/epoch - 82ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 1.0990 - accuracy: 0.6746 - val_loss: 1.3875 - val_accuracy: 0.2407 - 325ms/epoch - 81ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 1.0738 - accuracy: 0.7143 - val_loss: 1.3878 - val_accuracy: 0.2407 - 343ms/epoch - 86ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 1.0950 - accuracy: 0.6349 - val_loss: 1.3878 - val_accuracy: 0.2407 - 336ms/epoch - 84ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 1.0265 - accuracy: 0.6905 - val_loss: 1.3879 - val_accuracy: 0.2407 - 330ms/epoch - 83ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 1.0624 - accuracy: 0.6746 - val_loss: 1.3882 - val_accuracy: 0.2407 - 334ms/epoch - 84ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.9891 - accuracy: 0.7540 - val_loss: 1.3886 - val_accuracy: 0.2407 - 336ms/epoch - 84ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 1.0094 - accuracy: 0.6905 - val_loss: 1.3886 - val_accuracy: 0.2407 - 329ms/epoch - 82ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.9833 - accuracy: 0.6825 - val_loss: 1.3882 - val_accuracy: 0.2407 - 335ms/epoch - 84ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.9804 - accuracy: 0.7143 - val_loss: 1.3882 - val_accuracy: 0.2407 - 363ms/epoch - 91ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.9704 - accuracy: 0.6984 - val_loss: 1.3889 - val_accuracy: 0.2407 - 338ms/epoch - 84ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.9670 - accuracy: 0.7381 - val_loss: 1.3893 - val_accuracy: 0.2407 - 341ms/epoch - 85ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.9700 - accuracy: 0.7381 - val_loss: 1.3891 - val_accuracy: 0.2407 - 335ms/epoch - 84ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.9362 - accuracy: 0.7698 - val_loss: 1.3887 - val_accuracy: 0.2407 - 331ms/epoch - 83ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.8987 - accuracy: 0.7619 - val_loss: 1.3895 - val_accuracy: 0.2407 - 338ms/epoch - 85ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.8957 - accuracy: 0.8175 - val_loss: 1.3905 - val_accuracy: 0.2407 - 348ms/epoch - 87ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.8737 - accuracy: 0.7698 - val_loss: 1.3893 - val_accuracy: 0.2407 - 332ms/epoch - 83ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.9046 - accuracy: 0.7540 - val_loss: 1.3901 - val_accuracy: 0.2407 - 329ms/epoch - 82ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.8851 - accuracy: 0.7937 - val_loss: 1.3919 - val_accuracy: 0.2407 - 320ms/epoch - 80ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.8455 - accuracy: 0.8175 - val_loss: 1.3903 - val_accuracy: 0.2407 - 348ms/epoch - 87ms/step\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.8708 - accuracy: 0.7619 - val_loss: 1.3920 - val_accuracy: 0.2407 - 335ms/epoch - 84ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.8191 - accuracy: 0.8333 - val_loss: 1.3937 - val_accuracy: 0.2407 - 341ms/epoch - 85ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.8181 - accuracy: 0.8175 - val_loss: 1.3948 - val_accuracy: 0.2407 - 348ms/epoch - 87ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.8270 - accuracy: 0.8254 - val_loss: 1.3949 - val_accuracy: 0.2407 - 324ms/epoch - 81ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.7842 - accuracy: 0.8730 - val_loss: 1.3962 - val_accuracy: 0.2407 - 333ms/epoch - 83ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.8091 - accuracy: 0.8492 - val_loss: 1.3980 - val_accuracy: 0.2407 - 337ms/epoch - 84ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.7715 - accuracy: 0.8889 - val_loss: 1.4004 - val_accuracy: 0.2407 - 335ms/epoch - 84ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.7598 - accuracy: 0.8889 - val_loss: 1.3978 - val_accuracy: 0.2407 - 345ms/epoch - 86ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.7385 - accuracy: 0.9048 - val_loss: 1.4041 - val_accuracy: 0.2407 - 344ms/epoch - 86ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.7333 - accuracy: 0.8571 - val_loss: 1.4066 - val_accuracy: 0.2407 - 343ms/epoch - 86ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.7256 - accuracy: 0.9048 - val_loss: 1.4077 - val_accuracy: 0.2407 - 336ms/epoch - 84ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.7318 - accuracy: 0.9048 - val_loss: 1.4172 - val_accuracy: 0.2407 - 329ms/epoch - 82ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.7228 - accuracy: 0.9127 - val_loss: 1.4241 - val_accuracy: 0.2407 - 328ms/epoch - 82ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.6903 - accuracy: 0.9365 - val_loss: 1.4083 - val_accuracy: 0.2407 - 331ms/epoch - 83ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.6522 - accuracy: 0.9444 - val_loss: 1.4313 - val_accuracy: 0.2407 - 326ms/epoch - 81ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.6521 - accuracy: 0.9206 - val_loss: 1.4249 - val_accuracy: 0.2407 - 329ms/epoch - 82ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.6532 - accuracy: 0.9048 - val_loss: 1.4185 - val_accuracy: 0.2407 - 350ms/epoch - 88ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.6959 - accuracy: 0.8968 - val_loss: 1.4421 - val_accuracy: 0.2407 - 326ms/epoch - 81ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.6534 - accuracy: 0.9444 - val_loss: 1.4423 - val_accuracy: 0.2407 - 342ms/epoch - 85ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.6720 - accuracy: 0.8810 - val_loss: 1.4354 - val_accuracy: 0.2407 - 349ms/epoch - 87ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.6061 - accuracy: 0.9524 - val_loss: 1.4515 - val_accuracy: 0.2407 - 330ms/epoch - 82ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.5925 - accuracy: 0.9603 - val_loss: 1.4457 - val_accuracy: 0.2407 - 346ms/epoch - 86ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.6041 - accuracy: 0.9683 - val_loss: 1.4446 - val_accuracy: 0.2407 - 336ms/epoch - 84ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.5903 - accuracy: 0.9365 - val_loss: 1.4911 - val_accuracy: 0.2407 - 326ms/epoch - 82ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.5757 - accuracy: 0.9365 - val_loss: 1.4794 - val_accuracy: 0.2407 - 334ms/epoch - 84ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.5812 - accuracy: 0.9206 - val_loss: 1.4745 - val_accuracy: 0.2407 - 335ms/epoch - 84ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.5474 - accuracy: 0.9683 - val_loss: 1.4840 - val_accuracy: 0.2407 - 324ms/epoch - 81ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.5264 - accuracy: 0.9603 - val_loss: 1.5244 - val_accuracy: 0.2407 - 337ms/epoch - 84ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.5124 - accuracy: 0.9841 - val_loss: 1.4394 - val_accuracy: 0.2407 - 319ms/epoch - 80ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.5521 - accuracy: 0.9762 - val_loss: 1.5267 - val_accuracy: 0.2407 - 326ms/epoch - 82ms/step\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.5135 - accuracy: 0.9365 - val_loss: 1.4628 - val_accuracy: 0.2407 - 342ms/epoch - 85ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.4947 - accuracy: 0.9841 - val_loss: 1.5175 - val_accuracy: 0.2407 - 337ms/epoch - 84ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.5391 - accuracy: 0.9206 - val_loss: 1.4713 - val_accuracy: 0.2407 - 333ms/epoch - 83ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.5193 - accuracy: 0.9683 - val_loss: 1.5726 - val_accuracy: 0.2407 - 337ms/epoch - 84ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.5411 - accuracy: 0.9286 - val_loss: 1.4888 - val_accuracy: 0.2407 - 325ms/epoch - 81ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.4901 - accuracy: 0.9762 - val_loss: 1.5109 - val_accuracy: 0.2407 - 332ms/epoch - 83ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.4867 - accuracy: 0.9841 - val_loss: 1.5683 - val_accuracy: 0.2407 - 325ms/epoch - 81ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.4549 - accuracy: 0.9841 - val_loss: 1.4712 - val_accuracy: 0.2407 - 333ms/epoch - 83ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.4935 - accuracy: 0.9603 - val_loss: 1.5197 - val_accuracy: 0.2407 - 327ms/epoch - 82ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.4399 - accuracy: 0.9841 - val_loss: 1.5743 - val_accuracy: 0.2407 - 331ms/epoch - 83ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.4589 - accuracy: 0.9524 - val_loss: 1.5659 - val_accuracy: 0.2407 - 348ms/epoch - 87ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.4411 - accuracy: 0.9762 - val_loss: 1.5591 - val_accuracy: 0.2407 - 331ms/epoch - 83ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.4276 - accuracy: 0.9921 - val_loss: 1.5620 - val_accuracy: 0.2407 - 331ms/epoch - 83ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.4491 - accuracy: 0.9762 - val_loss: 1.5508 - val_accuracy: 0.2407 - 349ms/epoch - 87ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.4246 - accuracy: 0.9841 - val_loss: 1.5150 - val_accuracy: 0.2407 - 324ms/epoch - 81ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.4283 - accuracy: 0.9762 - val_loss: 1.6238 - val_accuracy: 0.2222 - 338ms/epoch - 84ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.4022 - accuracy: 0.9921 - val_loss: 1.4981 - val_accuracy: 0.2222 - 327ms/epoch - 82ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.4250 - accuracy: 0.9841 - val_loss: 1.6123 - val_accuracy: 0.2407 - 340ms/epoch - 85ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.3676 - accuracy: 0.9921 - val_loss: 1.5877 - val_accuracy: 0.2407 - 341ms/epoch - 85ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.3807 - accuracy: 0.9841 - val_loss: 1.5746 - val_accuracy: 0.2222 - 327ms/epoch - 82ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.3744 - accuracy: 1.0000 - val_loss: 1.5984 - val_accuracy: 0.2407 - 325ms/epoch - 81ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.3576 - accuracy: 0.9841 - val_loss: 1.5569 - val_accuracy: 0.2222 - 341ms/epoch - 85ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.3712 - accuracy: 0.9841 - val_loss: 1.5650 - val_accuracy: 0.2037 - 339ms/epoch - 85ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.3778 - accuracy: 0.9762 - val_loss: 1.6772 - val_accuracy: 0.2222 - 334ms/epoch - 83ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.3865 - accuracy: 0.9921 - val_loss: 1.5766 - val_accuracy: 0.2222 - 340ms/epoch - 85ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.3667 - accuracy: 0.9921 - val_loss: 1.6796 - val_accuracy: 0.2407 - 338ms/epoch - 84ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.3368 - accuracy: 0.9921 - val_loss: 1.5833 - val_accuracy: 0.2407 - 326ms/epoch - 82ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.3187 - accuracy: 0.9921 - val_loss: 1.6562 - val_accuracy: 0.2037 - 342ms/epoch - 86ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.3425 - accuracy: 1.0000 - val_loss: 1.7062 - val_accuracy: 0.2407 - 337ms/epoch - 84ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.3349 - accuracy: 1.0000 - val_loss: 1.6673 - val_accuracy: 0.1852 - 335ms/epoch - 84ms/step\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.3333 - accuracy: 1.0000 - val_loss: 1.7941 - val_accuracy: 0.2222 - 323ms/epoch - 81ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.3523 - accuracy: 0.9921 - val_loss: 1.5907 - val_accuracy: 0.2037 - 329ms/epoch - 82ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.3195 - accuracy: 0.9921 - val_loss: 1.7069 - val_accuracy: 0.1852 - 345ms/epoch - 86ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.3202 - accuracy: 1.0000 - val_loss: 1.7216 - val_accuracy: 0.1667 - 340ms/epoch - 85ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2911 - accuracy: 1.0000 - val_loss: 1.6159 - val_accuracy: 0.2222 - 333ms/epoch - 83ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 1.38650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.2880 - accuracy: 1.0000 - val_loss: 1.7531 - val_accuracy: 0.2037 - 324ms/epoch - 81ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.3003 - accuracy: 1.0000 - val_loss: 1.6236 - val_accuracy: 0.2037 - 326ms/epoch - 82ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2969 - accuracy: 1.0000 - val_loss: 1.7739 - val_accuracy: 0.2037 - 330ms/epoch - 83ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2926 - accuracy: 0.9921 - val_loss: 1.6145 - val_accuracy: 0.2222 - 351ms/epoch - 88ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.3074 - accuracy: 1.0000 - val_loss: 1.8621 - val_accuracy: 0.2037 - 347ms/epoch - 87ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2929 - accuracy: 0.9921 - val_loss: 1.6989 - val_accuracy: 0.2222 - 333ms/epoch - 83ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2723 - accuracy: 1.0000 - val_loss: 1.8077 - val_accuracy: 0.2222 - 324ms/epoch - 81ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2678 - accuracy: 0.9921 - val_loss: 1.8173 - val_accuracy: 0.2222 - 324ms/epoch - 81ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2932 - accuracy: 0.9921 - val_loss: 1.7671 - val_accuracy: 0.2222 - 334ms/epoch - 84ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2827 - accuracy: 1.0000 - val_loss: 1.8664 - val_accuracy: 0.2222 - 337ms/epoch - 84ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2723 - accuracy: 1.0000 - val_loss: 1.6993 - val_accuracy: 0.0926 - 338ms/epoch - 85ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2803 - accuracy: 0.9921 - val_loss: 1.8854 - val_accuracy: 0.2037 - 324ms/epoch - 81ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2803 - accuracy: 1.0000 - val_loss: 1.7204 - val_accuracy: 0.1667 - 342ms/epoch - 86ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2551 - accuracy: 1.0000 - val_loss: 1.8785 - val_accuracy: 0.2222 - 340ms/epoch - 85ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2728 - accuracy: 1.0000 - val_loss: 1.7430 - val_accuracy: 0.1481 - 339ms/epoch - 85ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2640 - accuracy: 1.0000 - val_loss: 1.8301 - val_accuracy: 0.2222 - 344ms/epoch - 86ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2819 - accuracy: 0.9921 - val_loss: 1.9014 - val_accuracy: 0.2037 - 331ms/epoch - 83ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2830 - accuracy: 1.0000 - val_loss: 1.8214 - val_accuracy: 0.1852 - 336ms/epoch - 84ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2528 - accuracy: 0.9841 - val_loss: 1.8844 - val_accuracy: 0.2407 - 345ms/epoch - 86ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2617 - accuracy: 0.9921 - val_loss: 1.7758 - val_accuracy: 0.1111 - 330ms/epoch - 82ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2639 - accuracy: 0.9921 - val_loss: 1.9887 - val_accuracy: 0.1852 - 337ms/epoch - 84ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2428 - accuracy: 1.0000 - val_loss: 1.7694 - val_accuracy: 0.1667 - 328ms/epoch - 82ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2422 - accuracy: 0.9921 - val_loss: 1.9151 - val_accuracy: 0.1852 - 346ms/epoch - 87ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2241 - accuracy: 1.0000 - val_loss: 1.8214 - val_accuracy: 0.1667 - 332ms/epoch - 83ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2314 - accuracy: 0.9921 - val_loss: 1.8334 - val_accuracy: 0.1296 - 332ms/epoch - 83ms/step\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2259 - accuracy: 1.0000 - val_loss: 1.8747 - val_accuracy: 0.1296 - 323ms/epoch - 81ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 1.8243 - val_accuracy: 0.1296 - 330ms/epoch - 82ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2453 - accuracy: 1.0000 - val_loss: 1.8845 - val_accuracy: 0.1667 - 317ms/epoch - 79ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2229 - accuracy: 1.0000 - val_loss: 1.8841 - val_accuracy: 0.2037 - 327ms/epoch - 82ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1987 - accuracy: 1.0000 - val_loss: 1.8658 - val_accuracy: 0.1852 - 327ms/epoch - 82ms/step\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.8583 - val_accuracy: 0.1296 - 333ms/epoch - 83ms/step\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 1.8668 - val_accuracy: 0.1667 - 328ms/epoch - 82ms/step\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2015 - accuracy: 1.0000 - val_loss: 1.9037 - val_accuracy: 0.1111 - 328ms/epoch - 82ms/step\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2023 - accuracy: 1.0000 - val_loss: 1.8619 - val_accuracy: 0.1481 - 332ms/epoch - 83ms/step\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1919 - accuracy: 1.0000 - val_loss: 1.9268 - val_accuracy: 0.1667 - 350ms/epoch - 87ms/step\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2186 - accuracy: 1.0000 - val_loss: 1.9458 - val_accuracy: 0.1481 - 348ms/epoch - 87ms/step\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 1.9232 - val_accuracy: 0.1481 - 329ms/epoch - 82ms/step\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2015 - accuracy: 1.0000 - val_loss: 1.9245 - val_accuracy: 0.1481 - 329ms/epoch - 82ms/step\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2011 - accuracy: 1.0000 - val_loss: 1.9824 - val_accuracy: 0.0926 - 326ms/epoch - 81ms/step\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 135: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2029 - accuracy: 1.0000 - val_loss: 1.9465 - val_accuracy: 0.1481 - 330ms/epoch - 83ms/step\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 136: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1981 - accuracy: 1.0000 - val_loss: 2.0934 - val_accuracy: 0.1481 - 344ms/epoch - 86ms/step\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 137: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1941 - accuracy: 1.0000 - val_loss: 1.9978 - val_accuracy: 0.1111 - 328ms/epoch - 82ms/step\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 138: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2029 - accuracy: 0.9921 - val_loss: 2.0319 - val_accuracy: 0.1852 - 348ms/epoch - 87ms/step\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 139: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 1.9671 - val_accuracy: 0.1481 - 331ms/epoch - 83ms/step\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 140: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1948 - accuracy: 1.0000 - val_loss: 1.9316 - val_accuracy: 0.1481 - 321ms/epoch - 80ms/step\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 141: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.2194 - accuracy: 1.0000 - val_loss: 1.8901 - val_accuracy: 0.1481 - 342ms/epoch - 86ms/step\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 142: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1759 - accuracy: 1.0000 - val_loss: 1.8971 - val_accuracy: 0.1852 - 329ms/epoch - 82ms/step\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 143: val_loss did not improve from 1.38650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.1892 - accuracy: 0.9921 - val_loss: 2.1036 - val_accuracy: 0.1296 - 326ms/epoch - 82ms/step\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 144: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1957 - accuracy: 1.0000 - val_loss: 2.1536 - val_accuracy: 0.1296 - 330ms/epoch - 82ms/step\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 145: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1929 - accuracy: 1.0000 - val_loss: 2.0485 - val_accuracy: 0.1296 - 334ms/epoch - 83ms/step\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 146: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1778 - accuracy: 1.0000 - val_loss: 2.0075 - val_accuracy: 0.1481 - 328ms/epoch - 82ms/step\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 147: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1749 - accuracy: 1.0000 - val_loss: 2.0452 - val_accuracy: 0.1111 - 334ms/epoch - 83ms/step\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 148: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1716 - accuracy: 1.0000 - val_loss: 2.0610 - val_accuracy: 0.1111 - 330ms/epoch - 82ms/step\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 149: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1719 - accuracy: 1.0000 - val_loss: 2.0343 - val_accuracy: 0.1296 - 325ms/epoch - 81ms/step\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 150: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1603 - accuracy: 1.0000 - val_loss: 2.0302 - val_accuracy: 0.1667 - 345ms/epoch - 86ms/step\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 151: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1915 - accuracy: 1.0000 - val_loss: 1.9604 - val_accuracy: 0.2037 - 342ms/epoch - 85ms/step\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 152: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1797 - accuracy: 1.0000 - val_loss: 1.8982 - val_accuracy: 0.1852 - 345ms/epoch - 86ms/step\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 153: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1746 - accuracy: 1.0000 - val_loss: 1.9678 - val_accuracy: 0.2037 - 336ms/epoch - 84ms/step\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 154: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1645 - accuracy: 1.0000 - val_loss: 2.0134 - val_accuracy: 0.1852 - 357ms/epoch - 89ms/step\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 155: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1628 - accuracy: 1.0000 - val_loss: 2.0156 - val_accuracy: 0.1852 - 345ms/epoch - 86ms/step\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 156: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1467 - accuracy: 1.0000 - val_loss: 2.1035 - val_accuracy: 0.0926 - 329ms/epoch - 82ms/step\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 157: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1574 - accuracy: 1.0000 - val_loss: 2.0748 - val_accuracy: 0.1667 - 326ms/epoch - 82ms/step\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 158: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1611 - accuracy: 1.0000 - val_loss: 2.0309 - val_accuracy: 0.1852 - 358ms/epoch - 89ms/step\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 159: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1663 - accuracy: 1.0000 - val_loss: 2.0284 - val_accuracy: 0.1481 - 336ms/epoch - 84ms/step\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 160: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1408 - accuracy: 1.0000 - val_loss: 2.0440 - val_accuracy: 0.1852 - 329ms/epoch - 82ms/step\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 161: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1415 - accuracy: 1.0000 - val_loss: 2.0678 - val_accuracy: 0.1296 - 328ms/epoch - 82ms/step\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 162: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1575 - accuracy: 1.0000 - val_loss: 2.0243 - val_accuracy: 0.1481 - 329ms/epoch - 82ms/step\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 163: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1429 - accuracy: 1.0000 - val_loss: 2.0343 - val_accuracy: 0.1852 - 325ms/epoch - 81ms/step\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 164: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1591 - accuracy: 1.0000 - val_loss: 2.0054 - val_accuracy: 0.1481 - 335ms/epoch - 84ms/step\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 165: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1533 - accuracy: 1.0000 - val_loss: 2.0626 - val_accuracy: 0.1481 - 331ms/epoch - 83ms/step\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 166: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1504 - accuracy: 1.0000 - val_loss: 2.0662 - val_accuracy: 0.1852 - 332ms/epoch - 83ms/step\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 167: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1413 - accuracy: 1.0000 - val_loss: 2.0826 - val_accuracy: 0.1852 - 336ms/epoch - 84ms/step\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 168: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1526 - accuracy: 1.0000 - val_loss: 2.0437 - val_accuracy: 0.2037 - 336ms/epoch - 84ms/step\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 169: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1505 - accuracy: 1.0000 - val_loss: 2.0657 - val_accuracy: 0.1481 - 333ms/epoch - 83ms/step\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 170: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1421 - accuracy: 1.0000 - val_loss: 2.0258 - val_accuracy: 0.1667 - 328ms/epoch - 82ms/step\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 171: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1451 - accuracy: 1.0000 - val_loss: 1.9848 - val_accuracy: 0.1296 - 324ms/epoch - 81ms/step\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 172: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1536 - accuracy: 1.0000 - val_loss: 2.1352 - val_accuracy: 0.1667 - 341ms/epoch - 85ms/step\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 173: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1383 - accuracy: 0.9921 - val_loss: 2.0834 - val_accuracy: 0.1852 - 341ms/epoch - 85ms/step\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 174: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1421 - accuracy: 1.0000 - val_loss: 2.0953 - val_accuracy: 0.1852 - 330ms/epoch - 82ms/step\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 175: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1406 - accuracy: 1.0000 - val_loss: 2.1186 - val_accuracy: 0.0741 - 333ms/epoch - 83ms/step\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 176: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1424 - accuracy: 1.0000 - val_loss: 2.1680 - val_accuracy: 0.0741 - 330ms/epoch - 82ms/step\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 177: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1345 - accuracy: 1.0000 - val_loss: 2.0906 - val_accuracy: 0.1481 - 326ms/epoch - 82ms/step\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 178: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1512 - accuracy: 1.0000 - val_loss: 2.0763 - val_accuracy: 0.1111 - 329ms/epoch - 82ms/step\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 179: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1384 - accuracy: 1.0000 - val_loss: 2.0952 - val_accuracy: 0.1481 - 327ms/epoch - 82ms/step\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 180: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1593 - accuracy: 0.9921 - val_loss: 2.0777 - val_accuracy: 0.1481 - 326ms/epoch - 81ms/step\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 181: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1598 - accuracy: 1.0000 - val_loss: 2.0643 - val_accuracy: 0.2037 - 331ms/epoch - 83ms/step\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 182: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1359 - accuracy: 1.0000 - val_loss: 2.0635 - val_accuracy: 0.2037 - 336ms/epoch - 84ms/step\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 183: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1535 - accuracy: 1.0000 - val_loss: 2.1367 - val_accuracy: 0.1667 - 330ms/epoch - 82ms/step\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 184: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1495 - accuracy: 1.0000 - val_loss: 2.1614 - val_accuracy: 0.1111 - 343ms/epoch - 86ms/step\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 185: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1598 - accuracy: 1.0000 - val_loss: 2.3011 - val_accuracy: 0.1111 - 324ms/epoch - 81ms/step\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 186: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1477 - accuracy: 1.0000 - val_loss: 2.3494 - val_accuracy: 0.0926 - 329ms/epoch - 82ms/step\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 187: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1480 - accuracy: 1.0000 - val_loss: 2.4879 - val_accuracy: 0.0926 - 340ms/epoch - 85ms/step\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 188: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1602 - accuracy: 1.0000 - val_loss: 2.1213 - val_accuracy: 0.1296 - 327ms/epoch - 82ms/step\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 189: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1371 - accuracy: 1.0000 - val_loss: 2.2073 - val_accuracy: 0.1481 - 338ms/epoch - 85ms/step\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 190: val_loss did not improve from 1.38650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.1377 - accuracy: 1.0000 - val_loss: 2.1030 - val_accuracy: 0.1481 - 360ms/epoch - 90ms/step\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 191: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1457 - accuracy: 1.0000 - val_loss: 2.1037 - val_accuracy: 0.1667 - 334ms/epoch - 84ms/step\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 192: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1268 - accuracy: 1.0000 - val_loss: 2.0657 - val_accuracy: 0.1852 - 336ms/epoch - 84ms/step\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 193: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1212 - accuracy: 1.0000 - val_loss: 2.1581 - val_accuracy: 0.2222 - 328ms/epoch - 82ms/step\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 194: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1215 - accuracy: 1.0000 - val_loss: 2.0706 - val_accuracy: 0.2037 - 329ms/epoch - 82ms/step\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 195: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1601 - accuracy: 0.9921 - val_loss: 2.1442 - val_accuracy: 0.1667 - 322ms/epoch - 81ms/step\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 196: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1134 - accuracy: 1.0000 - val_loss: 2.1858 - val_accuracy: 0.1296 - 344ms/epoch - 86ms/step\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 197: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1318 - accuracy: 1.0000 - val_loss: 2.1171 - val_accuracy: 0.1667 - 334ms/epoch - 84ms/step\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 198: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1249 - accuracy: 1.0000 - val_loss: 2.2005 - val_accuracy: 0.1852 - 332ms/epoch - 83ms/step\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 199: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1197 - accuracy: 1.0000 - val_loss: 2.1210 - val_accuracy: 0.2222 - 346ms/epoch - 87ms/step\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 200: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1074 - accuracy: 1.0000 - val_loss: 2.0985 - val_accuracy: 0.1852 - 332ms/epoch - 83ms/step\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 201: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1287 - accuracy: 1.0000 - val_loss: 2.1744 - val_accuracy: 0.1296 - 346ms/epoch - 86ms/step\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 202: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1296 - accuracy: 1.0000 - val_loss: 2.2164 - val_accuracy: 0.1296 - 344ms/epoch - 86ms/step\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 203: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1173 - accuracy: 1.0000 - val_loss: 2.1783 - val_accuracy: 0.1667 - 341ms/epoch - 85ms/step\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 204: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1055 - accuracy: 1.0000 - val_loss: 2.0693 - val_accuracy: 0.1852 - 328ms/epoch - 82ms/step\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 205: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1311 - accuracy: 1.0000 - val_loss: 2.1350 - val_accuracy: 0.1667 - 324ms/epoch - 81ms/step\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 206: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1005 - accuracy: 1.0000 - val_loss: 2.1800 - val_accuracy: 0.1296 - 337ms/epoch - 84ms/step\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 207: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1030 - accuracy: 1.0000 - val_loss: 2.0906 - val_accuracy: 0.2037 - 334ms/epoch - 84ms/step\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 208: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1015 - accuracy: 1.0000 - val_loss: 2.0454 - val_accuracy: 0.1852 - 338ms/epoch - 85ms/step\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 209: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1078 - accuracy: 0.9921 - val_loss: 2.1876 - val_accuracy: 0.2037 - 332ms/epoch - 83ms/step\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 210: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1113 - accuracy: 1.0000 - val_loss: 2.3236 - val_accuracy: 0.1111 - 326ms/epoch - 82ms/step\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 211: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1151 - accuracy: 1.0000 - val_loss: 2.3377 - val_accuracy: 0.1111 - 334ms/epoch - 83ms/step\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 212: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1157 - accuracy: 1.0000 - val_loss: 2.2159 - val_accuracy: 0.1111 - 337ms/epoch - 84ms/step\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 213: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1194 - accuracy: 1.0000 - val_loss: 2.1750 - val_accuracy: 0.1296 - 339ms/epoch - 85ms/step\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 214: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1209 - accuracy: 1.0000 - val_loss: 2.1732 - val_accuracy: 0.1296 - 329ms/epoch - 82ms/step\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 215: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1147 - accuracy: 1.0000 - val_loss: 2.1601 - val_accuracy: 0.1667 - 340ms/epoch - 85ms/step\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 216: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1024 - accuracy: 1.0000 - val_loss: 2.1311 - val_accuracy: 0.1111 - 333ms/epoch - 83ms/step\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 217: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0997 - accuracy: 1.0000 - val_loss: 2.1452 - val_accuracy: 0.1667 - 325ms/epoch - 81ms/step\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 218: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0992 - accuracy: 1.0000 - val_loss: 2.1192 - val_accuracy: 0.1111 - 335ms/epoch - 84ms/step\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 219: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0941 - accuracy: 1.0000 - val_loss: 2.1900 - val_accuracy: 0.1481 - 331ms/epoch - 83ms/step\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 220: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1041 - accuracy: 1.0000 - val_loss: 2.1808 - val_accuracy: 0.1481 - 356ms/epoch - 89ms/step\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 221: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1048 - accuracy: 1.0000 - val_loss: 2.2429 - val_accuracy: 0.1296 - 329ms/epoch - 82ms/step\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 222: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1219 - accuracy: 1.0000 - val_loss: 2.2238 - val_accuracy: 0.1296 - 324ms/epoch - 81ms/step\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 223: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1140 - accuracy: 1.0000 - val_loss: 2.1224 - val_accuracy: 0.1667 - 346ms/epoch - 86ms/step\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 224: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1052 - accuracy: 1.0000 - val_loss: 2.1146 - val_accuracy: 0.2407 - 344ms/epoch - 86ms/step\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 225: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1028 - accuracy: 1.0000 - val_loss: 2.1587 - val_accuracy: 0.1296 - 335ms/epoch - 84ms/step\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 226: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0978 - accuracy: 1.0000 - val_loss: 2.2336 - val_accuracy: 0.1296 - 352ms/epoch - 88ms/step\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 227: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1164 - accuracy: 1.0000 - val_loss: 2.1376 - val_accuracy: 0.1481 - 344ms/epoch - 86ms/step\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 228: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0981 - accuracy: 1.0000 - val_loss: 2.1087 - val_accuracy: 0.1852 - 326ms/epoch - 82ms/step\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 229: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0981 - accuracy: 1.0000 - val_loss: 2.1507 - val_accuracy: 0.2037 - 327ms/epoch - 82ms/step\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 230: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1034 - accuracy: 1.0000 - val_loss: 2.1681 - val_accuracy: 0.2037 - 343ms/epoch - 86ms/step\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 231: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0912 - accuracy: 1.0000 - val_loss: 2.1295 - val_accuracy: 0.1667 - 325ms/epoch - 81ms/step\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 232: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0954 - accuracy: 1.0000 - val_loss: 2.1038 - val_accuracy: 0.1481 - 336ms/epoch - 84ms/step\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 233: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0976 - accuracy: 1.0000 - val_loss: 2.1210 - val_accuracy: 0.1667 - 328ms/epoch - 82ms/step\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 234: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1010 - accuracy: 1.0000 - val_loss: 2.1365 - val_accuracy: 0.1667 - 343ms/epoch - 86ms/step\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 235: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0926 - accuracy: 1.0000 - val_loss: 2.1551 - val_accuracy: 0.2222 - 332ms/epoch - 83ms/step\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 236: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0960 - accuracy: 1.0000 - val_loss: 2.1482 - val_accuracy: 0.1667 - 326ms/epoch - 81ms/step\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 237: val_loss did not improve from 1.38650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.0961 - accuracy: 1.0000 - val_loss: 2.1860 - val_accuracy: 0.1111 - 337ms/epoch - 84ms/step\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 238: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0923 - accuracy: 1.0000 - val_loss: 2.1499 - val_accuracy: 0.1667 - 336ms/epoch - 84ms/step\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 239: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0948 - accuracy: 1.0000 - val_loss: 2.2099 - val_accuracy: 0.1296 - 343ms/epoch - 86ms/step\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 240: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1025 - accuracy: 1.0000 - val_loss: 2.2623 - val_accuracy: 0.1481 - 331ms/epoch - 83ms/step\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 241: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0795 - accuracy: 1.0000 - val_loss: 2.2263 - val_accuracy: 0.0926 - 342ms/epoch - 85ms/step\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 242: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0863 - accuracy: 1.0000 - val_loss: 2.1553 - val_accuracy: 0.1667 - 324ms/epoch - 81ms/step\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 243: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0966 - accuracy: 1.0000 - val_loss: 2.2226 - val_accuracy: 0.1481 - 329ms/epoch - 82ms/step\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 244: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0919 - accuracy: 1.0000 - val_loss: 2.2157 - val_accuracy: 0.1296 - 329ms/epoch - 82ms/step\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 245: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0795 - accuracy: 1.0000 - val_loss: 2.2154 - val_accuracy: 0.1111 - 326ms/epoch - 81ms/step\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 246: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0957 - accuracy: 1.0000 - val_loss: 2.1969 - val_accuracy: 0.1111 - 341ms/epoch - 85ms/step\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 247: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0763 - accuracy: 1.0000 - val_loss: 2.1988 - val_accuracy: 0.1296 - 340ms/epoch - 85ms/step\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 248: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0946 - accuracy: 1.0000 - val_loss: 2.2076 - val_accuracy: 0.1852 - 326ms/epoch - 82ms/step\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 249: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0810 - accuracy: 1.0000 - val_loss: 2.1522 - val_accuracy: 0.1296 - 326ms/epoch - 81ms/step\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 250: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1007 - accuracy: 1.0000 - val_loss: 2.2494 - val_accuracy: 0.1852 - 344ms/epoch - 86ms/step\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 251: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1028 - accuracy: 1.0000 - val_loss: 2.2738 - val_accuracy: 0.1667 - 322ms/epoch - 81ms/step\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 252: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1120 - accuracy: 1.0000 - val_loss: 2.2849 - val_accuracy: 0.1481 - 344ms/epoch - 86ms/step\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 253: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1116 - accuracy: 1.0000 - val_loss: 2.2546 - val_accuracy: 0.1481 - 338ms/epoch - 85ms/step\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 254: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0952 - accuracy: 1.0000 - val_loss: 2.2271 - val_accuracy: 0.1481 - 324ms/epoch - 81ms/step\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 255: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0901 - accuracy: 1.0000 - val_loss: 2.3028 - val_accuracy: 0.1111 - 332ms/epoch - 83ms/step\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 256: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1129 - accuracy: 0.9921 - val_loss: 2.2958 - val_accuracy: 0.1296 - 335ms/epoch - 84ms/step\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 257: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0867 - accuracy: 1.0000 - val_loss: 2.2615 - val_accuracy: 0.1667 - 325ms/epoch - 81ms/step\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 258: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0804 - accuracy: 1.0000 - val_loss: 2.2543 - val_accuracy: 0.1296 - 330ms/epoch - 82ms/step\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 259: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0881 - accuracy: 1.0000 - val_loss: 2.2263 - val_accuracy: 0.1481 - 345ms/epoch - 86ms/step\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 260: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0858 - accuracy: 1.0000 - val_loss: 2.2086 - val_accuracy: 0.1852 - 333ms/epoch - 83ms/step\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 261: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0925 - accuracy: 1.0000 - val_loss: 2.2260 - val_accuracy: 0.2593 - 343ms/epoch - 86ms/step\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 262: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0932 - accuracy: 1.0000 - val_loss: 2.1785 - val_accuracy: 0.2222 - 348ms/epoch - 87ms/step\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 263: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0873 - accuracy: 1.0000 - val_loss: 2.1726 - val_accuracy: 0.1481 - 334ms/epoch - 83ms/step\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 264: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0879 - accuracy: 1.0000 - val_loss: 2.1878 - val_accuracy: 0.1481 - 334ms/epoch - 84ms/step\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 265: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0761 - accuracy: 1.0000 - val_loss: 2.2759 - val_accuracy: 0.1481 - 323ms/epoch - 81ms/step\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 266: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0902 - accuracy: 1.0000 - val_loss: 2.2989 - val_accuracy: 0.1481 - 335ms/epoch - 84ms/step\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 267: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0677 - accuracy: 1.0000 - val_loss: 2.3041 - val_accuracy: 0.1481 - 332ms/epoch - 83ms/step\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 268: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.1021 - accuracy: 1.0000 - val_loss: 2.3221 - val_accuracy: 0.1296 - 332ms/epoch - 83ms/step\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 269: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0799 - accuracy: 1.0000 - val_loss: 2.2978 - val_accuracy: 0.0926 - 348ms/epoch - 87ms/step\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 270: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0714 - accuracy: 1.0000 - val_loss: 2.2385 - val_accuracy: 0.0556 - 332ms/epoch - 83ms/step\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 271: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0700 - accuracy: 1.0000 - val_loss: 2.2055 - val_accuracy: 0.1296 - 331ms/epoch - 83ms/step\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 272: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0803 - accuracy: 1.0000 - val_loss: 2.1960 - val_accuracy: 0.1111 - 338ms/epoch - 85ms/step\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 273: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0785 - accuracy: 1.0000 - val_loss: 2.2269 - val_accuracy: 0.1481 - 336ms/epoch - 84ms/step\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 274: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0798 - accuracy: 1.0000 - val_loss: 2.3080 - val_accuracy: 0.1481 - 339ms/epoch - 85ms/step\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 275: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0646 - accuracy: 1.0000 - val_loss: 2.3239 - val_accuracy: 0.1481 - 327ms/epoch - 82ms/step\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 276: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0761 - accuracy: 1.0000 - val_loss: 2.2701 - val_accuracy: 0.1296 - 329ms/epoch - 82ms/step\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 277: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0786 - accuracy: 1.0000 - val_loss: 2.2952 - val_accuracy: 0.1296 - 331ms/epoch - 83ms/step\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 278: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0726 - accuracy: 1.0000 - val_loss: 2.2427 - val_accuracy: 0.1481 - 346ms/epoch - 86ms/step\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 279: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0786 - accuracy: 1.0000 - val_loss: 2.1842 - val_accuracy: 0.1296 - 324ms/epoch - 81ms/step\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 280: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0808 - accuracy: 1.0000 - val_loss: 2.2504 - val_accuracy: 0.0926 - 340ms/epoch - 85ms/step\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 281: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0752 - accuracy: 1.0000 - val_loss: 2.3441 - val_accuracy: 0.1111 - 339ms/epoch - 85ms/step\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 282: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0921 - accuracy: 1.0000 - val_loss: 2.2761 - val_accuracy: 0.1296 - 340ms/epoch - 85ms/step\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 283: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0735 - accuracy: 1.0000 - val_loss: 2.3905 - val_accuracy: 0.0741 - 326ms/epoch - 81ms/step\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 284: val_loss did not improve from 1.38650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.0728 - accuracy: 1.0000 - val_loss: 2.3095 - val_accuracy: 0.1481 - 334ms/epoch - 84ms/step\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 285: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0762 - accuracy: 1.0000 - val_loss: 2.2826 - val_accuracy: 0.1852 - 339ms/epoch - 85ms/step\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 286: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0746 - accuracy: 1.0000 - val_loss: 2.3502 - val_accuracy: 0.1481 - 332ms/epoch - 83ms/step\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 287: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0750 - accuracy: 1.0000 - val_loss: 2.2784 - val_accuracy: 0.1296 - 332ms/epoch - 83ms/step\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 288: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0655 - accuracy: 1.0000 - val_loss: 2.1494 - val_accuracy: 0.1111 - 339ms/epoch - 85ms/step\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 289: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0664 - accuracy: 1.0000 - val_loss: 2.1898 - val_accuracy: 0.0926 - 334ms/epoch - 83ms/step\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 290: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0749 - accuracy: 1.0000 - val_loss: 2.2885 - val_accuracy: 0.1296 - 322ms/epoch - 81ms/step\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 291: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0613 - accuracy: 1.0000 - val_loss: 2.3851 - val_accuracy: 0.1111 - 330ms/epoch - 83ms/step\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 292: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0749 - accuracy: 1.0000 - val_loss: 2.4741 - val_accuracy: 0.0926 - 333ms/epoch - 83ms/step\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 293: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0736 - accuracy: 1.0000 - val_loss: 2.4177 - val_accuracy: 0.1296 - 329ms/epoch - 82ms/step\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 294: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0907 - accuracy: 1.0000 - val_loss: 2.2211 - val_accuracy: 0.1111 - 343ms/epoch - 86ms/step\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 295: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0672 - accuracy: 1.0000 - val_loss: 2.3295 - val_accuracy: 0.2037 - 330ms/epoch - 83ms/step\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 296: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0717 - accuracy: 1.0000 - val_loss: 2.3009 - val_accuracy: 0.1667 - 342ms/epoch - 85ms/step\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 297: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0666 - accuracy: 1.0000 - val_loss: 2.3025 - val_accuracy: 0.1296 - 327ms/epoch - 82ms/step\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 298: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0702 - accuracy: 1.0000 - val_loss: 2.2888 - val_accuracy: 0.0926 - 339ms/epoch - 85ms/step\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 299: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0668 - accuracy: 1.0000 - val_loss: 2.3160 - val_accuracy: 0.1296 - 321ms/epoch - 80ms/step\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 300: val_loss did not improve from 1.38650\n",
      "4/4 - 0s - loss: 0.0540 - accuracy: 1.0000 - val_loss: 2.3442 - val_accuracy: 0.1111 - 330ms/epoch - 82ms/step\n",
      "2/2 [==============================] - 0s 22ms/step\n",
      "Lists\n",
      "[0.21666666666666667, 0.16666666666666666, 0.26666666666666666, 0.21666666666666667]\n",
      "[0.05416666666666667, 0.041666666666666664, 0.14814814814814814, 0.15261865793780688]\n",
      "[0.25, 0.25, 0.2520833333333333, 0.28214285714285714]\n",
      "[0.08904109589041095, 0.07142857142857142, 0.1476190476190476, 0.17251461988304095]\n",
      "dicts\n",
      "{1: 0.28, 2: 0.2, 3: 0.22777777777777777, 4: 0.18333333333333335, 5: 0.21666666666666665, 6: 0, 7: 0, 8: 0}\n",
      "{1: 0.179879077643203, 2: 0.06654896421845574, 3: 0.07670940170940171, 4: 0.07773809523809523, 5: 0.09915003485482209, 6: 0, 7: 0, 8: 0}\n",
      "{1: 0.285120781995782, 2: 0.2456597222222222, 3: 0.2569444444444444, 4: 0.2416466346153846, 5: 0.2585565476190476, 6: 0, 7: 0, 8: 0}\n",
      "{1: 0.19991143316006618, 2: 0.09862908327582241, 3: 0.1074404761904762, 4: 0.10099907282139219, 5: 0.12015083370526773, 6: 0, 7: 0, 8: 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Number of devices: 2\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 09:42:14.291141: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_9582674\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:629596\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
      "2022-11-11 09:42:18.312017: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_9585744\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:629638\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38660, saving model to checkpoint1.h5\n",
      "4/4 - 6s - loss: 1.4857 - accuracy: 0.2478 - val_loss: 1.3866 - val_accuracy: 0.1429 - 6s/epoch - 1s/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 1.3258 - accuracy: 0.4159 - val_loss: 1.3871 - val_accuracy: 0.1429 - 431ms/epoch - 108ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 1.2347 - accuracy: 0.5929 - val_loss: 1.3875 - val_accuracy: 0.1429 - 325ms/epoch - 81ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 1.1892 - accuracy: 0.5575 - val_loss: 1.3880 - val_accuracy: 0.1429 - 312ms/epoch - 78ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 1.1894 - accuracy: 0.5664 - val_loss: 1.3884 - val_accuracy: 0.1429 - 318ms/epoch - 80ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 1.1357 - accuracy: 0.6195 - val_loss: 1.3884 - val_accuracy: 0.1429 - 321ms/epoch - 80ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 1.1400 - accuracy: 0.5841 - val_loss: 1.3885 - val_accuracy: 0.1429 - 320ms/epoch - 80ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 1.0950 - accuracy: 0.6903 - val_loss: 1.3886 - val_accuracy: 0.1429 - 333ms/epoch - 83ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 1.0613 - accuracy: 0.6814 - val_loss: 1.3890 - val_accuracy: 0.1429 - 312ms/epoch - 78ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 1.0361 - accuracy: 0.6991 - val_loss: 1.3895 - val_accuracy: 0.1429 - 317ms/epoch - 79ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.9945 - accuracy: 0.7876 - val_loss: 1.3895 - val_accuracy: 0.1429 - 319ms/epoch - 80ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.9863 - accuracy: 0.7965 - val_loss: 1.3895 - val_accuracy: 0.1429 - 325ms/epoch - 81ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.9590 - accuracy: 0.7876 - val_loss: 1.3894 - val_accuracy: 0.1429 - 315ms/epoch - 79ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.9409 - accuracy: 0.8053 - val_loss: 1.3897 - val_accuracy: 0.1429 - 312ms/epoch - 78ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.9152 - accuracy: 0.8053 - val_loss: 1.3902 - val_accuracy: 0.1429 - 329ms/epoch - 82ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.9016 - accuracy: 0.8142 - val_loss: 1.3905 - val_accuracy: 0.1429 - 344ms/epoch - 86ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.8925 - accuracy: 0.7965 - val_loss: 1.3908 - val_accuracy: 0.1429 - 319ms/epoch - 80ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.8681 - accuracy: 0.8319 - val_loss: 1.3909 - val_accuracy: 0.1429 - 333ms/epoch - 83ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.8527 - accuracy: 0.8673 - val_loss: 1.3909 - val_accuracy: 0.2041 - 313ms/epoch - 78ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.8150 - accuracy: 0.8496 - val_loss: 1.3911 - val_accuracy: 0.1633 - 337ms/epoch - 84ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.8246 - accuracy: 0.8761 - val_loss: 1.3919 - val_accuracy: 0.1633 - 310ms/epoch - 77ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.7877 - accuracy: 0.9115 - val_loss: 1.3923 - val_accuracy: 0.1429 - 324ms/epoch - 81ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.8007 - accuracy: 0.8584 - val_loss: 1.3933 - val_accuracy: 0.1633 - 311ms/epoch - 78ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.7734 - accuracy: 0.9204 - val_loss: 1.3940 - val_accuracy: 0.1633 - 323ms/epoch - 81ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.7562 - accuracy: 0.9115 - val_loss: 1.3934 - val_accuracy: 0.1633 - 342ms/epoch - 85ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.7409 - accuracy: 0.9204 - val_loss: 1.3935 - val_accuracy: 0.1429 - 324ms/epoch - 81ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.7321 - accuracy: 0.9646 - val_loss: 1.3953 - val_accuracy: 0.1429 - 312ms/epoch - 78ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.7370 - accuracy: 0.9204 - val_loss: 1.3959 - val_accuracy: 0.1429 - 317ms/epoch - 79ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.6998 - accuracy: 0.9027 - val_loss: 1.3948 - val_accuracy: 0.1633 - 327ms/epoch - 82ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.6722 - accuracy: 0.9558 - val_loss: 1.3950 - val_accuracy: 0.1633 - 322ms/epoch - 81ms/step\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.6794 - accuracy: 0.9292 - val_loss: 1.3968 - val_accuracy: 0.1837 - 329ms/epoch - 82ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.6697 - accuracy: 0.9558 - val_loss: 1.3985 - val_accuracy: 0.1633 - 314ms/epoch - 78ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.6687 - accuracy: 0.9646 - val_loss: 1.3990 - val_accuracy: 0.1429 - 319ms/epoch - 80ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.6391 - accuracy: 0.9469 - val_loss: 1.3989 - val_accuracy: 0.1429 - 328ms/epoch - 82ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.6477 - accuracy: 0.9558 - val_loss: 1.3986 - val_accuracy: 0.1837 - 335ms/epoch - 84ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.6387 - accuracy: 0.9381 - val_loss: 1.3997 - val_accuracy: 0.1224 - 310ms/epoch - 77ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.6388 - accuracy: 0.9558 - val_loss: 1.3960 - val_accuracy: 0.1429 - 325ms/epoch - 81ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.6316 - accuracy: 0.9558 - val_loss: 1.3987 - val_accuracy: 0.1837 - 313ms/epoch - 78ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.6146 - accuracy: 0.9646 - val_loss: 1.4012 - val_accuracy: 0.1633 - 316ms/epoch - 79ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.6058 - accuracy: 0.9912 - val_loss: 1.4005 - val_accuracy: 0.1429 - 316ms/epoch - 79ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.6053 - accuracy: 0.9646 - val_loss: 1.3999 - val_accuracy: 0.1837 - 324ms/epoch - 81ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.5931 - accuracy: 0.9646 - val_loss: 1.4045 - val_accuracy: 0.1837 - 308ms/epoch - 77ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.5883 - accuracy: 0.9204 - val_loss: 1.4078 - val_accuracy: 0.1429 - 330ms/epoch - 83ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.5692 - accuracy: 0.9735 - val_loss: 1.4011 - val_accuracy: 0.2245 - 332ms/epoch - 83ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.5695 - accuracy: 0.9823 - val_loss: 1.4062 - val_accuracy: 0.1429 - 348ms/epoch - 87ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.5561 - accuracy: 0.9735 - val_loss: 1.4069 - val_accuracy: 0.1837 - 317ms/epoch - 79ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.5250 - accuracy: 0.9912 - val_loss: 1.4014 - val_accuracy: 0.2041 - 319ms/epoch - 80ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.5414 - accuracy: 0.9735 - val_loss: 1.4098 - val_accuracy: 0.1429 - 313ms/epoch - 78ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.5132 - accuracy: 0.9912 - val_loss: 1.4054 - val_accuracy: 0.1429 - 318ms/epoch - 79ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.4838 - accuracy: 0.9823 - val_loss: 1.4041 - val_accuracy: 0.2245 - 323ms/epoch - 81ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.4470 - accuracy: 1.0000 - val_loss: 1.4111 - val_accuracy: 0.1837 - 331ms/epoch - 83ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.4586 - accuracy: 0.9912 - val_loss: 1.4101 - val_accuracy: 0.1429 - 323ms/epoch - 81ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.4087 - accuracy: 1.0000 - val_loss: 1.4069 - val_accuracy: 0.1837 - 324ms/epoch - 81ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.4265 - accuracy: 1.0000 - val_loss: 1.4147 - val_accuracy: 0.2245 - 312ms/epoch - 78ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.4078 - accuracy: 1.0000 - val_loss: 1.4004 - val_accuracy: 0.1837 - 332ms/epoch - 83ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.4210 - accuracy: 1.0000 - val_loss: 1.4049 - val_accuracy: 0.2245 - 324ms/epoch - 81ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.4126 - accuracy: 0.9912 - val_loss: 1.4129 - val_accuracy: 0.2245 - 316ms/epoch - 79ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.3955 - accuracy: 1.0000 - val_loss: 1.4056 - val_accuracy: 0.2245 - 324ms/epoch - 81ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.4177 - accuracy: 1.0000 - val_loss: 1.4089 - val_accuracy: 0.2449 - 308ms/epoch - 77ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.3620 - accuracy: 1.0000 - val_loss: 1.4018 - val_accuracy: 0.2653 - 316ms/epoch - 79ms/step\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.3930 - accuracy: 1.0000 - val_loss: 1.4094 - val_accuracy: 0.2245 - 320ms/epoch - 80ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.3788 - accuracy: 0.9912 - val_loss: 1.4217 - val_accuracy: 0.2245 - 316ms/epoch - 79ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.3633 - accuracy: 1.0000 - val_loss: 1.4037 - val_accuracy: 0.2041 - 318ms/epoch - 80ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.3696 - accuracy: 1.0000 - val_loss: 1.4092 - val_accuracy: 0.2449 - 318ms/epoch - 80ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.3886 - accuracy: 0.9823 - val_loss: 1.3906 - val_accuracy: 0.2653 - 314ms/epoch - 78ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.3519 - accuracy: 1.0000 - val_loss: 1.4206 - val_accuracy: 0.2857 - 317ms/epoch - 79ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.3497 - accuracy: 1.0000 - val_loss: 1.3965 - val_accuracy: 0.2653 - 323ms/epoch - 81ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.3464 - accuracy: 1.0000 - val_loss: 1.4289 - val_accuracy: 0.2653 - 315ms/epoch - 79ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.3312 - accuracy: 1.0000 - val_loss: 1.3874 - val_accuracy: 0.2857 - 319ms/epoch - 80ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.3297 - accuracy: 1.0000 - val_loss: 1.4442 - val_accuracy: 0.2041 - 328ms/epoch - 82ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.3214 - accuracy: 1.0000 - val_loss: 1.4126 - val_accuracy: 0.2653 - 311ms/epoch - 78ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.3200 - accuracy: 1.0000 - val_loss: 1.4166 - val_accuracy: 0.2653 - 314ms/epoch - 78ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.3078 - accuracy: 1.0000 - val_loss: 1.4089 - val_accuracy: 0.2653 - 322ms/epoch - 81ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.3232 - accuracy: 1.0000 - val_loss: 1.4351 - val_accuracy: 0.2653 - 316ms/epoch - 79ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.3317 - accuracy: 1.0000 - val_loss: 1.3941 - val_accuracy: 0.3061 - 319ms/epoch - 80ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.3222 - accuracy: 1.0000 - val_loss: 1.4202 - val_accuracy: 0.2449 - 322ms/epoch - 81ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.3095 - accuracy: 1.0000 - val_loss: 1.3923 - val_accuracy: 0.2857 - 313ms/epoch - 78ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.2948 - accuracy: 1.0000 - val_loss: 1.4237 - val_accuracy: 0.2041 - 318ms/epoch - 80ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.3395 - accuracy: 1.0000 - val_loss: 1.3994 - val_accuracy: 0.2245 - 324ms/epoch - 81ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.2777 - accuracy: 1.0000 - val_loss: 1.3937 - val_accuracy: 0.2857 - 314ms/epoch - 79ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.2767 - accuracy: 1.0000 - val_loss: 1.4206 - val_accuracy: 0.3061 - 323ms/epoch - 81ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.3050 - accuracy: 0.9912 - val_loss: 1.4027 - val_accuracy: 0.2449 - 328ms/epoch - 82ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.3040 - accuracy: 1.0000 - val_loss: 1.4250 - val_accuracy: 0.2653 - 314ms/epoch - 79ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.2644 - accuracy: 1.0000 - val_loss: 1.4210 - val_accuracy: 0.2653 - 320ms/epoch - 80ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.2680 - accuracy: 1.0000 - val_loss: 1.4061 - val_accuracy: 0.2857 - 322ms/epoch - 81ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.2575 - accuracy: 1.0000 - val_loss: 1.3999 - val_accuracy: 0.2857 - 327ms/epoch - 82ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.2542 - accuracy: 1.0000 - val_loss: 1.4247 - val_accuracy: 0.2653 - 327ms/epoch - 82ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.2452 - accuracy: 1.0000 - val_loss: 1.3989 - val_accuracy: 0.2449 - 314ms/epoch - 78ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.2292 - accuracy: 1.0000 - val_loss: 1.4313 - val_accuracy: 0.2449 - 315ms/epoch - 79ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.2531 - accuracy: 1.0000 - val_loss: 1.3957 - val_accuracy: 0.2857 - 318ms/epoch - 79ms/step\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.2320 - accuracy: 0.9912 - val_loss: 1.4348 - val_accuracy: 0.2245 - 333ms/epoch - 83ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.2358 - accuracy: 1.0000 - val_loss: 1.4156 - val_accuracy: 0.2449 - 318ms/epoch - 80ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.2211 - accuracy: 1.0000 - val_loss: 1.4699 - val_accuracy: 0.2857 - 324ms/epoch - 81ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.2351 - accuracy: 1.0000 - val_loss: 1.4087 - val_accuracy: 0.2245 - 320ms/epoch - 80ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 1.4380 - val_accuracy: 0.2449 - 312ms/epoch - 78ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 1.38660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.2331 - accuracy: 1.0000 - val_loss: 1.4594 - val_accuracy: 0.2245 - 323ms/epoch - 81ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.2350 - accuracy: 1.0000 - val_loss: 1.4340 - val_accuracy: 0.2245 - 337ms/epoch - 84ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.2185 - accuracy: 1.0000 - val_loss: 1.4858 - val_accuracy: 0.2653 - 320ms/epoch - 80ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.2369 - accuracy: 1.0000 - val_loss: 1.4051 - val_accuracy: 0.2857 - 322ms/epoch - 81ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 1.4436 - val_accuracy: 0.2449 - 322ms/epoch - 80ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.2166 - accuracy: 1.0000 - val_loss: 1.4324 - val_accuracy: 0.2653 - 313ms/epoch - 78ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.2348 - accuracy: 0.9912 - val_loss: 1.4243 - val_accuracy: 0.2857 - 317ms/epoch - 79ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.2234 - accuracy: 1.0000 - val_loss: 1.4594 - val_accuracy: 0.2449 - 330ms/epoch - 82ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.1887 - accuracy: 1.0000 - val_loss: 1.4780 - val_accuracy: 0.2449 - 324ms/epoch - 81ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.1928 - accuracy: 1.0000 - val_loss: 1.4699 - val_accuracy: 0.2449 - 321ms/epoch - 80ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.1938 - accuracy: 1.0000 - val_loss: 1.4761 - val_accuracy: 0.2653 - 323ms/epoch - 81ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.1787 - accuracy: 1.0000 - val_loss: 1.4855 - val_accuracy: 0.3265 - 316ms/epoch - 79ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.1826 - accuracy: 1.0000 - val_loss: 1.4734 - val_accuracy: 0.2449 - 309ms/epoch - 77ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.1969 - accuracy: 1.0000 - val_loss: 1.4473 - val_accuracy: 0.2449 - 317ms/epoch - 79ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.1953 - accuracy: 1.0000 - val_loss: 1.4999 - val_accuracy: 0.2449 - 308ms/epoch - 77ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.1950 - accuracy: 1.0000 - val_loss: 1.4741 - val_accuracy: 0.2449 - 309ms/epoch - 77ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.1834 - accuracy: 1.0000 - val_loss: 1.5071 - val_accuracy: 0.2245 - 321ms/epoch - 80ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.1793 - accuracy: 1.0000 - val_loss: 1.5250 - val_accuracy: 0.1837 - 320ms/epoch - 80ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.1696 - accuracy: 1.0000 - val_loss: 1.4436 - val_accuracy: 0.2449 - 328ms/epoch - 82ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.1702 - accuracy: 1.0000 - val_loss: 1.4755 - val_accuracy: 0.2449 - 331ms/epoch - 83ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.1730 - accuracy: 1.0000 - val_loss: 1.5199 - val_accuracy: 0.2245 - 319ms/epoch - 80ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.1606 - accuracy: 1.0000 - val_loss: 1.5028 - val_accuracy: 0.2857 - 314ms/epoch - 79ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.1742 - accuracy: 1.0000 - val_loss: 1.4352 - val_accuracy: 0.2857 - 315ms/epoch - 79ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.1630 - accuracy: 1.0000 - val_loss: 1.4567 - val_accuracy: 0.2857 - 331ms/epoch - 83ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.1658 - accuracy: 1.0000 - val_loss: 1.4767 - val_accuracy: 0.2449 - 319ms/epoch - 80ms/step\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.1634 - accuracy: 1.0000 - val_loss: 1.4781 - val_accuracy: 0.2449 - 332ms/epoch - 83ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.1476 - accuracy: 1.0000 - val_loss: 1.4493 - val_accuracy: 0.2653 - 313ms/epoch - 78ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.1659 - accuracy: 1.0000 - val_loss: 1.5016 - val_accuracy: 0.2653 - 323ms/epoch - 81ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.1736 - accuracy: 1.0000 - val_loss: 1.4679 - val_accuracy: 0.3061 - 311ms/epoch - 78ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.1576 - accuracy: 1.0000 - val_loss: 1.5193 - val_accuracy: 0.2653 - 327ms/epoch - 82ms/step\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.1567 - accuracy: 1.0000 - val_loss: 1.4747 - val_accuracy: 0.3061 - 311ms/epoch - 78ms/step\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.1648 - accuracy: 1.0000 - val_loss: 1.5123 - val_accuracy: 0.2653 - 322ms/epoch - 81ms/step\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: val_loss did not improve from 1.38660\n",
      "4/4 - 0s - loss: 0.1453 - accuracy: 1.0000 - val_loss: 1.6071 - val_accuracy: 0.2653 - 325ms/epoch - 81ms/step\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: val_loss improved from 1.38660 to 1.38120, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.1686 - accuracy: 1.0000 - val_loss: 1.3812 - val_accuracy: 0.4082 - 368ms/epoch - 92ms/step\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1692 - accuracy: 1.0000 - val_loss: 1.6744 - val_accuracy: 0.2857 - 316ms/epoch - 79ms/step\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1501 - accuracy: 1.0000 - val_loss: 1.4770 - val_accuracy: 0.2653 - 324ms/epoch - 81ms/step\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1543 - accuracy: 1.0000 - val_loss: 1.4918 - val_accuracy: 0.2653 - 324ms/epoch - 81ms/step\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1564 - accuracy: 1.0000 - val_loss: 1.5249 - val_accuracy: 0.3061 - 335ms/epoch - 84ms/step\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1398 - accuracy: 1.0000 - val_loss: 1.4324 - val_accuracy: 0.3061 - 321ms/epoch - 80ms/step\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 135: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1595 - accuracy: 1.0000 - val_loss: 1.5062 - val_accuracy: 0.3061 - 332ms/epoch - 83ms/step\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 136: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1491 - accuracy: 1.0000 - val_loss: 1.4835 - val_accuracy: 0.3061 - 312ms/epoch - 78ms/step\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 137: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1522 - accuracy: 1.0000 - val_loss: 1.5465 - val_accuracy: 0.2857 - 311ms/epoch - 78ms/step\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 138: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1387 - accuracy: 1.0000 - val_loss: 1.5622 - val_accuracy: 0.2449 - 325ms/epoch - 81ms/step\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 139: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1271 - accuracy: 1.0000 - val_loss: 1.6360 - val_accuracy: 0.2245 - 329ms/epoch - 82ms/step\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 140: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1270 - accuracy: 1.0000 - val_loss: 1.5277 - val_accuracy: 0.2857 - 312ms/epoch - 78ms/step\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 141: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1266 - accuracy: 1.0000 - val_loss: 1.5805 - val_accuracy: 0.2245 - 322ms/epoch - 80ms/step\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 142: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1322 - accuracy: 1.0000 - val_loss: 1.5234 - val_accuracy: 0.2245 - 308ms/epoch - 77ms/step\n",
      "Epoch 143/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 143: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1169 - accuracy: 1.0000 - val_loss: 1.6014 - val_accuracy: 0.2653 - 314ms/epoch - 79ms/step\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 144: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1298 - accuracy: 1.0000 - val_loss: 1.6567 - val_accuracy: 0.2041 - 312ms/epoch - 78ms/step\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 145: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1327 - accuracy: 1.0000 - val_loss: 1.5670 - val_accuracy: 0.2653 - 322ms/epoch - 81ms/step\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 146: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1470 - accuracy: 1.0000 - val_loss: 1.5198 - val_accuracy: 0.2653 - 313ms/epoch - 78ms/step\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 147: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1181 - accuracy: 1.0000 - val_loss: 1.5251 - val_accuracy: 0.2857 - 311ms/epoch - 78ms/step\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 148: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1351 - accuracy: 1.0000 - val_loss: 1.4759 - val_accuracy: 0.2653 - 340ms/epoch - 85ms/step\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 149: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1224 - accuracy: 1.0000 - val_loss: 1.6007 - val_accuracy: 0.2653 - 326ms/epoch - 81ms/step\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 150: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1361 - accuracy: 1.0000 - val_loss: 1.5696 - val_accuracy: 0.2245 - 318ms/epoch - 79ms/step\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 151: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1245 - accuracy: 1.0000 - val_loss: 1.5418 - val_accuracy: 0.3469 - 323ms/epoch - 81ms/step\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 152: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1209 - accuracy: 1.0000 - val_loss: 1.4577 - val_accuracy: 0.3265 - 312ms/epoch - 78ms/step\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 153: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1305 - accuracy: 1.0000 - val_loss: 1.5315 - val_accuracy: 0.3061 - 316ms/epoch - 79ms/step\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 154: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1175 - accuracy: 1.0000 - val_loss: 1.4751 - val_accuracy: 0.2653 - 323ms/epoch - 81ms/step\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 155: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1265 - accuracy: 1.0000 - val_loss: 1.5572 - val_accuracy: 0.1837 - 316ms/epoch - 79ms/step\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 156: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1017 - accuracy: 1.0000 - val_loss: 1.5139 - val_accuracy: 0.2857 - 312ms/epoch - 78ms/step\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 157: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1046 - accuracy: 1.0000 - val_loss: 1.5800 - val_accuracy: 0.2449 - 328ms/epoch - 82ms/step\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 158: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1105 - accuracy: 1.0000 - val_loss: 1.5561 - val_accuracy: 0.2653 - 318ms/epoch - 79ms/step\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 159: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1090 - accuracy: 1.0000 - val_loss: 1.5579 - val_accuracy: 0.2653 - 315ms/epoch - 79ms/step\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 160: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1053 - accuracy: 1.0000 - val_loss: 1.5509 - val_accuracy: 0.2449 - 328ms/epoch - 82ms/step\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 161: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0994 - accuracy: 1.0000 - val_loss: 1.5018 - val_accuracy: 0.2857 - 309ms/epoch - 77ms/step\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 162: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1031 - accuracy: 1.0000 - val_loss: 1.5707 - val_accuracy: 0.2245 - 317ms/epoch - 79ms/step\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 163: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0989 - accuracy: 1.0000 - val_loss: 1.5199 - val_accuracy: 0.3061 - 318ms/epoch - 80ms/step\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 164: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1129 - accuracy: 1.0000 - val_loss: 1.5680 - val_accuracy: 0.3061 - 315ms/epoch - 79ms/step\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 165: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0976 - accuracy: 1.0000 - val_loss: 1.5398 - val_accuracy: 0.2653 - 317ms/epoch - 79ms/step\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 166: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1048 - accuracy: 1.0000 - val_loss: 1.5831 - val_accuracy: 0.3469 - 313ms/epoch - 78ms/step\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 167: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1064 - accuracy: 1.0000 - val_loss: 1.5814 - val_accuracy: 0.2449 - 335ms/epoch - 84ms/step\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 168: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0968 - accuracy: 1.0000 - val_loss: 1.5139 - val_accuracy: 0.2857 - 309ms/epoch - 77ms/step\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 169: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1105 - accuracy: 1.0000 - val_loss: 1.5331 - val_accuracy: 0.2857 - 321ms/epoch - 80ms/step\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 170: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0992 - accuracy: 1.0000 - val_loss: 1.5183 - val_accuracy: 0.2041 - 321ms/epoch - 80ms/step\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 171: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1065 - accuracy: 1.0000 - val_loss: 1.5307 - val_accuracy: 0.3061 - 313ms/epoch - 78ms/step\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 172: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1009 - accuracy: 1.0000 - val_loss: 1.5471 - val_accuracy: 0.2653 - 306ms/epoch - 77ms/step\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 173: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1029 - accuracy: 1.0000 - val_loss: 1.6165 - val_accuracy: 0.3061 - 311ms/epoch - 78ms/step\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 174: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0980 - accuracy: 1.0000 - val_loss: 1.5428 - val_accuracy: 0.3061 - 307ms/epoch - 77ms/step\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 175: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0894 - accuracy: 1.0000 - val_loss: 1.5661 - val_accuracy: 0.3061 - 315ms/epoch - 79ms/step\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 176: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0949 - accuracy: 1.0000 - val_loss: 1.5647 - val_accuracy: 0.2653 - 330ms/epoch - 83ms/step\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 177: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0880 - accuracy: 1.0000 - val_loss: 1.5334 - val_accuracy: 0.2857 - 322ms/epoch - 80ms/step\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 178: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0825 - accuracy: 1.0000 - val_loss: 1.5007 - val_accuracy: 0.3061 - 325ms/epoch - 81ms/step\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 179: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0915 - accuracy: 1.0000 - val_loss: 1.6089 - val_accuracy: 0.2245 - 320ms/epoch - 80ms/step\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 180: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0932 - accuracy: 1.0000 - val_loss: 1.5870 - val_accuracy: 0.2857 - 312ms/epoch - 78ms/step\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 181: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0937 - accuracy: 1.0000 - val_loss: 1.5879 - val_accuracy: 0.2041 - 315ms/epoch - 79ms/step\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 182: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0935 - accuracy: 1.0000 - val_loss: 1.5901 - val_accuracy: 0.3469 - 325ms/epoch - 81ms/step\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 183: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0910 - accuracy: 1.0000 - val_loss: 1.6064 - val_accuracy: 0.2653 - 314ms/epoch - 78ms/step\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 184: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0948 - accuracy: 1.0000 - val_loss: 1.6561 - val_accuracy: 0.2449 - 314ms/epoch - 78ms/step\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 185: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0963 - accuracy: 1.0000 - val_loss: 1.5651 - val_accuracy: 0.2449 - 318ms/epoch - 80ms/step\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 186: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0985 - accuracy: 1.0000 - val_loss: 1.5756 - val_accuracy: 0.3061 - 310ms/epoch - 77ms/step\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 187: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0900 - accuracy: 1.0000 - val_loss: 1.5414 - val_accuracy: 0.2653 - 318ms/epoch - 80ms/step\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 188: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0867 - accuracy: 1.0000 - val_loss: 1.6759 - val_accuracy: 0.2857 - 316ms/epoch - 79ms/step\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 189: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0894 - accuracy: 1.0000 - val_loss: 1.5459 - val_accuracy: 0.2449 - 328ms/epoch - 82ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190/300\n",
      "\n",
      "Epoch 190: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0991 - accuracy: 1.0000 - val_loss: 1.5369 - val_accuracy: 0.3878 - 323ms/epoch - 81ms/step\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 191: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0849 - accuracy: 1.0000 - val_loss: 1.5248 - val_accuracy: 0.2857 - 310ms/epoch - 77ms/step\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 192: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.1019 - accuracy: 1.0000 - val_loss: 1.5660 - val_accuracy: 0.2449 - 309ms/epoch - 77ms/step\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 193: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0914 - accuracy: 1.0000 - val_loss: 1.5050 - val_accuracy: 0.2449 - 324ms/epoch - 81ms/step\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 194: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0854 - accuracy: 1.0000 - val_loss: 1.6466 - val_accuracy: 0.3061 - 313ms/epoch - 78ms/step\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 195: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0922 - accuracy: 1.0000 - val_loss: 1.6782 - val_accuracy: 0.2449 - 324ms/epoch - 81ms/step\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 196: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0765 - accuracy: 1.0000 - val_loss: 1.5571 - val_accuracy: 0.2857 - 315ms/epoch - 79ms/step\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 197: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0900 - accuracy: 1.0000 - val_loss: 1.5880 - val_accuracy: 0.2449 - 326ms/epoch - 82ms/step\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 198: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0779 - accuracy: 1.0000 - val_loss: 1.5684 - val_accuracy: 0.2857 - 345ms/epoch - 86ms/step\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 199: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0931 - accuracy: 1.0000 - val_loss: 1.6396 - val_accuracy: 0.2041 - 317ms/epoch - 79ms/step\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 200: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0816 - accuracy: 1.0000 - val_loss: 1.4900 - val_accuracy: 0.2449 - 314ms/epoch - 79ms/step\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 201: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0776 - accuracy: 1.0000 - val_loss: 1.6216 - val_accuracy: 0.3061 - 328ms/epoch - 82ms/step\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 202: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0831 - accuracy: 1.0000 - val_loss: 1.5483 - val_accuracy: 0.2653 - 319ms/epoch - 80ms/step\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 203: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0715 - accuracy: 1.0000 - val_loss: 1.5953 - val_accuracy: 0.3469 - 307ms/epoch - 77ms/step\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 204: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0783 - accuracy: 1.0000 - val_loss: 1.6194 - val_accuracy: 0.2449 - 315ms/epoch - 79ms/step\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 205: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0792 - accuracy: 1.0000 - val_loss: 1.5504 - val_accuracy: 0.2449 - 314ms/epoch - 79ms/step\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 206: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0813 - accuracy: 1.0000 - val_loss: 1.5607 - val_accuracy: 0.2857 - 315ms/epoch - 79ms/step\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 207: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0774 - accuracy: 1.0000 - val_loss: 1.4986 - val_accuracy: 0.3061 - 317ms/epoch - 79ms/step\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 208: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0853 - accuracy: 1.0000 - val_loss: 1.6584 - val_accuracy: 0.2653 - 318ms/epoch - 80ms/step\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 209: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0761 - accuracy: 1.0000 - val_loss: 1.5775 - val_accuracy: 0.2857 - 307ms/epoch - 77ms/step\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 210: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0703 - accuracy: 1.0000 - val_loss: 1.6092 - val_accuracy: 0.2653 - 317ms/epoch - 79ms/step\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 211: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0685 - accuracy: 1.0000 - val_loss: 1.5447 - val_accuracy: 0.2245 - 316ms/epoch - 79ms/step\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 212: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0658 - accuracy: 1.0000 - val_loss: 1.5672 - val_accuracy: 0.2449 - 331ms/epoch - 83ms/step\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 213: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0614 - accuracy: 1.0000 - val_loss: 1.5708 - val_accuracy: 0.2857 - 309ms/epoch - 77ms/step\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 214: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0764 - accuracy: 1.0000 - val_loss: 1.6478 - val_accuracy: 0.2857 - 318ms/epoch - 80ms/step\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 215: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0729 - accuracy: 1.0000 - val_loss: 1.5634 - val_accuracy: 0.3265 - 318ms/epoch - 79ms/step\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 216: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0688 - accuracy: 1.0000 - val_loss: 1.5655 - val_accuracy: 0.2653 - 318ms/epoch - 80ms/step\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 217: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0702 - accuracy: 1.0000 - val_loss: 1.4529 - val_accuracy: 0.2857 - 323ms/epoch - 81ms/step\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 218: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0719 - accuracy: 1.0000 - val_loss: 1.5973 - val_accuracy: 0.2857 - 311ms/epoch - 78ms/step\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 219: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0760 - accuracy: 1.0000 - val_loss: 1.5140 - val_accuracy: 0.3469 - 320ms/epoch - 80ms/step\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 220: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0743 - accuracy: 1.0000 - val_loss: 1.6599 - val_accuracy: 0.2653 - 309ms/epoch - 77ms/step\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 221: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0747 - accuracy: 1.0000 - val_loss: 1.5366 - val_accuracy: 0.2857 - 317ms/epoch - 79ms/step\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 222: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0777 - accuracy: 1.0000 - val_loss: 1.6015 - val_accuracy: 0.2857 - 319ms/epoch - 80ms/step\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 223: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0718 - accuracy: 1.0000 - val_loss: 1.4874 - val_accuracy: 0.2653 - 317ms/epoch - 79ms/step\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 224: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0684 - accuracy: 1.0000 - val_loss: 1.5586 - val_accuracy: 0.2245 - 310ms/epoch - 77ms/step\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 225: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0680 - accuracy: 1.0000 - val_loss: 1.5106 - val_accuracy: 0.3469 - 307ms/epoch - 77ms/step\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 226: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0716 - accuracy: 1.0000 - val_loss: 1.6647 - val_accuracy: 0.2245 - 306ms/epoch - 76ms/step\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 227: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0688 - accuracy: 1.0000 - val_loss: 1.5662 - val_accuracy: 0.3265 - 311ms/epoch - 78ms/step\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 228: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0717 - accuracy: 1.0000 - val_loss: 1.6175 - val_accuracy: 0.2857 - 315ms/epoch - 79ms/step\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 229: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0653 - accuracy: 1.0000 - val_loss: 1.6195 - val_accuracy: 0.2449 - 330ms/epoch - 82ms/step\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 230: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0651 - accuracy: 1.0000 - val_loss: 1.6146 - val_accuracy: 0.2857 - 320ms/epoch - 80ms/step\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 231: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0622 - accuracy: 1.0000 - val_loss: 1.5177 - val_accuracy: 0.2857 - 311ms/epoch - 78ms/step\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 232: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0626 - accuracy: 1.0000 - val_loss: 1.5555 - val_accuracy: 0.2653 - 316ms/epoch - 79ms/step\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 233: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0623 - accuracy: 1.0000 - val_loss: 1.5603 - val_accuracy: 0.2653 - 314ms/epoch - 78ms/step\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 234: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0664 - accuracy: 1.0000 - val_loss: 1.5403 - val_accuracy: 0.2449 - 313ms/epoch - 78ms/step\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 235: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0629 - accuracy: 1.0000 - val_loss: 1.5225 - val_accuracy: 0.3469 - 331ms/epoch - 83ms/step\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 236: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0591 - accuracy: 1.0000 - val_loss: 1.6076 - val_accuracy: 0.2449 - 310ms/epoch - 77ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237/300\n",
      "\n",
      "Epoch 237: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0655 - accuracy: 1.0000 - val_loss: 1.6013 - val_accuracy: 0.2449 - 329ms/epoch - 82ms/step\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 238: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0622 - accuracy: 1.0000 - val_loss: 1.5849 - val_accuracy: 0.2449 - 316ms/epoch - 79ms/step\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 239: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0701 - accuracy: 1.0000 - val_loss: 1.5567 - val_accuracy: 0.2857 - 318ms/epoch - 79ms/step\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 240: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0619 - accuracy: 1.0000 - val_loss: 1.5090 - val_accuracy: 0.2449 - 317ms/epoch - 79ms/step\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 241: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0729 - accuracy: 1.0000 - val_loss: 1.5622 - val_accuracy: 0.2245 - 331ms/epoch - 83ms/step\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 242: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0561 - accuracy: 1.0000 - val_loss: 1.5000 - val_accuracy: 0.2857 - 306ms/epoch - 77ms/step\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 243: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0644 - accuracy: 1.0000 - val_loss: 1.5783 - val_accuracy: 0.2449 - 310ms/epoch - 77ms/step\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 244: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0677 - accuracy: 1.0000 - val_loss: 1.5638 - val_accuracy: 0.2653 - 312ms/epoch - 78ms/step\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 245: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0615 - accuracy: 1.0000 - val_loss: 1.6022 - val_accuracy: 0.2653 - 310ms/epoch - 78ms/step\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 246: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0537 - accuracy: 1.0000 - val_loss: 1.5878 - val_accuracy: 0.3061 - 320ms/epoch - 80ms/step\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 247: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0579 - accuracy: 1.0000 - val_loss: 1.5888 - val_accuracy: 0.2857 - 316ms/epoch - 79ms/step\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 248: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0504 - accuracy: 1.0000 - val_loss: 1.5573 - val_accuracy: 0.2653 - 307ms/epoch - 77ms/step\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 249: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0576 - accuracy: 1.0000 - val_loss: 1.6185 - val_accuracy: 0.3265 - 310ms/epoch - 77ms/step\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 250: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0579 - accuracy: 1.0000 - val_loss: 1.6111 - val_accuracy: 0.2653 - 311ms/epoch - 78ms/step\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 251: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0558 - accuracy: 1.0000 - val_loss: 1.6117 - val_accuracy: 0.2653 - 314ms/epoch - 79ms/step\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 252: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0629 - accuracy: 1.0000 - val_loss: 1.6675 - val_accuracy: 0.2041 - 305ms/epoch - 76ms/step\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 253: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0632 - accuracy: 1.0000 - val_loss: 1.6567 - val_accuracy: 0.2449 - 313ms/epoch - 78ms/step\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 254: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0582 - accuracy: 1.0000 - val_loss: 1.5963 - val_accuracy: 0.2245 - 308ms/epoch - 77ms/step\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 255: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0618 - accuracy: 1.0000 - val_loss: 1.7224 - val_accuracy: 0.2041 - 307ms/epoch - 77ms/step\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 256: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0601 - accuracy: 1.0000 - val_loss: 1.6271 - val_accuracy: 0.3061 - 323ms/epoch - 81ms/step\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 257: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0562 - accuracy: 1.0000 - val_loss: 1.6210 - val_accuracy: 0.2653 - 312ms/epoch - 78ms/step\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 258: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0592 - accuracy: 1.0000 - val_loss: 1.6215 - val_accuracy: 0.2449 - 308ms/epoch - 77ms/step\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 259: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0507 - accuracy: 1.0000 - val_loss: 1.6015 - val_accuracy: 0.2653 - 331ms/epoch - 83ms/step\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 260: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0579 - accuracy: 1.0000 - val_loss: 1.5770 - val_accuracy: 0.3061 - 306ms/epoch - 77ms/step\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 261: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0514 - accuracy: 1.0000 - val_loss: 1.6140 - val_accuracy: 0.2653 - 309ms/epoch - 77ms/step\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 262: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0520 - accuracy: 1.0000 - val_loss: 1.5619 - val_accuracy: 0.3265 - 318ms/epoch - 80ms/step\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 263: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0564 - accuracy: 1.0000 - val_loss: 1.6253 - val_accuracy: 0.2653 - 310ms/epoch - 77ms/step\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 264: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0538 - accuracy: 1.0000 - val_loss: 1.5570 - val_accuracy: 0.3061 - 321ms/epoch - 80ms/step\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 265: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0547 - accuracy: 1.0000 - val_loss: 1.5462 - val_accuracy: 0.3265 - 320ms/epoch - 80ms/step\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 266: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0610 - accuracy: 1.0000 - val_loss: 1.6159 - val_accuracy: 0.2449 - 312ms/epoch - 78ms/step\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 267: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0525 - accuracy: 1.0000 - val_loss: 1.5211 - val_accuracy: 0.2857 - 324ms/epoch - 81ms/step\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 268: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0574 - accuracy: 1.0000 - val_loss: 1.6967 - val_accuracy: 0.2857 - 313ms/epoch - 78ms/step\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 269: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0600 - accuracy: 1.0000 - val_loss: 1.5592 - val_accuracy: 0.2653 - 316ms/epoch - 79ms/step\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 270: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0575 - accuracy: 1.0000 - val_loss: 1.6277 - val_accuracy: 0.2449 - 318ms/epoch - 80ms/step\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 271: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0527 - accuracy: 1.0000 - val_loss: 1.6040 - val_accuracy: 0.3265 - 326ms/epoch - 81ms/step\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 272: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0535 - accuracy: 1.0000 - val_loss: 1.6092 - val_accuracy: 0.3469 - 311ms/epoch - 78ms/step\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 273: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0615 - accuracy: 1.0000 - val_loss: 1.5054 - val_accuracy: 0.2653 - 314ms/epoch - 78ms/step\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 274: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0747 - accuracy: 1.0000 - val_loss: 1.5923 - val_accuracy: 0.3469 - 322ms/epoch - 81ms/step\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 275: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0566 - accuracy: 1.0000 - val_loss: 1.6606 - val_accuracy: 0.2857 - 319ms/epoch - 80ms/step\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 276: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0695 - accuracy: 1.0000 - val_loss: 1.4863 - val_accuracy: 0.2857 - 318ms/epoch - 80ms/step\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 277: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0570 - accuracy: 1.0000 - val_loss: 1.6483 - val_accuracy: 0.2857 - 313ms/epoch - 78ms/step\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 278: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0552 - accuracy: 1.0000 - val_loss: 1.5980 - val_accuracy: 0.2857 - 333ms/epoch - 83ms/step\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 279: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0654 - accuracy: 1.0000 - val_loss: 1.5717 - val_accuracy: 0.3265 - 309ms/epoch - 77ms/step\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 280: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0591 - accuracy: 1.0000 - val_loss: 1.6319 - val_accuracy: 0.2857 - 312ms/epoch - 78ms/step\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 281: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0536 - accuracy: 1.0000 - val_loss: 1.6409 - val_accuracy: 0.3265 - 315ms/epoch - 79ms/step\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 282: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0542 - accuracy: 1.0000 - val_loss: 1.5980 - val_accuracy: 0.2653 - 312ms/epoch - 78ms/step\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 283: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0513 - accuracy: 1.0000 - val_loss: 1.5098 - val_accuracy: 0.2857 - 332ms/epoch - 83ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284/300\n",
      "\n",
      "Epoch 284: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0498 - accuracy: 1.0000 - val_loss: 1.6739 - val_accuracy: 0.2653 - 319ms/epoch - 80ms/step\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 285: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0494 - accuracy: 1.0000 - val_loss: 1.6835 - val_accuracy: 0.2653 - 316ms/epoch - 79ms/step\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 286: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0444 - accuracy: 1.0000 - val_loss: 1.6652 - val_accuracy: 0.2857 - 307ms/epoch - 77ms/step\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 287: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0492 - accuracy: 1.0000 - val_loss: 1.6537 - val_accuracy: 0.2653 - 314ms/epoch - 79ms/step\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 288: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0435 - accuracy: 1.0000 - val_loss: 1.6053 - val_accuracy: 0.2245 - 310ms/epoch - 78ms/step\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 289: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0478 - accuracy: 1.0000 - val_loss: 1.6800 - val_accuracy: 0.2245 - 316ms/epoch - 79ms/step\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 290: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0447 - accuracy: 1.0000 - val_loss: 1.6438 - val_accuracy: 0.2449 - 310ms/epoch - 78ms/step\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 291: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0449 - accuracy: 1.0000 - val_loss: 1.6172 - val_accuracy: 0.2857 - 321ms/epoch - 80ms/step\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 292: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0489 - accuracy: 1.0000 - val_loss: 1.6296 - val_accuracy: 0.2857 - 323ms/epoch - 81ms/step\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 293: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0425 - accuracy: 1.0000 - val_loss: 1.5827 - val_accuracy: 0.2857 - 314ms/epoch - 78ms/step\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 294: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0484 - accuracy: 1.0000 - val_loss: 1.6624 - val_accuracy: 0.2245 - 313ms/epoch - 78ms/step\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 295: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0473 - accuracy: 1.0000 - val_loss: 1.6236 - val_accuracy: 0.3469 - 336ms/epoch - 84ms/step\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 296: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0446 - accuracy: 1.0000 - val_loss: 1.6908 - val_accuracy: 0.2449 - 311ms/epoch - 78ms/step\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 297: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0489 - accuracy: 1.0000 - val_loss: 1.5946 - val_accuracy: 0.2653 - 328ms/epoch - 82ms/step\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 298: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0437 - accuracy: 1.0000 - val_loss: 1.5691 - val_accuracy: 0.3061 - 308ms/epoch - 77ms/step\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 299: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0452 - accuracy: 1.0000 - val_loss: 1.4983 - val_accuracy: 0.3265 - 306ms/epoch - 77ms/step\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 300: val_loss did not improve from 1.38120\n",
      "4/4 - 0s - loss: 0.0529 - accuracy: 1.0000 - val_loss: 1.6460 - val_accuracy: 0.3061 - 307ms/epoch - 77ms/step\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 09:43:58.875680: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_9647144\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:633850\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
      "2022-11-11 09:44:02.854666: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_9650214\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:633892\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38674, saving model to checkpoint1.h5\n",
      "4/4 - 5s - loss: 1.4272 - accuracy: 0.2389 - val_loss: 1.3867 - val_accuracy: 0.1429 - 5s/epoch - 1s/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss did not improve from 1.38674\n",
      "4/4 - 0s - loss: 1.3123 - accuracy: 0.4159 - val_loss: 1.3872 - val_accuracy: 0.1837 - 321ms/epoch - 80ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss did not improve from 1.38674\n",
      "4/4 - 0s - loss: 1.2731 - accuracy: 0.4425 - val_loss: 1.3876 - val_accuracy: 0.1837 - 315ms/epoch - 79ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss did not improve from 1.38674\n",
      "4/4 - 0s - loss: 1.2520 - accuracy: 0.4867 - val_loss: 1.3879 - val_accuracy: 0.1837 - 301ms/epoch - 75ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss did not improve from 1.38674\n",
      "4/4 - 0s - loss: 1.2345 - accuracy: 0.5221 - val_loss: 1.3881 - val_accuracy: 0.1837 - 321ms/epoch - 80ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.38674\n",
      "4/4 - 0s - loss: 1.1931 - accuracy: 0.5487 - val_loss: 1.3884 - val_accuracy: 0.1837 - 306ms/epoch - 76ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 1.38674\n",
      "4/4 - 0s - loss: 1.1801 - accuracy: 0.5752 - val_loss: 1.3884 - val_accuracy: 0.1837 - 315ms/epoch - 79ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 1.38674\n",
      "4/4 - 0s - loss: 1.1620 - accuracy: 0.5841 - val_loss: 1.3885 - val_accuracy: 0.1837 - 307ms/epoch - 77ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 1.38674\n",
      "4/4 - 0s - loss: 1.1586 - accuracy: 0.5752 - val_loss: 1.3886 - val_accuracy: 0.1837 - 322ms/epoch - 80ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.38674\n",
      "4/4 - 1s - loss: 1.1409 - accuracy: 0.5929 - val_loss: 1.3890 - val_accuracy: 0.1837 - 675ms/epoch - 169ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.38674\n",
      "4/4 - 0s - loss: 1.0663 - accuracy: 0.6991 - val_loss: 1.3891 - val_accuracy: 0.1837 - 323ms/epoch - 81ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.38674\n",
      "4/4 - 0s - loss: 1.0815 - accuracy: 0.6814 - val_loss: 1.3893 - val_accuracy: 0.1837 - 327ms/epoch - 82ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.38674\n",
      "4/4 - 0s - loss: 1.0487 - accuracy: 0.7699 - val_loss: 1.3893 - val_accuracy: 0.1837 - 326ms/epoch - 81ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 1.38674\n",
      "4/4 - 0s - loss: 1.0411 - accuracy: 0.7257 - val_loss: 1.3895 - val_accuracy: 0.1837 - 323ms/epoch - 81ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.38674\n",
      "4/4 - 0s - loss: 1.0110 - accuracy: 0.7080 - val_loss: 1.3899 - val_accuracy: 0.1837 - 318ms/epoch - 80ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 1.38674\n",
      "4/4 - 0s - loss: 0.9919 - accuracy: 0.7699 - val_loss: 1.3901 - val_accuracy: 0.1837 - 315ms/epoch - 79ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 1.38674\n",
      "4/4 - 0s - loss: 0.9579 - accuracy: 0.7699 - val_loss: 1.3894 - val_accuracy: 0.1837 - 320ms/epoch - 80ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 1.38674\n",
      "4/4 - 0s - loss: 0.9715 - accuracy: 0.7876 - val_loss: 1.3891 - val_accuracy: 0.1837 - 332ms/epoch - 83ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 1.38674\n",
      "4/4 - 0s - loss: 0.9405 - accuracy: 0.8319 - val_loss: 1.3900 - val_accuracy: 0.1837 - 318ms/epoch - 79ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 1.38674\n",
      "4/4 - 0s - loss: 0.9364 - accuracy: 0.8407 - val_loss: 1.3909 - val_accuracy: 0.1837 - 323ms/epoch - 81ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 1.38674\n",
      "4/4 - 0s - loss: 0.9257 - accuracy: 0.8496 - val_loss: 1.3902 - val_accuracy: 0.1837 - 335ms/epoch - 84ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 1.38674\n",
      "4/4 - 0s - loss: 0.8960 - accuracy: 0.8496 - val_loss: 1.3908 - val_accuracy: 0.1837 - 326ms/epoch - 81ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 1.38674\n",
      "4/4 - 0s - loss: 0.9011 - accuracy: 0.8230 - val_loss: 1.3895 - val_accuracy: 0.1837 - 315ms/epoch - 79ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 1.38674\n",
      "4/4 - 0s - loss: 0.8432 - accuracy: 0.8584 - val_loss: 1.3889 - val_accuracy: 0.1837 - 317ms/epoch - 79ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.38674\n",
      "4/4 - 0s - loss: 0.8786 - accuracy: 0.8319 - val_loss: 1.3901 - val_accuracy: 0.1837 - 320ms/epoch - 80ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 1.38674\n",
      "4/4 - 0s - loss: 0.8526 - accuracy: 0.8584 - val_loss: 1.3880 - val_accuracy: 0.1837 - 319ms/epoch - 80ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 1.38674\n",
      "4/4 - 0s - loss: 0.8193 - accuracy: 0.9027 - val_loss: 1.3891 - val_accuracy: 0.1837 - 329ms/epoch - 82ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 1.38674\n",
      "4/4 - 0s - loss: 0.8265 - accuracy: 0.8761 - val_loss: 1.3908 - val_accuracy: 0.1837 - 322ms/epoch - 81ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss improved from 1.38674 to 1.38594, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.8153 - accuracy: 0.8673 - val_loss: 1.3859 - val_accuracy: 0.1837 - 366ms/epoch - 91ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss improved from 1.38594 to 1.38529, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.8040 - accuracy: 0.8850 - val_loss: 1.3853 - val_accuracy: 0.2041 - 377ms/epoch - 94ms/step\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 1.38529\n",
      "4/4 - 0s - loss: 0.8168 - accuracy: 0.8938 - val_loss: 1.3890 - val_accuracy: 0.1837 - 337ms/epoch - 84ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 1.38529\n",
      "4/4 - 0s - loss: 0.7642 - accuracy: 0.8850 - val_loss: 1.3856 - val_accuracy: 0.1837 - 320ms/epoch - 80ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss improved from 1.38529 to 1.38152, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.7718 - accuracy: 0.8673 - val_loss: 1.3815 - val_accuracy: 0.2653 - 380ms/epoch - 95ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 1.38152\n",
      "4/4 - 0s - loss: 0.7472 - accuracy: 0.8761 - val_loss: 1.3871 - val_accuracy: 0.1633 - 338ms/epoch - 85ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 1.38152\n",
      "4/4 - 0s - loss: 0.7300 - accuracy: 0.9027 - val_loss: 1.3833 - val_accuracy: 0.2245 - 322ms/epoch - 81ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 1.38152\n",
      "4/4 - 0s - loss: 0.7319 - accuracy: 0.9115 - val_loss: 1.3816 - val_accuracy: 0.3061 - 316ms/epoch - 79ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 1.38152\n",
      "4/4 - 0s - loss: 0.7225 - accuracy: 0.9292 - val_loss: 1.3858 - val_accuracy: 0.1837 - 315ms/epoch - 79ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss improved from 1.38152 to 1.38097, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.6953 - accuracy: 0.9292 - val_loss: 1.3810 - val_accuracy: 0.2245 - 365ms/epoch - 91ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss improved from 1.38097 to 1.37921, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.6773 - accuracy: 0.9381 - val_loss: 1.3792 - val_accuracy: 0.2245 - 367ms/epoch - 92ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 1.37921\n",
      "4/4 - 0s - loss: 0.6803 - accuracy: 0.9381 - val_loss: 1.3837 - val_accuracy: 0.2041 - 329ms/epoch - 82ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 1.37921\n",
      "4/4 - 0s - loss: 0.6884 - accuracy: 0.9292 - val_loss: 1.3835 - val_accuracy: 0.2041 - 324ms/epoch - 81ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss improved from 1.37921 to 1.37912, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.6621 - accuracy: 0.9292 - val_loss: 1.3791 - val_accuracy: 0.2449 - 364ms/epoch - 91ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 1.37912\n",
      "4/4 - 0s - loss: 0.6568 - accuracy: 0.9469 - val_loss: 1.3850 - val_accuracy: 0.1633 - 315ms/epoch - 79ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss improved from 1.37912 to 1.37622, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.6411 - accuracy: 0.9469 - val_loss: 1.3762 - val_accuracy: 0.3061 - 379ms/epoch - 95ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 1.37622\n",
      "4/4 - 0s - loss: 0.6423 - accuracy: 0.9558 - val_loss: 1.3947 - val_accuracy: 0.1837 - 324ms/epoch - 81ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 1.37622\n",
      "4/4 - 0s - loss: 0.6372 - accuracy: 0.9646 - val_loss: 1.4057 - val_accuracy: 0.1837 - 327ms/epoch - 82ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss improved from 1.37622 to 1.37444, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.6012 - accuracy: 0.9735 - val_loss: 1.3744 - val_accuracy: 0.2653 - 372ms/epoch - 93ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.5988 - accuracy: 0.9735 - val_loss: 1.3882 - val_accuracy: 0.2245 - 329ms/epoch - 82ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.5996 - accuracy: 0.9735 - val_loss: 1.3917 - val_accuracy: 0.2041 - 322ms/epoch - 80ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.5213 - accuracy: 0.9912 - val_loss: 1.3829 - val_accuracy: 0.2653 - 320ms/epoch - 80ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.5491 - accuracy: 0.9735 - val_loss: 1.3822 - val_accuracy: 0.2653 - 330ms/epoch - 83ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.5655 - accuracy: 0.9381 - val_loss: 1.3830 - val_accuracy: 0.2653 - 327ms/epoch - 82ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.5519 - accuracy: 0.9381 - val_loss: 1.3908 - val_accuracy: 0.2245 - 320ms/epoch - 80ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.5154 - accuracy: 0.9558 - val_loss: 1.3927 - val_accuracy: 0.3265 - 326ms/epoch - 81ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.4843 - accuracy: 0.9912 - val_loss: 1.3804 - val_accuracy: 0.2857 - 332ms/epoch - 83ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.4877 - accuracy: 0.9735 - val_loss: 1.3996 - val_accuracy: 0.2857 - 316ms/epoch - 79ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.4713 - accuracy: 0.9735 - val_loss: 1.3918 - val_accuracy: 0.2449 - 328ms/epoch - 82ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.4815 - accuracy: 1.0000 - val_loss: 1.3997 - val_accuracy: 0.2653 - 325ms/epoch - 81ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.4790 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.1837 - 316ms/epoch - 79ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.4442 - accuracy: 1.0000 - val_loss: 1.3894 - val_accuracy: 0.3061 - 318ms/epoch - 80ms/step\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.4404 - accuracy: 1.0000 - val_loss: 1.4234 - val_accuracy: 0.1633 - 317ms/epoch - 79ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.4180 - accuracy: 0.9912 - val_loss: 1.3853 - val_accuracy: 0.2653 - 320ms/epoch - 80ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.4263 - accuracy: 0.9912 - val_loss: 1.4449 - val_accuracy: 0.2041 - 323ms/epoch - 81ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.3897 - accuracy: 0.9912 - val_loss: 1.3894 - val_accuracy: 0.3061 - 316ms/epoch - 79ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.4293 - accuracy: 1.0000 - val_loss: 1.4210 - val_accuracy: 0.3061 - 320ms/epoch - 80ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.3944 - accuracy: 1.0000 - val_loss: 1.4253 - val_accuracy: 0.1837 - 327ms/epoch - 82ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.3891 - accuracy: 0.9912 - val_loss: 1.4182 - val_accuracy: 0.2857 - 345ms/epoch - 86ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.3827 - accuracy: 0.9912 - val_loss: 1.4475 - val_accuracy: 0.2041 - 319ms/epoch - 80ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.3407 - accuracy: 1.0000 - val_loss: 1.4193 - val_accuracy: 0.2857 - 337ms/epoch - 84ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.3896 - accuracy: 0.9912 - val_loss: 1.4958 - val_accuracy: 0.2653 - 322ms/epoch - 80ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.3786 - accuracy: 0.9823 - val_loss: 1.4279 - val_accuracy: 0.2449 - 323ms/epoch - 81ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.3560 - accuracy: 0.9912 - val_loss: 1.4503 - val_accuracy: 0.2653 - 320ms/epoch - 80ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.3247 - accuracy: 1.0000 - val_loss: 1.4462 - val_accuracy: 0.2245 - 328ms/epoch - 82ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.3254 - accuracy: 1.0000 - val_loss: 1.4396 - val_accuracy: 0.3469 - 328ms/epoch - 82ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.3271 - accuracy: 1.0000 - val_loss: 1.4885 - val_accuracy: 0.1837 - 316ms/epoch - 79ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.3157 - accuracy: 1.0000 - val_loss: 1.4253 - val_accuracy: 0.3061 - 326ms/epoch - 82ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.3105 - accuracy: 1.0000 - val_loss: 1.5042 - val_accuracy: 0.2041 - 319ms/epoch - 80ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.3203 - accuracy: 0.9912 - val_loss: 1.4781 - val_accuracy: 0.3469 - 316ms/epoch - 79ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.3249 - accuracy: 1.0000 - val_loss: 1.4675 - val_accuracy: 0.1837 - 330ms/epoch - 82ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.2638 - accuracy: 1.0000 - val_loss: 1.4927 - val_accuracy: 0.2857 - 326ms/epoch - 82ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.2797 - accuracy: 0.9912 - val_loss: 1.5015 - val_accuracy: 0.1837 - 318ms/epoch - 79ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.3055 - accuracy: 0.9912 - val_loss: 1.4659 - val_accuracy: 0.2857 - 316ms/epoch - 79ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.2975 - accuracy: 1.0000 - val_loss: 1.5490 - val_accuracy: 0.1837 - 318ms/epoch - 80ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.2847 - accuracy: 1.0000 - val_loss: 1.4768 - val_accuracy: 0.3673 - 317ms/epoch - 79ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.3032 - accuracy: 1.0000 - val_loss: 1.5123 - val_accuracy: 0.2041 - 318ms/epoch - 79ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.2756 - accuracy: 1.0000 - val_loss: 1.5153 - val_accuracy: 0.3061 - 313ms/epoch - 78ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.2874 - accuracy: 1.0000 - val_loss: 1.5058 - val_accuracy: 0.2449 - 313ms/epoch - 78ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.2747 - accuracy: 1.0000 - val_loss: 1.5616 - val_accuracy: 0.2245 - 313ms/epoch - 78ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.2674 - accuracy: 1.0000 - val_loss: 1.4740 - val_accuracy: 0.2449 - 318ms/epoch - 80ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.2741 - accuracy: 1.0000 - val_loss: 1.5575 - val_accuracy: 0.2245 - 317ms/epoch - 79ms/step\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.2419 - accuracy: 1.0000 - val_loss: 1.5940 - val_accuracy: 0.2245 - 331ms/epoch - 83ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.2570 - accuracy: 1.0000 - val_loss: 1.6286 - val_accuracy: 0.2245 - 319ms/epoch - 80ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.2628 - accuracy: 1.0000 - val_loss: 1.5912 - val_accuracy: 0.2653 - 311ms/epoch - 78ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 1.37444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.2529 - accuracy: 1.0000 - val_loss: 1.5641 - val_accuracy: 0.2653 - 314ms/epoch - 78ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.2522 - accuracy: 0.9912 - val_loss: 1.6215 - val_accuracy: 0.3061 - 324ms/epoch - 81ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 1.5574 - val_accuracy: 0.3061 - 326ms/epoch - 81ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.2605 - accuracy: 1.0000 - val_loss: 1.6003 - val_accuracy: 0.2449 - 350ms/epoch - 87ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.2539 - accuracy: 0.9912 - val_loss: 1.5339 - val_accuracy: 0.2857 - 318ms/epoch - 80ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.2288 - accuracy: 1.0000 - val_loss: 1.6198 - val_accuracy: 0.2245 - 315ms/epoch - 79ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.2187 - accuracy: 1.0000 - val_loss: 1.5776 - val_accuracy: 0.2857 - 314ms/epoch - 78ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.2324 - accuracy: 1.0000 - val_loss: 1.5997 - val_accuracy: 0.2857 - 320ms/epoch - 80ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.2392 - accuracy: 1.0000 - val_loss: 1.6407 - val_accuracy: 0.2653 - 315ms/epoch - 79ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 1.5711 - val_accuracy: 0.2653 - 326ms/epoch - 82ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.2242 - accuracy: 1.0000 - val_loss: 1.6392 - val_accuracy: 0.2653 - 313ms/epoch - 78ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.2215 - accuracy: 1.0000 - val_loss: 1.6266 - val_accuracy: 0.2653 - 315ms/epoch - 79ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.2021 - accuracy: 1.0000 - val_loss: 1.6210 - val_accuracy: 0.2653 - 322ms/epoch - 81ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.2055 - accuracy: 1.0000 - val_loss: 1.6012 - val_accuracy: 0.3265 - 333ms/epoch - 83ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1936 - accuracy: 1.0000 - val_loss: 1.6310 - val_accuracy: 0.2857 - 307ms/epoch - 77ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1892 - accuracy: 1.0000 - val_loss: 1.5628 - val_accuracy: 0.3265 - 325ms/epoch - 81ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1904 - accuracy: 1.0000 - val_loss: 1.6671 - val_accuracy: 0.2857 - 317ms/epoch - 79ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1865 - accuracy: 1.0000 - val_loss: 1.6104 - val_accuracy: 0.3265 - 316ms/epoch - 79ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1762 - accuracy: 1.0000 - val_loss: 1.6336 - val_accuracy: 0.3061 - 327ms/epoch - 82ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1800 - accuracy: 1.0000 - val_loss: 1.7000 - val_accuracy: 0.2653 - 318ms/epoch - 80ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1817 - accuracy: 1.0000 - val_loss: 1.7558 - val_accuracy: 0.2245 - 311ms/epoch - 78ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1897 - accuracy: 1.0000 - val_loss: 1.6165 - val_accuracy: 0.3265 - 326ms/epoch - 82ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1617 - accuracy: 1.0000 - val_loss: 1.7169 - val_accuracy: 0.2653 - 322ms/epoch - 80ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1695 - accuracy: 1.0000 - val_loss: 1.6643 - val_accuracy: 0.3265 - 313ms/epoch - 78ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1602 - accuracy: 1.0000 - val_loss: 1.6919 - val_accuracy: 0.2653 - 316ms/epoch - 79ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1835 - accuracy: 1.0000 - val_loss: 1.6766 - val_accuracy: 0.2857 - 325ms/epoch - 81ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.2000 - accuracy: 1.0000 - val_loss: 1.7749 - val_accuracy: 0.2653 - 320ms/epoch - 80ms/step\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1861 - accuracy: 1.0000 - val_loss: 1.7407 - val_accuracy: 0.2857 - 316ms/epoch - 79ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1439 - accuracy: 1.0000 - val_loss: 1.6356 - val_accuracy: 0.3469 - 311ms/epoch - 78ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1707 - accuracy: 1.0000 - val_loss: 1.7030 - val_accuracy: 0.2857 - 324ms/epoch - 81ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1675 - accuracy: 1.0000 - val_loss: 1.6606 - val_accuracy: 0.3265 - 321ms/epoch - 80ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1683 - accuracy: 1.0000 - val_loss: 1.6813 - val_accuracy: 0.2653 - 324ms/epoch - 81ms/step\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1539 - accuracy: 1.0000 - val_loss: 1.6923 - val_accuracy: 0.3061 - 312ms/epoch - 78ms/step\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1613 - accuracy: 1.0000 - val_loss: 1.7636 - val_accuracy: 0.2041 - 330ms/epoch - 82ms/step\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1587 - accuracy: 1.0000 - val_loss: 1.7050 - val_accuracy: 0.2857 - 327ms/epoch - 82ms/step\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1518 - accuracy: 1.0000 - val_loss: 1.7090 - val_accuracy: 0.3061 - 317ms/epoch - 79ms/step\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1624 - accuracy: 1.0000 - val_loss: 1.8741 - val_accuracy: 0.2245 - 315ms/epoch - 79ms/step\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1693 - accuracy: 1.0000 - val_loss: 1.8084 - val_accuracy: 0.2857 - 322ms/epoch - 80ms/step\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1476 - accuracy: 1.0000 - val_loss: 1.7513 - val_accuracy: 0.3061 - 313ms/epoch - 78ms/step\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1532 - accuracy: 1.0000 - val_loss: 1.8986 - val_accuracy: 0.2041 - 323ms/epoch - 81ms/step\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1612 - accuracy: 1.0000 - val_loss: 1.6956 - val_accuracy: 0.3061 - 315ms/epoch - 79ms/step\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 135: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1560 - accuracy: 1.0000 - val_loss: 1.7603 - val_accuracy: 0.2245 - 314ms/epoch - 78ms/step\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 136: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1505 - accuracy: 1.0000 - val_loss: 1.7231 - val_accuracy: 0.3061 - 311ms/epoch - 78ms/step\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 137: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1492 - accuracy: 1.0000 - val_loss: 1.7185 - val_accuracy: 0.2449 - 312ms/epoch - 78ms/step\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 138: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1507 - accuracy: 1.0000 - val_loss: 1.7125 - val_accuracy: 0.2857 - 336ms/epoch - 84ms/step\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 139: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1333 - accuracy: 1.0000 - val_loss: 1.7686 - val_accuracy: 0.2041 - 343ms/epoch - 86ms/step\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 140: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1439 - accuracy: 1.0000 - val_loss: 1.8083 - val_accuracy: 0.2245 - 323ms/epoch - 81ms/step\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 141: val_loss did not improve from 1.37444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.1450 - accuracy: 1.0000 - val_loss: 1.8074 - val_accuracy: 0.2653 - 323ms/epoch - 81ms/step\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 142: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1433 - accuracy: 1.0000 - val_loss: 1.8349 - val_accuracy: 0.2245 - 324ms/epoch - 81ms/step\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 143: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1289 - accuracy: 1.0000 - val_loss: 1.8035 - val_accuracy: 0.2449 - 327ms/epoch - 82ms/step\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 144: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1452 - accuracy: 1.0000 - val_loss: 1.8600 - val_accuracy: 0.1837 - 322ms/epoch - 80ms/step\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 145: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1311 - accuracy: 1.0000 - val_loss: 1.7595 - val_accuracy: 0.2857 - 322ms/epoch - 81ms/step\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 146: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1378 - accuracy: 1.0000 - val_loss: 1.7336 - val_accuracy: 0.3061 - 321ms/epoch - 80ms/step\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 147: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1361 - accuracy: 1.0000 - val_loss: 1.7697 - val_accuracy: 0.2857 - 312ms/epoch - 78ms/step\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 148: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1391 - accuracy: 1.0000 - val_loss: 1.7929 - val_accuracy: 0.2653 - 314ms/epoch - 78ms/step\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 149: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1409 - accuracy: 1.0000 - val_loss: 1.7559 - val_accuracy: 0.2449 - 317ms/epoch - 79ms/step\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 150: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1212 - accuracy: 1.0000 - val_loss: 1.7347 - val_accuracy: 0.2653 - 330ms/epoch - 83ms/step\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 151: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1515 - accuracy: 1.0000 - val_loss: 1.7970 - val_accuracy: 0.2653 - 324ms/epoch - 81ms/step\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 152: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1336 - accuracy: 1.0000 - val_loss: 1.7761 - val_accuracy: 0.2653 - 315ms/epoch - 79ms/step\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 153: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1390 - accuracy: 1.0000 - val_loss: 1.7598 - val_accuracy: 0.2857 - 316ms/epoch - 79ms/step\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 154: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1247 - accuracy: 1.0000 - val_loss: 1.7141 - val_accuracy: 0.3061 - 315ms/epoch - 79ms/step\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 155: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1270 - accuracy: 1.0000 - val_loss: 1.7995 - val_accuracy: 0.2449 - 329ms/epoch - 82ms/step\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 156: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1377 - accuracy: 1.0000 - val_loss: 1.7034 - val_accuracy: 0.3265 - 320ms/epoch - 80ms/step\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 157: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1188 - accuracy: 1.0000 - val_loss: 1.7408 - val_accuracy: 0.3265 - 346ms/epoch - 87ms/step\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 158: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1083 - accuracy: 1.0000 - val_loss: 1.7862 - val_accuracy: 0.3061 - 311ms/epoch - 78ms/step\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 159: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1234 - accuracy: 1.0000 - val_loss: 1.7569 - val_accuracy: 0.2653 - 322ms/epoch - 81ms/step\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 160: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1261 - accuracy: 1.0000 - val_loss: 1.6934 - val_accuracy: 0.2857 - 314ms/epoch - 78ms/step\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 161: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1225 - accuracy: 1.0000 - val_loss: 1.7372 - val_accuracy: 0.3061 - 316ms/epoch - 79ms/step\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 162: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1116 - accuracy: 1.0000 - val_loss: 1.8052 - val_accuracy: 0.2857 - 322ms/epoch - 80ms/step\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 163: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1027 - accuracy: 1.0000 - val_loss: 1.8733 - val_accuracy: 0.2653 - 333ms/epoch - 83ms/step\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 164: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1107 - accuracy: 1.0000 - val_loss: 1.8185 - val_accuracy: 0.2653 - 311ms/epoch - 78ms/step\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 165: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1115 - accuracy: 1.0000 - val_loss: 1.7460 - val_accuracy: 0.3061 - 316ms/epoch - 79ms/step\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 166: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1029 - accuracy: 1.0000 - val_loss: 1.7264 - val_accuracy: 0.2857 - 328ms/epoch - 82ms/step\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 167: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1123 - accuracy: 1.0000 - val_loss: 1.7564 - val_accuracy: 0.2857 - 315ms/epoch - 79ms/step\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 168: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1304 - accuracy: 1.0000 - val_loss: 1.8501 - val_accuracy: 0.2041 - 309ms/epoch - 77ms/step\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 169: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1501 - accuracy: 0.9912 - val_loss: 1.7910 - val_accuracy: 0.3061 - 321ms/epoch - 80ms/step\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 170: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1279 - accuracy: 1.0000 - val_loss: 1.8014 - val_accuracy: 0.2245 - 314ms/epoch - 79ms/step\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 171: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1126 - accuracy: 1.0000 - val_loss: 1.7854 - val_accuracy: 0.2653 - 325ms/epoch - 81ms/step\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 172: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1108 - accuracy: 1.0000 - val_loss: 1.7225 - val_accuracy: 0.3061 - 326ms/epoch - 82ms/step\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 173: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1112 - accuracy: 1.0000 - val_loss: 1.9007 - val_accuracy: 0.2245 - 309ms/epoch - 77ms/step\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 174: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1092 - accuracy: 1.0000 - val_loss: 1.7960 - val_accuracy: 0.2653 - 329ms/epoch - 82ms/step\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 175: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1028 - accuracy: 1.0000 - val_loss: 1.8114 - val_accuracy: 0.2857 - 317ms/epoch - 79ms/step\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 176: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0936 - accuracy: 1.0000 - val_loss: 1.8015 - val_accuracy: 0.2857 - 333ms/epoch - 83ms/step\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 177: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0981 - accuracy: 1.0000 - val_loss: 1.7600 - val_accuracy: 0.2449 - 314ms/epoch - 78ms/step\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 178: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0960 - accuracy: 1.0000 - val_loss: 1.7862 - val_accuracy: 0.2857 - 310ms/epoch - 77ms/step\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 179: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1094 - accuracy: 1.0000 - val_loss: 1.7095 - val_accuracy: 0.2857 - 317ms/epoch - 79ms/step\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 180: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1085 - accuracy: 1.0000 - val_loss: 1.7561 - val_accuracy: 0.3673 - 316ms/epoch - 79ms/step\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 181: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1084 - accuracy: 0.9912 - val_loss: 1.8165 - val_accuracy: 0.2857 - 326ms/epoch - 81ms/step\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 182: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1360 - accuracy: 1.0000 - val_loss: 1.9841 - val_accuracy: 0.2041 - 314ms/epoch - 79ms/step\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 183: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1251 - accuracy: 1.0000 - val_loss: 1.9094 - val_accuracy: 0.1837 - 340ms/epoch - 85ms/step\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 184: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1196 - accuracy: 1.0000 - val_loss: 1.9369 - val_accuracy: 0.2041 - 331ms/epoch - 83ms/step\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 185: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1076 - accuracy: 1.0000 - val_loss: 1.9212 - val_accuracy: 0.1837 - 311ms/epoch - 78ms/step\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 186: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0970 - accuracy: 1.0000 - val_loss: 1.7565 - val_accuracy: 0.2857 - 313ms/epoch - 78ms/step\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 187: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0938 - accuracy: 1.0000 - val_loss: 1.7888 - val_accuracy: 0.2857 - 329ms/epoch - 82ms/step\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 188: val_loss did not improve from 1.37444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.0970 - accuracy: 1.0000 - val_loss: 1.8178 - val_accuracy: 0.2653 - 312ms/epoch - 78ms/step\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 189: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0929 - accuracy: 1.0000 - val_loss: 1.7677 - val_accuracy: 0.2857 - 314ms/epoch - 78ms/step\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 190: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.1029 - accuracy: 1.0000 - val_loss: 1.7768 - val_accuracy: 0.2653 - 320ms/epoch - 80ms/step\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 191: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0908 - accuracy: 1.0000 - val_loss: 1.8996 - val_accuracy: 0.2449 - 321ms/epoch - 80ms/step\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 192: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0959 - accuracy: 1.0000 - val_loss: 1.9452 - val_accuracy: 0.1837 - 314ms/epoch - 78ms/step\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 193: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0959 - accuracy: 1.0000 - val_loss: 1.8387 - val_accuracy: 0.2449 - 328ms/epoch - 82ms/step\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 194: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0830 - accuracy: 1.0000 - val_loss: 1.7939 - val_accuracy: 0.2653 - 334ms/epoch - 84ms/step\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 195: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0896 - accuracy: 1.0000 - val_loss: 1.7538 - val_accuracy: 0.2245 - 336ms/epoch - 84ms/step\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 196: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0850 - accuracy: 1.0000 - val_loss: 1.7418 - val_accuracy: 0.2857 - 334ms/epoch - 83ms/step\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 197: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0818 - accuracy: 1.0000 - val_loss: 1.8203 - val_accuracy: 0.2245 - 321ms/epoch - 80ms/step\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 198: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0792 - accuracy: 1.0000 - val_loss: 1.7414 - val_accuracy: 0.2653 - 323ms/epoch - 81ms/step\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 199: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0784 - accuracy: 1.0000 - val_loss: 1.7396 - val_accuracy: 0.3265 - 336ms/epoch - 84ms/step\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 200: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0803 - accuracy: 1.0000 - val_loss: 1.7883 - val_accuracy: 0.3265 - 316ms/epoch - 79ms/step\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 201: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0840 - accuracy: 1.0000 - val_loss: 1.8703 - val_accuracy: 0.2653 - 316ms/epoch - 79ms/step\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 202: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0694 - accuracy: 1.0000 - val_loss: 1.8287 - val_accuracy: 0.2653 - 316ms/epoch - 79ms/step\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 203: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0712 - accuracy: 1.0000 - val_loss: 1.7929 - val_accuracy: 0.2449 - 311ms/epoch - 78ms/step\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 204: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0682 - accuracy: 1.0000 - val_loss: 1.8118 - val_accuracy: 0.2245 - 314ms/epoch - 79ms/step\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 205: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0790 - accuracy: 1.0000 - val_loss: 1.7700 - val_accuracy: 0.2653 - 319ms/epoch - 80ms/step\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 206: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0815 - accuracy: 1.0000 - val_loss: 1.8014 - val_accuracy: 0.3061 - 315ms/epoch - 79ms/step\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 207: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0726 - accuracy: 1.0000 - val_loss: 1.7569 - val_accuracy: 0.3265 - 310ms/epoch - 77ms/step\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 208: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0757 - accuracy: 1.0000 - val_loss: 1.7598 - val_accuracy: 0.2653 - 317ms/epoch - 79ms/step\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 209: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0825 - accuracy: 1.0000 - val_loss: 1.7614 - val_accuracy: 0.2653 - 313ms/epoch - 78ms/step\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 210: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0768 - accuracy: 1.0000 - val_loss: 1.8365 - val_accuracy: 0.2857 - 319ms/epoch - 80ms/step\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 211: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0810 - accuracy: 1.0000 - val_loss: 1.8094 - val_accuracy: 0.2449 - 320ms/epoch - 80ms/step\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 212: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0704 - accuracy: 1.0000 - val_loss: 1.7691 - val_accuracy: 0.2857 - 327ms/epoch - 82ms/step\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 213: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0723 - accuracy: 1.0000 - val_loss: 1.8197 - val_accuracy: 0.2857 - 335ms/epoch - 84ms/step\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 214: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0746 - accuracy: 1.0000 - val_loss: 1.7982 - val_accuracy: 0.2653 - 323ms/epoch - 81ms/step\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 215: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0725 - accuracy: 1.0000 - val_loss: 1.8010 - val_accuracy: 0.3061 - 319ms/epoch - 80ms/step\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 216: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0695 - accuracy: 1.0000 - val_loss: 1.9229 - val_accuracy: 0.2245 - 318ms/epoch - 79ms/step\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 217: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0679 - accuracy: 1.0000 - val_loss: 1.8314 - val_accuracy: 0.2449 - 338ms/epoch - 85ms/step\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 218: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0664 - accuracy: 1.0000 - val_loss: 1.7299 - val_accuracy: 0.3061 - 324ms/epoch - 81ms/step\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 219: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0780 - accuracy: 1.0000 - val_loss: 1.7343 - val_accuracy: 0.2653 - 327ms/epoch - 82ms/step\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 220: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0713 - accuracy: 1.0000 - val_loss: 1.7128 - val_accuracy: 0.3061 - 320ms/epoch - 80ms/step\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 221: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0663 - accuracy: 1.0000 - val_loss: 1.6790 - val_accuracy: 0.2041 - 327ms/epoch - 82ms/step\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 222: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0675 - accuracy: 1.0000 - val_loss: 1.7295 - val_accuracy: 0.2245 - 314ms/epoch - 79ms/step\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 223: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0717 - accuracy: 1.0000 - val_loss: 1.8216 - val_accuracy: 0.2857 - 324ms/epoch - 81ms/step\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 224: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0658 - accuracy: 1.0000 - val_loss: 1.7953 - val_accuracy: 0.2857 - 310ms/epoch - 78ms/step\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 225: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0767 - accuracy: 1.0000 - val_loss: 1.8345 - val_accuracy: 0.2857 - 318ms/epoch - 79ms/step\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 226: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0853 - accuracy: 1.0000 - val_loss: 1.7863 - val_accuracy: 0.3061 - 316ms/epoch - 79ms/step\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 227: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0825 - accuracy: 1.0000 - val_loss: 1.9266 - val_accuracy: 0.2245 - 316ms/epoch - 79ms/step\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 228: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0777 - accuracy: 1.0000 - val_loss: 1.9366 - val_accuracy: 0.2449 - 323ms/epoch - 81ms/step\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 229: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0737 - accuracy: 1.0000 - val_loss: 1.7227 - val_accuracy: 0.3061 - 318ms/epoch - 80ms/step\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 230: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0785 - accuracy: 1.0000 - val_loss: 1.8200 - val_accuracy: 0.2653 - 313ms/epoch - 78ms/step\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 231: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0799 - accuracy: 1.0000 - val_loss: 1.8874 - val_accuracy: 0.2449 - 319ms/epoch - 80ms/step\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 232: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0784 - accuracy: 1.0000 - val_loss: 1.8775 - val_accuracy: 0.2857 - 313ms/epoch - 78ms/step\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 233: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0754 - accuracy: 1.0000 - val_loss: 1.8573 - val_accuracy: 0.3061 - 321ms/epoch - 80ms/step\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 234: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0713 - accuracy: 1.0000 - val_loss: 1.7292 - val_accuracy: 0.3061 - 315ms/epoch - 79ms/step\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 235: val_loss did not improve from 1.37444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.0741 - accuracy: 1.0000 - val_loss: 1.6499 - val_accuracy: 0.3061 - 322ms/epoch - 80ms/step\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 236: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0791 - accuracy: 1.0000 - val_loss: 1.7377 - val_accuracy: 0.3061 - 315ms/epoch - 79ms/step\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 237: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0832 - accuracy: 1.0000 - val_loss: 1.7587 - val_accuracy: 0.2653 - 313ms/epoch - 78ms/step\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 238: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0698 - accuracy: 1.0000 - val_loss: 1.7086 - val_accuracy: 0.2857 - 312ms/epoch - 78ms/step\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 239: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0776 - accuracy: 1.0000 - val_loss: 1.7662 - val_accuracy: 0.2449 - 310ms/epoch - 78ms/step\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 240: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0751 - accuracy: 1.0000 - val_loss: 1.8827 - val_accuracy: 0.2245 - 320ms/epoch - 80ms/step\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 241: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0775 - accuracy: 1.0000 - val_loss: 1.9569 - val_accuracy: 0.2041 - 320ms/epoch - 80ms/step\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 242: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0668 - accuracy: 1.0000 - val_loss: 1.9930 - val_accuracy: 0.2245 - 323ms/epoch - 81ms/step\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 243: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0757 - accuracy: 1.0000 - val_loss: 1.9971 - val_accuracy: 0.2245 - 317ms/epoch - 79ms/step\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 244: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0683 - accuracy: 1.0000 - val_loss: 1.8357 - val_accuracy: 0.2449 - 319ms/epoch - 80ms/step\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 245: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0639 - accuracy: 1.0000 - val_loss: 1.7407 - val_accuracy: 0.2449 - 338ms/epoch - 85ms/step\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 246: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0729 - accuracy: 1.0000 - val_loss: 1.8120 - val_accuracy: 0.2857 - 329ms/epoch - 82ms/step\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 247: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0675 - accuracy: 1.0000 - val_loss: 1.7008 - val_accuracy: 0.3061 - 324ms/epoch - 81ms/step\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 248: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0726 - accuracy: 1.0000 - val_loss: 1.7927 - val_accuracy: 0.2653 - 318ms/epoch - 80ms/step\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 249: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0777 - accuracy: 1.0000 - val_loss: 1.8114 - val_accuracy: 0.2857 - 314ms/epoch - 79ms/step\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 250: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0690 - accuracy: 1.0000 - val_loss: 1.8815 - val_accuracy: 0.2449 - 315ms/epoch - 79ms/step\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 251: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0712 - accuracy: 1.0000 - val_loss: 1.9371 - val_accuracy: 0.2857 - 312ms/epoch - 78ms/step\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 252: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0688 - accuracy: 1.0000 - val_loss: 1.8620 - val_accuracy: 0.2653 - 315ms/epoch - 79ms/step\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 253: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0737 - accuracy: 1.0000 - val_loss: 1.8850 - val_accuracy: 0.2449 - 323ms/epoch - 81ms/step\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 254: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0684 - accuracy: 1.0000 - val_loss: 1.8731 - val_accuracy: 0.2653 - 324ms/epoch - 81ms/step\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 255: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0673 - accuracy: 1.0000 - val_loss: 1.7978 - val_accuracy: 0.2245 - 331ms/epoch - 83ms/step\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 256: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0675 - accuracy: 1.0000 - val_loss: 1.8687 - val_accuracy: 0.2653 - 319ms/epoch - 80ms/step\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 257: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0735 - accuracy: 1.0000 - val_loss: 1.8083 - val_accuracy: 0.2857 - 330ms/epoch - 83ms/step\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 258: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0666 - accuracy: 1.0000 - val_loss: 1.8109 - val_accuracy: 0.2449 - 329ms/epoch - 82ms/step\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 259: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0624 - accuracy: 1.0000 - val_loss: 1.8221 - val_accuracy: 0.2653 - 321ms/epoch - 80ms/step\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 260: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0648 - accuracy: 1.0000 - val_loss: 1.7389 - val_accuracy: 0.2653 - 322ms/epoch - 81ms/step\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 261: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0565 - accuracy: 1.0000 - val_loss: 1.7669 - val_accuracy: 0.2857 - 313ms/epoch - 78ms/step\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 262: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0609 - accuracy: 1.0000 - val_loss: 1.7836 - val_accuracy: 0.3265 - 313ms/epoch - 78ms/step\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 263: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0589 - accuracy: 1.0000 - val_loss: 1.7853 - val_accuracy: 0.2857 - 323ms/epoch - 81ms/step\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 264: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0662 - accuracy: 1.0000 - val_loss: 1.7810 - val_accuracy: 0.2245 - 314ms/epoch - 79ms/step\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 265: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0662 - accuracy: 1.0000 - val_loss: 1.8321 - val_accuracy: 0.2653 - 330ms/epoch - 82ms/step\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 266: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0657 - accuracy: 1.0000 - val_loss: 1.7380 - val_accuracy: 0.3061 - 329ms/epoch - 82ms/step\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 267: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0651 - accuracy: 1.0000 - val_loss: 1.7777 - val_accuracy: 0.3469 - 326ms/epoch - 82ms/step\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 268: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0624 - accuracy: 1.0000 - val_loss: 1.7855 - val_accuracy: 0.3061 - 325ms/epoch - 81ms/step\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 269: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0548 - accuracy: 1.0000 - val_loss: 1.7780 - val_accuracy: 0.3061 - 340ms/epoch - 85ms/step\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 270: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0583 - accuracy: 1.0000 - val_loss: 1.7712 - val_accuracy: 0.2653 - 325ms/epoch - 81ms/step\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 271: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0447 - accuracy: 1.0000 - val_loss: 1.7610 - val_accuracy: 0.2245 - 325ms/epoch - 81ms/step\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 272: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0587 - accuracy: 1.0000 - val_loss: 1.8169 - val_accuracy: 0.2449 - 320ms/epoch - 80ms/step\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 273: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0481 - accuracy: 1.0000 - val_loss: 1.7681 - val_accuracy: 0.2653 - 327ms/epoch - 82ms/step\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 274: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0593 - accuracy: 1.0000 - val_loss: 1.7909 - val_accuracy: 0.2653 - 322ms/epoch - 80ms/step\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 275: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0517 - accuracy: 1.0000 - val_loss: 1.8012 - val_accuracy: 0.2653 - 323ms/epoch - 81ms/step\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 276: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0525 - accuracy: 1.0000 - val_loss: 1.7788 - val_accuracy: 0.2653 - 331ms/epoch - 83ms/step\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 277: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0493 - accuracy: 1.0000 - val_loss: 1.8256 - val_accuracy: 0.2449 - 322ms/epoch - 80ms/step\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 278: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0511 - accuracy: 1.0000 - val_loss: 1.8642 - val_accuracy: 0.2653 - 313ms/epoch - 78ms/step\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 279: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0511 - accuracy: 1.0000 - val_loss: 1.8253 - val_accuracy: 0.2857 - 315ms/epoch - 79ms/step\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 280: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0573 - accuracy: 1.0000 - val_loss: 1.7949 - val_accuracy: 0.2857 - 312ms/epoch - 78ms/step\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 281: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0532 - accuracy: 1.0000 - val_loss: 1.8415 - val_accuracy: 0.3061 - 317ms/epoch - 79ms/step\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 282: val_loss did not improve from 1.37444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.0429 - accuracy: 1.0000 - val_loss: 1.8040 - val_accuracy: 0.2857 - 316ms/epoch - 79ms/step\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 283: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0513 - accuracy: 1.0000 - val_loss: 1.7835 - val_accuracy: 0.2653 - 321ms/epoch - 80ms/step\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 284: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0486 - accuracy: 1.0000 - val_loss: 1.7805 - val_accuracy: 0.3061 - 336ms/epoch - 84ms/step\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 285: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0460 - accuracy: 1.0000 - val_loss: 1.7472 - val_accuracy: 0.2653 - 319ms/epoch - 80ms/step\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 286: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0499 - accuracy: 1.0000 - val_loss: 1.8388 - val_accuracy: 0.2449 - 320ms/epoch - 80ms/step\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 287: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0467 - accuracy: 1.0000 - val_loss: 1.7627 - val_accuracy: 0.2449 - 334ms/epoch - 84ms/step\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 288: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0457 - accuracy: 1.0000 - val_loss: 1.7593 - val_accuracy: 0.2449 - 331ms/epoch - 83ms/step\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 289: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0486 - accuracy: 1.0000 - val_loss: 1.7550 - val_accuracy: 0.2857 - 321ms/epoch - 80ms/step\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 290: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0527 - accuracy: 1.0000 - val_loss: 1.7485 - val_accuracy: 0.3265 - 325ms/epoch - 81ms/step\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 291: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0546 - accuracy: 1.0000 - val_loss: 1.7638 - val_accuracy: 0.3061 - 319ms/epoch - 80ms/step\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 292: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0528 - accuracy: 1.0000 - val_loss: 1.8498 - val_accuracy: 0.2653 - 325ms/epoch - 81ms/step\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 293: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0530 - accuracy: 1.0000 - val_loss: 1.8504 - val_accuracy: 0.2857 - 312ms/epoch - 78ms/step\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 294: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0475 - accuracy: 1.0000 - val_loss: 1.8531 - val_accuracy: 0.2857 - 312ms/epoch - 78ms/step\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 295: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0562 - accuracy: 1.0000 - val_loss: 1.8831 - val_accuracy: 0.2857 - 325ms/epoch - 81ms/step\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 296: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0546 - accuracy: 1.0000 - val_loss: 1.8518 - val_accuracy: 0.2857 - 314ms/epoch - 79ms/step\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 297: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0514 - accuracy: 1.0000 - val_loss: 1.7704 - val_accuracy: 0.2653 - 310ms/epoch - 78ms/step\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 298: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0548 - accuracy: 1.0000 - val_loss: 1.8416 - val_accuracy: 0.2653 - 311ms/epoch - 78ms/step\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 299: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0452 - accuracy: 1.0000 - val_loss: 1.8916 - val_accuracy: 0.2857 - 315ms/epoch - 79ms/step\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 300: val_loss did not improve from 1.37444\n",
      "4/4 - 0s - loss: 0.0471 - accuracy: 1.0000 - val_loss: 1.8405 - val_accuracy: 0.3061 - 308ms/epoch - 77ms/step\n",
      "2/2 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2022-11-11 09:45:44.322025: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_9712748\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:638104\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 09:45:48.308675: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_9715818\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:638146\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38616, saving model to checkpoint1.h5\n",
      "4/4 - 5s - loss: 1.5139 - accuracy: 0.2566 - val_loss: 1.3862 - val_accuracy: 0.3061 - 5s/epoch - 1s/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss improved from 1.38616 to 1.38607, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 1.3322 - accuracy: 0.3451 - val_loss: 1.3861 - val_accuracy: 0.3061 - 371ms/epoch - 93ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss improved from 1.38607 to 1.38590, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 1.2507 - accuracy: 0.5133 - val_loss: 1.3859 - val_accuracy: 0.3061 - 361ms/epoch - 90ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss improved from 1.38590 to 1.38576, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 1.2673 - accuracy: 0.4159 - val_loss: 1.3858 - val_accuracy: 0.3061 - 359ms/epoch - 90ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 1.2238 - accuracy: 0.5752 - val_loss: 1.3859 - val_accuracy: 0.3061 - 305ms/epoch - 76ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 1.1674 - accuracy: 0.6195 - val_loss: 1.3863 - val_accuracy: 0.2857 - 312ms/epoch - 78ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 1.1449 - accuracy: 0.5929 - val_loss: 1.3868 - val_accuracy: 0.1429 - 324ms/epoch - 81ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 1.1143 - accuracy: 0.6460 - val_loss: 1.3869 - val_accuracy: 0.1837 - 310ms/epoch - 78ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 1.0894 - accuracy: 0.6460 - val_loss: 1.3874 - val_accuracy: 0.1429 - 306ms/epoch - 77ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 1.0518 - accuracy: 0.7345 - val_loss: 1.3875 - val_accuracy: 0.1429 - 326ms/epoch - 82ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 1.0441 - accuracy: 0.7699 - val_loss: 1.3876 - val_accuracy: 0.1429 - 313ms/epoch - 78ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 1.0306 - accuracy: 0.7522 - val_loss: 1.3883 - val_accuracy: 0.1429 - 307ms/epoch - 77ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 1.0174 - accuracy: 0.7699 - val_loss: 1.3889 - val_accuracy: 0.1429 - 319ms/epoch - 80ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.9848 - accuracy: 0.7611 - val_loss: 1.3885 - val_accuracy: 0.1429 - 321ms/epoch - 80ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.9939 - accuracy: 0.7257 - val_loss: 1.3893 - val_accuracy: 0.1429 - 307ms/epoch - 77ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.9619 - accuracy: 0.7611 - val_loss: 1.3901 - val_accuracy: 0.1429 - 321ms/epoch - 80ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.9096 - accuracy: 0.7876 - val_loss: 1.3896 - val_accuracy: 0.1429 - 323ms/epoch - 81ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.9479 - accuracy: 0.7788 - val_loss: 1.3897 - val_accuracy: 0.1429 - 312ms/epoch - 78ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.8776 - accuracy: 0.8673 - val_loss: 1.3914 - val_accuracy: 0.1429 - 314ms/epoch - 78ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.8776 - accuracy: 0.8319 - val_loss: 1.3912 - val_accuracy: 0.1429 - 307ms/epoch - 77ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.8416 - accuracy: 0.8673 - val_loss: 1.3918 - val_accuracy: 0.1429 - 306ms/epoch - 76ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.8091 - accuracy: 0.9115 - val_loss: 1.3906 - val_accuracy: 0.2041 - 309ms/epoch - 77ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.8654 - accuracy: 0.8407 - val_loss: 1.3897 - val_accuracy: 0.2245 - 313ms/epoch - 78ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.8122 - accuracy: 0.8673 - val_loss: 1.3917 - val_accuracy: 0.2041 - 317ms/epoch - 79ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.8055 - accuracy: 0.8938 - val_loss: 1.3923 - val_accuracy: 0.2041 - 321ms/epoch - 80ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.7739 - accuracy: 0.9381 - val_loss: 1.3894 - val_accuracy: 0.2245 - 303ms/epoch - 76ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.7633 - accuracy: 0.8938 - val_loss: 1.3927 - val_accuracy: 0.2245 - 307ms/epoch - 77ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.7687 - accuracy: 0.8850 - val_loss: 1.3934 - val_accuracy: 0.2041 - 310ms/epoch - 78ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.7516 - accuracy: 0.9115 - val_loss: 1.3941 - val_accuracy: 0.2041 - 301ms/epoch - 75ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.7008 - accuracy: 0.9381 - val_loss: 1.3954 - val_accuracy: 0.1837 - 305ms/epoch - 76ms/step\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.6762 - accuracy: 0.9381 - val_loss: 1.3942 - val_accuracy: 0.2449 - 308ms/epoch - 77ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.6856 - accuracy: 0.9204 - val_loss: 1.3937 - val_accuracy: 0.2449 - 304ms/epoch - 76ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.6854 - accuracy: 0.9381 - val_loss: 1.3960 - val_accuracy: 0.2041 - 312ms/epoch - 78ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.6738 - accuracy: 0.9558 - val_loss: 1.3945 - val_accuracy: 0.2653 - 311ms/epoch - 78ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.6345 - accuracy: 0.9646 - val_loss: 1.3980 - val_accuracy: 0.2041 - 306ms/epoch - 76ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.6483 - accuracy: 0.9292 - val_loss: 1.3965 - val_accuracy: 0.2449 - 305ms/epoch - 76ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.6264 - accuracy: 0.9558 - val_loss: 1.4003 - val_accuracy: 0.2857 - 314ms/epoch - 78ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 1.38576\n",
      "4/4 - 1s - loss: 0.6284 - accuracy: 0.9646 - val_loss: 1.3992 - val_accuracy: 0.1837 - 691ms/epoch - 173ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.6239 - accuracy: 0.9912 - val_loss: 1.4003 - val_accuracy: 0.2857 - 331ms/epoch - 83ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.5491 - accuracy: 1.0000 - val_loss: 1.4033 - val_accuracy: 0.2041 - 332ms/epoch - 83ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.5566 - accuracy: 0.9823 - val_loss: 1.4040 - val_accuracy: 0.2245 - 330ms/epoch - 82ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.5404 - accuracy: 0.9823 - val_loss: 1.4100 - val_accuracy: 0.1837 - 331ms/epoch - 83ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.5480 - accuracy: 1.0000 - val_loss: 1.4109 - val_accuracy: 0.2857 - 315ms/epoch - 79ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.5408 - accuracy: 0.9912 - val_loss: 1.4056 - val_accuracy: 0.2653 - 320ms/epoch - 80ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.5305 - accuracy: 0.9823 - val_loss: 1.4241 - val_accuracy: 0.1633 - 337ms/epoch - 84ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.5520 - accuracy: 0.9912 - val_loss: 1.4093 - val_accuracy: 0.1837 - 321ms/epoch - 80ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.5239 - accuracy: 0.9735 - val_loss: 1.4280 - val_accuracy: 0.3265 - 315ms/epoch - 79ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.4941 - accuracy: 1.0000 - val_loss: 1.4077 - val_accuracy: 0.1837 - 312ms/epoch - 78ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.5246 - accuracy: 0.9735 - val_loss: 1.4413 - val_accuracy: 0.2653 - 315ms/epoch - 79ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.5024 - accuracy: 0.9735 - val_loss: 1.4266 - val_accuracy: 0.1837 - 332ms/epoch - 83ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.4656 - accuracy: 1.0000 - val_loss: 1.4230 - val_accuracy: 0.2041 - 318ms/epoch - 80ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.4756 - accuracy: 0.9912 - val_loss: 1.4643 - val_accuracy: 0.2041 - 319ms/epoch - 80ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.4715 - accuracy: 0.9823 - val_loss: 1.4341 - val_accuracy: 0.1837 - 312ms/epoch - 78ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.4359 - accuracy: 0.9912 - val_loss: 1.4556 - val_accuracy: 0.2449 - 342ms/epoch - 86ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.4232 - accuracy: 0.9912 - val_loss: 1.4290 - val_accuracy: 0.2041 - 320ms/epoch - 80ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.4574 - accuracy: 0.9735 - val_loss: 1.4950 - val_accuracy: 0.2041 - 316ms/epoch - 79ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.4235 - accuracy: 1.0000 - val_loss: 1.4451 - val_accuracy: 0.2041 - 333ms/epoch - 83ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.4070 - accuracy: 1.0000 - val_loss: 1.5141 - val_accuracy: 0.2245 - 328ms/epoch - 82ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.4295 - accuracy: 1.0000 - val_loss: 1.4673 - val_accuracy: 0.2041 - 316ms/epoch - 79ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.3784 - accuracy: 1.0000 - val_loss: 1.4944 - val_accuracy: 0.2041 - 312ms/epoch - 78ms/step\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.3876 - accuracy: 1.0000 - val_loss: 1.5379 - val_accuracy: 0.1633 - 324ms/epoch - 81ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.3483 - accuracy: 1.0000 - val_loss: 1.5013 - val_accuracy: 0.2041 - 326ms/epoch - 81ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.3632 - accuracy: 1.0000 - val_loss: 1.5454 - val_accuracy: 0.2245 - 325ms/epoch - 81ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.3742 - accuracy: 0.9912 - val_loss: 1.5257 - val_accuracy: 0.2041 - 316ms/epoch - 79ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.4038 - accuracy: 1.0000 - val_loss: 1.5800 - val_accuracy: 0.2245 - 318ms/epoch - 79ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.3570 - accuracy: 1.0000 - val_loss: 1.5511 - val_accuracy: 0.2041 - 329ms/epoch - 82ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.3682 - accuracy: 1.0000 - val_loss: 1.5726 - val_accuracy: 0.2041 - 319ms/epoch - 80ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.3449 - accuracy: 1.0000 - val_loss: 1.6285 - val_accuracy: 0.2041 - 327ms/epoch - 82ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.3643 - accuracy: 0.9912 - val_loss: 1.5827 - val_accuracy: 0.2041 - 333ms/epoch - 83ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.3236 - accuracy: 1.0000 - val_loss: 1.5871 - val_accuracy: 0.2041 - 318ms/epoch - 79ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.3636 - accuracy: 0.9735 - val_loss: 1.6717 - val_accuracy: 0.1837 - 325ms/epoch - 81ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.3833 - accuracy: 1.0000 - val_loss: 1.5432 - val_accuracy: 0.2449 - 324ms/epoch - 81ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.3390 - accuracy: 0.9912 - val_loss: 1.6694 - val_accuracy: 0.2449 - 335ms/epoch - 84ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.3207 - accuracy: 1.0000 - val_loss: 1.6260 - val_accuracy: 0.2041 - 318ms/epoch - 79ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.3075 - accuracy: 1.0000 - val_loss: 1.6637 - val_accuracy: 0.2041 - 318ms/epoch - 80ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.3105 - accuracy: 1.0000 - val_loss: 1.6426 - val_accuracy: 0.2449 - 320ms/epoch - 80ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.2896 - accuracy: 1.0000 - val_loss: 1.6641 - val_accuracy: 0.1837 - 324ms/epoch - 81ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.3000 - accuracy: 1.0000 - val_loss: 1.6808 - val_accuracy: 0.2653 - 333ms/epoch - 83ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.2999 - accuracy: 0.9912 - val_loss: 1.6583 - val_accuracy: 0.2041 - 318ms/epoch - 80ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.2733 - accuracy: 1.0000 - val_loss: 1.7393 - val_accuracy: 0.2245 - 317ms/epoch - 79ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.2838 - accuracy: 1.0000 - val_loss: 1.6981 - val_accuracy: 0.2041 - 326ms/epoch - 82ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.2499 - accuracy: 1.0000 - val_loss: 1.7216 - val_accuracy: 0.2041 - 315ms/epoch - 79ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.2605 - accuracy: 1.0000 - val_loss: 1.6852 - val_accuracy: 0.2245 - 315ms/epoch - 79ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.2815 - accuracy: 1.0000 - val_loss: 1.7919 - val_accuracy: 0.2245 - 332ms/epoch - 83ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.2511 - accuracy: 1.0000 - val_loss: 1.7789 - val_accuracy: 0.1633 - 317ms/epoch - 79ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.2683 - accuracy: 1.0000 - val_loss: 1.6993 - val_accuracy: 0.2857 - 321ms/epoch - 80ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.3100 - accuracy: 0.9823 - val_loss: 1.7986 - val_accuracy: 0.1837 - 317ms/epoch - 79ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.2599 - accuracy: 1.0000 - val_loss: 1.8266 - val_accuracy: 0.2041 - 317ms/epoch - 79ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.2752 - accuracy: 0.9912 - val_loss: 1.7059 - val_accuracy: 0.2041 - 314ms/epoch - 78ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.2637 - accuracy: 1.0000 - val_loss: 1.8461 - val_accuracy: 0.2245 - 322ms/epoch - 80ms/step\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.2598 - accuracy: 1.0000 - val_loss: 1.7834 - val_accuracy: 0.2245 - 327ms/epoch - 82ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.2418 - accuracy: 1.0000 - val_loss: 1.7986 - val_accuracy: 0.1837 - 314ms/epoch - 79ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.2447 - accuracy: 1.0000 - val_loss: 1.7062 - val_accuracy: 0.2245 - 323ms/epoch - 81ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.2038 - accuracy: 1.0000 - val_loss: 1.8091 - val_accuracy: 0.2653 - 315ms/epoch - 79ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 1.38576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.2237 - accuracy: 1.0000 - val_loss: 1.8705 - val_accuracy: 0.1837 - 317ms/epoch - 79ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.2625 - accuracy: 0.9912 - val_loss: 1.7484 - val_accuracy: 0.2449 - 346ms/epoch - 86ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.2516 - accuracy: 0.9912 - val_loss: 1.8662 - val_accuracy: 0.2653 - 320ms/epoch - 80ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.2603 - accuracy: 1.0000 - val_loss: 1.7483 - val_accuracy: 0.1633 - 339ms/epoch - 85ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.2349 - accuracy: 1.0000 - val_loss: 1.8136 - val_accuracy: 0.2857 - 327ms/epoch - 82ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.2211 - accuracy: 1.0000 - val_loss: 1.8569 - val_accuracy: 0.2245 - 321ms/epoch - 80ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.2362 - accuracy: 1.0000 - val_loss: 1.9240 - val_accuracy: 0.1837 - 315ms/epoch - 79ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.2429 - accuracy: 1.0000 - val_loss: 1.8325 - val_accuracy: 0.2653 - 336ms/epoch - 84ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.2465 - accuracy: 1.0000 - val_loss: 1.8541 - val_accuracy: 0.2245 - 316ms/epoch - 79ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.2284 - accuracy: 1.0000 - val_loss: 1.7922 - val_accuracy: 0.2449 - 321ms/epoch - 80ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 1.8677 - val_accuracy: 0.2857 - 329ms/epoch - 82ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 1.8156 - val_accuracy: 0.2041 - 320ms/epoch - 80ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.2055 - accuracy: 1.0000 - val_loss: 1.7759 - val_accuracy: 0.2245 - 327ms/epoch - 82ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.2008 - accuracy: 1.0000 - val_loss: 1.8807 - val_accuracy: 0.2449 - 336ms/epoch - 84ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1870 - accuracy: 1.0000 - val_loss: 1.8151 - val_accuracy: 0.3061 - 314ms/epoch - 79ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.2262 - accuracy: 1.0000 - val_loss: 1.8568 - val_accuracy: 0.3265 - 323ms/epoch - 81ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.2009 - accuracy: 1.0000 - val_loss: 1.8205 - val_accuracy: 0.2653 - 322ms/epoch - 80ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1823 - accuracy: 1.0000 - val_loss: 1.7993 - val_accuracy: 0.2449 - 310ms/epoch - 78ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1843 - accuracy: 1.0000 - val_loss: 1.8162 - val_accuracy: 0.2653 - 326ms/epoch - 82ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1787 - accuracy: 1.0000 - val_loss: 1.7961 - val_accuracy: 0.2653 - 319ms/epoch - 80ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1883 - accuracy: 1.0000 - val_loss: 1.7981 - val_accuracy: 0.2245 - 333ms/epoch - 83ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1786 - accuracy: 1.0000 - val_loss: 1.8119 - val_accuracy: 0.2245 - 318ms/epoch - 80ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1730 - accuracy: 1.0000 - val_loss: 1.7799 - val_accuracy: 0.3061 - 318ms/epoch - 79ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.2007 - accuracy: 1.0000 - val_loss: 1.8540 - val_accuracy: 0.2449 - 317ms/epoch - 79ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1664 - accuracy: 1.0000 - val_loss: 1.8294 - val_accuracy: 0.2653 - 327ms/epoch - 82ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1772 - accuracy: 1.0000 - val_loss: 1.8749 - val_accuracy: 0.3061 - 347ms/epoch - 87ms/step\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1806 - accuracy: 1.0000 - val_loss: 1.7939 - val_accuracy: 0.2449 - 320ms/epoch - 80ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1516 - accuracy: 1.0000 - val_loss: 1.8383 - val_accuracy: 0.2653 - 315ms/epoch - 79ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1911 - accuracy: 1.0000 - val_loss: 1.8784 - val_accuracy: 0.2857 - 314ms/epoch - 78ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1546 - accuracy: 1.0000 - val_loss: 1.8950 - val_accuracy: 0.1837 - 314ms/epoch - 78ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1643 - accuracy: 1.0000 - val_loss: 1.8993 - val_accuracy: 0.2653 - 325ms/epoch - 81ms/step\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1417 - accuracy: 1.0000 - val_loss: 1.9094 - val_accuracy: 0.2041 - 314ms/epoch - 79ms/step\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1580 - accuracy: 1.0000 - val_loss: 1.8319 - val_accuracy: 0.2653 - 320ms/epoch - 80ms/step\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1598 - accuracy: 1.0000 - val_loss: 1.8329 - val_accuracy: 0.2041 - 309ms/epoch - 77ms/step\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1375 - accuracy: 1.0000 - val_loss: 1.7602 - val_accuracy: 0.3265 - 315ms/epoch - 79ms/step\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1673 - accuracy: 1.0000 - val_loss: 1.7617 - val_accuracy: 0.3061 - 327ms/epoch - 82ms/step\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1571 - accuracy: 1.0000 - val_loss: 1.8208 - val_accuracy: 0.2653 - 317ms/epoch - 79ms/step\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1536 - accuracy: 1.0000 - val_loss: 1.7604 - val_accuracy: 0.3061 - 336ms/epoch - 84ms/step\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1404 - accuracy: 1.0000 - val_loss: 1.7789 - val_accuracy: 0.3265 - 312ms/epoch - 78ms/step\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1482 - accuracy: 1.0000 - val_loss: 1.8315 - val_accuracy: 0.2245 - 327ms/epoch - 82ms/step\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 135: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1495 - accuracy: 1.0000 - val_loss: 1.7289 - val_accuracy: 0.2653 - 323ms/epoch - 81ms/step\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 136: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1610 - accuracy: 1.0000 - val_loss: 1.7916 - val_accuracy: 0.2653 - 314ms/epoch - 78ms/step\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 137: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1385 - accuracy: 1.0000 - val_loss: 1.7689 - val_accuracy: 0.2449 - 314ms/epoch - 79ms/step\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 138: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1316 - accuracy: 1.0000 - val_loss: 1.7466 - val_accuracy: 0.2857 - 334ms/epoch - 84ms/step\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 139: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1403 - accuracy: 1.0000 - val_loss: 1.7734 - val_accuracy: 0.2857 - 322ms/epoch - 80ms/step\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 140: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1330 - accuracy: 1.0000 - val_loss: 1.8028 - val_accuracy: 0.3469 - 314ms/epoch - 78ms/step\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 141: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1678 - accuracy: 1.0000 - val_loss: 1.7586 - val_accuracy: 0.2653 - 324ms/epoch - 81ms/step\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 142: val_loss did not improve from 1.38576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.1301 - accuracy: 1.0000 - val_loss: 1.7314 - val_accuracy: 0.2653 - 315ms/epoch - 79ms/step\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 143: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1471 - accuracy: 1.0000 - val_loss: 1.7742 - val_accuracy: 0.2449 - 315ms/epoch - 79ms/step\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 144: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1273 - accuracy: 1.0000 - val_loss: 1.7955 - val_accuracy: 0.3265 - 323ms/epoch - 81ms/step\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 145: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1473 - accuracy: 1.0000 - val_loss: 1.8310 - val_accuracy: 0.3265 - 315ms/epoch - 79ms/step\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 146: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1380 - accuracy: 1.0000 - val_loss: 1.8052 - val_accuracy: 0.2245 - 314ms/epoch - 78ms/step\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 147: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1533 - accuracy: 1.0000 - val_loss: 1.7109 - val_accuracy: 0.2857 - 312ms/epoch - 78ms/step\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 148: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1298 - accuracy: 1.0000 - val_loss: 1.7238 - val_accuracy: 0.2449 - 316ms/epoch - 79ms/step\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 149: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1343 - accuracy: 1.0000 - val_loss: 1.7600 - val_accuracy: 0.2857 - 332ms/epoch - 83ms/step\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 150: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1436 - accuracy: 1.0000 - val_loss: 1.7537 - val_accuracy: 0.2857 - 322ms/epoch - 80ms/step\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 151: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1327 - accuracy: 1.0000 - val_loss: 1.7434 - val_accuracy: 0.2653 - 315ms/epoch - 79ms/step\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 152: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1294 - accuracy: 1.0000 - val_loss: 1.7413 - val_accuracy: 0.3061 - 310ms/epoch - 78ms/step\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 153: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1496 - accuracy: 1.0000 - val_loss: 1.8389 - val_accuracy: 0.2449 - 324ms/epoch - 81ms/step\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 154: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1628 - accuracy: 1.0000 - val_loss: 1.8041 - val_accuracy: 0.3061 - 316ms/epoch - 79ms/step\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 155: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1556 - accuracy: 1.0000 - val_loss: 1.7767 - val_accuracy: 0.3469 - 313ms/epoch - 78ms/step\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 156: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1658 - accuracy: 1.0000 - val_loss: 1.8149 - val_accuracy: 0.2857 - 318ms/epoch - 80ms/step\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 157: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1359 - accuracy: 1.0000 - val_loss: 1.8538 - val_accuracy: 0.2653 - 318ms/epoch - 79ms/step\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 158: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1452 - accuracy: 1.0000 - val_loss: 1.8540 - val_accuracy: 0.2653 - 314ms/epoch - 79ms/step\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 159: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1347 - accuracy: 1.0000 - val_loss: 1.9548 - val_accuracy: 0.2653 - 314ms/epoch - 78ms/step\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 160: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1259 - accuracy: 1.0000 - val_loss: 1.8469 - val_accuracy: 0.3265 - 314ms/epoch - 79ms/step\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 161: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1171 - accuracy: 1.0000 - val_loss: 1.8231 - val_accuracy: 0.2041 - 313ms/epoch - 78ms/step\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 162: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1131 - accuracy: 1.0000 - val_loss: 1.8676 - val_accuracy: 0.2449 - 321ms/epoch - 80ms/step\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 163: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1191 - accuracy: 1.0000 - val_loss: 1.8089 - val_accuracy: 0.2857 - 311ms/epoch - 78ms/step\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 164: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1124 - accuracy: 1.0000 - val_loss: 1.9669 - val_accuracy: 0.2449 - 324ms/epoch - 81ms/step\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 165: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1173 - accuracy: 1.0000 - val_loss: 1.8436 - val_accuracy: 0.2653 - 315ms/epoch - 79ms/step\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 166: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1184 - accuracy: 1.0000 - val_loss: 1.7964 - val_accuracy: 0.2857 - 316ms/epoch - 79ms/step\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 167: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1140 - accuracy: 1.0000 - val_loss: 1.7657 - val_accuracy: 0.2653 - 320ms/epoch - 80ms/step\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 168: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1130 - accuracy: 1.0000 - val_loss: 1.7555 - val_accuracy: 0.3061 - 326ms/epoch - 82ms/step\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 169: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1234 - accuracy: 1.0000 - val_loss: 1.8059 - val_accuracy: 0.2857 - 312ms/epoch - 78ms/step\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 170: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1037 - accuracy: 1.0000 - val_loss: 1.8160 - val_accuracy: 0.2857 - 317ms/epoch - 79ms/step\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 171: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1160 - accuracy: 1.0000 - val_loss: 1.7612 - val_accuracy: 0.3265 - 318ms/epoch - 79ms/step\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 172: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1033 - accuracy: 1.0000 - val_loss: 1.8013 - val_accuracy: 0.2449 - 316ms/epoch - 79ms/step\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 173: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1075 - accuracy: 1.0000 - val_loss: 1.8673 - val_accuracy: 0.2245 - 315ms/epoch - 79ms/step\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 174: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1021 - accuracy: 1.0000 - val_loss: 1.7647 - val_accuracy: 0.3061 - 320ms/epoch - 80ms/step\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 175: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1130 - accuracy: 1.0000 - val_loss: 1.8325 - val_accuracy: 0.2041 - 313ms/epoch - 78ms/step\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 176: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1163 - accuracy: 1.0000 - val_loss: 1.9484 - val_accuracy: 0.2857 - 330ms/epoch - 82ms/step\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 177: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1119 - accuracy: 1.0000 - val_loss: 1.8362 - val_accuracy: 0.2653 - 324ms/epoch - 81ms/step\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 178: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1013 - accuracy: 1.0000 - val_loss: 1.8634 - val_accuracy: 0.2857 - 311ms/epoch - 78ms/step\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 179: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1162 - accuracy: 1.0000 - val_loss: 1.8387 - val_accuracy: 0.2857 - 323ms/epoch - 81ms/step\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 180: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1065 - accuracy: 1.0000 - val_loss: 1.7803 - val_accuracy: 0.2245 - 327ms/epoch - 82ms/step\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 181: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1044 - accuracy: 1.0000 - val_loss: 1.7917 - val_accuracy: 0.2653 - 311ms/epoch - 78ms/step\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 182: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1037 - accuracy: 1.0000 - val_loss: 1.8142 - val_accuracy: 0.2245 - 316ms/epoch - 79ms/step\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 183: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0897 - accuracy: 1.0000 - val_loss: 1.8222 - val_accuracy: 0.2653 - 313ms/epoch - 78ms/step\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 184: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1077 - accuracy: 1.0000 - val_loss: 1.8019 - val_accuracy: 0.2857 - 320ms/epoch - 80ms/step\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 185: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0948 - accuracy: 1.0000 - val_loss: 1.7989 - val_accuracy: 0.3061 - 317ms/epoch - 79ms/step\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 186: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0924 - accuracy: 1.0000 - val_loss: 1.8109 - val_accuracy: 0.2857 - 318ms/epoch - 80ms/step\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 187: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0849 - accuracy: 1.0000 - val_loss: 1.8089 - val_accuracy: 0.2857 - 312ms/epoch - 78ms/step\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 188: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0976 - accuracy: 1.0000 - val_loss: 1.7594 - val_accuracy: 0.2449 - 315ms/epoch - 79ms/step\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 189: val_loss did not improve from 1.38576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.1069 - accuracy: 1.0000 - val_loss: 1.7879 - val_accuracy: 0.2041 - 311ms/epoch - 78ms/step\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 190: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0992 - accuracy: 1.0000 - val_loss: 1.8862 - val_accuracy: 0.2245 - 315ms/epoch - 79ms/step\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 191: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0835 - accuracy: 1.0000 - val_loss: 1.9980 - val_accuracy: 0.2041 - 333ms/epoch - 83ms/step\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 192: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0958 - accuracy: 1.0000 - val_loss: 1.9097 - val_accuracy: 0.2653 - 318ms/epoch - 80ms/step\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 193: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0915 - accuracy: 1.0000 - val_loss: 1.8862 - val_accuracy: 0.2653 - 309ms/epoch - 77ms/step\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 194: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1005 - accuracy: 1.0000 - val_loss: 1.8255 - val_accuracy: 0.2857 - 314ms/epoch - 78ms/step\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 195: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0980 - accuracy: 1.0000 - val_loss: 1.7510 - val_accuracy: 0.2857 - 313ms/epoch - 78ms/step\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 196: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1006 - accuracy: 1.0000 - val_loss: 1.7665 - val_accuracy: 0.2857 - 318ms/epoch - 79ms/step\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 197: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1011 - accuracy: 1.0000 - val_loss: 1.7940 - val_accuracy: 0.2653 - 313ms/epoch - 78ms/step\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 198: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1115 - accuracy: 1.0000 - val_loss: 1.8790 - val_accuracy: 0.2245 - 318ms/epoch - 79ms/step\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 199: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0781 - accuracy: 1.0000 - val_loss: 1.8295 - val_accuracy: 0.3469 - 311ms/epoch - 78ms/step\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 200: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1002 - accuracy: 1.0000 - val_loss: 1.7897 - val_accuracy: 0.2449 - 324ms/epoch - 81ms/step\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 201: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0885 - accuracy: 1.0000 - val_loss: 1.8914 - val_accuracy: 0.2245 - 327ms/epoch - 82ms/step\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 202: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0989 - accuracy: 1.0000 - val_loss: 1.8671 - val_accuracy: 0.2857 - 324ms/epoch - 81ms/step\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 203: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0956 - accuracy: 1.0000 - val_loss: 1.8299 - val_accuracy: 0.1837 - 309ms/epoch - 77ms/step\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 204: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0970 - accuracy: 1.0000 - val_loss: 1.8138 - val_accuracy: 0.2653 - 327ms/epoch - 82ms/step\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 205: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0964 - accuracy: 1.0000 - val_loss: 1.8044 - val_accuracy: 0.2245 - 333ms/epoch - 83ms/step\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 206: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0861 - accuracy: 1.0000 - val_loss: 1.8730 - val_accuracy: 0.2041 - 316ms/epoch - 79ms/step\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 207: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1127 - accuracy: 1.0000 - val_loss: 1.8068 - val_accuracy: 0.2653 - 318ms/epoch - 79ms/step\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 208: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0904 - accuracy: 1.0000 - val_loss: 1.7739 - val_accuracy: 0.2653 - 312ms/epoch - 78ms/step\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 209: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1001 - accuracy: 1.0000 - val_loss: 1.8338 - val_accuracy: 0.2041 - 310ms/epoch - 77ms/step\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 210: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0992 - accuracy: 1.0000 - val_loss: 1.8407 - val_accuracy: 0.2449 - 334ms/epoch - 84ms/step\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 211: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0949 - accuracy: 1.0000 - val_loss: 1.8991 - val_accuracy: 0.2041 - 321ms/epoch - 80ms/step\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 212: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0827 - accuracy: 1.0000 - val_loss: 1.8715 - val_accuracy: 0.2653 - 315ms/epoch - 79ms/step\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 213: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0998 - accuracy: 1.0000 - val_loss: 1.8407 - val_accuracy: 0.2653 - 312ms/epoch - 78ms/step\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 214: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0931 - accuracy: 1.0000 - val_loss: 1.8071 - val_accuracy: 0.2245 - 311ms/epoch - 78ms/step\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 215: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1264 - accuracy: 1.0000 - val_loss: 1.8872 - val_accuracy: 0.2245 - 313ms/epoch - 78ms/step\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 216: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1128 - accuracy: 1.0000 - val_loss: 1.8131 - val_accuracy: 0.3061 - 318ms/epoch - 79ms/step\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 217: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0978 - accuracy: 1.0000 - val_loss: 1.7723 - val_accuracy: 0.2245 - 312ms/epoch - 78ms/step\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 218: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1048 - accuracy: 1.0000 - val_loss: 1.8790 - val_accuracy: 0.1837 - 313ms/epoch - 78ms/step\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 219: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0868 - accuracy: 1.0000 - val_loss: 1.8849 - val_accuracy: 0.2245 - 312ms/epoch - 78ms/step\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 220: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0987 - accuracy: 1.0000 - val_loss: 1.9390 - val_accuracy: 0.3061 - 326ms/epoch - 81ms/step\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 221: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1006 - accuracy: 1.0000 - val_loss: 2.0258 - val_accuracy: 0.1633 - 309ms/epoch - 77ms/step\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 222: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0938 - accuracy: 1.0000 - val_loss: 1.9123 - val_accuracy: 0.2449 - 323ms/epoch - 81ms/step\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 223: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.1054 - accuracy: 1.0000 - val_loss: 1.9356 - val_accuracy: 0.2041 - 309ms/epoch - 77ms/step\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 224: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0838 - accuracy: 1.0000 - val_loss: 1.8669 - val_accuracy: 0.2449 - 317ms/epoch - 79ms/step\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 225: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0866 - accuracy: 1.0000 - val_loss: 1.8309 - val_accuracy: 0.2449 - 311ms/epoch - 78ms/step\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 226: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0865 - accuracy: 1.0000 - val_loss: 1.7992 - val_accuracy: 0.3265 - 316ms/epoch - 79ms/step\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 227: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0713 - accuracy: 1.0000 - val_loss: 1.8170 - val_accuracy: 0.2857 - 312ms/epoch - 78ms/step\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 228: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0749 - accuracy: 1.0000 - val_loss: 1.8484 - val_accuracy: 0.2653 - 319ms/epoch - 80ms/step\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 229: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0845 - accuracy: 1.0000 - val_loss: 1.8325 - val_accuracy: 0.2041 - 314ms/epoch - 78ms/step\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 230: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0830 - accuracy: 1.0000 - val_loss: 1.8209 - val_accuracy: 0.2041 - 329ms/epoch - 82ms/step\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 231: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0728 - accuracy: 1.0000 - val_loss: 1.8577 - val_accuracy: 0.2653 - 316ms/epoch - 79ms/step\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 232: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0823 - accuracy: 1.0000 - val_loss: 1.8263 - val_accuracy: 0.2857 - 315ms/epoch - 79ms/step\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 233: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0753 - accuracy: 1.0000 - val_loss: 1.8553 - val_accuracy: 0.2653 - 312ms/epoch - 78ms/step\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 234: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0733 - accuracy: 1.0000 - val_loss: 2.0235 - val_accuracy: 0.1837 - 326ms/epoch - 81ms/step\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 235: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0763 - accuracy: 1.0000 - val_loss: 1.8971 - val_accuracy: 0.2245 - 311ms/epoch - 78ms/step\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 236: val_loss did not improve from 1.38576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.0671 - accuracy: 1.0000 - val_loss: 1.9007 - val_accuracy: 0.2041 - 324ms/epoch - 81ms/step\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 237: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0710 - accuracy: 1.0000 - val_loss: 1.8448 - val_accuracy: 0.2449 - 324ms/epoch - 81ms/step\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 238: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0773 - accuracy: 1.0000 - val_loss: 1.8572 - val_accuracy: 0.2653 - 310ms/epoch - 77ms/step\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 239: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0691 - accuracy: 1.0000 - val_loss: 1.8752 - val_accuracy: 0.1633 - 326ms/epoch - 81ms/step\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 240: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0736 - accuracy: 1.0000 - val_loss: 1.8503 - val_accuracy: 0.2449 - 319ms/epoch - 80ms/step\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 241: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0623 - accuracy: 1.0000 - val_loss: 1.8657 - val_accuracy: 0.2449 - 323ms/epoch - 81ms/step\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 242: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0724 - accuracy: 1.0000 - val_loss: 1.8210 - val_accuracy: 0.2449 - 318ms/epoch - 80ms/step\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 243: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0688 - accuracy: 1.0000 - val_loss: 1.8753 - val_accuracy: 0.2449 - 309ms/epoch - 77ms/step\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 244: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0712 - accuracy: 1.0000 - val_loss: 1.9463 - val_accuracy: 0.2041 - 318ms/epoch - 79ms/step\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 245: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0723 - accuracy: 1.0000 - val_loss: 1.9166 - val_accuracy: 0.2449 - 315ms/epoch - 79ms/step\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 246: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0754 - accuracy: 1.0000 - val_loss: 1.9033 - val_accuracy: 0.2245 - 318ms/epoch - 79ms/step\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 247: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0673 - accuracy: 1.0000 - val_loss: 1.8370 - val_accuracy: 0.2041 - 329ms/epoch - 82ms/step\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 248: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0725 - accuracy: 1.0000 - val_loss: 1.9075 - val_accuracy: 0.2041 - 319ms/epoch - 80ms/step\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 249: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0599 - accuracy: 1.0000 - val_loss: 1.9735 - val_accuracy: 0.2041 - 314ms/epoch - 79ms/step\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 250: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0629 - accuracy: 1.0000 - val_loss: 1.9608 - val_accuracy: 0.2245 - 335ms/epoch - 84ms/step\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 251: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0714 - accuracy: 1.0000 - val_loss: 1.9032 - val_accuracy: 0.2245 - 320ms/epoch - 80ms/step\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 252: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0659 - accuracy: 1.0000 - val_loss: 1.9270 - val_accuracy: 0.2245 - 321ms/epoch - 80ms/step\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 253: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0653 - accuracy: 1.0000 - val_loss: 1.9391 - val_accuracy: 0.2857 - 310ms/epoch - 78ms/step\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 254: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0771 - accuracy: 1.0000 - val_loss: 1.9266 - val_accuracy: 0.2449 - 312ms/epoch - 78ms/step\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 255: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0585 - accuracy: 1.0000 - val_loss: 1.8665 - val_accuracy: 0.2449 - 330ms/epoch - 83ms/step\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 256: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0684 - accuracy: 1.0000 - val_loss: 1.9250 - val_accuracy: 0.1837 - 320ms/epoch - 80ms/step\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 257: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0688 - accuracy: 1.0000 - val_loss: 1.9133 - val_accuracy: 0.2245 - 319ms/epoch - 80ms/step\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 258: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0632 - accuracy: 1.0000 - val_loss: 1.8913 - val_accuracy: 0.2653 - 320ms/epoch - 80ms/step\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 259: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0614 - accuracy: 1.0000 - val_loss: 1.8972 - val_accuracy: 0.1837 - 318ms/epoch - 80ms/step\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 260: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0661 - accuracy: 1.0000 - val_loss: 1.9041 - val_accuracy: 0.2245 - 312ms/epoch - 78ms/step\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 261: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0594 - accuracy: 1.0000 - val_loss: 1.9192 - val_accuracy: 0.2245 - 326ms/epoch - 81ms/step\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 262: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0654 - accuracy: 1.0000 - val_loss: 1.8527 - val_accuracy: 0.2857 - 320ms/epoch - 80ms/step\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 263: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0677 - accuracy: 1.0000 - val_loss: 1.8112 - val_accuracy: 0.2857 - 323ms/epoch - 81ms/step\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 264: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0555 - accuracy: 1.0000 - val_loss: 1.8746 - val_accuracy: 0.2653 - 319ms/epoch - 80ms/step\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 265: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0594 - accuracy: 1.0000 - val_loss: 1.8939 - val_accuracy: 0.2041 - 323ms/epoch - 81ms/step\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 266: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0606 - accuracy: 1.0000 - val_loss: 1.9070 - val_accuracy: 0.1633 - 328ms/epoch - 82ms/step\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 267: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0615 - accuracy: 1.0000 - val_loss: 1.8712 - val_accuracy: 0.2245 - 312ms/epoch - 78ms/step\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 268: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0593 - accuracy: 1.0000 - val_loss: 1.8614 - val_accuracy: 0.2041 - 331ms/epoch - 83ms/step\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 269: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0542 - accuracy: 1.0000 - val_loss: 1.8773 - val_accuracy: 0.2449 - 325ms/epoch - 81ms/step\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 270: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0549 - accuracy: 1.0000 - val_loss: 1.8983 - val_accuracy: 0.2245 - 324ms/epoch - 81ms/step\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 271: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0600 - accuracy: 1.0000 - val_loss: 1.8985 - val_accuracy: 0.2449 - 323ms/epoch - 81ms/step\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 272: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0567 - accuracy: 1.0000 - val_loss: 1.8833 - val_accuracy: 0.2449 - 313ms/epoch - 78ms/step\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 273: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0588 - accuracy: 1.0000 - val_loss: 1.8551 - val_accuracy: 0.2245 - 302ms/epoch - 75ms/step\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 274: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0563 - accuracy: 1.0000 - val_loss: 1.8739 - val_accuracy: 0.2653 - 326ms/epoch - 82ms/step\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 275: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0579 - accuracy: 1.0000 - val_loss: 2.0337 - val_accuracy: 0.2245 - 323ms/epoch - 81ms/step\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 276: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0479 - accuracy: 1.0000 - val_loss: 1.9956 - val_accuracy: 0.2857 - 319ms/epoch - 80ms/step\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 277: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0557 - accuracy: 1.0000 - val_loss: 2.0043 - val_accuracy: 0.2449 - 314ms/epoch - 79ms/step\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 278: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0535 - accuracy: 1.0000 - val_loss: 2.0217 - val_accuracy: 0.2041 - 337ms/epoch - 84ms/step\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 279: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0485 - accuracy: 1.0000 - val_loss: 1.9412 - val_accuracy: 0.2041 - 323ms/epoch - 81ms/step\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 280: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0550 - accuracy: 1.0000 - val_loss: 1.9832 - val_accuracy: 0.1633 - 322ms/epoch - 81ms/step\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 281: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0500 - accuracy: 1.0000 - val_loss: 1.9200 - val_accuracy: 0.2041 - 317ms/epoch - 79ms/step\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 282: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0461 - accuracy: 1.0000 - val_loss: 1.8990 - val_accuracy: 0.2245 - 318ms/epoch - 79ms/step\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 283: val_loss did not improve from 1.38576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.0500 - accuracy: 1.0000 - val_loss: 1.9337 - val_accuracy: 0.2041 - 314ms/epoch - 78ms/step\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 284: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0482 - accuracy: 1.0000 - val_loss: 1.9790 - val_accuracy: 0.1837 - 313ms/epoch - 78ms/step\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 285: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0524 - accuracy: 1.0000 - val_loss: 1.9440 - val_accuracy: 0.2041 - 326ms/epoch - 81ms/step\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 286: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0499 - accuracy: 1.0000 - val_loss: 1.8788 - val_accuracy: 0.2245 - 318ms/epoch - 79ms/step\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 287: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0544 - accuracy: 1.0000 - val_loss: 1.8175 - val_accuracy: 0.2653 - 324ms/epoch - 81ms/step\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 288: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0543 - accuracy: 1.0000 - val_loss: 1.8259 - val_accuracy: 0.2653 - 329ms/epoch - 82ms/step\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 289: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0510 - accuracy: 1.0000 - val_loss: 1.9371 - val_accuracy: 0.2245 - 326ms/epoch - 81ms/step\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 290: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0462 - accuracy: 1.0000 - val_loss: 1.9487 - val_accuracy: 0.2245 - 325ms/epoch - 81ms/step\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 291: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0562 - accuracy: 1.0000 - val_loss: 1.9620 - val_accuracy: 0.2449 - 312ms/epoch - 78ms/step\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 292: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0498 - accuracy: 1.0000 - val_loss: 1.8878 - val_accuracy: 0.2449 - 313ms/epoch - 78ms/step\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 293: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0511 - accuracy: 1.0000 - val_loss: 1.9254 - val_accuracy: 0.2245 - 324ms/epoch - 81ms/step\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 294: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0593 - accuracy: 1.0000 - val_loss: 1.9900 - val_accuracy: 0.2449 - 318ms/epoch - 79ms/step\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 295: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0517 - accuracy: 1.0000 - val_loss: 1.9103 - val_accuracy: 0.2653 - 308ms/epoch - 77ms/step\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 296: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0523 - accuracy: 1.0000 - val_loss: 1.9201 - val_accuracy: 0.2245 - 317ms/epoch - 79ms/step\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 297: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0554 - accuracy: 1.0000 - val_loss: 1.9925 - val_accuracy: 0.2041 - 323ms/epoch - 81ms/step\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 298: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0502 - accuracy: 1.0000 - val_loss: 1.9654 - val_accuracy: 0.2245 - 317ms/epoch - 79ms/step\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 299: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0548 - accuracy: 1.0000 - val_loss: 1.9266 - val_accuracy: 0.2041 - 313ms/epoch - 78ms/step\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 300: val_loss did not improve from 1.38576\n",
      "4/4 - 0s - loss: 0.0506 - accuracy: 1.0000 - val_loss: 1.8950 - val_accuracy: 0.2245 - 319ms/epoch - 80ms/step\n",
      "2/2 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2022-11-11 09:47:28.930775: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_9777542\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:642358\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 09:47:32.879028: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_9780612\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:642400\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38679, saving model to checkpoint1.h5\n",
      "4/4 - 5s - loss: 1.3841 - accuracy: 0.3451 - val_loss: 1.3868 - val_accuracy: 0.1837 - 5s/epoch - 1s/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss did not improve from 1.38679\n",
      "4/4 - 0s - loss: 1.3077 - accuracy: 0.3982 - val_loss: 1.3869 - val_accuracy: 0.1429 - 339ms/epoch - 85ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss did not improve from 1.38679\n",
      "4/4 - 0s - loss: 1.2487 - accuracy: 0.5221 - val_loss: 1.3869 - val_accuracy: 0.1837 - 320ms/epoch - 80ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss did not improve from 1.38679\n",
      "4/4 - 0s - loss: 1.1937 - accuracy: 0.5841 - val_loss: 1.3868 - val_accuracy: 0.1837 - 308ms/epoch - 77ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss improved from 1.38679 to 1.38670, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 1.1749 - accuracy: 0.5841 - val_loss: 1.3867 - val_accuracy: 0.1837 - 377ms/epoch - 94ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 1.1603 - accuracy: 0.5841 - val_loss: 1.3868 - val_accuracy: 0.1837 - 318ms/epoch - 79ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 1.1191 - accuracy: 0.6283 - val_loss: 1.3869 - val_accuracy: 0.1837 - 314ms/epoch - 79ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 1.0812 - accuracy: 0.6903 - val_loss: 1.3871 - val_accuracy: 0.2041 - 304ms/epoch - 76ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 1.0821 - accuracy: 0.7345 - val_loss: 1.3871 - val_accuracy: 0.1429 - 322ms/epoch - 80ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 1.0129 - accuracy: 0.7345 - val_loss: 1.3872 - val_accuracy: 0.1837 - 309ms/epoch - 77ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 1.0047 - accuracy: 0.6814 - val_loss: 1.3877 - val_accuracy: 0.1837 - 319ms/epoch - 80ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.9705 - accuracy: 0.8142 - val_loss: 1.3883 - val_accuracy: 0.1837 - 324ms/epoch - 81ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.9705 - accuracy: 0.7788 - val_loss: 1.3887 - val_accuracy: 0.1837 - 311ms/epoch - 78ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.9519 - accuracy: 0.7522 - val_loss: 1.3890 - val_accuracy: 0.1837 - 326ms/epoch - 82ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.9250 - accuracy: 0.7876 - val_loss: 1.3893 - val_accuracy: 0.1837 - 313ms/epoch - 78ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.8881 - accuracy: 0.8142 - val_loss: 1.3890 - val_accuracy: 0.1837 - 311ms/epoch - 78ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.8994 - accuracy: 0.8584 - val_loss: 1.3892 - val_accuracy: 0.1837 - 300ms/epoch - 75ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.8812 - accuracy: 0.8319 - val_loss: 1.3892 - val_accuracy: 0.1837 - 326ms/epoch - 82ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.8556 - accuracy: 0.8407 - val_loss: 1.3897 - val_accuracy: 0.1837 - 326ms/epoch - 81ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.8418 - accuracy: 0.8142 - val_loss: 1.3913 - val_accuracy: 0.1633 - 309ms/epoch - 77ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.8390 - accuracy: 0.8407 - val_loss: 1.3913 - val_accuracy: 0.1837 - 306ms/epoch - 76ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.7996 - accuracy: 0.9204 - val_loss: 1.3912 - val_accuracy: 0.1837 - 310ms/epoch - 78ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.8030 - accuracy: 0.9027 - val_loss: 1.3916 - val_accuracy: 0.1837 - 312ms/epoch - 78ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.8001 - accuracy: 0.8673 - val_loss: 1.3911 - val_accuracy: 0.1837 - 315ms/epoch - 79ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.7731 - accuracy: 0.8761 - val_loss: 1.3913 - val_accuracy: 0.1837 - 325ms/epoch - 81ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.8016 - accuracy: 0.8673 - val_loss: 1.3943 - val_accuracy: 0.1837 - 311ms/epoch - 78ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.7322 - accuracy: 0.9292 - val_loss: 1.3953 - val_accuracy: 0.1429 - 313ms/epoch - 78ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.7557 - accuracy: 0.8938 - val_loss: 1.3935 - val_accuracy: 0.1837 - 314ms/epoch - 78ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.7455 - accuracy: 0.9204 - val_loss: 1.3936 - val_accuracy: 0.1224 - 309ms/epoch - 77ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.7464 - accuracy: 0.9115 - val_loss: 1.3957 - val_accuracy: 0.1633 - 327ms/epoch - 82ms/step\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.7088 - accuracy: 0.9558 - val_loss: 1.3944 - val_accuracy: 0.1837 - 323ms/epoch - 81ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.7047 - accuracy: 0.9558 - val_loss: 1.3976 - val_accuracy: 0.1224 - 303ms/epoch - 76ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.7015 - accuracy: 0.9204 - val_loss: 1.3960 - val_accuracy: 0.1837 - 325ms/epoch - 81ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.6821 - accuracy: 0.9381 - val_loss: 1.3981 - val_accuracy: 0.1837 - 322ms/epoch - 81ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.6764 - accuracy: 0.9292 - val_loss: 1.3984 - val_accuracy: 0.1837 - 314ms/epoch - 78ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.6389 - accuracy: 0.9735 - val_loss: 1.3959 - val_accuracy: 0.1224 - 319ms/epoch - 80ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.6375 - accuracy: 0.9381 - val_loss: 1.3958 - val_accuracy: 0.1837 - 329ms/epoch - 82ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.6414 - accuracy: 0.9469 - val_loss: 1.3981 - val_accuracy: 0.1837 - 334ms/epoch - 83ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.6315 - accuracy: 0.9646 - val_loss: 1.3960 - val_accuracy: 0.1837 - 306ms/epoch - 76ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.6188 - accuracy: 0.9558 - val_loss: 1.3967 - val_accuracy: 0.1633 - 328ms/epoch - 82ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.6278 - accuracy: 0.9823 - val_loss: 1.3992 - val_accuracy: 0.1633 - 307ms/epoch - 77ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.5698 - accuracy: 0.9823 - val_loss: 1.3992 - val_accuracy: 0.1429 - 322ms/epoch - 81ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.5949 - accuracy: 0.9735 - val_loss: 1.3945 - val_accuracy: 0.2041 - 306ms/epoch - 77ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.5710 - accuracy: 0.9646 - val_loss: 1.3959 - val_accuracy: 0.1837 - 317ms/epoch - 79ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.5749 - accuracy: 0.9381 - val_loss: 1.3951 - val_accuracy: 0.1837 - 302ms/epoch - 76ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.5603 - accuracy: 0.9735 - val_loss: 1.4011 - val_accuracy: 0.1429 - 315ms/epoch - 79ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.5352 - accuracy: 0.9823 - val_loss: 1.3872 - val_accuracy: 0.3061 - 315ms/epoch - 79ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 1.38670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.5016 - accuracy: 0.9912 - val_loss: 1.4036 - val_accuracy: 0.1837 - 308ms/epoch - 77ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.5335 - accuracy: 0.9823 - val_loss: 1.3961 - val_accuracy: 0.1837 - 323ms/epoch - 81ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.4956 - accuracy: 1.0000 - val_loss: 1.3986 - val_accuracy: 0.2041 - 308ms/epoch - 77ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 1.38670\n",
      "4/4 - 0s - loss: 0.4956 - accuracy: 0.9823 - val_loss: 1.3949 - val_accuracy: 0.2041 - 301ms/epoch - 75ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss improved from 1.38670 to 1.38632, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.4786 - accuracy: 0.9823 - val_loss: 1.3863 - val_accuracy: 0.2041 - 366ms/epoch - 92ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.4802 - accuracy: 0.9912 - val_loss: 1.4099 - val_accuracy: 0.1633 - 308ms/epoch - 77ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.4547 - accuracy: 1.0000 - val_loss: 1.3966 - val_accuracy: 0.2041 - 316ms/epoch - 79ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.4529 - accuracy: 0.9912 - val_loss: 1.3932 - val_accuracy: 0.2449 - 317ms/epoch - 79ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.4711 - accuracy: 0.9823 - val_loss: 1.4080 - val_accuracy: 0.1633 - 302ms/epoch - 76ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.4366 - accuracy: 1.0000 - val_loss: 1.4077 - val_accuracy: 0.1633 - 310ms/epoch - 77ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.4109 - accuracy: 0.9912 - val_loss: 1.4007 - val_accuracy: 0.2449 - 308ms/epoch - 77ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.4185 - accuracy: 1.0000 - val_loss: 1.3997 - val_accuracy: 0.2245 - 304ms/epoch - 76ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.4065 - accuracy: 0.9912 - val_loss: 1.4039 - val_accuracy: 0.2245 - 307ms/epoch - 77ms/step\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.4091 - accuracy: 1.0000 - val_loss: 1.4120 - val_accuracy: 0.2245 - 313ms/epoch - 78ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.3963 - accuracy: 1.0000 - val_loss: 1.4213 - val_accuracy: 0.1837 - 311ms/epoch - 78ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.3908 - accuracy: 1.0000 - val_loss: 1.4108 - val_accuracy: 0.2041 - 307ms/epoch - 77ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.3791 - accuracy: 1.0000 - val_loss: 1.4149 - val_accuracy: 0.1633 - 300ms/epoch - 75ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.4192 - accuracy: 0.9823 - val_loss: 1.4289 - val_accuracy: 0.1429 - 336ms/epoch - 84ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.3858 - accuracy: 0.9823 - val_loss: 1.4037 - val_accuracy: 0.1837 - 321ms/epoch - 80ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.3669 - accuracy: 1.0000 - val_loss: 1.3979 - val_accuracy: 0.2041 - 310ms/epoch - 78ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 1.38632\n",
      "4/4 - 1s - loss: 0.3429 - accuracy: 1.0000 - val_loss: 1.4238 - val_accuracy: 0.2041 - 681ms/epoch - 170ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.3653 - accuracy: 0.9912 - val_loss: 1.4414 - val_accuracy: 0.1837 - 330ms/epoch - 83ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.3523 - accuracy: 0.9823 - val_loss: 1.4661 - val_accuracy: 0.3469 - 317ms/epoch - 79ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.3990 - accuracy: 0.9735 - val_loss: 1.5089 - val_accuracy: 0.1224 - 342ms/epoch - 86ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.3940 - accuracy: 0.9912 - val_loss: 1.4275 - val_accuracy: 0.3265 - 343ms/epoch - 86ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.3683 - accuracy: 0.9912 - val_loss: 1.4507 - val_accuracy: 0.1224 - 324ms/epoch - 81ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.3179 - accuracy: 0.9912 - val_loss: 1.4144 - val_accuracy: 0.2653 - 317ms/epoch - 79ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.2905 - accuracy: 1.0000 - val_loss: 1.4196 - val_accuracy: 0.1633 - 336ms/epoch - 84ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.3287 - accuracy: 1.0000 - val_loss: 1.4334 - val_accuracy: 0.1429 - 318ms/epoch - 79ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.2951 - accuracy: 1.0000 - val_loss: 1.4181 - val_accuracy: 0.2653 - 322ms/epoch - 81ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.3162 - accuracy: 1.0000 - val_loss: 1.4794 - val_accuracy: 0.2245 - 329ms/epoch - 82ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.2699 - accuracy: 1.0000 - val_loss: 1.4449 - val_accuracy: 0.1837 - 320ms/epoch - 80ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.2822 - accuracy: 1.0000 - val_loss: 1.4381 - val_accuracy: 0.2041 - 338ms/epoch - 85ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.2549 - accuracy: 1.0000 - val_loss: 1.4314 - val_accuracy: 0.2653 - 316ms/epoch - 79ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.2641 - accuracy: 1.0000 - val_loss: 1.4800 - val_accuracy: 0.2449 - 330ms/epoch - 82ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.2633 - accuracy: 1.0000 - val_loss: 1.4533 - val_accuracy: 0.1429 - 327ms/epoch - 82ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.2393 - accuracy: 1.0000 - val_loss: 1.4712 - val_accuracy: 0.1837 - 322ms/epoch - 81ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.2571 - accuracy: 1.0000 - val_loss: 1.4777 - val_accuracy: 0.2653 - 319ms/epoch - 80ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.2459 - accuracy: 1.0000 - val_loss: 1.4674 - val_accuracy: 0.1633 - 311ms/epoch - 78ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.2454 - accuracy: 1.0000 - val_loss: 1.4807 - val_accuracy: 0.2449 - 320ms/epoch - 80ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.2166 - accuracy: 1.0000 - val_loss: 1.4585 - val_accuracy: 0.2041 - 317ms/epoch - 79ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.2505 - accuracy: 1.0000 - val_loss: 1.5147 - val_accuracy: 0.2449 - 340ms/epoch - 85ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 1.5124 - val_accuracy: 0.2245 - 316ms/epoch - 79ms/step\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.2268 - accuracy: 1.0000 - val_loss: 1.4722 - val_accuracy: 0.1633 - 325ms/epoch - 81ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.2215 - accuracy: 0.9912 - val_loss: 1.4980 - val_accuracy: 0.2449 - 314ms/epoch - 78ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.2303 - accuracy: 1.0000 - val_loss: 1.5342 - val_accuracy: 0.1224 - 336ms/epoch - 84ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.2421 - accuracy: 1.0000 - val_loss: 1.5652 - val_accuracy: 0.1020 - 318ms/epoch - 80ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 1.5249 - val_accuracy: 0.1429 - 332ms/epoch - 83ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 1.4981 - val_accuracy: 0.2653 - 319ms/epoch - 80ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 1.5726 - val_accuracy: 0.1837 - 315ms/epoch - 79ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 1.5349 - val_accuracy: 0.1633 - 321ms/epoch - 80ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.2020 - accuracy: 1.0000 - val_loss: 1.5965 - val_accuracy: 0.2041 - 321ms/epoch - 80ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.2044 - accuracy: 1.0000 - val_loss: 1.5099 - val_accuracy: 0.1837 - 319ms/epoch - 80ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.2016 - accuracy: 1.0000 - val_loss: 1.5665 - val_accuracy: 0.1837 - 326ms/epoch - 82ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1956 - accuracy: 1.0000 - val_loss: 1.5812 - val_accuracy: 0.1020 - 321ms/epoch - 80ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1939 - accuracy: 1.0000 - val_loss: 1.5856 - val_accuracy: 0.2449 - 322ms/epoch - 80ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.5633 - val_accuracy: 0.1633 - 321ms/epoch - 80ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.2066 - accuracy: 1.0000 - val_loss: 1.5900 - val_accuracy: 0.1429 - 320ms/epoch - 80ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 1.6170 - val_accuracy: 0.2245 - 319ms/epoch - 80ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1892 - accuracy: 1.0000 - val_loss: 1.5752 - val_accuracy: 0.1837 - 314ms/epoch - 78ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1951 - accuracy: 1.0000 - val_loss: 1.6293 - val_accuracy: 0.2041 - 325ms/epoch - 81ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1853 - accuracy: 1.0000 - val_loss: 1.5220 - val_accuracy: 0.2041 - 325ms/epoch - 81ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1935 - accuracy: 1.0000 - val_loss: 1.5645 - val_accuracy: 0.1429 - 331ms/epoch - 83ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1810 - accuracy: 1.0000 - val_loss: 1.5698 - val_accuracy: 0.1837 - 323ms/epoch - 81ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1620 - accuracy: 1.0000 - val_loss: 1.5425 - val_accuracy: 0.1837 - 323ms/epoch - 81ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1687 - accuracy: 1.0000 - val_loss: 1.5790 - val_accuracy: 0.2041 - 327ms/epoch - 82ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1660 - accuracy: 1.0000 - val_loss: 1.5690 - val_accuracy: 0.1633 - 331ms/epoch - 83ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1748 - accuracy: 1.0000 - val_loss: 1.6100 - val_accuracy: 0.1633 - 333ms/epoch - 83ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1617 - accuracy: 1.0000 - val_loss: 1.6682 - val_accuracy: 0.1224 - 331ms/epoch - 83ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1822 - accuracy: 1.0000 - val_loss: 1.6081 - val_accuracy: 0.2041 - 325ms/epoch - 81ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1661 - accuracy: 1.0000 - val_loss: 1.5395 - val_accuracy: 0.2041 - 321ms/epoch - 80ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1786 - accuracy: 1.0000 - val_loss: 1.6544 - val_accuracy: 0.1224 - 316ms/epoch - 79ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1464 - accuracy: 1.0000 - val_loss: 1.5676 - val_accuracy: 0.2245 - 322ms/epoch - 80ms/step\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1666 - accuracy: 1.0000 - val_loss: 1.6560 - val_accuracy: 0.1429 - 336ms/epoch - 84ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1647 - accuracy: 1.0000 - val_loss: 1.6104 - val_accuracy: 0.1837 - 318ms/epoch - 80ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1511 - accuracy: 1.0000 - val_loss: 1.6807 - val_accuracy: 0.1429 - 327ms/epoch - 82ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1493 - accuracy: 1.0000 - val_loss: 1.6108 - val_accuracy: 0.1837 - 320ms/epoch - 80ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1472 - accuracy: 1.0000 - val_loss: 1.6525 - val_accuracy: 0.1224 - 322ms/epoch - 81ms/step\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1443 - accuracy: 1.0000 - val_loss: 1.5475 - val_accuracy: 0.1837 - 321ms/epoch - 80ms/step\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1708 - accuracy: 0.9912 - val_loss: 1.6034 - val_accuracy: 0.1429 - 314ms/epoch - 78ms/step\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1565 - accuracy: 1.0000 - val_loss: 1.6821 - val_accuracy: 0.1429 - 313ms/epoch - 78ms/step\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1702 - accuracy: 1.0000 - val_loss: 1.6830 - val_accuracy: 0.1429 - 317ms/epoch - 79ms/step\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1593 - accuracy: 1.0000 - val_loss: 1.6129 - val_accuracy: 0.1633 - 319ms/epoch - 80ms/step\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1363 - accuracy: 1.0000 - val_loss: 1.5984 - val_accuracy: 0.2653 - 316ms/epoch - 79ms/step\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1512 - accuracy: 1.0000 - val_loss: 1.6492 - val_accuracy: 0.2245 - 342ms/epoch - 86ms/step\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1355 - accuracy: 1.0000 - val_loss: 1.6869 - val_accuracy: 0.1429 - 340ms/epoch - 85ms/step\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1493 - accuracy: 1.0000 - val_loss: 1.6597 - val_accuracy: 0.2041 - 337ms/epoch - 84ms/step\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 135: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1425 - accuracy: 1.0000 - val_loss: 1.6099 - val_accuracy: 0.2245 - 317ms/epoch - 79ms/step\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 136: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1180 - accuracy: 1.0000 - val_loss: 1.6833 - val_accuracy: 0.1837 - 317ms/epoch - 79ms/step\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 137: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1251 - accuracy: 1.0000 - val_loss: 1.6805 - val_accuracy: 0.1224 - 329ms/epoch - 82ms/step\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 138: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1325 - accuracy: 1.0000 - val_loss: 1.6111 - val_accuracy: 0.1837 - 335ms/epoch - 84ms/step\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 139: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1197 - accuracy: 1.0000 - val_loss: 1.6495 - val_accuracy: 0.1837 - 318ms/epoch - 80ms/step\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 140: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1157 - accuracy: 1.0000 - val_loss: 1.6558 - val_accuracy: 0.2245 - 314ms/epoch - 78ms/step\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 141: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1175 - accuracy: 1.0000 - val_loss: 1.7023 - val_accuracy: 0.1837 - 338ms/epoch - 85ms/step\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 142: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1331 - accuracy: 1.0000 - val_loss: 1.6321 - val_accuracy: 0.1837 - 319ms/epoch - 80ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/300\n",
      "\n",
      "Epoch 143: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1148 - accuracy: 1.0000 - val_loss: 1.6289 - val_accuracy: 0.1837 - 313ms/epoch - 78ms/step\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 144: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1154 - accuracy: 1.0000 - val_loss: 1.6475 - val_accuracy: 0.1633 - 328ms/epoch - 82ms/step\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 145: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1200 - accuracy: 1.0000 - val_loss: 1.5942 - val_accuracy: 0.1837 - 307ms/epoch - 77ms/step\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 146: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1212 - accuracy: 1.0000 - val_loss: 1.5610 - val_accuracy: 0.2245 - 315ms/epoch - 79ms/step\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 147: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1103 - accuracy: 1.0000 - val_loss: 1.6015 - val_accuracy: 0.1837 - 328ms/epoch - 82ms/step\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 148: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1176 - accuracy: 1.0000 - val_loss: 1.5597 - val_accuracy: 0.2041 - 323ms/epoch - 81ms/step\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 149: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1174 - accuracy: 1.0000 - val_loss: 1.5854 - val_accuracy: 0.2041 - 317ms/epoch - 79ms/step\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 150: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1089 - accuracy: 1.0000 - val_loss: 1.6255 - val_accuracy: 0.2041 - 325ms/epoch - 81ms/step\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 151: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1158 - accuracy: 1.0000 - val_loss: 1.6547 - val_accuracy: 0.2041 - 326ms/epoch - 81ms/step\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 152: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1114 - accuracy: 1.0000 - val_loss: 1.6236 - val_accuracy: 0.2245 - 337ms/epoch - 84ms/step\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 153: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1127 - accuracy: 1.0000 - val_loss: 1.6950 - val_accuracy: 0.1633 - 323ms/epoch - 81ms/step\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 154: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1095 - accuracy: 1.0000 - val_loss: 1.7309 - val_accuracy: 0.2041 - 321ms/epoch - 80ms/step\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 155: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1131 - accuracy: 1.0000 - val_loss: 1.7479 - val_accuracy: 0.1429 - 314ms/epoch - 79ms/step\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 156: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1204 - accuracy: 1.0000 - val_loss: 1.6459 - val_accuracy: 0.1633 - 334ms/epoch - 83ms/step\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 157: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1058 - accuracy: 1.0000 - val_loss: 1.7478 - val_accuracy: 0.2041 - 326ms/epoch - 81ms/step\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 158: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1127 - accuracy: 1.0000 - val_loss: 1.6699 - val_accuracy: 0.2041 - 308ms/epoch - 77ms/step\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 159: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1068 - accuracy: 1.0000 - val_loss: 1.7274 - val_accuracy: 0.1224 - 314ms/epoch - 78ms/step\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 160: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1127 - accuracy: 1.0000 - val_loss: 1.6488 - val_accuracy: 0.2041 - 317ms/epoch - 79ms/step\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 161: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1125 - accuracy: 1.0000 - val_loss: 1.7174 - val_accuracy: 0.1224 - 325ms/epoch - 81ms/step\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 162: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1060 - accuracy: 1.0000 - val_loss: 1.6104 - val_accuracy: 0.1837 - 319ms/epoch - 80ms/step\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 163: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1049 - accuracy: 1.0000 - val_loss: 1.6937 - val_accuracy: 0.2041 - 320ms/epoch - 80ms/step\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 164: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1129 - accuracy: 1.0000 - val_loss: 1.5844 - val_accuracy: 0.2245 - 312ms/epoch - 78ms/step\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 165: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1116 - accuracy: 1.0000 - val_loss: 1.6678 - val_accuracy: 0.1633 - 323ms/epoch - 81ms/step\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 166: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1244 - accuracy: 1.0000 - val_loss: 1.7359 - val_accuracy: 0.1633 - 328ms/epoch - 82ms/step\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 167: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1300 - accuracy: 1.0000 - val_loss: 1.8246 - val_accuracy: 0.1837 - 330ms/epoch - 82ms/step\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 168: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1204 - accuracy: 1.0000 - val_loss: 1.7997 - val_accuracy: 0.1633 - 327ms/epoch - 82ms/step\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 169: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1226 - accuracy: 1.0000 - val_loss: 1.7598 - val_accuracy: 0.1633 - 310ms/epoch - 78ms/step\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 170: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1119 - accuracy: 1.0000 - val_loss: 1.6807 - val_accuracy: 0.2449 - 311ms/epoch - 78ms/step\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 171: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1126 - accuracy: 1.0000 - val_loss: 1.7054 - val_accuracy: 0.2041 - 322ms/epoch - 81ms/step\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 172: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1010 - accuracy: 1.0000 - val_loss: 1.6768 - val_accuracy: 0.1633 - 315ms/epoch - 79ms/step\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 173: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0953 - accuracy: 1.0000 - val_loss: 1.6524 - val_accuracy: 0.1837 - 330ms/epoch - 83ms/step\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 174: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0838 - accuracy: 1.0000 - val_loss: 1.7447 - val_accuracy: 0.1429 - 323ms/epoch - 81ms/step\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 175: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1002 - accuracy: 1.0000 - val_loss: 1.7007 - val_accuracy: 0.1837 - 311ms/epoch - 78ms/step\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 176: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0842 - accuracy: 1.0000 - val_loss: 1.7831 - val_accuracy: 0.1633 - 326ms/epoch - 81ms/step\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 177: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.1035 - accuracy: 1.0000 - val_loss: 1.6357 - val_accuracy: 0.2041 - 331ms/epoch - 83ms/step\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 178: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0896 - accuracy: 1.0000 - val_loss: 1.7091 - val_accuracy: 0.2041 - 327ms/epoch - 82ms/step\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 179: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0957 - accuracy: 1.0000 - val_loss: 1.7643 - val_accuracy: 0.1837 - 320ms/epoch - 80ms/step\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 180: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0999 - accuracy: 1.0000 - val_loss: 1.6592 - val_accuracy: 0.2041 - 312ms/epoch - 78ms/step\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 181: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0883 - accuracy: 1.0000 - val_loss: 1.7764 - val_accuracy: 0.1633 - 318ms/epoch - 80ms/step\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 182: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0897 - accuracy: 1.0000 - val_loss: 1.7137 - val_accuracy: 0.1633 - 313ms/epoch - 78ms/step\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 183: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0722 - accuracy: 1.0000 - val_loss: 1.7390 - val_accuracy: 0.2041 - 309ms/epoch - 77ms/step\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 184: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0913 - accuracy: 1.0000 - val_loss: 1.7367 - val_accuracy: 0.1837 - 315ms/epoch - 79ms/step\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 185: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0950 - accuracy: 1.0000 - val_loss: 1.8239 - val_accuracy: 0.1224 - 318ms/epoch - 79ms/step\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 186: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0953 - accuracy: 1.0000 - val_loss: 1.6261 - val_accuracy: 0.2041 - 319ms/epoch - 80ms/step\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 187: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0919 - accuracy: 1.0000 - val_loss: 1.7199 - val_accuracy: 0.2041 - 316ms/epoch - 79ms/step\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 188: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0909 - accuracy: 1.0000 - val_loss: 1.7050 - val_accuracy: 0.1633 - 309ms/epoch - 77ms/step\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 189: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0846 - accuracy: 1.0000 - val_loss: 1.6653 - val_accuracy: 0.2245 - 318ms/epoch - 80ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190/300\n",
      "\n",
      "Epoch 190: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0890 - accuracy: 1.0000 - val_loss: 1.6939 - val_accuracy: 0.2245 - 323ms/epoch - 81ms/step\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 191: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0804 - accuracy: 1.0000 - val_loss: 1.7350 - val_accuracy: 0.2041 - 316ms/epoch - 79ms/step\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 192: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0944 - accuracy: 1.0000 - val_loss: 1.7191 - val_accuracy: 0.2041 - 329ms/epoch - 82ms/step\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 193: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0911 - accuracy: 1.0000 - val_loss: 1.8366 - val_accuracy: 0.1633 - 317ms/epoch - 79ms/step\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 194: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0804 - accuracy: 1.0000 - val_loss: 1.8519 - val_accuracy: 0.1429 - 317ms/epoch - 79ms/step\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 195: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0706 - accuracy: 1.0000 - val_loss: 1.7537 - val_accuracy: 0.1837 - 329ms/epoch - 82ms/step\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 196: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0746 - accuracy: 1.0000 - val_loss: 1.7045 - val_accuracy: 0.2041 - 322ms/epoch - 81ms/step\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 197: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0753 - accuracy: 1.0000 - val_loss: 1.6910 - val_accuracy: 0.2041 - 314ms/epoch - 78ms/step\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 198: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0796 - accuracy: 1.0000 - val_loss: 1.6860 - val_accuracy: 0.1837 - 334ms/epoch - 83ms/step\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 199: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0744 - accuracy: 1.0000 - val_loss: 1.6928 - val_accuracy: 0.2041 - 324ms/epoch - 81ms/step\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 200: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0829 - accuracy: 1.0000 - val_loss: 1.7309 - val_accuracy: 0.1837 - 315ms/epoch - 79ms/step\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 201: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0736 - accuracy: 1.0000 - val_loss: 1.6946 - val_accuracy: 0.2041 - 321ms/epoch - 80ms/step\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 202: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0735 - accuracy: 1.0000 - val_loss: 1.7816 - val_accuracy: 0.1837 - 311ms/epoch - 78ms/step\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 203: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0758 - accuracy: 1.0000 - val_loss: 1.7720 - val_accuracy: 0.1633 - 331ms/epoch - 83ms/step\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 204: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0765 - accuracy: 1.0000 - val_loss: 1.7204 - val_accuracy: 0.2041 - 324ms/epoch - 81ms/step\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 205: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0742 - accuracy: 1.0000 - val_loss: 1.7453 - val_accuracy: 0.1837 - 321ms/epoch - 80ms/step\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 206: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0687 - accuracy: 1.0000 - val_loss: 1.7003 - val_accuracy: 0.2041 - 317ms/epoch - 79ms/step\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 207: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0743 - accuracy: 1.0000 - val_loss: 1.8643 - val_accuracy: 0.1429 - 319ms/epoch - 80ms/step\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 208: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0911 - accuracy: 1.0000 - val_loss: 1.7819 - val_accuracy: 0.1633 - 319ms/epoch - 80ms/step\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 209: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0810 - accuracy: 1.0000 - val_loss: 1.8510 - val_accuracy: 0.1224 - 314ms/epoch - 79ms/step\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 210: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0854 - accuracy: 1.0000 - val_loss: 1.6361 - val_accuracy: 0.1837 - 331ms/epoch - 83ms/step\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 211: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0821 - accuracy: 1.0000 - val_loss: 1.8433 - val_accuracy: 0.1837 - 311ms/epoch - 78ms/step\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 212: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0672 - accuracy: 1.0000 - val_loss: 1.7631 - val_accuracy: 0.1837 - 313ms/epoch - 78ms/step\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 213: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0733 - accuracy: 1.0000 - val_loss: 1.8799 - val_accuracy: 0.1633 - 321ms/epoch - 80ms/step\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 214: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0811 - accuracy: 1.0000 - val_loss: 1.7388 - val_accuracy: 0.2041 - 329ms/epoch - 82ms/step\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 215: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0699 - accuracy: 1.0000 - val_loss: 1.6576 - val_accuracy: 0.2245 - 315ms/epoch - 79ms/step\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 216: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0703 - accuracy: 1.0000 - val_loss: 1.8546 - val_accuracy: 0.2041 - 318ms/epoch - 80ms/step\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 217: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0717 - accuracy: 1.0000 - val_loss: 1.6952 - val_accuracy: 0.2449 - 312ms/epoch - 78ms/step\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 218: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0748 - accuracy: 1.0000 - val_loss: 1.7628 - val_accuracy: 0.1633 - 309ms/epoch - 77ms/step\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 219: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0641 - accuracy: 1.0000 - val_loss: 1.7605 - val_accuracy: 0.2041 - 325ms/epoch - 81ms/step\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 220: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0665 - accuracy: 1.0000 - val_loss: 1.8126 - val_accuracy: 0.2041 - 318ms/epoch - 80ms/step\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 221: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0756 - accuracy: 1.0000 - val_loss: 1.7896 - val_accuracy: 0.1633 - 323ms/epoch - 81ms/step\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 222: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0692 - accuracy: 1.0000 - val_loss: 1.7633 - val_accuracy: 0.1633 - 320ms/epoch - 80ms/step\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 223: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0709 - accuracy: 1.0000 - val_loss: 1.6591 - val_accuracy: 0.2041 - 322ms/epoch - 81ms/step\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 224: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0748 - accuracy: 1.0000 - val_loss: 1.7289 - val_accuracy: 0.2041 - 315ms/epoch - 79ms/step\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 225: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0689 - accuracy: 1.0000 - val_loss: 1.8488 - val_accuracy: 0.1429 - 322ms/epoch - 81ms/step\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 226: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0740 - accuracy: 1.0000 - val_loss: 1.7088 - val_accuracy: 0.1837 - 314ms/epoch - 78ms/step\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 227: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0763 - accuracy: 1.0000 - val_loss: 1.8609 - val_accuracy: 0.1633 - 309ms/epoch - 77ms/step\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 228: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0558 - accuracy: 1.0000 - val_loss: 1.7722 - val_accuracy: 0.1837 - 334ms/epoch - 84ms/step\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 229: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0782 - accuracy: 1.0000 - val_loss: 1.7757 - val_accuracy: 0.2041 - 316ms/epoch - 79ms/step\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 230: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0668 - accuracy: 1.0000 - val_loss: 1.7076 - val_accuracy: 0.1837 - 326ms/epoch - 81ms/step\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 231: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0587 - accuracy: 1.0000 - val_loss: 1.6629 - val_accuracy: 0.2041 - 325ms/epoch - 81ms/step\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 232: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0640 - accuracy: 1.0000 - val_loss: 1.7694 - val_accuracy: 0.1837 - 337ms/epoch - 84ms/step\n",
      "Epoch 233/300\n",
      "\n",
      "Epoch 233: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0557 - accuracy: 1.0000 - val_loss: 1.7631 - val_accuracy: 0.1633 - 321ms/epoch - 80ms/step\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 234: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0603 - accuracy: 1.0000 - val_loss: 1.7737 - val_accuracy: 0.1837 - 338ms/epoch - 85ms/step\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 235: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0654 - accuracy: 1.0000 - val_loss: 1.7438 - val_accuracy: 0.1633 - 322ms/epoch - 80ms/step\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 236: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0615 - accuracy: 1.0000 - val_loss: 1.7934 - val_accuracy: 0.1837 - 324ms/epoch - 81ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237/300\n",
      "\n",
      "Epoch 237: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0725 - accuracy: 1.0000 - val_loss: 1.8466 - val_accuracy: 0.2245 - 316ms/epoch - 79ms/step\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 238: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0714 - accuracy: 1.0000 - val_loss: 1.7938 - val_accuracy: 0.2245 - 301ms/epoch - 75ms/step\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 239: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0689 - accuracy: 1.0000 - val_loss: 1.8269 - val_accuracy: 0.2449 - 317ms/epoch - 79ms/step\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 240: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0701 - accuracy: 1.0000 - val_loss: 1.8959 - val_accuracy: 0.1837 - 313ms/epoch - 78ms/step\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 241: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0757 - accuracy: 1.0000 - val_loss: 1.7268 - val_accuracy: 0.2245 - 319ms/epoch - 80ms/step\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 242: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0607 - accuracy: 1.0000 - val_loss: 1.7447 - val_accuracy: 0.1837 - 323ms/epoch - 81ms/step\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 243: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0645 - accuracy: 1.0000 - val_loss: 1.8544 - val_accuracy: 0.1837 - 311ms/epoch - 78ms/step\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 244: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0579 - accuracy: 1.0000 - val_loss: 1.7669 - val_accuracy: 0.2041 - 327ms/epoch - 82ms/step\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 245: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0612 - accuracy: 1.0000 - val_loss: 1.8494 - val_accuracy: 0.1429 - 315ms/epoch - 79ms/step\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 246: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0570 - accuracy: 1.0000 - val_loss: 1.8038 - val_accuracy: 0.2245 - 328ms/epoch - 82ms/step\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 247: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0660 - accuracy: 1.0000 - val_loss: 1.8474 - val_accuracy: 0.1837 - 307ms/epoch - 77ms/step\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 248: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0571 - accuracy: 1.0000 - val_loss: 1.7551 - val_accuracy: 0.2041 - 304ms/epoch - 76ms/step\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 249: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0628 - accuracy: 1.0000 - val_loss: 1.7625 - val_accuracy: 0.1837 - 315ms/epoch - 79ms/step\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 250: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0509 - accuracy: 1.0000 - val_loss: 1.7745 - val_accuracy: 0.2245 - 313ms/epoch - 78ms/step\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 251: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0462 - accuracy: 1.0000 - val_loss: 1.7380 - val_accuracy: 0.2041 - 324ms/epoch - 81ms/step\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 252: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0595 - accuracy: 1.0000 - val_loss: 1.6806 - val_accuracy: 0.2041 - 324ms/epoch - 81ms/step\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 253: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0644 - accuracy: 1.0000 - val_loss: 1.5858 - val_accuracy: 0.2653 - 306ms/epoch - 76ms/step\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 254: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0520 - accuracy: 1.0000 - val_loss: 1.7018 - val_accuracy: 0.2449 - 320ms/epoch - 80ms/step\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 255: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0539 - accuracy: 1.0000 - val_loss: 1.7375 - val_accuracy: 0.2245 - 318ms/epoch - 80ms/step\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 256: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0570 - accuracy: 1.0000 - val_loss: 1.6808 - val_accuracy: 0.2245 - 319ms/epoch - 80ms/step\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 257: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0502 - accuracy: 1.0000 - val_loss: 1.7683 - val_accuracy: 0.1837 - 320ms/epoch - 80ms/step\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 258: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0563 - accuracy: 1.0000 - val_loss: 1.6570 - val_accuracy: 0.2041 - 318ms/epoch - 79ms/step\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 259: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0509 - accuracy: 1.0000 - val_loss: 1.7283 - val_accuracy: 0.1837 - 325ms/epoch - 81ms/step\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 260: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0536 - accuracy: 1.0000 - val_loss: 1.8436 - val_accuracy: 0.1837 - 322ms/epoch - 81ms/step\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 261: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0505 - accuracy: 1.0000 - val_loss: 1.7638 - val_accuracy: 0.1837 - 321ms/epoch - 80ms/step\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 262: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0493 - accuracy: 1.0000 - val_loss: 1.7428 - val_accuracy: 0.1837 - 317ms/epoch - 79ms/step\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 263: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0519 - accuracy: 1.0000 - val_loss: 1.7977 - val_accuracy: 0.2041 - 308ms/epoch - 77ms/step\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 264: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0478 - accuracy: 1.0000 - val_loss: 1.7906 - val_accuracy: 0.2041 - 322ms/epoch - 80ms/step\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 265: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0563 - accuracy: 1.0000 - val_loss: 1.7615 - val_accuracy: 0.1429 - 320ms/epoch - 80ms/step\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 266: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0471 - accuracy: 1.0000 - val_loss: 1.7616 - val_accuracy: 0.1837 - 305ms/epoch - 76ms/step\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 267: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0479 - accuracy: 1.0000 - val_loss: 1.6799 - val_accuracy: 0.2041 - 314ms/epoch - 79ms/step\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 268: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0493 - accuracy: 1.0000 - val_loss: 1.7252 - val_accuracy: 0.2041 - 306ms/epoch - 76ms/step\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 269: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0480 - accuracy: 1.0000 - val_loss: 1.7636 - val_accuracy: 0.1633 - 311ms/epoch - 78ms/step\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 270: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0463 - accuracy: 1.0000 - val_loss: 1.7430 - val_accuracy: 0.1429 - 315ms/epoch - 79ms/step\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 271: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0528 - accuracy: 1.0000 - val_loss: 1.7531 - val_accuracy: 0.1837 - 316ms/epoch - 79ms/step\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 272: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0435 - accuracy: 1.0000 - val_loss: 1.7512 - val_accuracy: 0.2041 - 309ms/epoch - 77ms/step\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 273: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0568 - accuracy: 1.0000 - val_loss: 1.7398 - val_accuracy: 0.2041 - 318ms/epoch - 79ms/step\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 274: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0494 - accuracy: 1.0000 - val_loss: 1.7748 - val_accuracy: 0.2245 - 313ms/epoch - 78ms/step\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 275: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0429 - accuracy: 1.0000 - val_loss: 1.7437 - val_accuracy: 0.2041 - 330ms/epoch - 82ms/step\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 276: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0512 - accuracy: 1.0000 - val_loss: 1.7654 - val_accuracy: 0.1837 - 324ms/epoch - 81ms/step\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 277: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0491 - accuracy: 1.0000 - val_loss: 1.7185 - val_accuracy: 0.2449 - 316ms/epoch - 79ms/step\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 278: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0467 - accuracy: 1.0000 - val_loss: 1.7910 - val_accuracy: 0.2041 - 318ms/epoch - 80ms/step\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 279: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0466 - accuracy: 1.0000 - val_loss: 1.7800 - val_accuracy: 0.2245 - 318ms/epoch - 79ms/step\n",
      "Epoch 280/300\n",
      "\n",
      "Epoch 280: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0486 - accuracy: 1.0000 - val_loss: 1.7829 - val_accuracy: 0.2449 - 322ms/epoch - 80ms/step\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 281: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0457 - accuracy: 1.0000 - val_loss: 1.7495 - val_accuracy: 0.2245 - 313ms/epoch - 78ms/step\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 282: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0440 - accuracy: 1.0000 - val_loss: 1.8225 - val_accuracy: 0.1837 - 326ms/epoch - 82ms/step\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 283: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0439 - accuracy: 1.0000 - val_loss: 1.8403 - val_accuracy: 0.2245 - 325ms/epoch - 81ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284/300\n",
      "\n",
      "Epoch 284: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0452 - accuracy: 1.0000 - val_loss: 1.7423 - val_accuracy: 0.2041 - 320ms/epoch - 80ms/step\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 285: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0505 - accuracy: 1.0000 - val_loss: 1.7365 - val_accuracy: 0.2041 - 310ms/epoch - 77ms/step\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 286: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0374 - accuracy: 1.0000 - val_loss: 1.7247 - val_accuracy: 0.2245 - 309ms/epoch - 77ms/step\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 287: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0367 - accuracy: 1.0000 - val_loss: 1.7754 - val_accuracy: 0.2245 - 307ms/epoch - 77ms/step\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 288: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0457 - accuracy: 1.0000 - val_loss: 1.8058 - val_accuracy: 0.1837 - 322ms/epoch - 80ms/step\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 289: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0421 - accuracy: 1.0000 - val_loss: 1.7814 - val_accuracy: 0.2041 - 315ms/epoch - 79ms/step\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 290: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0479 - accuracy: 1.0000 - val_loss: 1.8104 - val_accuracy: 0.1429 - 315ms/epoch - 79ms/step\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 291: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0450 - accuracy: 1.0000 - val_loss: 1.8209 - val_accuracy: 0.1837 - 310ms/epoch - 77ms/step\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 292: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0546 - accuracy: 1.0000 - val_loss: 1.7695 - val_accuracy: 0.1837 - 318ms/epoch - 80ms/step\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 293: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0367 - accuracy: 1.0000 - val_loss: 1.8318 - val_accuracy: 0.1633 - 314ms/epoch - 79ms/step\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 294: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0473 - accuracy: 1.0000 - val_loss: 1.8044 - val_accuracy: 0.2041 - 313ms/epoch - 78ms/step\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 295: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0511 - accuracy: 1.0000 - val_loss: 1.8453 - val_accuracy: 0.1224 - 310ms/epoch - 77ms/step\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 296: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0516 - accuracy: 1.0000 - val_loss: 1.8375 - val_accuracy: 0.2041 - 311ms/epoch - 78ms/step\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 297: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0481 - accuracy: 1.0000 - val_loss: 1.7931 - val_accuracy: 0.1633 - 324ms/epoch - 81ms/step\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 298: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0362 - accuracy: 1.0000 - val_loss: 1.8340 - val_accuracy: 0.1429 - 327ms/epoch - 82ms/step\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 299: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0487 - accuracy: 1.0000 - val_loss: 1.8346 - val_accuracy: 0.1837 - 305ms/epoch - 76ms/step\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 300: val_loss did not improve from 1.38632\n",
      "4/4 - 0s - loss: 0.0425 - accuracy: 1.0000 - val_loss: 1.7910 - val_accuracy: 0.1633 - 319ms/epoch - 80ms/step\n",
      "2/2 [==============================] - 0s 22ms/step\n",
      "Lists\n",
      "[0.24074074074074073, 0.2777777777777778, 0.2222222222222222, 0.16666666666666666]\n",
      "[0.2560457516339869, 0.3611607142857143, 0.05555555555555555, 0.08333333333333333]\n",
      "[0.26111111111111107, 0.27197802197802196, 0.25, 0.20769230769230768]\n",
      "[0.24155810983397188, 0.2317961667425591, 0.0909090909090909, 0.11360448807854137]\n",
      "dicts\n",
      "{1: 0.28, 2: 0.2, 3: 0.22777777777777777, 4: 0.18333333333333335, 5: 0.21666666666666665, 6: 0.22685185185185183, 7: 0, 8: 0}\n",
      "{1: 0.179879077643203, 2: 0.06654896421845574, 3: 0.07670940170940171, 4: 0.07773809523809523, 5: 0.09915003485482209, 6: 0.18902383870214753, 7: 0, 8: 0}\n",
      "{1: 0.285120781995782, 2: 0.2456597222222222, 3: 0.2569444444444444, 4: 0.2416466346153846, 5: 0.2585565476190476, 6: 0.24769536019536015, 7: 0, 8: 0}\n",
      "{1: 0.19991143316006618, 2: 0.09862908327582241, 3: 0.1074404761904762, 4: 0.10099907282139219, 5: 0.12015083370526773, 6: 0.16946696389104082, 7: 0, 8: 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Number of devices: 2\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 09:49:15.368101: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_9842180\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:646612\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
      "2022-11-11 09:49:19.383932: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_9845250\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:646654\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38653, saving model to checkpoint1.h5\n",
      "4/4 - 5s - loss: 1.4507 - accuracy: 0.2381 - val_loss: 1.3865 - val_accuracy: 0.2407 - 5s/epoch - 1s/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss improved from 1.38653 to 1.38628, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 1.3389 - accuracy: 0.3730 - val_loss: 1.3863 - val_accuracy: 0.2407 - 389ms/epoch - 97ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss improved from 1.38628 to 1.38627, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 1.3200 - accuracy: 0.4206 - val_loss: 1.3863 - val_accuracy: 0.2407 - 379ms/epoch - 95ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 1.2834 - accuracy: 0.5317 - val_loss: 1.3863 - val_accuracy: 0.2778 - 322ms/epoch - 81ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 1.2519 - accuracy: 0.5476 - val_loss: 1.3864 - val_accuracy: 0.1111 - 340ms/epoch - 85ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 1.2235 - accuracy: 0.5159 - val_loss: 1.3864 - val_accuracy: 0.2222 - 329ms/epoch - 82ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 1.38627\n",
      "4/4 - 0s - loss: 1.2389 - accuracy: 0.5159 - val_loss: 1.3863 - val_accuracy: 0.2407 - 334ms/epoch - 83ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss improved from 1.38627 to 1.38599, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 1.1970 - accuracy: 0.5238 - val_loss: 1.3860 - val_accuracy: 0.2407 - 384ms/epoch - 96ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 1.38599\n",
      "4/4 - 0s - loss: 1.1922 - accuracy: 0.5952 - val_loss: 1.3861 - val_accuracy: 0.2407 - 349ms/epoch - 87ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.38599\n",
      "4/4 - 0s - loss: 1.1523 - accuracy: 0.6349 - val_loss: 1.3862 - val_accuracy: 0.2407 - 329ms/epoch - 82ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.38599\n",
      "4/4 - 0s - loss: 1.1349 - accuracy: 0.6667 - val_loss: 1.3861 - val_accuracy: 0.2407 - 325ms/epoch - 81ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss improved from 1.38599 to 1.38592, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 1.1159 - accuracy: 0.7143 - val_loss: 1.3859 - val_accuracy: 0.2407 - 392ms/epoch - 98ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.38592\n",
      "4/4 - 0s - loss: 1.1008 - accuracy: 0.7143 - val_loss: 1.3859 - val_accuracy: 0.2407 - 328ms/epoch - 82ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 1.38592\n",
      "4/4 - 0s - loss: 1.0670 - accuracy: 0.7063 - val_loss: 1.3864 - val_accuracy: 0.2407 - 328ms/epoch - 82ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.38592\n",
      "4/4 - 0s - loss: 1.0791 - accuracy: 0.6984 - val_loss: 1.3864 - val_accuracy: 0.2407 - 333ms/epoch - 83ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss improved from 1.38592 to 1.38579, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 1.0451 - accuracy: 0.7302 - val_loss: 1.3858 - val_accuracy: 0.2407 - 391ms/epoch - 98ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss improved from 1.38579 to 1.38522, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 1.0096 - accuracy: 0.7381 - val_loss: 1.3852 - val_accuracy: 0.2407 - 385ms/epoch - 96ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 1.38522\n",
      "4/4 - 0s - loss: 1.0355 - accuracy: 0.6984 - val_loss: 1.3854 - val_accuracy: 0.2407 - 337ms/epoch - 84ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 1.38522\n",
      "4/4 - 0s - loss: 1.0069 - accuracy: 0.7063 - val_loss: 1.3863 - val_accuracy: 0.2407 - 322ms/epoch - 80ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 1.38522\n",
      "4/4 - 0s - loss: 1.0184 - accuracy: 0.7460 - val_loss: 1.3862 - val_accuracy: 0.2407 - 336ms/epoch - 84ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss improved from 1.38522 to 1.38500, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.9568 - accuracy: 0.7778 - val_loss: 1.3850 - val_accuracy: 0.2407 - 377ms/epoch - 94ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss improved from 1.38500 to 1.38467, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.9621 - accuracy: 0.8095 - val_loss: 1.3847 - val_accuracy: 0.2407 - 379ms/epoch - 95ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss improved from 1.38467 to 1.38444, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.9527 - accuracy: 0.8016 - val_loss: 1.3844 - val_accuracy: 0.2407 - 376ms/epoch - 94ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 1.38444\n",
      "4/4 - 0s - loss: 0.9440 - accuracy: 0.7857 - val_loss: 1.3848 - val_accuracy: 0.2407 - 326ms/epoch - 82ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.38444\n",
      "4/4 - 0s - loss: 0.9130 - accuracy: 0.8254 - val_loss: 1.3853 - val_accuracy: 0.2407 - 318ms/epoch - 79ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss improved from 1.38444 to 1.38443, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.8985 - accuracy: 0.8492 - val_loss: 1.3844 - val_accuracy: 0.2407 - 376ms/epoch - 94ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss improved from 1.38443 to 1.38333, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.9056 - accuracy: 0.8254 - val_loss: 1.3833 - val_accuracy: 0.2407 - 390ms/epoch - 97ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss improved from 1.38333 to 1.38298, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.9280 - accuracy: 0.8254 - val_loss: 1.3830 - val_accuracy: 0.2407 - 380ms/epoch - 95ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 1.38298\n",
      "4/4 - 0s - loss: 0.8898 - accuracy: 0.8413 - val_loss: 1.3844 - val_accuracy: 0.2407 - 323ms/epoch - 81ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 1.38298\n",
      "4/4 - 0s - loss: 0.8927 - accuracy: 0.8413 - val_loss: 1.3834 - val_accuracy: 0.2407 - 328ms/epoch - 82ms/step\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 1.38298\n",
      "4/4 - 0s - loss: 0.8503 - accuracy: 0.8651 - val_loss: 1.3842 - val_accuracy: 0.2407 - 322ms/epoch - 81ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 1.38298\n",
      "4/4 - 0s - loss: 0.8361 - accuracy: 0.8492 - val_loss: 1.3841 - val_accuracy: 0.2407 - 361ms/epoch - 90ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss improved from 1.38298 to 1.38021, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.8130 - accuracy: 0.8730 - val_loss: 1.3802 - val_accuracy: 0.2407 - 383ms/epoch - 96ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss improved from 1.38021 to 1.37866, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.8232 - accuracy: 0.8968 - val_loss: 1.3787 - val_accuracy: 0.2407 - 385ms/epoch - 96ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 1.37866\n",
      "4/4 - 0s - loss: 0.8025 - accuracy: 0.9206 - val_loss: 1.3815 - val_accuracy: 0.2407 - 337ms/epoch - 84ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 1.37866\n",
      "4/4 - 0s - loss: 0.7915 - accuracy: 0.8730 - val_loss: 1.3818 - val_accuracy: 0.2407 - 338ms/epoch - 84ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss improved from 1.37866 to 1.37840, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.8009 - accuracy: 0.8968 - val_loss: 1.3784 - val_accuracy: 0.2593 - 389ms/epoch - 97ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 1.37840\n",
      "4/4 - 0s - loss: 0.7885 - accuracy: 0.9286 - val_loss: 1.3811 - val_accuracy: 0.2407 - 339ms/epoch - 85ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 1.37840\n",
      "4/4 - 0s - loss: 0.7428 - accuracy: 0.9048 - val_loss: 1.3832 - val_accuracy: 0.2407 - 335ms/epoch - 84ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 1.37840\n",
      "4/4 - 0s - loss: 0.7197 - accuracy: 0.9762 - val_loss: 1.3813 - val_accuracy: 0.2407 - 325ms/epoch - 81ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 1.37840\n",
      "4/4 - 0s - loss: 0.7189 - accuracy: 0.9444 - val_loss: 1.3796 - val_accuracy: 0.2963 - 344ms/epoch - 86ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 1.37840\n",
      "4/4 - 0s - loss: 0.7155 - accuracy: 0.9444 - val_loss: 1.3787 - val_accuracy: 0.2407 - 353ms/epoch - 88ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 1.37840\n",
      "4/4 - 0s - loss: 0.7113 - accuracy: 0.9048 - val_loss: 1.3813 - val_accuracy: 0.2407 - 320ms/epoch - 80ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 1.37840\n",
      "4/4 - 0s - loss: 0.7142 - accuracy: 0.9683 - val_loss: 1.3805 - val_accuracy: 0.2407 - 336ms/epoch - 84ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 1.37840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.6755 - accuracy: 0.9444 - val_loss: 1.3794 - val_accuracy: 0.2407 - 323ms/epoch - 81ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss improved from 1.37840 to 1.37809, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.6919 - accuracy: 0.9206 - val_loss: 1.3781 - val_accuracy: 0.2407 - 384ms/epoch - 96ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 1.37809\n",
      "4/4 - 0s - loss: 0.6628 - accuracy: 0.9286 - val_loss: 1.3817 - val_accuracy: 0.2407 - 338ms/epoch - 85ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss improved from 1.37809 to 1.37688, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.6452 - accuracy: 0.9762 - val_loss: 1.3769 - val_accuracy: 0.2222 - 378ms/epoch - 95ms/step\n",
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 1.37688\n",
      "4/4 - 0s - loss: 0.5973 - accuracy: 0.9841 - val_loss: 1.3822 - val_accuracy: 0.2407 - 324ms/epoch - 81ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 1.37688\n",
      "4/4 - 0s - loss: 0.6289 - accuracy: 0.9762 - val_loss: 1.3784 - val_accuracy: 0.2593 - 333ms/epoch - 83ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss improved from 1.37688 to 1.37305, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.6189 - accuracy: 0.9683 - val_loss: 1.3730 - val_accuracy: 0.2593 - 376ms/epoch - 94ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 1.37305\n",
      "4/4 - 0s - loss: 0.5974 - accuracy: 0.9841 - val_loss: 1.3810 - val_accuracy: 0.2593 - 333ms/epoch - 83ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 1.37305\n",
      "4/4 - 0s - loss: 0.6199 - accuracy: 0.9524 - val_loss: 1.3831 - val_accuracy: 0.2778 - 345ms/epoch - 86ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss improved from 1.37305 to 1.37296, saving model to checkpoint1.h5\n",
      "4/4 - 0s - loss: 0.5592 - accuracy: 0.9683 - val_loss: 1.3730 - val_accuracy: 0.2407 - 376ms/epoch - 94ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.5580 - accuracy: 0.9921 - val_loss: 1.3817 - val_accuracy: 0.2407 - 325ms/epoch - 81ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.5604 - accuracy: 0.9921 - val_loss: 1.3899 - val_accuracy: 0.2593 - 323ms/epoch - 81ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.5468 - accuracy: 0.9921 - val_loss: 1.3840 - val_accuracy: 0.2593 - 331ms/epoch - 83ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.5039 - accuracy: 0.9762 - val_loss: 1.3761 - val_accuracy: 0.2593 - 342ms/epoch - 85ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.5366 - accuracy: 0.9762 - val_loss: 1.3967 - val_accuracy: 0.2593 - 329ms/epoch - 82ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.5850 - accuracy: 0.9683 - val_loss: 1.4190 - val_accuracy: 0.2037 - 326ms/epoch - 81ms/step\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.5029 - accuracy: 0.9841 - val_loss: 1.3814 - val_accuracy: 0.2593 - 312ms/epoch - 78ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.5261 - accuracy: 0.9921 - val_loss: 1.3915 - val_accuracy: 0.2593 - 329ms/epoch - 82ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.5043 - accuracy: 0.9921 - val_loss: 1.4044 - val_accuracy: 0.2222 - 337ms/epoch - 84ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.4846 - accuracy: 0.9762 - val_loss: 1.3997 - val_accuracy: 0.2407 - 346ms/epoch - 86ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.4640 - accuracy: 0.9841 - val_loss: 1.3841 - val_accuracy: 0.2593 - 333ms/epoch - 83ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.4320 - accuracy: 0.9921 - val_loss: 1.4085 - val_accuracy: 0.2593 - 338ms/epoch - 85ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.4503 - accuracy: 0.9762 - val_loss: 1.3800 - val_accuracy: 0.2407 - 343ms/epoch - 86ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.4345 - accuracy: 0.9921 - val_loss: 1.4178 - val_accuracy: 0.2037 - 338ms/epoch - 85ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.4331 - accuracy: 1.0000 - val_loss: 1.3938 - val_accuracy: 0.2778 - 325ms/epoch - 81ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.4004 - accuracy: 0.9921 - val_loss: 1.4372 - val_accuracy: 0.2222 - 328ms/epoch - 82ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.4454 - accuracy: 0.9841 - val_loss: 1.3910 - val_accuracy: 0.2963 - 339ms/epoch - 85ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.4196 - accuracy: 1.0000 - val_loss: 1.4026 - val_accuracy: 0.2407 - 335ms/epoch - 84ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.3920 - accuracy: 0.9921 - val_loss: 1.4071 - val_accuracy: 0.2037 - 320ms/epoch - 80ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.3651 - accuracy: 1.0000 - val_loss: 1.4016 - val_accuracy: 0.2222 - 348ms/epoch - 87ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.3976 - accuracy: 0.9841 - val_loss: 1.4197 - val_accuracy: 0.2593 - 334ms/epoch - 83ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.3816 - accuracy: 1.0000 - val_loss: 1.4238 - val_accuracy: 0.1852 - 335ms/epoch - 84ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.3656 - accuracy: 1.0000 - val_loss: 1.4146 - val_accuracy: 0.2222 - 324ms/epoch - 81ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.3401 - accuracy: 1.0000 - val_loss: 1.4095 - val_accuracy: 0.2593 - 323ms/epoch - 81ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.3583 - accuracy: 1.0000 - val_loss: 1.4317 - val_accuracy: 0.2037 - 331ms/epoch - 83ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.3341 - accuracy: 1.0000 - val_loss: 1.4175 - val_accuracy: 0.2407 - 335ms/epoch - 84ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.3615 - accuracy: 0.9921 - val_loss: 1.4379 - val_accuracy: 0.2778 - 322ms/epoch - 81ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.3395 - accuracy: 0.9841 - val_loss: 1.4374 - val_accuracy: 0.2037 - 330ms/epoch - 83ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.3754 - accuracy: 0.9921 - val_loss: 1.4815 - val_accuracy: 0.2407 - 339ms/epoch - 85ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.3907 - accuracy: 0.9921 - val_loss: 1.4271 - val_accuracy: 0.2407 - 322ms/epoch - 81ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.3459 - accuracy: 1.0000 - val_loss: 1.4510 - val_accuracy: 0.2407 - 322ms/epoch - 81ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.3003 - accuracy: 1.0000 - val_loss: 1.3935 - val_accuracy: 0.2778 - 323ms/epoch - 81ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.3247 - accuracy: 1.0000 - val_loss: 1.5122 - val_accuracy: 0.2222 - 331ms/epoch - 83ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.3187 - accuracy: 1.0000 - val_loss: 1.4785 - val_accuracy: 0.2778 - 337ms/epoch - 84ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.2994 - accuracy: 1.0000 - val_loss: 1.4684 - val_accuracy: 0.2222 - 337ms/epoch - 84ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.3198 - accuracy: 0.9921 - val_loss: 1.4756 - val_accuracy: 0.2407 - 333ms/epoch - 83ms/step\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.3053 - accuracy: 1.0000 - val_loss: 1.4835 - val_accuracy: 0.2037 - 326ms/epoch - 82ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.3067 - accuracy: 1.0000 - val_loss: 1.4947 - val_accuracy: 0.2593 - 343ms/epoch - 86ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.2730 - accuracy: 1.0000 - val_loss: 1.4725 - val_accuracy: 0.1852 - 337ms/epoch - 84ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.2780 - accuracy: 1.0000 - val_loss: 1.5368 - val_accuracy: 0.2778 - 357ms/epoch - 89ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.2872 - accuracy: 1.0000 - val_loss: 1.5312 - val_accuracy: 0.2037 - 332ms/epoch - 83ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.2508 - accuracy: 1.0000 - val_loss: 1.5129 - val_accuracy: 0.2593 - 331ms/epoch - 83ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.2857 - accuracy: 0.9921 - val_loss: 1.4897 - val_accuracy: 0.2963 - 330ms/epoch - 83ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.2880 - accuracy: 1.0000 - val_loss: 1.5581 - val_accuracy: 0.2778 - 338ms/epoch - 84ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.2750 - accuracy: 1.0000 - val_loss: 1.5678 - val_accuracy: 0.2407 - 341ms/epoch - 85ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.2586 - accuracy: 1.0000 - val_loss: 1.6003 - val_accuracy: 0.1667 - 323ms/epoch - 81ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.2528 - accuracy: 1.0000 - val_loss: 1.5217 - val_accuracy: 0.2407 - 340ms/epoch - 85ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.2551 - accuracy: 1.0000 - val_loss: 1.5680 - val_accuracy: 0.2407 - 330ms/epoch - 83ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.2451 - accuracy: 1.0000 - val_loss: 1.5911 - val_accuracy: 0.2222 - 324ms/epoch - 81ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.2505 - accuracy: 1.0000 - val_loss: 1.5407 - val_accuracy: 0.2778 - 326ms/epoch - 81ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.2068 - accuracy: 1.0000 - val_loss: 1.6112 - val_accuracy: 0.1852 - 331ms/epoch - 83ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 1.5775 - val_accuracy: 0.2778 - 327ms/epoch - 82ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.2210 - accuracy: 1.0000 - val_loss: 1.6012 - val_accuracy: 0.2037 - 332ms/epoch - 83ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.2334 - accuracy: 0.9921 - val_loss: 1.6237 - val_accuracy: 0.2407 - 339ms/epoch - 85ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.2195 - accuracy: 1.0000 - val_loss: 1.6709 - val_accuracy: 0.2778 - 315ms/epoch - 79ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.2252 - accuracy: 1.0000 - val_loss: 1.6672 - val_accuracy: 0.2222 - 329ms/epoch - 82ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.2227 - accuracy: 1.0000 - val_loss: 1.7031 - val_accuracy: 0.2222 - 332ms/epoch - 83ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.2445 - accuracy: 0.9841 - val_loss: 1.7942 - val_accuracy: 0.1852 - 327ms/epoch - 82ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 1.6928 - val_accuracy: 0.1852 - 327ms/epoch - 82ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 1.6931 - val_accuracy: 0.2037 - 328ms/epoch - 82ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 1.6497 - val_accuracy: 0.2593 - 335ms/epoch - 84ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.2024 - accuracy: 1.0000 - val_loss: 1.6319 - val_accuracy: 0.2222 - 323ms/epoch - 81ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.2060 - accuracy: 1.0000 - val_loss: 1.6939 - val_accuracy: 0.2778 - 329ms/epoch - 82ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.6192 - val_accuracy: 0.2778 - 328ms/epoch - 82ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 1.6535 - val_accuracy: 0.2593 - 335ms/epoch - 84ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1816 - accuracy: 1.0000 - val_loss: 1.7850 - val_accuracy: 0.2407 - 340ms/epoch - 85ms/step\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1901 - accuracy: 1.0000 - val_loss: 1.8434 - val_accuracy: 0.2037 - 325ms/epoch - 81ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.2009 - accuracy: 1.0000 - val_loss: 1.8181 - val_accuracy: 0.2778 - 325ms/epoch - 81ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1862 - accuracy: 1.0000 - val_loss: 1.7750 - val_accuracy: 0.2593 - 323ms/epoch - 81ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1908 - accuracy: 1.0000 - val_loss: 1.8023 - val_accuracy: 0.2222 - 338ms/epoch - 85ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.2050 - accuracy: 1.0000 - val_loss: 1.8226 - val_accuracy: 0.1667 - 330ms/epoch - 83ms/step\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1872 - accuracy: 1.0000 - val_loss: 1.8608 - val_accuracy: 0.1296 - 333ms/epoch - 83ms/step\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1983 - accuracy: 1.0000 - val_loss: 1.7951 - val_accuracy: 0.2407 - 322ms/epoch - 81ms/step\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1932 - accuracy: 1.0000 - val_loss: 1.8890 - val_accuracy: 0.2037 - 326ms/epoch - 81ms/step\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1729 - accuracy: 1.0000 - val_loss: 1.7637 - val_accuracy: 0.2593 - 335ms/epoch - 84ms/step\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1717 - accuracy: 1.0000 - val_loss: 1.8071 - val_accuracy: 0.2407 - 335ms/epoch - 84ms/step\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1829 - accuracy: 1.0000 - val_loss: 1.8213 - val_accuracy: 0.2593 - 336ms/epoch - 84ms/step\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1710 - accuracy: 1.0000 - val_loss: 1.8542 - val_accuracy: 0.1852 - 329ms/epoch - 82ms/step\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1868 - accuracy: 1.0000 - val_loss: 1.8388 - val_accuracy: 0.1852 - 342ms/epoch - 86ms/step\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1947 - accuracy: 1.0000 - val_loss: 1.8965 - val_accuracy: 0.2407 - 327ms/epoch - 82ms/step\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 135: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1759 - accuracy: 1.0000 - val_loss: 1.8447 - val_accuracy: 0.2222 - 322ms/epoch - 80ms/step\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 136: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1615 - accuracy: 1.0000 - val_loss: 1.9710 - val_accuracy: 0.2593 - 339ms/epoch - 85ms/step\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 137: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1549 - accuracy: 1.0000 - val_loss: 1.9071 - val_accuracy: 0.2037 - 338ms/epoch - 84ms/step\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 138: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1613 - accuracy: 1.0000 - val_loss: 1.8794 - val_accuracy: 0.2778 - 333ms/epoch - 83ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/300\n",
      "\n",
      "Epoch 139: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1499 - accuracy: 1.0000 - val_loss: 1.8503 - val_accuracy: 0.2222 - 318ms/epoch - 80ms/step\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 140: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1695 - accuracy: 1.0000 - val_loss: 1.9685 - val_accuracy: 0.2037 - 335ms/epoch - 84ms/step\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 141: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1737 - accuracy: 1.0000 - val_loss: 1.8738 - val_accuracy: 0.2222 - 323ms/epoch - 81ms/step\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 142: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1618 - accuracy: 1.0000 - val_loss: 1.8718 - val_accuracy: 0.2407 - 333ms/epoch - 83ms/step\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 143: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1591 - accuracy: 1.0000 - val_loss: 1.9741 - val_accuracy: 0.2407 - 326ms/epoch - 82ms/step\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 144: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1597 - accuracy: 1.0000 - val_loss: 1.9862 - val_accuracy: 0.2407 - 320ms/epoch - 80ms/step\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 145: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1577 - accuracy: 1.0000 - val_loss: 2.0077 - val_accuracy: 0.2222 - 320ms/epoch - 80ms/step\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 146: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1470 - accuracy: 1.0000 - val_loss: 1.9880 - val_accuracy: 0.2222 - 335ms/epoch - 84ms/step\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 147: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1585 - accuracy: 1.0000 - val_loss: 2.0181 - val_accuracy: 0.2407 - 347ms/epoch - 87ms/step\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 148: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1523 - accuracy: 1.0000 - val_loss: 1.9779 - val_accuracy: 0.2222 - 325ms/epoch - 81ms/step\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 149: val_loss did not improve from 1.37296\n",
      "4/4 - 1s - loss: 0.1571 - accuracy: 1.0000 - val_loss: 1.9642 - val_accuracy: 0.2222 - 669ms/epoch - 167ms/step\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 150: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1385 - accuracy: 1.0000 - val_loss: 1.8733 - val_accuracy: 0.2037 - 342ms/epoch - 85ms/step\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 151: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1556 - accuracy: 1.0000 - val_loss: 1.9031 - val_accuracy: 0.2222 - 343ms/epoch - 86ms/step\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 152: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1473 - accuracy: 1.0000 - val_loss: 1.9447 - val_accuracy: 0.2222 - 333ms/epoch - 83ms/step\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 153: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1495 - accuracy: 1.0000 - val_loss: 1.8983 - val_accuracy: 0.1667 - 342ms/epoch - 85ms/step\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 154: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1531 - accuracy: 1.0000 - val_loss: 1.9191 - val_accuracy: 0.2222 - 339ms/epoch - 85ms/step\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 155: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1516 - accuracy: 1.0000 - val_loss: 1.9337 - val_accuracy: 0.2037 - 341ms/epoch - 85ms/step\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 156: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1742 - accuracy: 1.0000 - val_loss: 2.1802 - val_accuracy: 0.2037 - 337ms/epoch - 84ms/step\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 157: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1546 - accuracy: 1.0000 - val_loss: 2.1693 - val_accuracy: 0.2407 - 343ms/epoch - 86ms/step\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 158: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1469 - accuracy: 1.0000 - val_loss: 2.1310 - val_accuracy: 0.1852 - 347ms/epoch - 87ms/step\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 159: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1448 - accuracy: 1.0000 - val_loss: 1.9974 - val_accuracy: 0.2222 - 344ms/epoch - 86ms/step\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 160: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1434 - accuracy: 1.0000 - val_loss: 1.9941 - val_accuracy: 0.2407 - 345ms/epoch - 86ms/step\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 161: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1391 - accuracy: 1.0000 - val_loss: 1.9959 - val_accuracy: 0.2778 - 354ms/epoch - 88ms/step\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 162: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1343 - accuracy: 1.0000 - val_loss: 2.0212 - val_accuracy: 0.1852 - 330ms/epoch - 82ms/step\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 163: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1067 - accuracy: 1.0000 - val_loss: 2.0638 - val_accuracy: 0.1852 - 351ms/epoch - 88ms/step\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 164: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1225 - accuracy: 1.0000 - val_loss: 1.9765 - val_accuracy: 0.2778 - 340ms/epoch - 85ms/step\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 165: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1261 - accuracy: 1.0000 - val_loss: 1.9816 - val_accuracy: 0.2407 - 353ms/epoch - 88ms/step\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 166: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1202 - accuracy: 1.0000 - val_loss: 1.9736 - val_accuracy: 0.2407 - 355ms/epoch - 89ms/step\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 167: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1087 - accuracy: 1.0000 - val_loss: 2.0040 - val_accuracy: 0.2593 - 333ms/epoch - 83ms/step\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 168: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1188 - accuracy: 1.0000 - val_loss: 1.9902 - val_accuracy: 0.2222 - 328ms/epoch - 82ms/step\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 169: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1265 - accuracy: 1.0000 - val_loss: 1.9972 - val_accuracy: 0.2407 - 352ms/epoch - 88ms/step\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 170: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1153 - accuracy: 1.0000 - val_loss: 1.8964 - val_accuracy: 0.2407 - 331ms/epoch - 83ms/step\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 171: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1190 - accuracy: 1.0000 - val_loss: 1.9436 - val_accuracy: 0.2222 - 357ms/epoch - 89ms/step\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 172: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1174 - accuracy: 1.0000 - val_loss: 1.9265 - val_accuracy: 0.2778 - 333ms/epoch - 83ms/step\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 173: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1247 - accuracy: 1.0000 - val_loss: 1.9852 - val_accuracy: 0.2593 - 334ms/epoch - 84ms/step\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 174: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1269 - accuracy: 1.0000 - val_loss: 1.9652 - val_accuracy: 0.2593 - 362ms/epoch - 91ms/step\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 175: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1106 - accuracy: 1.0000 - val_loss: 2.0684 - val_accuracy: 0.2222 - 340ms/epoch - 85ms/step\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 176: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1170 - accuracy: 1.0000 - val_loss: 2.0810 - val_accuracy: 0.2222 - 340ms/epoch - 85ms/step\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 177: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1102 - accuracy: 1.0000 - val_loss: 1.9883 - val_accuracy: 0.2407 - 335ms/epoch - 84ms/step\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 178: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1001 - accuracy: 1.0000 - val_loss: 1.9326 - val_accuracy: 0.2407 - 341ms/epoch - 85ms/step\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 179: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1109 - accuracy: 1.0000 - val_loss: 1.9786 - val_accuracy: 0.2222 - 342ms/epoch - 85ms/step\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 180: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1095 - accuracy: 1.0000 - val_loss: 1.9368 - val_accuracy: 0.2407 - 368ms/epoch - 92ms/step\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 181: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1008 - accuracy: 1.0000 - val_loss: 1.9647 - val_accuracy: 0.2407 - 338ms/epoch - 85ms/step\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 182: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1078 - accuracy: 1.0000 - val_loss: 1.9835 - val_accuracy: 0.2407 - 336ms/epoch - 84ms/step\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 183: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1059 - accuracy: 1.0000 - val_loss: 2.0029 - val_accuracy: 0.2407 - 340ms/epoch - 85ms/step\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 184: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1055 - accuracy: 1.0000 - val_loss: 2.0572 - val_accuracy: 0.2037 - 353ms/epoch - 88ms/step\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 185: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0980 - accuracy: 1.0000 - val_loss: 2.1166 - val_accuracy: 0.1852 - 337ms/epoch - 84ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186/300\n",
      "\n",
      "Epoch 186: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1015 - accuracy: 1.0000 - val_loss: 2.0894 - val_accuracy: 0.2222 - 333ms/epoch - 83ms/step\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 187: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0981 - accuracy: 1.0000 - val_loss: 2.1176 - val_accuracy: 0.2222 - 333ms/epoch - 83ms/step\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 188: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1125 - accuracy: 1.0000 - val_loss: 2.0701 - val_accuracy: 0.2778 - 350ms/epoch - 88ms/step\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 189: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1019 - accuracy: 1.0000 - val_loss: 2.0990 - val_accuracy: 0.2222 - 335ms/epoch - 84ms/step\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 190: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1165 - accuracy: 1.0000 - val_loss: 1.8866 - val_accuracy: 0.2407 - 340ms/epoch - 85ms/step\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 191: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0978 - accuracy: 1.0000 - val_loss: 1.9041 - val_accuracy: 0.2222 - 336ms/epoch - 84ms/step\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 192: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0958 - accuracy: 1.0000 - val_loss: 2.1051 - val_accuracy: 0.2037 - 346ms/epoch - 87ms/step\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 193: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0934 - accuracy: 1.0000 - val_loss: 2.2289 - val_accuracy: 0.2037 - 341ms/epoch - 85ms/step\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 194: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1050 - accuracy: 1.0000 - val_loss: 2.0580 - val_accuracy: 0.2778 - 344ms/epoch - 86ms/step\n",
      "Epoch 195/300\n",
      "\n",
      "Epoch 195: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0905 - accuracy: 1.0000 - val_loss: 2.0575 - val_accuracy: 0.2778 - 346ms/epoch - 87ms/step\n",
      "Epoch 196/300\n",
      "\n",
      "Epoch 196: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0990 - accuracy: 1.0000 - val_loss: 2.1387 - val_accuracy: 0.2407 - 340ms/epoch - 85ms/step\n",
      "Epoch 197/300\n",
      "\n",
      "Epoch 197: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1033 - accuracy: 1.0000 - val_loss: 2.2056 - val_accuracy: 0.2037 - 338ms/epoch - 85ms/step\n",
      "Epoch 198/300\n",
      "\n",
      "Epoch 198: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1030 - accuracy: 1.0000 - val_loss: 2.2183 - val_accuracy: 0.1667 - 344ms/epoch - 86ms/step\n",
      "Epoch 199/300\n",
      "\n",
      "Epoch 199: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0959 - accuracy: 1.0000 - val_loss: 2.1232 - val_accuracy: 0.2037 - 342ms/epoch - 86ms/step\n",
      "Epoch 200/300\n",
      "\n",
      "Epoch 200: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0932 - accuracy: 1.0000 - val_loss: 2.0747 - val_accuracy: 0.1481 - 346ms/epoch - 86ms/step\n",
      "Epoch 201/300\n",
      "\n",
      "Epoch 201: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0940 - accuracy: 1.0000 - val_loss: 2.0992 - val_accuracy: 0.2037 - 337ms/epoch - 84ms/step\n",
      "Epoch 202/300\n",
      "\n",
      "Epoch 202: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0928 - accuracy: 1.0000 - val_loss: 2.1602 - val_accuracy: 0.2222 - 351ms/epoch - 88ms/step\n",
      "Epoch 203/300\n",
      "\n",
      "Epoch 203: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0959 - accuracy: 1.0000 - val_loss: 2.0867 - val_accuracy: 0.2037 - 338ms/epoch - 84ms/step\n",
      "Epoch 204/300\n",
      "\n",
      "Epoch 204: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0981 - accuracy: 1.0000 - val_loss: 2.0539 - val_accuracy: 0.1481 - 348ms/epoch - 87ms/step\n",
      "Epoch 205/300\n",
      "\n",
      "Epoch 205: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0910 - accuracy: 1.0000 - val_loss: 2.0698 - val_accuracy: 0.2222 - 342ms/epoch - 86ms/step\n",
      "Epoch 206/300\n",
      "\n",
      "Epoch 206: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0879 - accuracy: 1.0000 - val_loss: 2.0370 - val_accuracy: 0.1667 - 340ms/epoch - 85ms/step\n",
      "Epoch 207/300\n",
      "\n",
      "Epoch 207: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0951 - accuracy: 1.0000 - val_loss: 2.0254 - val_accuracy: 0.2222 - 333ms/epoch - 83ms/step\n",
      "Epoch 208/300\n",
      "\n",
      "Epoch 208: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0959 - accuracy: 1.0000 - val_loss: 2.1159 - val_accuracy: 0.2407 - 344ms/epoch - 86ms/step\n",
      "Epoch 209/300\n",
      "\n",
      "Epoch 209: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.1009 - accuracy: 1.0000 - val_loss: 2.1559 - val_accuracy: 0.1852 - 335ms/epoch - 84ms/step\n",
      "Epoch 210/300\n",
      "\n",
      "Epoch 210: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0984 - accuracy: 1.0000 - val_loss: 2.1170 - val_accuracy: 0.2222 - 334ms/epoch - 84ms/step\n",
      "Epoch 211/300\n",
      "\n",
      "Epoch 211: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0900 - accuracy: 1.0000 - val_loss: 2.1810 - val_accuracy: 0.2407 - 348ms/epoch - 87ms/step\n",
      "Epoch 212/300\n",
      "\n",
      "Epoch 212: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0855 - accuracy: 1.0000 - val_loss: 2.1644 - val_accuracy: 0.1852 - 343ms/epoch - 86ms/step\n",
      "Epoch 213/300\n",
      "\n",
      "Epoch 213: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0767 - accuracy: 1.0000 - val_loss: 2.2160 - val_accuracy: 0.2037 - 340ms/epoch - 85ms/step\n",
      "Epoch 214/300\n",
      "\n",
      "Epoch 214: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0784 - accuracy: 1.0000 - val_loss: 2.1755 - val_accuracy: 0.2037 - 341ms/epoch - 85ms/step\n",
      "Epoch 215/300\n",
      "\n",
      "Epoch 215: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0824 - accuracy: 1.0000 - val_loss: 2.0929 - val_accuracy: 0.1852 - 335ms/epoch - 84ms/step\n",
      "Epoch 216/300\n",
      "\n",
      "Epoch 216: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0756 - accuracy: 1.0000 - val_loss: 2.1579 - val_accuracy: 0.1852 - 331ms/epoch - 83ms/step\n",
      "Epoch 217/300\n",
      "\n",
      "Epoch 217: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0823 - accuracy: 1.0000 - val_loss: 2.0892 - val_accuracy: 0.2593 - 339ms/epoch - 85ms/step\n",
      "Epoch 218/300\n",
      "\n",
      "Epoch 218: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0809 - accuracy: 1.0000 - val_loss: 2.1018 - val_accuracy: 0.2222 - 355ms/epoch - 89ms/step\n",
      "Epoch 219/300\n",
      "\n",
      "Epoch 219: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0719 - accuracy: 1.0000 - val_loss: 2.0827 - val_accuracy: 0.1852 - 331ms/epoch - 83ms/step\n",
      "Epoch 220/300\n",
      "\n",
      "Epoch 220: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0775 - accuracy: 1.0000 - val_loss: 2.1286 - val_accuracy: 0.2037 - 355ms/epoch - 89ms/step\n",
      "Epoch 221/300\n",
      "\n",
      "Epoch 221: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0819 - accuracy: 1.0000 - val_loss: 2.0863 - val_accuracy: 0.2407 - 332ms/epoch - 83ms/step\n",
      "Epoch 222/300\n",
      "\n",
      "Epoch 222: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0741 - accuracy: 1.0000 - val_loss: 2.0304 - val_accuracy: 0.2222 - 335ms/epoch - 84ms/step\n",
      "Epoch 223/300\n",
      "\n",
      "Epoch 223: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0695 - accuracy: 1.0000 - val_loss: 2.0200 - val_accuracy: 0.2593 - 342ms/epoch - 85ms/step\n",
      "Epoch 224/300\n",
      "\n",
      "Epoch 224: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0770 - accuracy: 1.0000 - val_loss: 2.0615 - val_accuracy: 0.2407 - 329ms/epoch - 82ms/step\n",
      "Epoch 225/300\n",
      "\n",
      "Epoch 225: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0732 - accuracy: 1.0000 - val_loss: 2.0210 - val_accuracy: 0.2778 - 351ms/epoch - 88ms/step\n",
      "Epoch 226/300\n",
      "\n",
      "Epoch 226: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0693 - accuracy: 1.0000 - val_loss: 1.9929 - val_accuracy: 0.2778 - 371ms/epoch - 93ms/step\n",
      "Epoch 227/300\n",
      "\n",
      "Epoch 227: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0844 - accuracy: 1.0000 - val_loss: 2.0586 - val_accuracy: 0.2593 - 343ms/epoch - 86ms/step\n",
      "Epoch 228/300\n",
      "\n",
      "Epoch 228: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0813 - accuracy: 1.0000 - val_loss: 2.1960 - val_accuracy: 0.2222 - 337ms/epoch - 84ms/step\n",
      "Epoch 229/300\n",
      "\n",
      "Epoch 229: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0712 - accuracy: 1.0000 - val_loss: 2.2216 - val_accuracy: 0.2407 - 357ms/epoch - 89ms/step\n",
      "Epoch 230/300\n",
      "\n",
      "Epoch 230: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0760 - accuracy: 1.0000 - val_loss: 2.1485 - val_accuracy: 0.2037 - 341ms/epoch - 85ms/step\n",
      "Epoch 231/300\n",
      "\n",
      "Epoch 231: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0726 - accuracy: 1.0000 - val_loss: 2.1103 - val_accuracy: 0.2407 - 341ms/epoch - 85ms/step\n",
      "Epoch 232/300\n",
      "\n",
      "Epoch 232: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0774 - accuracy: 1.0000 - val_loss: 2.1368 - val_accuracy: 0.2778 - 342ms/epoch - 85ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/300\n",
      "\n",
      "Epoch 233: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0841 - accuracy: 1.0000 - val_loss: 2.1606 - val_accuracy: 0.2222 - 336ms/epoch - 84ms/step\n",
      "Epoch 234/300\n",
      "\n",
      "Epoch 234: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0781 - accuracy: 1.0000 - val_loss: 2.2334 - val_accuracy: 0.2593 - 344ms/epoch - 86ms/step\n",
      "Epoch 235/300\n",
      "\n",
      "Epoch 235: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0773 - accuracy: 1.0000 - val_loss: 2.2010 - val_accuracy: 0.2222 - 344ms/epoch - 86ms/step\n",
      "Epoch 236/300\n",
      "\n",
      "Epoch 236: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0847 - accuracy: 1.0000 - val_loss: 2.1634 - val_accuracy: 0.2593 - 343ms/epoch - 86ms/step\n",
      "Epoch 237/300\n",
      "\n",
      "Epoch 237: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0698 - accuracy: 1.0000 - val_loss: 2.1893 - val_accuracy: 0.2222 - 340ms/epoch - 85ms/step\n",
      "Epoch 238/300\n",
      "\n",
      "Epoch 238: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0675 - accuracy: 1.0000 - val_loss: 2.0714 - val_accuracy: 0.2593 - 353ms/epoch - 88ms/step\n",
      "Epoch 239/300\n",
      "\n",
      "Epoch 239: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0664 - accuracy: 1.0000 - val_loss: 2.0569 - val_accuracy: 0.2778 - 341ms/epoch - 85ms/step\n",
      "Epoch 240/300\n",
      "\n",
      "Epoch 240: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0768 - accuracy: 1.0000 - val_loss: 2.0622 - val_accuracy: 0.2037 - 356ms/epoch - 89ms/step\n",
      "Epoch 241/300\n",
      "\n",
      "Epoch 241: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0759 - accuracy: 1.0000 - val_loss: 2.1083 - val_accuracy: 0.2222 - 352ms/epoch - 88ms/step\n",
      "Epoch 242/300\n",
      "\n",
      "Epoch 242: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0613 - accuracy: 1.0000 - val_loss: 2.1046 - val_accuracy: 0.2407 - 340ms/epoch - 85ms/step\n",
      "Epoch 243/300\n",
      "\n",
      "Epoch 243: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0783 - accuracy: 1.0000 - val_loss: 2.1044 - val_accuracy: 0.2593 - 336ms/epoch - 84ms/step\n",
      "Epoch 244/300\n",
      "\n",
      "Epoch 244: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0683 - accuracy: 1.0000 - val_loss: 2.0072 - val_accuracy: 0.2778 - 343ms/epoch - 86ms/step\n",
      "Epoch 245/300\n",
      "\n",
      "Epoch 245: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0644 - accuracy: 1.0000 - val_loss: 2.0856 - val_accuracy: 0.2222 - 344ms/epoch - 86ms/step\n",
      "Epoch 246/300\n",
      "\n",
      "Epoch 246: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0666 - accuracy: 1.0000 - val_loss: 2.0109 - val_accuracy: 0.2593 - 337ms/epoch - 84ms/step\n",
      "Epoch 247/300\n",
      "\n",
      "Epoch 247: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0721 - accuracy: 1.0000 - val_loss: 2.0074 - val_accuracy: 0.2222 - 331ms/epoch - 83ms/step\n",
      "Epoch 248/300\n",
      "\n",
      "Epoch 248: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0758 - accuracy: 1.0000 - val_loss: 2.0379 - val_accuracy: 0.2593 - 339ms/epoch - 85ms/step\n",
      "Epoch 249/300\n",
      "\n",
      "Epoch 249: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0651 - accuracy: 1.0000 - val_loss: 2.0502 - val_accuracy: 0.2037 - 345ms/epoch - 86ms/step\n",
      "Epoch 250/300\n",
      "\n",
      "Epoch 250: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0679 - accuracy: 1.0000 - val_loss: 2.1638 - val_accuracy: 0.1852 - 348ms/epoch - 87ms/step\n",
      "Epoch 251/300\n",
      "\n",
      "Epoch 251: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0714 - accuracy: 1.0000 - val_loss: 2.1918 - val_accuracy: 0.1852 - 344ms/epoch - 86ms/step\n",
      "Epoch 252/300\n",
      "\n",
      "Epoch 252: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0619 - accuracy: 1.0000 - val_loss: 2.1080 - val_accuracy: 0.2222 - 336ms/epoch - 84ms/step\n",
      "Epoch 253/300\n",
      "\n",
      "Epoch 253: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0609 - accuracy: 1.0000 - val_loss: 2.0650 - val_accuracy: 0.2407 - 357ms/epoch - 89ms/step\n",
      "Epoch 254/300\n",
      "\n",
      "Epoch 254: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0729 - accuracy: 1.0000 - val_loss: 2.0609 - val_accuracy: 0.2778 - 346ms/epoch - 87ms/step\n",
      "Epoch 255/300\n",
      "\n",
      "Epoch 255: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0752 - accuracy: 1.0000 - val_loss: 2.0391 - val_accuracy: 0.1852 - 328ms/epoch - 82ms/step\n",
      "Epoch 256/300\n",
      "\n",
      "Epoch 256: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0664 - accuracy: 1.0000 - val_loss: 2.0864 - val_accuracy: 0.2222 - 335ms/epoch - 84ms/step\n",
      "Epoch 257/300\n",
      "\n",
      "Epoch 257: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0663 - accuracy: 1.0000 - val_loss: 2.1299 - val_accuracy: 0.2222 - 331ms/epoch - 83ms/step\n",
      "Epoch 258/300\n",
      "\n",
      "Epoch 258: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0649 - accuracy: 1.0000 - val_loss: 2.1876 - val_accuracy: 0.2407 - 345ms/epoch - 86ms/step\n",
      "Epoch 259/300\n",
      "\n",
      "Epoch 259: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0695 - accuracy: 1.0000 - val_loss: 2.2349 - val_accuracy: 0.2222 - 335ms/epoch - 84ms/step\n",
      "Epoch 260/300\n",
      "\n",
      "Epoch 260: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0650 - accuracy: 1.0000 - val_loss: 2.1597 - val_accuracy: 0.1852 - 338ms/epoch - 84ms/step\n",
      "Epoch 261/300\n",
      "\n",
      "Epoch 261: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0684 - accuracy: 1.0000 - val_loss: 2.1214 - val_accuracy: 0.2407 - 336ms/epoch - 84ms/step\n",
      "Epoch 262/300\n",
      "\n",
      "Epoch 262: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0619 - accuracy: 1.0000 - val_loss: 2.1478 - val_accuracy: 0.2593 - 343ms/epoch - 86ms/step\n",
      "Epoch 263/300\n",
      "\n",
      "Epoch 263: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0725 - accuracy: 1.0000 - val_loss: 2.1557 - val_accuracy: 0.1481 - 332ms/epoch - 83ms/step\n",
      "Epoch 264/300\n",
      "\n",
      "Epoch 264: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0662 - accuracy: 1.0000 - val_loss: 2.1368 - val_accuracy: 0.2037 - 346ms/epoch - 86ms/step\n",
      "Epoch 265/300\n",
      "\n",
      "Epoch 265: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0653 - accuracy: 1.0000 - val_loss: 2.0327 - val_accuracy: 0.2222 - 358ms/epoch - 89ms/step\n",
      "Epoch 266/300\n",
      "\n",
      "Epoch 266: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0591 - accuracy: 1.0000 - val_loss: 2.0446 - val_accuracy: 0.2222 - 341ms/epoch - 85ms/step\n",
      "Epoch 267/300\n",
      "\n",
      "Epoch 267: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0661 - accuracy: 1.0000 - val_loss: 2.1184 - val_accuracy: 0.1481 - 335ms/epoch - 84ms/step\n",
      "Epoch 268/300\n",
      "\n",
      "Epoch 268: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0643 - accuracy: 1.0000 - val_loss: 2.2665 - val_accuracy: 0.2037 - 338ms/epoch - 85ms/step\n",
      "Epoch 269/300\n",
      "\n",
      "Epoch 269: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0559 - accuracy: 1.0000 - val_loss: 2.4006 - val_accuracy: 0.2407 - 337ms/epoch - 84ms/step\n",
      "Epoch 270/300\n",
      "\n",
      "Epoch 270: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0591 - accuracy: 1.0000 - val_loss: 2.5738 - val_accuracy: 0.2407 - 333ms/epoch - 83ms/step\n",
      "Epoch 271/300\n",
      "\n",
      "Epoch 271: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0666 - accuracy: 1.0000 - val_loss: 2.3665 - val_accuracy: 0.2222 - 345ms/epoch - 86ms/step\n",
      "Epoch 272/300\n",
      "\n",
      "Epoch 272: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0664 - accuracy: 1.0000 - val_loss: 2.2304 - val_accuracy: 0.1667 - 331ms/epoch - 83ms/step\n",
      "Epoch 273/300\n",
      "\n",
      "Epoch 273: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0573 - accuracy: 1.0000 - val_loss: 2.1576 - val_accuracy: 0.2222 - 340ms/epoch - 85ms/step\n",
      "Epoch 274/300\n",
      "\n",
      "Epoch 274: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0576 - accuracy: 1.0000 - val_loss: 2.2131 - val_accuracy: 0.2037 - 357ms/epoch - 89ms/step\n",
      "Epoch 275/300\n",
      "\n",
      "Epoch 275: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0637 - accuracy: 1.0000 - val_loss: 2.1896 - val_accuracy: 0.1852 - 342ms/epoch - 86ms/step\n",
      "Epoch 276/300\n",
      "\n",
      "Epoch 276: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0581 - accuracy: 1.0000 - val_loss: 2.1950 - val_accuracy: 0.2222 - 341ms/epoch - 85ms/step\n",
      "Epoch 277/300\n",
      "\n",
      "Epoch 277: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0602 - accuracy: 1.0000 - val_loss: 2.2958 - val_accuracy: 0.2037 - 336ms/epoch - 84ms/step\n",
      "Epoch 278/300\n",
      "\n",
      "Epoch 278: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0561 - accuracy: 1.0000 - val_loss: 2.2994 - val_accuracy: 0.2222 - 335ms/epoch - 84ms/step\n",
      "Epoch 279/300\n",
      "\n",
      "Epoch 279: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0750 - accuracy: 1.0000 - val_loss: 2.2854 - val_accuracy: 0.2222 - 340ms/epoch - 85ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280/300\n",
      "\n",
      "Epoch 280: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0597 - accuracy: 1.0000 - val_loss: 2.2740 - val_accuracy: 0.2037 - 337ms/epoch - 84ms/step\n",
      "Epoch 281/300\n",
      "\n",
      "Epoch 281: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0611 - accuracy: 1.0000 - val_loss: 2.1607 - val_accuracy: 0.2037 - 334ms/epoch - 83ms/step\n",
      "Epoch 282/300\n",
      "\n",
      "Epoch 282: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0601 - accuracy: 1.0000 - val_loss: 2.2125 - val_accuracy: 0.2407 - 337ms/epoch - 84ms/step\n",
      "Epoch 283/300\n",
      "\n",
      "Epoch 283: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0604 - accuracy: 1.0000 - val_loss: 2.1969 - val_accuracy: 0.2037 - 342ms/epoch - 86ms/step\n",
      "Epoch 284/300\n",
      "\n",
      "Epoch 284: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0601 - accuracy: 1.0000 - val_loss: 2.3361 - val_accuracy: 0.1667 - 338ms/epoch - 84ms/step\n",
      "Epoch 285/300\n",
      "\n",
      "Epoch 285: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0627 - accuracy: 1.0000 - val_loss: 2.4171 - val_accuracy: 0.2222 - 343ms/epoch - 86ms/step\n",
      "Epoch 286/300\n",
      "\n",
      "Epoch 286: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0667 - accuracy: 1.0000 - val_loss: 2.5559 - val_accuracy: 0.2222 - 351ms/epoch - 88ms/step\n",
      "Epoch 287/300\n",
      "\n",
      "Epoch 287: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0605 - accuracy: 1.0000 - val_loss: 2.4311 - val_accuracy: 0.2222 - 337ms/epoch - 84ms/step\n",
      "Epoch 288/300\n",
      "\n",
      "Epoch 288: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0551 - accuracy: 1.0000 - val_loss: 2.3611 - val_accuracy: 0.2222 - 332ms/epoch - 83ms/step\n",
      "Epoch 289/300\n",
      "\n",
      "Epoch 289: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0586 - accuracy: 1.0000 - val_loss: 2.3173 - val_accuracy: 0.2222 - 334ms/epoch - 83ms/step\n",
      "Epoch 290/300\n",
      "\n",
      "Epoch 290: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0556 - accuracy: 1.0000 - val_loss: 2.2907 - val_accuracy: 0.2037 - 344ms/epoch - 86ms/step\n",
      "Epoch 291/300\n",
      "\n",
      "Epoch 291: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0537 - accuracy: 1.0000 - val_loss: 2.2162 - val_accuracy: 0.2407 - 330ms/epoch - 82ms/step\n",
      "Epoch 292/300\n",
      "\n",
      "Epoch 292: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0617 - accuracy: 1.0000 - val_loss: 2.2081 - val_accuracy: 0.1667 - 355ms/epoch - 89ms/step\n",
      "Epoch 293/300\n",
      "\n",
      "Epoch 293: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0616 - accuracy: 1.0000 - val_loss: 2.1305 - val_accuracy: 0.2407 - 351ms/epoch - 88ms/step\n",
      "Epoch 294/300\n",
      "\n",
      "Epoch 294: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0549 - accuracy: 1.0000 - val_loss: 2.2461 - val_accuracy: 0.2222 - 350ms/epoch - 88ms/step\n",
      "Epoch 295/300\n",
      "\n",
      "Epoch 295: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0513 - accuracy: 1.0000 - val_loss: 2.2576 - val_accuracy: 0.2222 - 330ms/epoch - 82ms/step\n",
      "Epoch 296/300\n",
      "\n",
      "Epoch 296: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0485 - accuracy: 1.0000 - val_loss: 2.1608 - val_accuracy: 0.2037 - 343ms/epoch - 86ms/step\n",
      "Epoch 297/300\n",
      "\n",
      "Epoch 297: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0583 - accuracy: 1.0000 - val_loss: 2.2522 - val_accuracy: 0.2037 - 336ms/epoch - 84ms/step\n",
      "Epoch 298/300\n",
      "\n",
      "Epoch 298: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0530 - accuracy: 1.0000 - val_loss: 2.3120 - val_accuracy: 0.2778 - 346ms/epoch - 87ms/step\n",
      "Epoch 299/300\n",
      "\n",
      "Epoch 299: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0510 - accuracy: 1.0000 - val_loss: 2.2903 - val_accuracy: 0.2222 - 331ms/epoch - 83ms/step\n",
      "Epoch 300/300\n",
      "\n",
      "Epoch 300: val_loss did not improve from 1.37296\n",
      "4/4 - 0s - loss: 0.0532 - accuracy: 1.0000 - val_loss: 2.3675 - val_accuracy: 0.2222 - 335ms/epoch - 84ms/step\n",
      "2/2 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2022-11-11 09:51:05.981795: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_9909566\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:650866\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 09:51:10.030346: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_9912636\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025FlatMapDataset:650908\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.38639, saving model to checkpoint1.h5\n",
      "4/4 - 5s - loss: 1.4354 - accuracy: 0.2381 - val_loss: 1.3864 - val_accuracy: 0.2037 - 5s/epoch - 1s/step\n",
      "Epoch 2/300\n",
      "\n",
      "Epoch 2: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 1.3185 - accuracy: 0.3730 - val_loss: 1.3865 - val_accuracy: 0.2222 - 336ms/epoch - 84ms/step\n",
      "Epoch 3/300\n",
      "\n",
      "Epoch 3: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 1.2867 - accuracy: 0.4048 - val_loss: 1.3866 - val_accuracy: 0.2222 - 320ms/epoch - 80ms/step\n",
      "Epoch 4/300\n",
      "\n",
      "Epoch 4: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 1.2737 - accuracy: 0.4048 - val_loss: 1.3868 - val_accuracy: 0.2222 - 337ms/epoch - 84ms/step\n",
      "Epoch 5/300\n",
      "\n",
      "Epoch 5: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 1.2189 - accuracy: 0.4762 - val_loss: 1.3869 - val_accuracy: 0.2222 - 336ms/epoch - 84ms/step\n",
      "Epoch 6/300\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 1.2006 - accuracy: 0.5476 - val_loss: 1.3871 - val_accuracy: 0.2222 - 338ms/epoch - 84ms/step\n",
      "Epoch 7/300\n",
      "\n",
      "Epoch 7: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 1.1693 - accuracy: 0.5714 - val_loss: 1.3872 - val_accuracy: 0.2222 - 345ms/epoch - 86ms/step\n",
      "Epoch 8/300\n",
      "\n",
      "Epoch 8: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 1.1634 - accuracy: 0.5794 - val_loss: 1.3873 - val_accuracy: 0.1667 - 326ms/epoch - 82ms/step\n",
      "Epoch 9/300\n",
      "\n",
      "Epoch 9: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 1.1313 - accuracy: 0.6032 - val_loss: 1.3874 - val_accuracy: 0.2037 - 326ms/epoch - 81ms/step\n",
      "Epoch 10/300\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 1.1347 - accuracy: 0.6270 - val_loss: 1.3875 - val_accuracy: 0.2037 - 342ms/epoch - 85ms/step\n",
      "Epoch 11/300\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 1.1080 - accuracy: 0.6587 - val_loss: 1.3877 - val_accuracy: 0.2037 - 334ms/epoch - 84ms/step\n",
      "Epoch 12/300\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 1.0618 - accuracy: 0.6905 - val_loss: 1.3878 - val_accuracy: 0.1852 - 346ms/epoch - 86ms/step\n",
      "Epoch 13/300\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 1.0568 - accuracy: 0.6270 - val_loss: 1.3881 - val_accuracy: 0.2222 - 332ms/epoch - 83ms/step\n",
      "Epoch 14/300\n",
      "\n",
      "Epoch 14: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 1.0213 - accuracy: 0.7143 - val_loss: 1.3883 - val_accuracy: 0.2222 - 320ms/epoch - 80ms/step\n",
      "Epoch 15/300\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.9996 - accuracy: 0.7540 - val_loss: 1.3882 - val_accuracy: 0.1667 - 326ms/epoch - 81ms/step\n",
      "Epoch 16/300\n",
      "\n",
      "Epoch 16: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.9966 - accuracy: 0.6825 - val_loss: 1.3887 - val_accuracy: 0.1667 - 338ms/epoch - 84ms/step\n",
      "Epoch 17/300\n",
      "\n",
      "Epoch 17: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.9719 - accuracy: 0.7063 - val_loss: 1.3892 - val_accuracy: 0.1852 - 336ms/epoch - 84ms/step\n",
      "Epoch 18/300\n",
      "\n",
      "Epoch 18: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.9750 - accuracy: 0.7222 - val_loss: 1.3895 - val_accuracy: 0.2222 - 332ms/epoch - 83ms/step\n",
      "Epoch 19/300\n",
      "\n",
      "Epoch 19: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.9367 - accuracy: 0.7698 - val_loss: 1.3892 - val_accuracy: 0.2407 - 322ms/epoch - 80ms/step\n",
      "Epoch 20/300\n",
      "\n",
      "Epoch 20: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.9223 - accuracy: 0.7778 - val_loss: 1.3900 - val_accuracy: 0.2593 - 343ms/epoch - 86ms/step\n",
      "Epoch 21/300\n",
      "\n",
      "Epoch 21: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.9245 - accuracy: 0.7143 - val_loss: 1.3904 - val_accuracy: 0.2593 - 330ms/epoch - 82ms/step\n",
      "Epoch 22/300\n",
      "\n",
      "Epoch 22: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.8897 - accuracy: 0.7937 - val_loss: 1.3898 - val_accuracy: 0.2222 - 326ms/epoch - 82ms/step\n",
      "Epoch 23/300\n",
      "\n",
      "Epoch 23: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.8867 - accuracy: 0.8254 - val_loss: 1.3909 - val_accuracy: 0.2593 - 356ms/epoch - 89ms/step\n",
      "Epoch 24/300\n",
      "\n",
      "Epoch 24: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.8801 - accuracy: 0.8016 - val_loss: 1.3916 - val_accuracy: 0.2593 - 338ms/epoch - 84ms/step\n",
      "Epoch 25/300\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.8536 - accuracy: 0.8175 - val_loss: 1.3916 - val_accuracy: 0.2037 - 324ms/epoch - 81ms/step\n",
      "Epoch 26/300\n",
      "\n",
      "Epoch 26: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.8443 - accuracy: 0.8016 - val_loss: 1.3916 - val_accuracy: 0.2593 - 327ms/epoch - 82ms/step\n",
      "Epoch 27/300\n",
      "\n",
      "Epoch 27: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.8384 - accuracy: 0.8413 - val_loss: 1.3927 - val_accuracy: 0.1852 - 336ms/epoch - 84ms/step\n",
      "Epoch 28/300\n",
      "\n",
      "Epoch 28: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.7801 - accuracy: 0.8651 - val_loss: 1.3934 - val_accuracy: 0.2593 - 328ms/epoch - 82ms/step\n",
      "Epoch 29/300\n",
      "\n",
      "Epoch 29: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.8038 - accuracy: 0.8810 - val_loss: 1.3931 - val_accuracy: 0.2593 - 329ms/epoch - 82ms/step\n",
      "Epoch 30/300\n",
      "\n",
      "Epoch 30: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.7829 - accuracy: 0.8810 - val_loss: 1.3926 - val_accuracy: 0.2593 - 328ms/epoch - 82ms/step\n",
      "Epoch 31/300\n",
      "\n",
      "Epoch 31: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.7662 - accuracy: 0.8810 - val_loss: 1.3946 - val_accuracy: 0.2593 - 333ms/epoch - 83ms/step\n",
      "Epoch 32/300\n",
      "\n",
      "Epoch 32: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.8102 - accuracy: 0.8175 - val_loss: 1.3969 - val_accuracy: 0.2593 - 339ms/epoch - 85ms/step\n",
      "Epoch 33/300\n",
      "\n",
      "Epoch 33: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.7138 - accuracy: 0.9048 - val_loss: 1.3940 - val_accuracy: 0.2593 - 323ms/epoch - 81ms/step\n",
      "Epoch 34/300\n",
      "\n",
      "Epoch 34: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.7434 - accuracy: 0.8889 - val_loss: 1.3962 - val_accuracy: 0.2593 - 323ms/epoch - 81ms/step\n",
      "Epoch 35/300\n",
      "\n",
      "Epoch 35: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.7506 - accuracy: 0.8571 - val_loss: 1.3989 - val_accuracy: 0.2593 - 330ms/epoch - 82ms/step\n",
      "Epoch 36/300\n",
      "\n",
      "Epoch 36: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.6859 - accuracy: 0.8810 - val_loss: 1.3957 - val_accuracy: 0.2222 - 342ms/epoch - 85ms/step\n",
      "Epoch 37/300\n",
      "\n",
      "Epoch 37: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.6996 - accuracy: 0.8889 - val_loss: 1.3967 - val_accuracy: 0.2593 - 342ms/epoch - 86ms/step\n",
      "Epoch 38/300\n",
      "\n",
      "Epoch 38: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.7089 - accuracy: 0.8968 - val_loss: 1.4011 - val_accuracy: 0.2593 - 329ms/epoch - 82ms/step\n",
      "Epoch 39/300\n",
      "\n",
      "Epoch 39: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.6840 - accuracy: 0.8889 - val_loss: 1.3982 - val_accuracy: 0.2593 - 343ms/epoch - 86ms/step\n",
      "Epoch 40/300\n",
      "\n",
      "Epoch 40: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.6880 - accuracy: 0.8889 - val_loss: 1.3953 - val_accuracy: 0.2593 - 328ms/epoch - 82ms/step\n",
      "Epoch 41/300\n",
      "\n",
      "Epoch 41: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.6364 - accuracy: 0.9365 - val_loss: 1.4096 - val_accuracy: 0.2593 - 329ms/epoch - 82ms/step\n",
      "Epoch 42/300\n",
      "\n",
      "Epoch 42: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.6424 - accuracy: 0.9365 - val_loss: 1.4061 - val_accuracy: 0.2593 - 326ms/epoch - 81ms/step\n",
      "Epoch 43/300\n",
      "\n",
      "Epoch 43: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.6048 - accuracy: 0.9444 - val_loss: 1.4019 - val_accuracy: 0.2593 - 328ms/epoch - 82ms/step\n",
      "Epoch 44/300\n",
      "\n",
      "Epoch 44: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.5979 - accuracy: 0.9524 - val_loss: 1.4098 - val_accuracy: 0.2593 - 342ms/epoch - 85ms/step\n",
      "Epoch 45/300\n",
      "\n",
      "Epoch 45: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.5961 - accuracy: 0.9683 - val_loss: 1.4129 - val_accuracy: 0.2593 - 335ms/epoch - 84ms/step\n",
      "Epoch 46/300\n",
      "\n",
      "Epoch 46: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.5912 - accuracy: 0.9524 - val_loss: 1.4058 - val_accuracy: 0.2593 - 323ms/epoch - 81ms/step\n",
      "Epoch 47/300\n",
      "\n",
      "Epoch 47: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.5833 - accuracy: 0.9524 - val_loss: 1.4136 - val_accuracy: 0.2593 - 344ms/epoch - 86ms/step\n",
      "Epoch 48/300\n",
      "\n",
      "Epoch 48: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.5905 - accuracy: 0.9286 - val_loss: 1.4167 - val_accuracy: 0.2593 - 332ms/epoch - 83ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/300\n",
      "\n",
      "Epoch 49: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.5561 - accuracy: 0.9444 - val_loss: 1.4061 - val_accuracy: 0.2593 - 332ms/epoch - 83ms/step\n",
      "Epoch 50/300\n",
      "\n",
      "Epoch 50: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.5315 - accuracy: 0.9524 - val_loss: 1.4243 - val_accuracy: 0.2593 - 352ms/epoch - 88ms/step\n",
      "Epoch 51/300\n",
      "\n",
      "Epoch 51: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.5030 - accuracy: 0.9841 - val_loss: 1.4128 - val_accuracy: 0.2593 - 325ms/epoch - 81ms/step\n",
      "Epoch 52/300\n",
      "\n",
      "Epoch 52: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.5074 - accuracy: 0.9841 - val_loss: 1.4219 - val_accuracy: 0.2593 - 342ms/epoch - 85ms/step\n",
      "Epoch 53/300\n",
      "\n",
      "Epoch 53: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.5071 - accuracy: 0.9683 - val_loss: 1.4150 - val_accuracy: 0.2593 - 331ms/epoch - 83ms/step\n",
      "Epoch 54/300\n",
      "\n",
      "Epoch 54: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.5071 - accuracy: 0.9683 - val_loss: 1.4238 - val_accuracy: 0.2593 - 345ms/epoch - 86ms/step\n",
      "Epoch 55/300\n",
      "\n",
      "Epoch 55: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.4964 - accuracy: 0.9762 - val_loss: 1.4222 - val_accuracy: 0.2407 - 327ms/epoch - 82ms/step\n",
      "Epoch 56/300\n",
      "\n",
      "Epoch 56: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.4887 - accuracy: 0.9762 - val_loss: 1.4285 - val_accuracy: 0.2593 - 341ms/epoch - 85ms/step\n",
      "Epoch 57/300\n",
      "\n",
      "Epoch 57: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.4475 - accuracy: 1.0000 - val_loss: 1.4320 - val_accuracy: 0.2593 - 329ms/epoch - 82ms/step\n",
      "Epoch 58/300\n",
      "\n",
      "Epoch 58: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.4375 - accuracy: 0.9841 - val_loss: 1.4346 - val_accuracy: 0.2593 - 325ms/epoch - 81ms/step\n",
      "Epoch 59/300\n",
      "\n",
      "Epoch 59: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.4600 - accuracy: 0.9921 - val_loss: 1.4375 - val_accuracy: 0.2593 - 362ms/epoch - 91ms/step\n",
      "Epoch 60/300\n",
      "\n",
      "Epoch 60: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.4238 - accuracy: 0.9762 - val_loss: 1.4320 - val_accuracy: 0.2593 - 332ms/epoch - 83ms/step\n",
      "Epoch 61/300\n",
      "\n",
      "Epoch 61: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.4410 - accuracy: 0.9841 - val_loss: 1.4372 - val_accuracy: 0.2407 - 329ms/epoch - 82ms/step\n",
      "Epoch 62/300\n",
      "\n",
      "Epoch 62: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.3960 - accuracy: 1.0000 - val_loss: 1.4438 - val_accuracy: 0.2593 - 318ms/epoch - 80ms/step\n",
      "Epoch 63/300\n",
      "\n",
      "Epoch 63: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.4216 - accuracy: 0.9683 - val_loss: 1.4390 - val_accuracy: 0.2593 - 347ms/epoch - 87ms/step\n",
      "Epoch 64/300\n",
      "\n",
      "Epoch 64: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.3899 - accuracy: 0.9921 - val_loss: 1.4415 - val_accuracy: 0.2407 - 348ms/epoch - 87ms/step\n",
      "Epoch 65/300\n",
      "\n",
      "Epoch 65: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.3952 - accuracy: 0.9921 - val_loss: 1.4495 - val_accuracy: 0.2593 - 341ms/epoch - 85ms/step\n",
      "Epoch 66/300\n",
      "\n",
      "Epoch 66: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.3849 - accuracy: 0.9921 - val_loss: 1.4490 - val_accuracy: 0.2593 - 335ms/epoch - 84ms/step\n",
      "Epoch 67/300\n",
      "\n",
      "Epoch 67: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.3772 - accuracy: 1.0000 - val_loss: 1.4581 - val_accuracy: 0.2593 - 325ms/epoch - 81ms/step\n",
      "Epoch 68/300\n",
      "\n",
      "Epoch 68: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.3791 - accuracy: 1.0000 - val_loss: 1.4686 - val_accuracy: 0.2593 - 327ms/epoch - 82ms/step\n",
      "Epoch 69/300\n",
      "\n",
      "Epoch 69: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.4062 - accuracy: 0.9603 - val_loss: 1.4866 - val_accuracy: 0.2593 - 333ms/epoch - 83ms/step\n",
      "Epoch 70/300\n",
      "\n",
      "Epoch 70: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.3655 - accuracy: 0.9921 - val_loss: 1.4568 - val_accuracy: 0.2593 - 324ms/epoch - 81ms/step\n",
      "Epoch 71/300\n",
      "\n",
      "Epoch 71: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.3552 - accuracy: 1.0000 - val_loss: 1.4667 - val_accuracy: 0.2593 - 334ms/epoch - 84ms/step\n",
      "Epoch 72/300\n",
      "\n",
      "Epoch 72: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.3516 - accuracy: 1.0000 - val_loss: 1.4664 - val_accuracy: 0.2593 - 323ms/epoch - 81ms/step\n",
      "Epoch 73/300\n",
      "\n",
      "Epoch 73: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.3504 - accuracy: 1.0000 - val_loss: 1.4698 - val_accuracy: 0.2407 - 324ms/epoch - 81ms/step\n",
      "Epoch 74/300\n",
      "\n",
      "Epoch 74: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.3617 - accuracy: 0.9921 - val_loss: 1.4996 - val_accuracy: 0.2593 - 340ms/epoch - 85ms/step\n",
      "Epoch 75/300\n",
      "\n",
      "Epoch 75: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.3398 - accuracy: 1.0000 - val_loss: 1.4439 - val_accuracy: 0.2778 - 322ms/epoch - 81ms/step\n",
      "Epoch 76/300\n",
      "\n",
      "Epoch 76: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.3316 - accuracy: 1.0000 - val_loss: 1.5119 - val_accuracy: 0.2593 - 342ms/epoch - 85ms/step\n",
      "Epoch 77/300\n",
      "\n",
      "Epoch 77: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.3265 - accuracy: 1.0000 - val_loss: 1.4621 - val_accuracy: 0.2407 - 340ms/epoch - 85ms/step\n",
      "Epoch 78/300\n",
      "\n",
      "Epoch 78: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.3245 - accuracy: 1.0000 - val_loss: 1.5092 - val_accuracy: 0.2407 - 329ms/epoch - 82ms/step\n",
      "Epoch 79/300\n",
      "\n",
      "Epoch 79: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.3310 - accuracy: 1.0000 - val_loss: 1.4573 - val_accuracy: 0.2778 - 328ms/epoch - 82ms/step\n",
      "Epoch 80/300\n",
      "\n",
      "Epoch 80: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.3159 - accuracy: 1.0000 - val_loss: 1.5286 - val_accuracy: 0.2593 - 340ms/epoch - 85ms/step\n",
      "Epoch 81/300\n",
      "\n",
      "Epoch 81: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.3223 - accuracy: 0.9921 - val_loss: 1.4943 - val_accuracy: 0.2778 - 326ms/epoch - 82ms/step\n",
      "Epoch 82/300\n",
      "\n",
      "Epoch 82: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.2948 - accuracy: 1.0000 - val_loss: 1.4792 - val_accuracy: 0.2593 - 337ms/epoch - 84ms/step\n",
      "Epoch 83/300\n",
      "\n",
      "Epoch 83: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.3003 - accuracy: 0.9841 - val_loss: 1.5185 - val_accuracy: 0.2593 - 324ms/epoch - 81ms/step\n",
      "Epoch 84/300\n",
      "\n",
      "Epoch 84: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.2971 - accuracy: 1.0000 - val_loss: 1.5144 - val_accuracy: 0.2407 - 332ms/epoch - 83ms/step\n",
      "Epoch 85/300\n",
      "\n",
      "Epoch 85: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.2961 - accuracy: 1.0000 - val_loss: 1.5642 - val_accuracy: 0.2593 - 345ms/epoch - 86ms/step\n",
      "Epoch 86/300\n",
      "\n",
      "Epoch 86: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.3023 - accuracy: 1.0000 - val_loss: 1.5124 - val_accuracy: 0.2778 - 323ms/epoch - 81ms/step\n",
      "Epoch 87/300\n",
      "\n",
      "Epoch 87: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.2721 - accuracy: 1.0000 - val_loss: 1.5252 - val_accuracy: 0.2593 - 340ms/epoch - 85ms/step\n",
      "Epoch 88/300\n",
      "\n",
      "Epoch 88: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.2690 - accuracy: 1.0000 - val_loss: 1.5139 - val_accuracy: 0.2407 - 322ms/epoch - 80ms/step\n",
      "Epoch 89/300\n",
      "\n",
      "Epoch 89: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.2590 - accuracy: 1.0000 - val_loss: 1.5246 - val_accuracy: 0.2963 - 346ms/epoch - 87ms/step\n",
      "Epoch 90/300\n",
      "\n",
      "Epoch 90: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.2836 - accuracy: 1.0000 - val_loss: 1.5066 - val_accuracy: 0.2778 - 327ms/epoch - 82ms/step\n",
      "Epoch 91/300\n",
      "\n",
      "Epoch 91: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.2491 - accuracy: 0.9921 - val_loss: 1.5774 - val_accuracy: 0.2963 - 340ms/epoch - 85ms/step\n",
      "Epoch 92/300\n",
      "\n",
      "Epoch 92: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.2513 - accuracy: 1.0000 - val_loss: 1.5140 - val_accuracy: 0.2593 - 335ms/epoch - 84ms/step\n",
      "Epoch 93/300\n",
      "\n",
      "Epoch 93: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.2776 - accuracy: 0.9921 - val_loss: 1.5621 - val_accuracy: 0.2778 - 328ms/epoch - 82ms/step\n",
      "Epoch 94/300\n",
      "\n",
      "Epoch 94: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.2663 - accuracy: 1.0000 - val_loss: 1.5363 - val_accuracy: 0.2778 - 327ms/epoch - 82ms/step\n",
      "Epoch 95/300\n",
      "\n",
      "Epoch 95: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.2514 - accuracy: 1.0000 - val_loss: 1.5887 - val_accuracy: 0.2407 - 346ms/epoch - 87ms/step\n",
      "Epoch 96/300\n",
      "\n",
      "Epoch 96: val_loss did not improve from 1.38639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.2495 - accuracy: 1.0000 - val_loss: 1.5591 - val_accuracy: 0.2778 - 331ms/epoch - 83ms/step\n",
      "Epoch 97/300\n",
      "\n",
      "Epoch 97: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.2263 - accuracy: 1.0000 - val_loss: 1.5632 - val_accuracy: 0.2778 - 335ms/epoch - 84ms/step\n",
      "Epoch 98/300\n",
      "\n",
      "Epoch 98: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.2362 - accuracy: 1.0000 - val_loss: 1.5808 - val_accuracy: 0.2778 - 325ms/epoch - 81ms/step\n",
      "Epoch 99/300\n",
      "\n",
      "Epoch 99: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.2555 - accuracy: 1.0000 - val_loss: 1.5303 - val_accuracy: 0.2778 - 344ms/epoch - 86ms/step\n",
      "Epoch 100/300\n",
      "\n",
      "Epoch 100: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 1.5519 - val_accuracy: 0.2222 - 343ms/epoch - 86ms/step\n",
      "Epoch 101/300\n",
      "\n",
      "Epoch 101: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.2517 - accuracy: 1.0000 - val_loss: 1.5731 - val_accuracy: 0.2407 - 338ms/epoch - 85ms/step\n",
      "Epoch 102/300\n",
      "\n",
      "Epoch 102: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.2202 - accuracy: 1.0000 - val_loss: 1.5964 - val_accuracy: 0.2778 - 325ms/epoch - 81ms/step\n",
      "Epoch 103/300\n",
      "\n",
      "Epoch 103: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.2348 - accuracy: 1.0000 - val_loss: 1.5796 - val_accuracy: 0.2963 - 338ms/epoch - 84ms/step\n",
      "Epoch 104/300\n",
      "\n",
      "Epoch 104: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.2118 - accuracy: 0.9921 - val_loss: 1.6299 - val_accuracy: 0.2407 - 325ms/epoch - 81ms/step\n",
      "Epoch 105/300\n",
      "\n",
      "Epoch 105: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.2224 - accuracy: 1.0000 - val_loss: 1.6104 - val_accuracy: 0.2778 - 322ms/epoch - 81ms/step\n",
      "Epoch 106/300\n",
      "\n",
      "Epoch 106: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1945 - accuracy: 1.0000 - val_loss: 1.5755 - val_accuracy: 0.2222 - 339ms/epoch - 85ms/step\n",
      "Epoch 107/300\n",
      "\n",
      "Epoch 107: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.2027 - accuracy: 1.0000 - val_loss: 1.5759 - val_accuracy: 0.2407 - 346ms/epoch - 87ms/step\n",
      "Epoch 108/300\n",
      "\n",
      "Epoch 108: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.2254 - accuracy: 0.9921 - val_loss: 1.6180 - val_accuracy: 0.2593 - 333ms/epoch - 83ms/step\n",
      "Epoch 109/300\n",
      "\n",
      "Epoch 109: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.2020 - accuracy: 1.0000 - val_loss: 1.5941 - val_accuracy: 0.2407 - 325ms/epoch - 81ms/step\n",
      "Epoch 110/300\n",
      "\n",
      "Epoch 110: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1958 - accuracy: 1.0000 - val_loss: 1.6147 - val_accuracy: 0.2593 - 347ms/epoch - 87ms/step\n",
      "Epoch 111/300\n",
      "\n",
      "Epoch 111: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.2017 - accuracy: 1.0000 - val_loss: 1.5826 - val_accuracy: 0.2037 - 321ms/epoch - 80ms/step\n",
      "Epoch 112/300\n",
      "\n",
      "Epoch 112: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1953 - accuracy: 1.0000 - val_loss: 1.6990 - val_accuracy: 0.2222 - 339ms/epoch - 85ms/step\n",
      "Epoch 113/300\n",
      "\n",
      "Epoch 113: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1892 - accuracy: 1.0000 - val_loss: 1.6432 - val_accuracy: 0.2593 - 349ms/epoch - 87ms/step\n",
      "Epoch 114/300\n",
      "\n",
      "Epoch 114: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1835 - accuracy: 1.0000 - val_loss: 1.7034 - val_accuracy: 0.2222 - 334ms/epoch - 83ms/step\n",
      "Epoch 115/300\n",
      "\n",
      "Epoch 115: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1662 - accuracy: 1.0000 - val_loss: 1.6592 - val_accuracy: 0.2593 - 338ms/epoch - 84ms/step\n",
      "Epoch 116/300\n",
      "\n",
      "Epoch 116: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1724 - accuracy: 1.0000 - val_loss: 1.6794 - val_accuracy: 0.2593 - 336ms/epoch - 84ms/step\n",
      "Epoch 117/300\n",
      "\n",
      "Epoch 117: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1677 - accuracy: 1.0000 - val_loss: 1.6583 - val_accuracy: 0.2037 - 333ms/epoch - 83ms/step\n",
      "Epoch 118/300\n",
      "\n",
      "Epoch 118: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1991 - accuracy: 1.0000 - val_loss: 1.6631 - val_accuracy: 0.2222 - 334ms/epoch - 84ms/step\n",
      "Epoch 119/300\n",
      "\n",
      "Epoch 119: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1742 - accuracy: 1.0000 - val_loss: 1.6595 - val_accuracy: 0.2037 - 333ms/epoch - 83ms/step\n",
      "Epoch 120/300\n",
      "\n",
      "Epoch 120: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1869 - accuracy: 1.0000 - val_loss: 1.6318 - val_accuracy: 0.2222 - 338ms/epoch - 84ms/step\n",
      "Epoch 121/300\n",
      "\n",
      "Epoch 121: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1808 - accuracy: 1.0000 - val_loss: 1.6484 - val_accuracy: 0.2778 - 325ms/epoch - 81ms/step\n",
      "Epoch 122/300\n",
      "\n",
      "Epoch 122: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1590 - accuracy: 1.0000 - val_loss: 1.6194 - val_accuracy: 0.2407 - 333ms/epoch - 83ms/step\n",
      "Epoch 123/300\n",
      "\n",
      "Epoch 123: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1565 - accuracy: 1.0000 - val_loss: 1.7015 - val_accuracy: 0.2778 - 324ms/epoch - 81ms/step\n",
      "Epoch 124/300\n",
      "\n",
      "Epoch 124: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1760 - accuracy: 1.0000 - val_loss: 1.6984 - val_accuracy: 0.2593 - 325ms/epoch - 81ms/step\n",
      "Epoch 125/300\n",
      "\n",
      "Epoch 125: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1950 - accuracy: 1.0000 - val_loss: 1.7376 - val_accuracy: 0.2593 - 339ms/epoch - 85ms/step\n",
      "Epoch 126/300\n",
      "\n",
      "Epoch 126: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1772 - accuracy: 1.0000 - val_loss: 1.6877 - val_accuracy: 0.1852 - 337ms/epoch - 84ms/step\n",
      "Epoch 127/300\n",
      "\n",
      "Epoch 127: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1784 - accuracy: 1.0000 - val_loss: 1.7272 - val_accuracy: 0.1852 - 318ms/epoch - 79ms/step\n",
      "Epoch 128/300\n",
      "\n",
      "Epoch 128: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1660 - accuracy: 1.0000 - val_loss: 1.6822 - val_accuracy: 0.2593 - 328ms/epoch - 82ms/step\n",
      "Epoch 129/300\n",
      "\n",
      "Epoch 129: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1594 - accuracy: 1.0000 - val_loss: 1.7559 - val_accuracy: 0.2593 - 334ms/epoch - 84ms/step\n",
      "Epoch 130/300\n",
      "\n",
      "Epoch 130: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1757 - accuracy: 1.0000 - val_loss: 1.7429 - val_accuracy: 0.2407 - 338ms/epoch - 84ms/step\n",
      "Epoch 131/300\n",
      "\n",
      "Epoch 131: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1640 - accuracy: 1.0000 - val_loss: 1.7170 - val_accuracy: 0.1852 - 350ms/epoch - 87ms/step\n",
      "Epoch 132/300\n",
      "\n",
      "Epoch 132: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1494 - accuracy: 1.0000 - val_loss: 1.6859 - val_accuracy: 0.2407 - 335ms/epoch - 84ms/step\n",
      "Epoch 133/300\n",
      "\n",
      "Epoch 133: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1691 - accuracy: 1.0000 - val_loss: 1.7015 - val_accuracy: 0.2037 - 339ms/epoch - 85ms/step\n",
      "Epoch 134/300\n",
      "\n",
      "Epoch 134: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1706 - accuracy: 1.0000 - val_loss: 1.7385 - val_accuracy: 0.2963 - 329ms/epoch - 82ms/step\n",
      "Epoch 135/300\n",
      "\n",
      "Epoch 135: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1455 - accuracy: 1.0000 - val_loss: 1.7676 - val_accuracy: 0.2778 - 323ms/epoch - 81ms/step\n",
      "Epoch 136/300\n",
      "\n",
      "Epoch 136: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1565 - accuracy: 1.0000 - val_loss: 1.7396 - val_accuracy: 0.2963 - 334ms/epoch - 83ms/step\n",
      "Epoch 137/300\n",
      "\n",
      "Epoch 137: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1800 - accuracy: 0.9921 - val_loss: 1.7570 - val_accuracy: 0.2593 - 349ms/epoch - 87ms/step\n",
      "Epoch 138/300\n",
      "\n",
      "Epoch 138: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1450 - accuracy: 1.0000 - val_loss: 1.7941 - val_accuracy: 0.2407 - 342ms/epoch - 85ms/step\n",
      "Epoch 139/300\n",
      "\n",
      "Epoch 139: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1439 - accuracy: 1.0000 - val_loss: 1.7750 - val_accuracy: 0.2593 - 323ms/epoch - 81ms/step\n",
      "Epoch 140/300\n",
      "\n",
      "Epoch 140: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1569 - accuracy: 1.0000 - val_loss: 1.7305 - val_accuracy: 0.2222 - 334ms/epoch - 83ms/step\n",
      "Epoch 141/300\n",
      "\n",
      "Epoch 141: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1774 - accuracy: 1.0000 - val_loss: 1.7415 - val_accuracy: 0.1852 - 334ms/epoch - 84ms/step\n",
      "Epoch 142/300\n",
      "\n",
      "Epoch 142: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1641 - accuracy: 1.0000 - val_loss: 1.8238 - val_accuracy: 0.2037 - 318ms/epoch - 80ms/step\n",
      "Epoch 143/300\n",
      "\n",
      "Epoch 143: val_loss did not improve from 1.38639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.1766 - accuracy: 1.0000 - val_loss: 2.0651 - val_accuracy: 0.1852 - 342ms/epoch - 86ms/step\n",
      "Epoch 144/300\n",
      "\n",
      "Epoch 144: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1600 - accuracy: 1.0000 - val_loss: 1.8161 - val_accuracy: 0.1852 - 318ms/epoch - 80ms/step\n",
      "Epoch 145/300\n",
      "\n",
      "Epoch 145: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1604 - accuracy: 1.0000 - val_loss: 1.7635 - val_accuracy: 0.2963 - 339ms/epoch - 85ms/step\n",
      "Epoch 146/300\n",
      "\n",
      "Epoch 146: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1508 - accuracy: 1.0000 - val_loss: 1.8100 - val_accuracy: 0.2778 - 332ms/epoch - 83ms/step\n",
      "Epoch 147/300\n",
      "\n",
      "Epoch 147: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1478 - accuracy: 1.0000 - val_loss: 1.8220 - val_accuracy: 0.2037 - 323ms/epoch - 81ms/step\n",
      "Epoch 148/300\n",
      "\n",
      "Epoch 148: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1454 - accuracy: 1.0000 - val_loss: 1.7427 - val_accuracy: 0.2778 - 338ms/epoch - 84ms/step\n",
      "Epoch 149/300\n",
      "\n",
      "Epoch 149: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1369 - accuracy: 1.0000 - val_loss: 1.7425 - val_accuracy: 0.2222 - 335ms/epoch - 84ms/step\n",
      "Epoch 150/300\n",
      "\n",
      "Epoch 150: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1474 - accuracy: 1.0000 - val_loss: 1.7678 - val_accuracy: 0.2778 - 359ms/epoch - 90ms/step\n",
      "Epoch 151/300\n",
      "\n",
      "Epoch 151: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1364 - accuracy: 1.0000 - val_loss: 1.7951 - val_accuracy: 0.2222 - 357ms/epoch - 89ms/step\n",
      "Epoch 152/300\n",
      "\n",
      "Epoch 152: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1357 - accuracy: 1.0000 - val_loss: 1.7973 - val_accuracy: 0.2778 - 343ms/epoch - 86ms/step\n",
      "Epoch 153/300\n",
      "\n",
      "Epoch 153: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1370 - accuracy: 1.0000 - val_loss: 1.8486 - val_accuracy: 0.2222 - 337ms/epoch - 84ms/step\n",
      "Epoch 154/300\n",
      "\n",
      "Epoch 154: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1316 - accuracy: 1.0000 - val_loss: 1.8872 - val_accuracy: 0.2778 - 322ms/epoch - 81ms/step\n",
      "Epoch 155/300\n",
      "\n",
      "Epoch 155: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1247 - accuracy: 1.0000 - val_loss: 1.7943 - val_accuracy: 0.2593 - 341ms/epoch - 85ms/step\n",
      "Epoch 156/300\n",
      "\n",
      "Epoch 156: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1431 - accuracy: 1.0000 - val_loss: 1.7957 - val_accuracy: 0.2963 - 345ms/epoch - 86ms/step\n",
      "Epoch 157/300\n",
      "\n",
      "Epoch 157: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1244 - accuracy: 1.0000 - val_loss: 1.7585 - val_accuracy: 0.2593 - 326ms/epoch - 81ms/step\n",
      "Epoch 158/300\n",
      "\n",
      "Epoch 158: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1481 - accuracy: 1.0000 - val_loss: 1.8174 - val_accuracy: 0.2037 - 338ms/epoch - 85ms/step\n",
      "Epoch 159/300\n",
      "\n",
      "Epoch 159: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1208 - accuracy: 1.0000 - val_loss: 1.7875 - val_accuracy: 0.2778 - 328ms/epoch - 82ms/step\n",
      "Epoch 160/300\n",
      "\n",
      "Epoch 160: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1296 - accuracy: 1.0000 - val_loss: 1.8004 - val_accuracy: 0.2222 - 324ms/epoch - 81ms/step\n",
      "Epoch 161/300\n",
      "\n",
      "Epoch 161: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1224 - accuracy: 1.0000 - val_loss: 1.8019 - val_accuracy: 0.3333 - 336ms/epoch - 84ms/step\n",
      "Epoch 162/300\n",
      "\n",
      "Epoch 162: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1238 - accuracy: 1.0000 - val_loss: 1.8606 - val_accuracy: 0.3148 - 353ms/epoch - 88ms/step\n",
      "Epoch 163/300\n",
      "\n",
      "Epoch 163: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1188 - accuracy: 1.0000 - val_loss: 1.8595 - val_accuracy: 0.2778 - 330ms/epoch - 82ms/step\n",
      "Epoch 164/300\n",
      "\n",
      "Epoch 164: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1249 - accuracy: 1.0000 - val_loss: 1.8278 - val_accuracy: 0.2222 - 341ms/epoch - 85ms/step\n",
      "Epoch 165/300\n",
      "\n",
      "Epoch 165: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1213 - accuracy: 1.0000 - val_loss: 1.8208 - val_accuracy: 0.2778 - 337ms/epoch - 84ms/step\n",
      "Epoch 166/300\n",
      "\n",
      "Epoch 166: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1112 - accuracy: 1.0000 - val_loss: 1.7817 - val_accuracy: 0.2963 - 328ms/epoch - 82ms/step\n",
      "Epoch 167/300\n",
      "\n",
      "Epoch 167: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1010 - accuracy: 1.0000 - val_loss: 1.8261 - val_accuracy: 0.2778 - 344ms/epoch - 86ms/step\n",
      "Epoch 168/300\n",
      "\n",
      "Epoch 168: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1160 - accuracy: 1.0000 - val_loss: 1.8095 - val_accuracy: 0.1667 - 356ms/epoch - 89ms/step\n",
      "Epoch 169/300\n",
      "\n",
      "Epoch 169: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1240 - accuracy: 1.0000 - val_loss: 1.8226 - val_accuracy: 0.2222 - 356ms/epoch - 89ms/step\n",
      "Epoch 170/300\n",
      "\n",
      "Epoch 170: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1067 - accuracy: 1.0000 - val_loss: 1.8236 - val_accuracy: 0.2593 - 344ms/epoch - 86ms/step\n",
      "Epoch 171/300\n",
      "\n",
      "Epoch 171: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1074 - accuracy: 1.0000 - val_loss: 1.8408 - val_accuracy: 0.2037 - 330ms/epoch - 83ms/step\n",
      "Epoch 172/300\n",
      "\n",
      "Epoch 172: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1029 - accuracy: 1.0000 - val_loss: 1.8186 - val_accuracy: 0.2222 - 352ms/epoch - 88ms/step\n",
      "Epoch 173/300\n",
      "\n",
      "Epoch 173: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.0931 - accuracy: 1.0000 - val_loss: 1.8877 - val_accuracy: 0.2222 - 340ms/epoch - 85ms/step\n",
      "Epoch 174/300\n",
      "\n",
      "Epoch 174: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1085 - accuracy: 1.0000 - val_loss: 1.8187 - val_accuracy: 0.2037 - 321ms/epoch - 80ms/step\n",
      "Epoch 175/300\n",
      "\n",
      "Epoch 175: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1009 - accuracy: 1.0000 - val_loss: 1.8002 - val_accuracy: 0.2778 - 328ms/epoch - 82ms/step\n",
      "Epoch 176/300\n",
      "\n",
      "Epoch 176: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.0957 - accuracy: 1.0000 - val_loss: 1.7847 - val_accuracy: 0.3333 - 331ms/epoch - 83ms/step\n",
      "Epoch 177/300\n",
      "\n",
      "Epoch 177: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1141 - accuracy: 1.0000 - val_loss: 1.8548 - val_accuracy: 0.2778 - 325ms/epoch - 81ms/step\n",
      "Epoch 178/300\n",
      "\n",
      "Epoch 178: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1017 - accuracy: 1.0000 - val_loss: 1.8929 - val_accuracy: 0.2037 - 328ms/epoch - 82ms/step\n",
      "Epoch 179/300\n",
      "\n",
      "Epoch 179: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1060 - accuracy: 1.0000 - val_loss: 1.8419 - val_accuracy: 0.2222 - 325ms/epoch - 81ms/step\n",
      "Epoch 180/300\n",
      "\n",
      "Epoch 180: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.0995 - accuracy: 1.0000 - val_loss: 1.8696 - val_accuracy: 0.2407 - 325ms/epoch - 81ms/step\n",
      "Epoch 181/300\n",
      "\n",
      "Epoch 181: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.0937 - accuracy: 1.0000 - val_loss: 1.8763 - val_accuracy: 0.2407 - 322ms/epoch - 80ms/step\n",
      "Epoch 182/300\n",
      "\n",
      "Epoch 182: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1062 - accuracy: 1.0000 - val_loss: 1.8822 - val_accuracy: 0.2037 - 340ms/epoch - 85ms/step\n",
      "Epoch 183/300\n",
      "\n",
      "Epoch 183: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1003 - accuracy: 1.0000 - val_loss: 1.8088 - val_accuracy: 0.2778 - 333ms/epoch - 83ms/step\n",
      "Epoch 184/300\n",
      "\n",
      "Epoch 184: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1022 - accuracy: 1.0000 - val_loss: 1.8139 - val_accuracy: 0.2778 - 337ms/epoch - 84ms/step\n",
      "Epoch 185/300\n",
      "\n",
      "Epoch 185: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1142 - accuracy: 1.0000 - val_loss: 1.8576 - val_accuracy: 0.1852 - 330ms/epoch - 82ms/step\n",
      "Epoch 186/300\n",
      "\n",
      "Epoch 186: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1176 - accuracy: 1.0000 - val_loss: 1.8773 - val_accuracy: 0.2407 - 336ms/epoch - 84ms/step\n",
      "Epoch 187/300\n",
      "\n",
      "Epoch 187: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.0874 - accuracy: 1.0000 - val_loss: 1.9412 - val_accuracy: 0.2222 - 323ms/epoch - 81ms/step\n",
      "Epoch 188/300\n",
      "\n",
      "Epoch 188: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.0984 - accuracy: 1.0000 - val_loss: 1.9363 - val_accuracy: 0.2407 - 340ms/epoch - 85ms/step\n",
      "Epoch 189/300\n",
      "\n",
      "Epoch 189: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1103 - accuracy: 1.0000 - val_loss: 1.9035 - val_accuracy: 0.2593 - 337ms/epoch - 84ms/step\n",
      "Epoch 190/300\n",
      "\n",
      "Epoch 190: val_loss did not improve from 1.38639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.0940 - accuracy: 1.0000 - val_loss: 1.9010 - val_accuracy: 0.2222 - 337ms/epoch - 84ms/step\n",
      "Epoch 191/300\n",
      "\n",
      "Epoch 191: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1017 - accuracy: 1.0000 - val_loss: 1.8504 - val_accuracy: 0.2407 - 337ms/epoch - 84ms/step\n",
      "Epoch 192/300\n",
      "\n",
      "Epoch 192: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1046 - accuracy: 1.0000 - val_loss: 1.8935 - val_accuracy: 0.2222 - 325ms/epoch - 81ms/step\n",
      "Epoch 193/300\n",
      "\n",
      "Epoch 193: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.0937 - accuracy: 1.0000 - val_loss: 1.8889 - val_accuracy: 0.2407 - 330ms/epoch - 83ms/step\n",
      "Epoch 194/300\n",
      "\n",
      "Epoch 194: val_loss did not improve from 1.38639\n",
      "4/4 - 0s - loss: 0.1013 - accuracy: 1.0000 - val_loss: 1.8685 - val_accuracy: 0.2407 - 332ms/epoch - 83ms/step\n",
      "Epoch 195/300\n"
     ]
    }
   ],
   "source": [
    "for subject in range(1,9):\n",
    "    # Load all trials for a sigle subject\n",
    "    X, Y = Extract_data_from_subject(root_dir, subject, datatype)\n",
    "\n",
    "    # Cut usefull time. i.e action interval\n",
    "    X = Select_time_window(X = X, t_start = t_start, t_end = t_end, fs = fs)\n",
    "\n",
    "    X, Y = Filter_by_condition(X, Y, \"INNER\")\n",
    "\n",
    "    best_channel_mask = [False, False,  True,  True, False, True, False, False, False, False, False,  True,\n",
    "        False,  True, False, False, False, False, False, False, False, False,  True, False,\n",
    "        False, False, False, False, False, False, False,  True, False, False, False, False,\n",
    "        False,  True, False, False,  True, False,  True, False,  True,  True, False, False,\n",
    "        False, False, False, False, False, False, False,  True, False, False, False, False,\n",
    "        False,  True, False, False, False,  True, False, False, False, False,  True,  True,\n",
    "        False, False,  True, False, False, False, False, False, False, False,  True, False,\n",
    "        False,  True, False,  True, False, False,  True,  True, False, False, False, False,\n",
    "        True,  True, False, False, False,  True, False, False,  True, False, False, False,\n",
    "        False, False,  True, False, False, False,  True, False,  True, False, False, False,\n",
    "        False, False, False,  True, False,  True, False, False,]\n",
    "    left_channels = np.array([0,\n",
    "                        1,\n",
    "                        3,\n",
    "                        4,\n",
    "                        7,\n",
    "                        8,\n",
    "                        9,\n",
    "                        14,\n",
    "                        18,\n",
    "                        19,\n",
    "                        21,\n",
    "                        22,\n",
    "                        23,\n",
    "                        81,\n",
    "                        83,\n",
    "                        90,\n",
    "                        94,\n",
    "                        95,\n",
    "                        100,\n",
    "                        101,\n",
    "                        105,\n",
    "                        110,\n",
    "                        114,\n",
    "                        116,\n",
    "                        121,\n",
    "                        125\n",
    "                        ])\n",
    "\n",
    "    X = X[:,left_channels,:]\n",
    "\n",
    "    x_min = X.min(axis=(2), keepdims=True)\n",
    "    x_max = X.max(axis=(2), keepdims=True)\n",
    "\n",
    "    x_min.shape\n",
    "\n",
    "    X = (X - x_min)/(x_max-x_min)\n",
    "\n",
    "\n",
    "\n",
    "    y_labels = Y[:,1]\n",
    "\n",
    "    kf = KFold(n_splits=4, shuffle=True)\n",
    "    kf.get_n_splits(X)\n",
    "    accuracies = []\n",
    "\n",
    "    kernels, chans, samples = 1, X.shape[1], X.shape[2]\n",
    "\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    F1s = []\n",
    "\n",
    "    split = 0\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        Y_train, Y_test = y_labels[train_index], y_labels[test_index]\n",
    "        # convert labels to one-hot encodings.\n",
    "        Y_train      = np_utils.to_categorical(Y_train)\n",
    "        Y_test       = np_utils.to_categorical(Y_test)\n",
    "        X_train      = X_train.reshape(X_train.shape[0], chans, samples, kernels)\n",
    "        X_test       = X_test.reshape(X_test.shape[0], chans, samples, kernels)\n",
    "        \n",
    "        X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.3, random_state=24)\n",
    "\n",
    "        checkpointer = ModelCheckpoint(filepath='checkpoint1.h5', verbose=1, monitor='val_loss',\n",
    "                                   save_best_only=True)\n",
    "\n",
    "        with strategy.scope():\n",
    "\n",
    "            model = EEGNet(nb_classes = 4, Chans = chans, Samples = samples,\n",
    "                      dropoutRate = dr, kernLength = kernLength, F1 = f1, D = d, F2 = f2, \n",
    "                       dropoutType = 'Dropout')\n",
    "            model.compile(\n",
    "                    tf.keras.optimizers.Adam(\n",
    "                        # Specifies the range of values for the tuner to try\n",
    "                        name=\"Adam\"),\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "\n",
    "        fittedModel = model.fit(X_train, Y_train, batch_size = 32, epochs = 300, \n",
    "                            verbose = 2,\n",
    "                            validation_data=(X_val, Y_val),\n",
    "                            callbacks=[checkpointer]\n",
    "                               )\n",
    "        best_model = tf.keras.models.load_model('checkpoint1.h5')\n",
    "        \n",
    "        probs       = best_model.predict(X_test)\n",
    "        preds       = probs.argmax(axis = -1)  \n",
    "        acc         = np.mean(preds == Y_test.argmax(axis=-1))\n",
    "        accuracies.append(acc)\n",
    "\n",
    "        precision, recall, F1, _ = precision_recall_fscore_support(Y_test.argmax(axis=-1), preds, average='macro')\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        F1s.append(F1)\n",
    "        \n",
    "        with open(f'./last_try/subject{subject}_split{split}.txt', 'w+') as f:\n",
    "            print('\\ntrain index:\\n', file=f)\n",
    "            print(train_index, file=f)\n",
    "            print('\\ntest index:\\n', file=f)\n",
    "            print(test_index, file=f)\n",
    "            # print('\\nBest Params:\\n', file=f)\n",
    "            # print(tuner.get_best_hyperparameters(1)[0], file=f)\n",
    "            print('\\nAccuracy:\\n', file=f)\n",
    "            print(acc, file=f)\n",
    "            print('\\Precision:\\n', file=f)\n",
    "            print(precision, file=f)\n",
    "            print('\\Recall:\\n', file=f)\n",
    "            print(recall, file=f)\n",
    "            print('\\F1:\\n', file=f)\n",
    "            print(F1, file=f)\n",
    "            print('Using Batch size of test', file=f)\n",
    "\n",
    "        split += 1\n",
    "    \n",
    "    print('Lists')\n",
    "    print(accuracies)\n",
    "    print(precisions)\n",
    "    print(recalls)\n",
    "    print(F1s)\n",
    "\n",
    "    av_accuracies[subject] = sum(accuracies)/4\n",
    "    av_precisions[subject] = sum(precisions)/4\n",
    "    av_recalls[subject] = sum(recalls)/4\n",
    "    av_F1s[subject] = sum(F1s)/4\n",
    "\n",
    "    print(\"dicts\")\n",
    "    print(av_accuracies)\n",
    "    print(av_precisions)\n",
    "    print(av_recalls)\n",
    "    print(av_F1s)\n",
    "# -\n",
    "\n",
    "with open('./last_try/output_FINAL_RESULTS.txt', 'w+') as f:\n",
    "    print('\\naccuracies:\\n', file=f)\n",
    "    print(av_accuracies, file=f)\n",
    "    print('\\nprecisions:\\n', file=f)\n",
    "    print(av_precisions, file=f)\n",
    "    print('\\nrecalls:\\n', file=f)\n",
    "    print(av_recalls, file=f)\n",
    "    print('\\nF1s:\\n', file=f)\n",
    "    print(av_F1s, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb8101f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([[y for x, y in av_accuracies.items()],\n",
    "               [y for x, y in av_precisions.items()],\n",
    "               [y for x, y in av_recalls.items()],\n",
    "               [y for x, y in av_F1s.items()]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d6adf7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.235     , 0.22083333, 0.20555556, 0.25416667, 0.25      ,\n",
       "        0.18518519, 0.2       , 0.21      ],\n",
       "       [0.23437906, 0.13274675, 0.15862078, 0.23380977, 0.21535903,\n",
       "        0.19120869, 0.1347803 , 0.16465134],\n",
       "       [0.23894036, 0.23737812, 0.21634373, 0.25425044, 0.24065066,\n",
       "        0.18194563, 0.20296115, 0.24078415],\n",
       "       [0.19763584, 0.15487661, 0.16328906, 0.21788362, 0.21216442,\n",
       "        0.18070742, 0.14987056, 0.18055567]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0297f2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.reshape(4, 8).T.tofile('./last_try/results_Base128.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95646a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.tofile('./last_try/results_Base128.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39de0e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('./last_try/results_tuned128.csv', arr.reshape(4, 8).T,\n",
    "              delimiter = \",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
